# See Less, Drive Better: Generalizable End-to-End Autonomous Driving via Foundation Models Stochastic Patch Selection

**相关性评分**: 6.0/10

**排名**: #33


---


## 基本信息

- **arXiv ID**: [2601.10707v1](https://arxiv.org/abs/2601.10707v1)
- **发布时间**: 2026-01-15T18:58:33Z
- **相关性评分**: 6.0/10
- **是否相关**: 是

## 作者

Amir Mallak, Erfan Aasi, Shiva Sreeram, Tsun-Hsuan Wang, Daniela Rus, Alaa Maalouf

## 关键词

Vision-Language-Action Model, VLA for Robotics, fine tune, world model

## 一句话总结

该论文提出了一种基于基础模型的随机补丁选择方法，通过减少特征冗余来提高端到端自动驾驶策略的泛化性和效率，与视觉-语言-动作模型和机器人应用相关，但未直接涉及流匹配、扩散模型或强化学习技术。

## 摘要

Recent advances in end-to-end autonomous driving show that policies trained on patch-aligned features extracted from foundation models generalize better to Out-of-Distribution (OOD). We hypothesize that due to the self-attention mechanism, each patch feature implicitly embeds/contains information from all other patches, represented in a different way and intensity, making these descriptors highly redundant. We quantify redundancy in such (BLIP2) features via PCA and cross-patch similarity: $90$% of variance is captured by $17/64$ principal components, and strong inter-token correlations are pervasive. Training on such overlapping information leads the policy to overfit spurious correlations, hurting OOD robustness. We present Stochastic-Patch-Selection (SPS), a simple yet effective approach for learning policies that are more robust, generalizable, and efficient. For every frame, SPS randomly masks a fraction of patch descriptors, not feeding them to the policy model, while preserving the spatial layout of the remaining patches. Thus, the policy is provided with different stochastic but complete views of the (same) scene: every random subset of patches acts like a different, yet still sensible, coherent projection of the world. The policy thus bases its decisions on features that are invariant to which specific tokens survive. Extensive experiments confirm that across all OOD scenarios, our method outperforms the state of the art (SOTA), achieving a $6.2$% average improvement and up to $20.4$% in closed-loop simulations, while being $2.4\times$ faster. We conduct ablations over masking rates and patch-feature reorganization, training and evaluating 9 systems, with 8 of them surpassing prior SOTA. Finally, we show that the same learned policy transfers to a physical, real-world car without any tuning.

## 详细分析

## 论文摘要

**论文标题：** 《看得更少，开得更好：通过基础模型随机块选择实现可泛化的端到端自动驾驶》

### 1. 研究背景和动机
近年来，基于基础模型提取**块对齐特征**来训练端到端自动驾驶策略的方法，在**分布外泛化**方面展现出优越性。然而，由于视觉Transformer中的**自注意力机制**，每个图像块的特征都隐式地包含了来自其他所有块的信息，导致这些块级特征描述符之间存在**高度冗余和强相关性**。这种冗余不仅增加了计算负担，更会导致策略网络学习到虚假的相关性，从而在遇到未见过的场景（OOD）时性能下降。本文旨在解决这一关键问题。

### 2. 核心方法和技术创新
本文提出了**随机块选择**方法。其核心思想非常简单却有效：在每一帧图像处理时，**随机地屏蔽掉一部分块的特征描述符**（例如50%），再将剩余的特征（保持其原始空间布局）输入给轻量级的策略网络进行训练和推理。
- **技术创新点**：
    - **强制学习不变性**：策略网络被迫基于不同的、随机的但完整的场景“视图”进行决策，从而学习对具体哪些块被保留**不敏感**的、更鲁棒的特征。
    - **即插即用**：SPS是一个后处理步骤，无需微调基础模型，可直接与现有基于基础模型的驾驶策略框架集成。
    - **理论支撑**：通过PCA和块间相似性分析量化了特征冗余（例如，BLIP2特征90%的方差仅由17/64个主成分解释），并从**子空间保持**的角度证明了随机采样能有效保留场景语义。

### 3. 主要实验结果
在CARLA模拟器上进行了广泛的闭环驾驶测试，覆盖了季节、天气、光照和动态参与者等多种OOD场景。
- **性能提升**：SPS方法在**所有OOD场景**上平均性能提升**6.2%**，在最具挑战性的场景下提升高达**20.4%**，全面超越了之前的SOTA方法。
- **效率增益**：由于只需计算部分块的特征，推理速度提升了**2.4倍**。
- **消融实验**：训练和评估了9个不同变体（如不同屏蔽率、特征重组方式），其中8个都超越了先前SOTA，证明了方法的鲁棒性。
- **仿真到现实迁移**：将仅在仿真中训练的SPS策略**直接部署**到真实世界的自动驾驶汽车上，无需任何调优，在乡村道路和地下停车场等复杂场景中均能成功运行。

### 4. 研究意义和价值
- **实际价值**：SPS提供了一种**高效、低成本**提升自动驾驶系统OOD鲁棒性的实用方案，同时显著加快了推理速度，对现实部署极具吸引力。
- **学术贡献**：首次系统性地指出并量化了基于基础模型的块特征冗余问题，并提出了一种简单通用的解决方案。其“**少即是多**”的核心思想——通过精心引入的随机稀疏性来提升泛化能力——对更广泛的视觉-语言模型在机器人领域的应用具有启发意义。
- **可扩展性**：方法不依赖于特定基础模型（在BLIP2和DINO上均有效），且兼容文本驱动的潜在空间数据增强，为进一步提升性能打开了空间。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析

### **研究问题**
论文旨在解决**端到端自动驾驶**中一个关键挑战：基于基础模型（如BLIP2）提取的**图像块特征存在高度冗余性**，导致下游策略模型容易**过拟合虚假相关性**，从而损害其在**分布外（OOD）场景**下的泛化能力和鲁棒性。

### **核心创新点：随机块选择（SPS）**
论文提出了一个**简单、高效且即插即用**的方法：**Stochastic Patch Selection**。

1.  **核心思想**：
    -   在每一帧图像处理时，**随机丢弃（掩码）一定比例**的图像块特征描述符。
    -   **关键设计**：保留剩余块特征的**原始空间布局**（即用零向量填充被丢弃块的位置），或将它们与原始位置编码一起重组为可变长度序列。
    -   这迫使策略模型基于**不同的、随机的但完整的场景视图**进行决策，从而学习对**具体哪些特征块被保留不敏感**的、更鲁棒的表示。

2.  **技术本质**：
    -   **一种针对特征冗余的正则化技术**：通过引入随机稀疏性，打破特征间的强相关性，防止策略过拟合。
    -   **一种高效的推理加速手段**：只需计算被选中的块特征，显著减少了基础模型前向传播的计算量。

### **解决方案的论证链条**

1.  **问题诊断与量化**：
    -   **假设**：由于Vision Transformer中的自注意力机制，每个图像块的特征都隐式编码了全局信息，导致特征高度冗余。
    -   **实证验证**：
        -   **PCA分析**：BLIP2提取的64维块特征，仅需前17个主成分即可解释90%的方差，表明其本质上是**低秩**的。
        -   **相关性分析**：块特征间存在广泛的强相关性（正/负）。
        -   **相似性可视化**：一个种子块的描述符与图像中许多其他区域在特征空间高度相似，证实了“全局纠缠”。

2.  **方法实施**：
    -   **训练与推理**：对每一帧，以固定概率（如50%）随机选择一部分块，仅计算这些块的特征，然后输入策略网络。
    -   **理论支撑**（Lemma 1）：在特征矩阵低秩且行相干性有界的条件下，均匀随机采样足够多的行（块），能以高概率保留原始特征的主子空间，从而**保持场景语义**。

3.  **全面验证**：
    -   **性能提升**：在多种OOD场景（不同季节、天气、光照、动态参与者）下，SPS平均性能超越之前SOTA方法（Drive Anywhere）**6.2%**，在最具挑战性的场景下提升高达**20.4%**。
    -   **效率提升**：因只需计算部分块特征，推理速度达到SOTA的 **2.4倍**。
    -   **消融实验**：系统测试了9种变体（不同掩码率、重组策略），其中8种均超越先前SOTA，证明了方法的鲁棒性。
    -   **模拟到现实迁移**：在未经任何微调的情况下，成功将训练好的策略部署到**真实物理车辆**上，在乡村道路和地下停车场等复杂场景中完成驾驶任务。
    -   **互补性**：展示了SPS可与**文本驱动的潜在空间数据增强**结合，进一步带来1.7%的性能提升。

### **实际价值与意义**

-   **提升安全性与可靠性**：显著增强了自动驾驶系统在未见过的、极端场景下的泛化能力，这是部署安全可靠自动驾驶系统的关键。
-   **降低计算成本**：大幅减少了基于大模型的特征提取计算开销，使得在边缘设备或车载平台上部署高性能端到端自动驾驶系统更具可行性。
-   **提供新范式**：为利用基础模型进行机器人学习提供了一个重要见解——**“少即是多”**。主动引入并管理特征冗余，而非被动接受，可以成为提升泛化性和效率的有效杠杆。
-   **方法通用**：SPS不依赖于特定基础模型（论文在BLIP2和DINO上均验证有效），且无需微调基础模型，是一种轻量级、易集成的通用策略。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文针对端到端自动驾驶中，基于基础模型提取的**图像块特征高度冗余**，导致下游策略模型容易过拟合、泛化能力差的问题，提出了**随机块选择**方法。该方法在训练和推理时，对每一帧图像随机丢弃一部分图像块的特征描述符，但保留剩余块的空间布局，从而迫使策略模型学习对具体块不敏感、更具鲁棒性的特征。实验表明，该方法在多种分布外场景下，平均性能提升了6.2%，最高提升达20.4%，同时推理速度提升了2.4倍，并能实现从仿真到真实世界的零样本迁移。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文创新点分析

这篇论文《See Less, Drive Better: Generalizable End-to-End Autonomous Driving via Foundation Models Stochastic Patch Selection》在基于基础模型的端到端自动驾驶领域提出了明确的创新点，具体如下：

### 1. **首次系统性地识别并量化了基础模型（FM）提取的补丁特征中的冗余性问题**
   - **改进/不同之处**：以往工作（如Drive Anywhere [3]）直接使用FM提取的补丁对齐特征训练策略，默认这些特征是有效且独立的。本文通过**PCA分析**和**跨补丁相似性计算**，首次实证表明这些特征存在高度冗余（例如，90%的方差仅由17/64个主成分捕获），且补丁间存在强相关性。
   - **解决的问题/优势**：揭示了现有方法中未被察觉的缺陷——冗余特征会导致策略网络过拟合虚假相关性，从而损害**分布外（OOD）鲁棒性**。这为后续的改进提供了理论基础。

### 2. **提出了“随机补丁选择（SPS）”这一简单而有效的训练方法**
   - **改进/不同之处**：与以往方法（如Drive Anywhere）将**所有补丁特征**完整地输入策略网络不同，SPS在每一帧随机**屏蔽（mask）**一部分补丁描述符（如50%），仅将剩余补丁（保持其原始空间布局）输入策略。
   - **解决的问题/优势**：
     - **提升OOD泛化能力**：迫使策略基于不同的、随机的但完整的场景子视图进行决策，从而学习对特定补丁身份不变的、更鲁棒的特征。实验表明，平均OOD成功率提升**6.2%**，最高提升**20.4%**。
     - **提升计算效率**：由于只需计算部分补丁的特征，推理速度提升**2.4倍**。
     - **防止过拟合**：通过打破补丁间的冗余相关性，鼓励策略关注因果相关的、稳定的线索。

### 3. **设计了多种SPS变体并进行大规模消融实验，验证了方法的鲁棒性和灵活性**
   - **改进/不同之处**：论文不仅提出了基础的SPS，还系统性地探索了多种变体：
     - **阈值掩码（Threshold Masking）**：每个补丁以独立概率被保留。
     - **位置调整的稀疏序列（Position-adjusted Sparse Sequence）**：完全移除被丢弃的令牌，并调整位置编码。
   - **解决的问题/优势**：
     - 通过训练和评估**9个系统**，其中**8个超越了之前的SOTA**，证明了SPS核心思想的有效性和对不同实现细节的鲁棒性。
     - 明确了不同变体（如SPS、SPPS、MSPPS）在不同保留率下的性能趋势，为实际部署提供了设计指导（如SPS-50%在精度和效率间取得最佳平衡）。

### 4. **在共享视觉-语言空间内实现了无需调优的仿真到现实（Sim-to-Real）迁移**
   - **改进/不同之处**：以往基于仿真的端到端驾驶策略在迁移到真实世界时通常需要微调或域适应。本文利用FM特征固有的**多模态（视觉-语言）对齐特性**，使得在仿真中训练的SPS策略能够**直接部署**到真实物理车辆上，无需任何调整。
   - **解决的问题/优势**：解决了仿真到现实迁移的经典难题，证明了方法学到的表征具有高度的**现实世界泛化能力**。在乡村道路和地下停车场等挑战性OOD场景中成功进行了验证。

### 5. **将SPS与潜在空间文本增强相结合，进一步提升了性能**
   - **改进/不同之处**：在SPS的基础上，利用FM的文本编码器，通过**语言引导的潜在特征替换**进行数据增强（例如，将“树”的概念替换为“房子”）。
   - **解决的问题/优势**：在保留场景连贯性的同时，引入了**语义层面的多样性**，为策略提供了更丰富的训练信号。实验表明，此方法为最佳模型带来了额外的**1.7%** 性能提升。

### 6. **提供了理论分析，证明了SPS在低秩和有限相干性条件下能保留场景语义**
   - **改进/不同之处**：通过**引理1**（Lemma 1）及其证明，从矩阵采样和子空间保留的角度，形式化地论证了：当补丁描述符矩阵是低秩且行相干性有界时，均匀随机采样足够多的行（补丁）可以高概率地保留其主行空间。
   - **解决的问题/优势**：为SPS的直观有效性（“更少即更多”）提供了**坚实的数学基础**，解释了为何随机丢弃大量补丁后，策略仍能获得足够的场景语义信息，从而增强了方法的可信度。

### 总结
本文的核心创新在于**将“特征冗余”视为一个可优化的杠杆**，并提出了**SPS这一极其简单却高效的干预机制**。它**不修改或微调基础模型本身**，仅在特征提取后、策略训练前插入一个随机丢弃步骤，就同时实现了**泛化性、鲁棒性和效率**的显著提升。这种“正交且互补”的设计思路，使其能够轻松集成到现有的FM驱动自动驾驶框架中，具有很高的实用价值。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 论文实验与评估效果总结

### 一、 核心实验效果
论文提出的 **Stochastic Patch Selection (SPS)** 方法在端到端自动驾驶任务中，显著提升了模型的**泛化能力、鲁棒性和效率**。核心结论是：**通过随机丢弃冗余的补丁特征，模型被迫学习更稳健、更本质的驾驶信号，从而在分布外场景下表现更优，同时计算速度更快。**

### 二、 数据集与评价指标

#### 1. 训练数据
- **来源组合**：结合了真实世界驾驶日志和模拟器生成的数据。
- **模拟器**：使用 **VISTA 2.0** 模拟器，该模拟器基于约2小时的真实驾驶数据构建，能生成多样化的环境、光照和天气条件。
- **训练方法**：采用**引导式策略学习 (Guided Policy Learning)**，利用模拟器中的特权信号（如PID控制器、控制屏障函数CBF）来监督基于图像的控制策略。

#### 2. 评价指标
- **主要指标**：**标准化成功持续时间**。在闭环模拟中，测量车辆在触发失败条件（压线、碰撞、航向偏差>30°）前能安全行驶的时间，并在约20秒的100个episode上取平均。
- **真实世界评估**：统计**安全驾驶员干预次数**，使用与模拟器相同的失败定义。
- **效率指标**：模型推理的**加速倍数**。

### 三、 基线方法对比
论文与以下四种代表性基线方法进行了全面对比：

1.  **No-FM**：不使用基础模型，直接训练卷积模型处理原始像素的基线。
2.  **Mask-based Features (MF)**：使用通用分割模型（如SAM）分割图像，然后为每个区域提取全局特征向量。
3.  **Inherent ViT Features (I-ViT)**：直接从ViT模型的中间层提取每补丁特征。
4.  **Drive Anywhere (DA)**：**当前最先进方法 (SOTA)**。使用BLIP2基础模型，通过掩码注意力机制提取对齐的补丁级多模态特征，然后训练轻量级策略。

### 四、 关键性能提升与结论

#### 1. 分布外 (OOD) 泛化性能（核心贡献）
- **平均提升**：在所有OOD场景下，**SPS (rate=0.5) 平均性能比SOTA (DA) 提升 6.2%**。
- **最大提升**：在最困难的OOD场景下，性能**最高提升达 20.4%**。
- **全面超越**：如表1所示，SPS在所有基线方法中取得了最佳的平均性能（0.90），显著优于No-FM (0.55)、MF (0.47)、I-ViT (0.83) 和 DA (0.84)。

#### 2. 计算效率
- **显著加速**：最佳性能模型 **SPS-50% 的推理速度比 DA 快 2.4倍**。
- **可调节的效率**：通过调整保留率 (`rate`)，可以在速度与精度间权衡。例如，`SPS-30%` 可实现 **3.47倍** 的加速。

#### 3. 消融实验与变体鲁棒性
- 论文训练并评估了 **9个不同变体** 的SPS模型（涉及不同保留率、掩码策略和特征重组方式）。
- **8个变体的性能超过了之前的SOTA (DA)**，证明了该方法的鲁棒性和设计灵活性。
- **最佳配置**：`SPS-50%`（均匀随机选择50%的补丁，并用零填充剩余位置）在泛化性能上表现最佳。

#### 4. 跨骨干网络泛化
- 将SPS应用于 **DINO 骨干网络**，在7个极具挑战性的动物OOD场景中，**6个场景性能提升，1个持平，平均绝对增益为 +3.3%**。这证明了SPS不依赖于特定基础模型，具有通用性。

#### 5. 语言引导的潜在空间增强
- 在 `SPS-50%` 模型上，使用LLM引导的潜在特征替换进行微调，带来了 **额外的 +1.7% 平均性能提升**。这展示了SPS与多模态、可解释增强技术的良好兼容性。

#### 6. 仿真到现实 (Sim-to-Real) 迁移
- 将 **SPS-50%** 模型**未经任何微调**，直接部署到真实的自动驾驶汽车（Lexus RX）上。
- 在**乡村道路**和具有挑战性的**地下停车场**（低光照、无清晰车道线）场景中均成功完成了车道跟随和静态障碍物避让，验证了其强大的现实世界泛化能力。

### 五、 总结
论文通过详实的实验证明，**SPS方法通过一种简单而有效的随机补丁选择机制，有效解决了基础模型提取的补丁特征冗余问题**。这不仅没有损失信息，反而迫使驾驶策略学习更本质、更稳健的特征表示，从而在**泛化性、鲁棒性和效率三个维度上全面超越了现有最佳方法**，并成功实现了从仿真到现实世界的零样本迁移。其核心价值在于提供了一种**即插即用、无需改动基础模型**的高效优化范式。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2601.10707v1)
- [HTML 版本](https://arxiv.org/html/2601.10707v1)
