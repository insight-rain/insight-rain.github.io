# Language-Agnostic Visual Embeddings for Cross-Script Handwriting Retrieval

**相关性评分**: 6.0/10

**排名**: #32


---


## 基本信息

- **arXiv ID**: [2601.11248v1](https://arxiv.org/abs/2601.11248v1)
- **发布时间**: 2026-01-16T12:55:41Z
- **相关性评分**: 6.0/10
- **是否相关**: 是

## 作者

Fangke Chen, Tianhao Dong, Sirry Chen, Guobin Zhang, Yishu Zhang, Yining Chen

## 关键词

Lightweight Architecture, Inference Efficiency, Edge Deployment

## 一句话总结

该论文提出一种轻量级非对称双编码器框架，通过语言无关的视觉嵌入实现跨脚本手写检索，旨在提高推理效率并支持边缘部署。

## 摘要

Handwritten word retrieval is vital for digital archives but remains challenging due to large handwriting variability and cross-lingual semantic gaps. While large vision-language models offer potential solutions, their prohibitive computational costs hinder practical edge deployment. To address this, we propose a lightweight asymmetric dual-encoder framework that learns unified, style-invariant visual embeddings. By jointly optimizing instance-level alignment and class-level semantic consistency, our approach anchors visual embeddings to language-agnostic semantic prototypes, enforcing invariance across scripts and writing styles. Experiments show that our method outperforms 28 baselines and achieves state-of-the-art accuracy on within-language retrieval benchmarks. We further conduct explicit cross-lingual retrieval, where the query language differs from the target language, to validate the effectiveness of the learned cross-lingual representations. Achieving strong performance with only a fraction of the parameters required by existing models, our framework enables accurate and resource-efficient cross-script handwriting retrieval.

## 详细分析

## 论文摘要

**论文标题：** Language-Agnostic Visual Embeddings for Cross-Script Handwriting Retrieval

**作者：** Fangke Chen, Tianhao Dong, Sirry Chen, Guobin Zhang, Yishu Zhang, Yining Chen

**机构：** 浙江大学、南洋理工大学、复旦大学、上海创新研究院

---

### 1. 研究背景和动机
手写体检索是挖掘海量非结构化文档内容的关键技术，在文档分析和历史手稿挖掘中不可或缺。然而，手写体固有的风格多样性和结构不规则性带来了巨大挑战，尤其是在多语言场景下，形态学模糊性和跨语言语义鸿沟使得检索任务异常困难。现有方法主要分为两类：基于转录（OCR）的方法容易因字符误识别导致错误传播；而基于嵌入的方法虽能绕过转录，但通常缺乏深层语义理解，难以跨越不同书写系统间的巨大差异。尽管大型视觉-语言模型（VLLMs）展现了潜力，但其庞大的计算成本和推理延迟使其难以在资源受限的边缘设备上部署。因此，亟需一种既能保持语义鲁棒性，又能满足边缘计算效率需求的解决方案。

### 2. 核心方法和技术创新
本文提出了一种**轻量级非对称双编码器框架**，用于学习统一、风格不变的视觉嵌入，以实现跨文字手写体检索。其核心创新点包括：
- **非对称架构与语义锚定：** 采用一个**部分冻结**的多语言文本编码器作为稳定的语义锚点生成器，引导一个轻量级的视觉编码器将多变的手写图像映射到统一的表示空间中，有效防止语义漂移并降低模型复杂度。
- **联合优化目标：** 设计了两个互补的损失函数进行联合优化：
    - **实例级对齐损失（ℒ_ITC）：** 通过对称的InfoNCE损失，建立视觉与文本嵌入之间的稳健双向映射。
    - **语义一致性对齐损失（ℒ_INV）：** 一种标签引导的、语言无关的损失，强制**同一语义类别**（无论来自何种语言或模态）的嵌入在共享空间中聚集，从而将语义内容与语言和书写风格相关的噪声解耦。
- **边缘设备友好性：** 模型参数量小（仅1.29M），且独立于支持的语言数量，通过“合成数据预训练 → 真实数据微调”的两阶段范式，确保了在资源受限环境下的高效部署潜力。

### 3. 主要实验结果
在涵盖中文（zh）、英文（en）、西班牙文（es）的数据集上进行了全面评估：
- **同语言检索：** 在具有挑战性的**域外（OOD）** 测试集上，本方法取得了最先进的性能（Acc@1: 86.05%），显著优于包括28个基线模型在内的现有方法（如EasyOCR、Chinese CLIP、GME-Qwen2VL系列等），同时在**参数量（1.29M）和推理延迟（2.89ms）上保持了绝对优势**，实现了性能与效率的最佳平衡。
- **跨语言检索：** 在查询语言与目标语言不同的显式跨语言检索任务中，本方法取得了**平均82.80%的Acc@1**，远超其他基线，验证了所学表征真正具备了语言无关的语义不变性。
- **表征空间分析：** 通过t-SNE可视化和几何指标（R/D Ratio）分析表明，本方法学习到的嵌入空间具有更紧凑的类内聚集和更清晰的类间分离，成功桥接了不同语言的分布并抑制了风格方差。
- **消融实验：** 证实了双向对齐损失（ℒ_ITC）与语义一致性损失（ℒ_INV）的互补作用，以及两阶段训练策略对泛化到未见手写风格的关键作用。

### 4. 研究意义和价值
本研究具有重要的理论意义和实际应用价值：
- **理论贡献：** 提出了一种通过语义锚定和联合优化来学习**语言无关、风格不变**的视觉表征的新范式，为跨模态、跨语言表示学习提供了新思路。
- **实践价值：** 所提出的框架在保持与大型VLLM相媲美的检索精度的同时，**计算开销极低**。硬件感知模拟实验表明，量化后模型可实现数百倍的延迟降低和功耗节省，为在移动设备、嵌入式系统等边缘场景中实现**高效、准确的多语言手写体检索**提供了切实可行的解决方案，极大地促进了数字档案、历史文献数字化等领域的应用发展。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析

### **一、 研究问题**
论文旨在解决**跨语言手写体检索**中的核心挑战：
1.  **手写体本身的巨大变异性**：同一单词因书写风格、连笔、扭曲等导致视觉形态差异极大。
2.  **跨语言的语义鸿沟**：不同书写系统（如中文、英文、西班牙文）中，语义相同的单词在视觉上毫无相似性。
3.  **现有方法的局限性**：
    *   **基于OCR转录的方法**：对连笔手写体识别错误率高，错误会不可逆地传播，导致检索失败。
    *   **传统嵌入方法**：通常只学习视觉纹理或形态相似性，缺乏深层语义理解，难以跨越不同文字体系。
    *   **通用视觉大模型**：虽具强大语义理解能力，但参数量巨大、推理延迟高，**无法在资源受限的边缘设备上部署**。

### **二、 核心创新点**
论文提出了一种**轻量级、非对称的双编码器框架**，以学习**语言无关、风格不变的视觉嵌入**。其创新主要体现在以下三个方面：

1.  **架构创新：基于冻结语义锚点的非对称框架**
    *   **设计**：采用一个**部分冻结**的多语言文本编码器作为稳定的“语义锚点”生成器，一个轻量级的视觉编码器学习将手写图像映射到锚点附近。
    *   **优势**：
        *   **防止语义漂移**：冻结的文本编码器提供了稳定、高质量的语言无关语义原型，在低资源手写场景下能有效引导视觉编码器的学习，避免语义崩溃。
        *   **实现高效部署**：视觉分支使用轻量级CNN（如MobileNetV3），模型总参数量极小（仅1.29M），独立于支持的语言数量。

2.  **目标函数创新：联合优化实例级与类级语义一致性**
    *   **实例级对齐损失**：使用对称的InfoNCE损失，建立图像与文本锚点之间稳健的双向映射。
        *   `ℒ_V2T`：驱动视觉到语义的主要映射，迫使模型克服形态扭曲。
        *   `ℒ_T2V`：作为逆向判别正则器，防止视觉空间坍塌，增强判别力。
    *   **语义一致性对齐损失**：这是关键创新。该损失**强制相同语义类别（跨语言、跨模态）的嵌入在共享空间中聚集**。
        *   **作用**：显式地鼓励模型将**词汇语义**与**语言身份和书写风格**相关的噪声解耦，从而学习到真正的语义不变表示。

3.  **训练范式与效率创新：“合成预训练 → 真实微调”及边缘友好性**
    *   **两阶段训练**：先在合成数据上预训练建立语义拓扑骨架，再在真实手写数据上微调以学习风格细节，确保了模型的泛化能力。
    *   **边缘设备友好**：整个框架参数量少，并通过硬件感知模拟（如NeuRRAM模拟器）验证了其量化后在延迟和功耗上的巨大优势（相比FP32基线，延迟降低约297倍，功耗节省约265倍），**在性能与效率间取得了最佳平衡**。

### **三、 解决方案总结**
论文通过 **“一个轻量框架 + 两个核心损失 + 一种训练策略”** 的系统性方案，解决了跨语言手写检索的难题：

1.  **用什么架构？** 一个**非对称双编码器**，文本侧冻结以提供稳定语义，视觉侧轻量以适配边缘设备。
2.  **怎么学习表示？** 联合优化**实例级对比损失**和**类级语义一致性损失**，前者对齐模态，后者提炼语义、剥离风格与语言噪声。
3.  **怎么保证泛化与效率？** 采用 **“合成到真实”的渐进式训练**，并设计整个框架以实现**模型大小与支持语言数解耦**，最终得到一个既准确又高效的模型。

**实际价值**：该工作为在手机、历史文档扫描仪等边缘设备上实现**准确、实时、低功耗的跨语言手写文档检索**提供了切实可行的技术方案，在数字档案管理、历史文献挖掘等领域具有重要应用前景。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文旨在解决**跨语言手写体检索**中的核心挑战：即如何构建一个**语义不变**的表示空间，以克服手写风格的高度变异性和不同书写系统（如中文、英文、西班牙文）之间的巨大视觉差异。现有方法（如OCR）存在错误传播问题，而大型视觉语言模型（VLLMs）则计算成本过高，难以在资源受限的边缘设备上部署。

为此，论文提出了一个**轻量级非对称双编码器框架**。其核心创新在于：1）使用一个**部分冻结的多语言文本编码器**作为稳定的语义锚点，生成语言无关的语义原型；2）一个轻量级的视觉编码器学习将手写图像映射到该统一空间；3）通过联合优化**实例级对齐损失**和**语义一致性对齐损失**，迫使模型分离语义内容与语言、风格相关的噪声，从而学习到风格不变的视觉嵌入。

实验表明，该方法在**同语言检索**任务上超越了28个基线模型，达到了最先进的准确率；在**显式的跨语言检索**任务上也表现出色，验证了其学习到的表示具有真正的语言无关性。最重要的是，该框架仅需极少的参数量（1.29M）和极低的推理延迟，在性能与效率之间取得了最优平衡，证明了其在边缘设备上高效部署的可行性。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文创新点分析

这篇论文针对跨语言手写体检索任务，提出了一种轻量级、语言无关的视觉嵌入学习方法。其核心创新点主要体现在**架构设计**、**优化目标**和**部署效率**三个方面，具体如下：

### 1. **创新的非对称双编码器框架与“冻结语义锚点”策略**
   - **改进/不同之处**：
     - **非对称设计**：与传统的对称式双塔模型（如CLIP）不同，本文采用**非对称架构**。文本编码器（基于预训练的DistilBERT）**部分冻结**，作为稳定的“语义锚点”生成器；视觉编码器（轻量级CNN）则完全可训练，负责将多变的手写图像映射到锚点附近。
     - **锚定策略**：文本编码器的底层参数被冻结以保留基础语言知识，仅微调上层以适应手写语义域。这避免了在数据有限的场景下，文本和视觉分支同时训练可能导致的“语义漂移”。
   - **解决的问题/带来的优势**：
     - **解决语义漂移问题**：在低资源手写数据场景下，固定一个分支作为锚点，为视觉表示学习提供了稳定、高质量的语义参照，防止模型在优化过程中偏离正确的语义空间。
     - **提升跨语言对齐鲁棒性**：预训练的多语言文本编码器本身已具备跨语言语义对齐能力，以此为锚点，能更有效地引导视觉编码器学习到语言无关的表示。
     - **降低模型复杂度**：文本分支大部分参数冻结，显著减少了可训练参数量，使模型整体更轻量。

### 2. **联合优化实例级对齐与语义一致性对齐的双重目标**
   - **改进/不同之处**：
     - **双重损失函数**：论文没有仅使用常见的实例对比损失（InfoNCE），而是提出了一个**联合优化目标**：`ℒ = ℒ_ITC + λ · ℒ_INV`。
       - **`ℒ_ITC`（实例级对齐）**：包含图像到文本(`ℒ_V2T`)和文本到图像(`ℒ_T2V`)两个方向的对比损失，确保跨模态的精准匹配。
       - **`ℒ_INV`（语义一致性对齐）**：这是一个**新颖的类级损失**。它强制**同一语义ID（跨语言、跨模态）的所有样本**在嵌入空间中彼此接近，无论其来自何种语言或书写风格。
   - **解决的问题/带来的优势**：
     - **解耦语义与风格**：`ℒ_INV` 损失关键性地促使模型分离出**语义内容**与**语言特异性及书写风格**的变异。这使得模型能够聚焦于词汇的“意义”，而非其视觉形态。
     - **构建真正语言无关的表示空间**：通过将不同语言但同义的样本拉近，该目标直接针对了跨语言检索的核心挑战——**跨语言语义鸿沟**，从而构建了一个统一的、语义不变的表征空间。
     - **增强拓扑结构**：如表4所示，该方法获得了最低的 `R/D Ratio`（类内半径/类间距离），表明其学习到的嵌入空间具有更紧凑的类内聚集和更清晰的类间分离，几何结构更优。

### 3. **面向边缘设备的高效部署与“合成到真实”的训练范式**
   - **改进/不同之处**：
     - **极致的轻量化设计**：视觉主干网络采用MobileNetV3-Small，文本编码器使用轻量版DistilBERT且部分冻结，最终模型参数量仅**1.29M**，远小于所有对比的VLLM模型（通常为数B到数十B）。
     - **两阶段训练**：采用 **“合成数据预训练 → 真实手写数据微调”** 的渐进策略。合成数据快速建立语义锚点的拓扑骨架，真实数据则注入应对风格多样性的细节纹理。
   - **解决的问题/带来的优势**：
     - **解决计算成本与延迟问题**：直接回应了现有VLLM方法**参数量巨大、推理延迟高、无法在边缘设备部署**的核心痛点。如图3所示，本文方法在取得SOTA或接近SOTA性能的同时，参数量和延迟均为最低。
     - **实现高效的跨语言扩展**：模型大小与支持的语言数量**无关**。一旦训练完成，单个轻量模型即可处理多种语言的检索任务，无需为每种语言维护独立模型，极大降低了部署和维护成本。
     - **验证边缘部署可行性**：通过硬件感知模拟（如NeuRRAM CIM模拟器）和量化实验（图5），证明了模型在量化后能以极低的功耗和延迟运行，**在精度与效率间取得了卓越的平衡**，为实际边缘应用（如移动端历史文档检索）提供了可行方案。

### 总结
本文的创新是一个系统性的解决方案：**通过“冻结锚点”的非对称架构确保学习稳定性，通过“双重对齐目标”实现语义与风格的解耦以达成语言无关性，最终通过极致的轻量化设计和训练策略使高性能跨语言检索在资源受限的边缘设备上成为可能**。这三大创新点环环相扣，共同解决了传统OCR方法错误传播、传统嵌入方法缺乏语义理解、以及大型VLLM无法落地应用的系列难题。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 论文实验与评估效果分析

该论文通过一系列严谨的实验，全面验证了所提出的**轻量级非对称双编码器框架**在跨语言手写检索任务上的有效性。其实验设计、评估指标和对比分析均体现了明确的技术创新和实际应用价值。

### 一、 实验数据集
论文采用了一个**多语言手写数据集**，包含中文（zh）、英文（en）和西班牙文（es），并严格划分为两个子集以评估泛化能力：

| 数据集 | 总样本数 | 语言分布 | 风格特点 |
| :--- | :--- | :--- | :--- |
| **In-Domain (域内)** | 65,700 | 各语言21,900个样本 | 45种标准字体风格，相对规范。 |
| **Out-of-Domain (域外/OOD)** | 19,880 | 中文7,200，英文5,376，西班牙文7,304 | 超过220种手写风格，包含大量未在训练中见过的、更具挑战性的真实手写变体。 |

**训练策略**：采用“**合成数据预训练 → 真实数据微调**”的两阶段范式。预训练使用26.2万合成样本，微调使用IAM（英文）和HWDB1.0（中文）等真实手写数据集。

### 二、 评价指标
论文使用了信息检索领域的标准指标，从不同维度评估检索性能：
- **Acc@K (K=1,3,5)**：前K个检索结果中包含正确答案的查询比例。
- **MRR (平均倒数排名)**：所有查询结果中，正确答案排名的倒数的平均值，对排名敏感。
- **NES (归一化编辑相似度)**：用于评估生成式模型（如OCR）的转录准确性，基于预测文本与真实文本的Levenshtein距离计算。

### 三、 基线方法对比
论文与**三大类共28个基线方法**进行了全面对比，覆盖了主流技术路线：

1.  **两阶段OCR策略**：如EasyOCR、RapidOCR、TrOCR、DeepSeek-OCR等。这类方法先识别文字，再进行文本匹配。
2.  **端到端视觉嵌入策略**：如Chinese CLIP系列、SigLIP系列、E5-V、BGE-Visualized等。这类方法直接将图像映射到嵌入空间。
3.  **通用视觉大语言模型策略**：如Phi-3.5-Vision、Llama-3.2-Vision、MiniCPM-o、QWen3-VL、InternVL3.5等。这类模型参数巨大，语义理解能力强。

### 四、 关键性能结果与结论

#### 1. **域内/同语言检索性能**
- **结论**：在相对规范的域内集上，本文方法取得了极具竞争力的性能（Acc@1: 97.26%），与最先进的VLLMs（如QWen3-VL-4B: 97.51%）相当。
- **意义**：证明了该方法在标准场景下已具备顶级识别能力。

#### 2. **域外/同语言检索性能（核心创新点）**
- **结论**：在更具挑战性的**域外(OOD)集**上，本文方法取得了**最先进的(SOTA)性能**（Acc@1: **86.05%**），显著超越了所有基线。
- **关键对比**：
    - **大幅领先传统OCR和视觉嵌入模型**：例如，比表现较好的SigLIP 2 Giant（55.26%）和GME-Qwen2VL-7B（78.02%）有显著提升。
    - **以极小参数量媲美或超越巨型VLLMs**：例如，QWen3-VL-4B（84.44%）和InternVL3.5-8B（84.84%）性能略低或相当，但它们的参数量（4.4B/8.5B）是本文方法（**1.29M**）的数千倍。
- **效率优势**：如表2所示，本文方法的**参数量（1.29M）和推理延迟（2.89ms）均为所有对比方法中最低**，实现了**性能与效率的最佳平衡**（见图3）。

#### 3. **显式跨语言检索性能**
- **实验设置**：查询语言与目标语言不同（如用英文手写查询中文文本）。
- **结论**：本文方法展现了**压倒性的跨语言检索能力**（平均Acc@1: **82.80%**），而其他基线方法普遍表现不佳（例如，GME-Qwen2VL-7B为42.89%，Chinese CLIP ViT Huge仅为10.63%）。
- **意义**：强有力地验证了该方法学习到了真正的**语言无关的语义表示**，成功解耦了语义内容与语言特定的视觉形式（如字符形状）。

#### 4. **表征空间分析**
- **指标**：使用**R/D比率**（类内半径/类间距离）衡量嵌入空间的紧密度和可分性。
- **结论**：本文方法获得了**最低的R/D比率（0.8910）**，表明其学习的表征空间具有最优的几何结构——**同类样本高度聚集，不同类样本充分分离**（见表4，图4）。这从机理上解释了其高性能的原因。

#### 5. **消融实验与硬件仿真**
- **消融实验**（表5）：验证了各个组件的必要性。
    - 双向对比损失（`ℒ_ITC`）是建立跨模态映射的基础。
    - 语义一致性损失（`ℒ_INV`）对提升OOD泛化能力和跨语言性能至关重要。
    - “合成到真实”的训练范式带来了巨大的性能跃升。
- **硬件仿真**（图5）：对模型进行INT8量化后，在模拟的边缘计算设备上，相比FP32 GPU基线，实现了**~298倍的延迟降低和~265倍的功耗节省**，仅伴随轻微精度下降。这证明了该框架在**资源受限的边缘设备上实际部署的可行性**。

### 总结
该论文通过系统的实验证明，其提出的框架在**跨语言手写检索**任务上：
1.  **在最具挑战性的域外场景下取得了最先进的准确率**。
2.  **首次实现了高效、强大的显式跨语言检索能力**。
3.  **以极低的参数量和计算开销（1.29M, 2.89ms）达到了与数百亿参数巨型VLLM相当的性能**。
4.  **通过表征空间分析和消融实验，从原理上验证了其“学习语言无关、风格不变的语义嵌入”这一核心创新的有效性**。
5.  **通过硬件仿真证实了其适用于边缘部署的巨大潜力**。

这些定量结果共同支撑了论文的核心贡献：为**准确、高效、跨语言的边缘手写检索**提供了一个切实可行的解决方案。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2601.11248v1)
- [HTML 版本](https://arxiv.org/html/2601.11248v1)
