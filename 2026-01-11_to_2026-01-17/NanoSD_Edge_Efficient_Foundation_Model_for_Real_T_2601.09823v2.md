# NanoSD: Edge Efficient Foundation Model for Real Time Image Restoration

**相关性评分**: 6.0/10

**排名**: #35


---


## 基本信息

- **arXiv ID**: [2601.09823v2](https://arxiv.org/abs/2601.09823v2)
- **发布时间**: 2026-01-14T19:30:53Z
- **相关性评分**: 6.0/10
- **是否相关**: 是

## 作者

Subhajit Sanyal, Srinivas Soumitri Miriyala, Akshay Janardan Bankar, Manjunath Arveti, Sowmya Vajrala, Shreyas Pandith, Sravanth Kodavanti, Abhishek Ameta, Harshit, Amit Satish Unde

## 关键词

Lightweight Architecture, Inference Efficiency, Edge Deployment

## 一句话总结

NanoSD是一种通过蒸馏和架构优化实现边缘设备实时图像恢复的轻量级扩散基础模型。

## 摘要

Latent diffusion models such as Stable Diffusion 1.5 offer strong generative priors that are highly valuable for image restoration, yet their full pipelines remain too computationally heavy for deployment on edge devices. Existing lightweight variants predominantly compress the denoising U-Net or reduce the diffusion trajectory, which disrupts the underlying latent manifold and limits generalization beyond a single task. We introduce NanoSD, a family of Pareto-optimal diffusion foundation models distilled from Stable Diffusion 1.5 through network surgery, feature-wise generative distillation, and structured architectural scaling jointly applied to the U-Net and the VAE encoder-decoder. This full-pipeline co-design preserves the generative prior while producing models that occupy distinct operating points along the accuracy-latency-size frontier (e.g., 130M-315M parameters, achieving real-time inference down to 20ms on mobile-class NPUs). We show that parameter reduction alone does not correlate with hardware efficiency, and we provide an analysis revealing how architectural balance, feature routing, and latent-space preservation jointly shape true on-device latency. When used as a drop-in backbone, NanoSD enables state-of-the-art performance across image super-resolution, image deblurring, face restoration, and monocular depth estimation, outperforming prior lightweight diffusion models in both perceptual quality and practical deployability. NanoSD establishes a general-purpose diffusion foundation model family suitable for real-time visual generation and restoration on edge devices.

## 详细分析

## NanoSD：面向实时图像恢复的边缘高效基础模型

**研究背景和动机**：基于潜在扩散模型（如 Stable Diffusion 1.5）的图像恢复方法虽然能提供强大的生成先验，但其完整计算流程过于繁重，难以部署在计算资源有限的边缘设备上。现有轻量化方法主要压缩去噪U-Net或减少扩散步数，这会破坏潜在的流形结构，并限制其在单一任务之外的泛化能力。因此，亟需一种能保留生成先验、同时实现边缘实时推理的通用基础模型。

**核心方法和技术创新**：本文提出了 **NanoSD**，一个从 Stable Diffusion 1.5 蒸馏而来的帕累托最优扩散模型家族。其核心创新在于：
- **硬件感知网络重构**：将SD 1.5的U-Net分解为阶段维度，并为每个阶段设计了一组保持输入输出张量形状的、面向边缘加速器的紧凑块变体。
- **特征级生成式蒸馏**：通过特征匹配损失，将每个候选块变体与其对应的SD 1.5教师块对齐，实现了无需完整模型重训练的大规模架构探索。
- **多目标贝叶斯优化搜索**：将高效骨干网的选择建模为在教师对齐FID（taFID）、设备端延迟和参数量之间的多目标优化问题，通过贝叶斯优化获得涵盖不同精度-效率权衡的帕累托最优U-Net架构集。
- **全流程协同设计**：在选定U-Net后，进一步蒸馏VAE编码器和解码器，构建了完整的轻量级潜在扩散流水线。

**主要实验结果**：NanoSD模型家族参数量在130M至315M之间，在移动级NPU上可实现低至20ms的实时推理。实验表明，NanoSD作为即插即用的骨干网络，在图像超分辨率、去模糊、人脸恢复、单目深度估计等多种低级视觉任务上均达到了先进水平，在感知质量和实际可部署性上均优于先前的轻量级扩散模型。例如，Nano-S3Diff在超分辨率任务上取得了优异的感知质量指标（NIQE, MUSIQ），而Nano-OSDFace在人脸恢复任务上以显著降低的计算成本实现了与SOTA相当的性能。

**研究意义和价值**：NanoSD首次系统性地通过硬件感知的架构搜索与生成先验保持的蒸馏技术，实现了扩散模型在边缘设备上的实用化部署。它证明了参数量减少并不直接等同于硬件效率提升，并揭示了架构平衡、特征路由和潜在空间保持对真实设备延迟的共同影响。该工作为在资源受限平台上进行实时视觉生成与修复任务建立了一个通用、高效的扩散基础模型家族，具有重要的实际应用价值。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析：NanoSD

### **一、 论文旨在解决的核心问题**
现有基于扩散模型（如 Stable Diffusion 1.5）的图像修复方法，虽然能利用强大的生成先验获得高质量结果，但其**计算量和模型规模过大，无法在计算资源有限的边缘设备（如手机）上实现实时推理**。具体问题包括：
1.  **部署障碍**：SD 1.5 的完整流程（U-Net + VAE）参数量巨大（约8.29亿），内存占用和延迟远超移动NPU的承受能力。
2.  **现有轻量化方法的局限**：当前方法多专注于压缩去噪U-Net或减少扩散步数，这**破坏了模型固有的潜在流形结构**，导致生成先验丢失，泛化能力受限，通常只能针对单一任务（如超分）进行优化。
3.  **效率指标与真实延迟脱节**：传统的理论计算指标（如FLOPs、参数量）无法准确预测在特定边缘硬件（NPU）上的真实推理延迟，因为硬件对算子模式、张量布局和内存访问高度敏感。

### **二、 核心创新点**
NanoSD 提出了一套**系统性、硬件感知的轻量化扩散模型设计框架**，而非单一的模型压缩技术。其创新是一个多阶段的协同设计流程：

1.  **硬件感知的U-Net架构搜索空间构建**
    *   **网络手术**：基于先验分析，移除了SD 1.5 U-Net中对生成质量贡献最小但参数量大的最深层编码器-中间层-解码器（E4-Mid-D4），将搜索空间聚焦于计算和延迟更敏感的浅层和中间层。
    *   **形状保持的块变体**：为保留的每个U-Net阶段，设计了一系列**严格保持输入/输出张量形状**的硬件友好块变体（如仅残差、减少注意力模块的配置）。这确保了所有候选架构在组合时维度兼容，无需适配器。

2.  **特征级生成式蒸馏**
    *   **分而治之的蒸馏策略**：将庞大的架构搜索（32,768种组合）分解为可并行处理的**块级蒸馏**。每个候选学生块独立地向对应的SD 1.5教师块学习，使用特征匹配损失（L2）。这**在局部层面保留了SD 1.5的生成行为**，使得后续任意组合的学生块都能近似教师模型，无需对每个完整架构进行端到端重训练。

3.  **基于贝叶斯优化的帕累托最优搜索**
    *   **多目标优化**：将高效骨干网的选择建模为一个多目标优化问题，目标函数包括：**生成保真度**、**真实设备延迟**和**参数量**。
    *   **硬件对齐的评估**：使用**教师对齐FID**（与SD 1.5输出分布的距离）衡量保真度，并直接在目标边缘NPU上**实测延迟**，而非依赖FLOPs。
    *   **高效搜索**：采用贝叶斯优化和期望超体积改进（EHVI）采集函数，在庞大的离散搜索空间中高效地寻找**帕累托最优前沿**，得到一系列在精度和效率间取得不同权衡的模型（NanoSD家族）。

4.  **全流程协同轻量化**
    *   **VAE的蒸馏**：在选定最优U-Net架构后，进一步对VAE的编码器和解码器进行蒸馏，使用特征匹配和感知损失，最终得到一个**完全轻量化的潜在扩散流程**（U-Net + VAE）。
    *   **作为即插即用的基础模型**：NanoSD本身是一个**多任务基础模型**，通过集成不同的条件控制机制（如LoRA、ControlNet、特定任务插件），可以高效地适配到超分辨率、人脸修复、去模糊、去雨雪、深度估计等多种低级视觉任务，且性能接近或超越特定任务的SOTA轻量化模型。

### **三、 解决方案的流程总结**
**目标**：从SD 1.5得到一个边缘高效的扩散基础模型。
**步骤**：
1.  **分解与设计**：对SD 1.5 U-Net进行硬件感知分解，构建形状保持的块变体搜索空间。
2.  **蒸馏与对齐**：对每个块变体进行特征级生成式蒸馏，使其输出与教师块对齐。
3.  **搜索与选择**：使用贝叶斯优化，以taFID和实测延迟/参数量为目标，搜索帕累托最优的U-Net架构组合，形成NanoSD模型家族，并从中选择平衡点（NanoSD-Prime）。
4.  **扩展与适配**：蒸馏对应的轻量化VAE，完成全流程压缩。将得到的NanoSD作为骨干，通过集成现有任务框架（如OSEDiff, S3Diff, Diff-Plugin, OSDFace, Marigold）的条件机制，快速适配到各类图像修复和生成任务。

### **四、 实际价值与意义**
*   **实现了边缘设备上的实时扩散模型推理**：NanoSD模型参数量在1.3亿至3.15亿之间，在移动NPU上处理128x128图块至512x512输出的延迟可低至**12-41毫秒**，使4K图像修复的端到端延迟达到约1.8秒，具备实际部署可行性。
*   **打破了“参数量/FLOPs降低等于延迟降低”的误区**：论文通过详实的硬件分析表明，**架构平衡、特征路由和潜在空间保持**共同决定了真实延迟，为边缘AI模型设计提供了重要见解。
*   **提供了一个通用的、高性能的扩散基础模型**：NanoSD保留了SD 1.5丰富的生成先验，同时具备模块化和高效率的特点，可作为多种边缘端视觉任务的强大即插即用骨干，推动了生成式AI在终端设备的落地。

**核心贡献一句话总结**：NanoSD通过**硬件感知的架构搜索空间设计**、**块级生成式蒸馏**和**多目标帕累托优化**，协同压缩了扩散模型的U-Net和VAE，在保持强大生成先验的同时，首次实现了扩散模型在边缘设备上的实时、多任务图像修复。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文旨在解决**预训练大扩散模型（如Stable Diffusion 1.5）因计算量和内存占用巨大而无法在边缘设备上实时部署**的核心问题。为此，作者提出了 **NanoSD**，一个通过**硬件感知的架构协同设计**方法得到的边缘高效扩散基础模型家族。该方法的核心是：1）对SD 1.5的U-Net进行**硬件感知分解**，构建一个保留张量形状的块级搜索空间；2）采用**特征级生成式蒸馏**，独立训练每个候选块以保留教师模型的生成先验；3）利用**多目标贝叶斯优化**在真实延迟、参数量和生成保真度（taFID）构成的帕累托前沿上搜索最优架构。最终，NanoSD在**大幅降低模型规模（130M-315M参数）和推理延迟（在移动NPU上最快达12ms）的同时，成功保留了原始SD 1.5的强生成先验**。实验表明，其作为即插即用的骨干网络，在超分辨率、人脸修复、去模糊、深度估计等多种底层视觉任务上达到了与SOTA方法相当的性能，首次实现了扩散模型在边缘设备上的实时高质量图像恢复。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## NanoSD论文创新点分析

这篇论文提出了一种面向边缘设备的、高效的扩散模型基础架构NanoSD，其核心创新在于**系统性、硬件感知的模型压缩与架构搜索方法**，旨在解决现有轻量化扩散模型在保持生成先验、任务通用性和实际部署效率方面的不足。以下是其明确的创新点及对比分析：

---

### 1. **硬件感知的U-Net架构分解与搜索空间构建**
- **改进/不同之处**：
    - **以往方法**：多数轻量化工作（如SnapFusion、MobileDiff）采用全局的、计算量导向的压缩（如剪枝、减少注意力头、替换卷积），或仅针对单一任务（如超分）进行优化。它们通常依赖FLOPs或参数量作为效率代理指标，但这些指标与边缘设备上的**真实延迟**关联性弱。
    - **NanoSD的做法**：对SD 1.5的U-Net进行**阶段式分解**，移除了对生成质量贡献低但参数量大的最深编码器-中间层-解码器（E4-Mid-D4）。为剩余的每个阶段（共6个）设计了一系列**形状保持的硬件友好型块变体**（如仅残差、减少注意力等），并直接在目标NPU上**实测每个变体的延迟**，构建了一个包含32,768种架构的、**延迟感知的离散搜索空间**。
- **解决的问题/优势**：
    - **解决了**：理论计算指标（FLOPs）与实际硬件延迟脱节的问题，以及盲目压缩可能破坏模型结构兼容性的问题。
    - **优势**：确保了搜索空间中的每个候选架构在张量形状上完全兼容，可直接组装，且其效率评估基于真实硬件性能，为后续优化提供了可靠基础。

### 2. **特征级生成式蒸馏与模块化训练**
- **改进/不同之处**：
    - **以往方法**：常见的知识蒸馏需要为每个待评估的学生模型进行端到端训练，计算成本极高，难以支撑大规模架构搜索。一些方法采用输出层或特征图匹配，但通常在完整模型层面进行。
    - **NanoSD的做法**：提出**特征级生成式蒸馏**。将SD 1.5教师模型的每个U-Net块与其对应的学生块变体**独立进行蒸馏**，使用L2特征匹配损失。这使得30个候选块可以**并行、一次性**完成训练，后续通过组合这些预蒸馏的“代理块”来快速组装任何候选U-Net，无需重新训练。
- **解决的问题/优势**：
    - **解决了**：大规模架构搜索中，为每个候选模型进行完整训练带来的计算不可行性问题。
    - **优势**：实现了**搜索与训练的分离**。块级蒸馏保留了教师模型局部的生成行为，使得组装出的任何U-Net都能近似SD 1.5的先验，从而可以快速、低成本地评估数万种架构的生成质量（通过taFID）。

### 3. **基于贝叶斯优化的多目标帕累托搜索**
- **改进/不同之处**：
    - **以往方法**：轻量化模型设计往往依赖人工设计或简单的网格搜索，难以在生成质量（FID）、延迟、参数量等多个竞争目标间找到最优平衡点。
    - **NanoSD的做法**：将高效骨干网选择形式化为一个**双目标优化问题**（taFID vs. 延迟；taFID vs. 参数量）。采用**贝叶斯优化**与**期望超体积改进**采集函数，在连续的松弛空间中进行高效搜索，并将结果映射回离散的架构空间。
- **解决的问题/优势**：
    - **解决了**：在庞大的设计空间中，手动或穷举搜索效率低下，难以找到帕累托最优解的问题。
    - **优势**：自动化地找到了一系列**帕累托最优的架构**（NanoSD家族，7个模型），覆盖了从极致延迟（12ms）到极致参数量（130M）的不同权衡点。这提供了灵活的部署选项，并能清晰展示现有基线（如TinySD）在帕累托前沿之外的劣势。

### 4. **全流程协同设计：U-Net与VAE的联合轻量化**
- **改进/不同之处**：
    - **以往方法**：大多数边缘高效的扩散模型仅压缩去噪U-Net，或简单量化VAE，忽略了VAE编码器/解码器也是计算和内存瓶颈。一些工作（如AdcSR）会剪枝VAE，但通常是独立进行的。
    - **NanoSD的做法**：在选定帕累托最优的U-Net骨干（NanoSD-Prime）后，**同步蒸馏VAE的编码器和解码器**。使用特征匹配、感知损失和KL散度正则化等多种损失，确保轻量化VAE与轻量化U-Net在潜在空间上对齐。最后进行端到端的对齐微调。
- **解决的问题/优势**：
    - **解决了**：仅压缩U-Net而保留庞大VAE导致的“木桶效应”，整体管道无法真正在边缘部署的问题。
    - **优势**：实现了**从潜空间到像素空间的完整轻量化管道**。这是实现**实时推理**（低至20ms/图块）和**小内存占用**的关键，使得整个扩散模型能真正部署在移动NPU上。

### 5. **作为通用基础模型的验证与即插即用能力**
- **改进/不同之处**：
    - **以往方法**：现有的边缘高效扩散模型大多为**单一任务**（特别是超分辨率）设计，缺乏作为通用视觉先验的灵活性，难以适配其他条件控制机制（如ControlNet、LoRA）。
    - **NanoSD的做法**：将NanoSD作为**即插即用的基础骨干**，成功集成到多个先进的图像恢复框架中，包括：
        - **Nano-OSEDiff / Nano-S3Diff**：用于单图像超分。
        - **Nano-OSDFace**：用于人脸恢复。
        - **Nano-Diff-Plugin / Nano-DiffBIR**：用于通用图像恢复（去模糊、去雾等）。
        - **Nano-Marigold**：用于单目深度估计。
- **解决的问题/优势**：
    - **解决了**：轻量化模型任务泛化能力差、无法利用现有高级条件控制插件的问题。
    - **优势**：证明了NanoSD**保留了强大的生成先验和模块化兼容性**。它不仅能作为文本到图像的基础模型，更能作为多任务低层视觉的通用高效骨干，在保持与SOTA方法相当性能的同时，大幅降低了计算成本和延迟，实现了 **“一次压缩，多处可用”** 的实际价值。

---

### **总结：核心创新价值**
NanoSD的创新不是单一的算法改进，而是一个**系统性的协同设计框架**。它通过**硬件感知的架构空间定义**、**可扩展的模块化蒸馏**、**数据驱动的帕累托搜索**和**全流程轻量化**，解决了将大型扩散模型实用化部署到边缘设备的核心矛盾：**生成质量、计算效率与任务通用性之间的权衡**。其最终产出的模型家族在多项任务上达到了SOTA的效能比，为在手机等设备上实现实时、高质量的生成式图像修复提供了可行的技术路径。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 实验与评估效果总结

论文通过广泛的实验验证了NanoSD在多个低层视觉任务上的有效性、高效性和泛化能力，最终实现了**在移动端NPU上达到实时推理（最快20ms）的同时，保持了与原始Stable Diffusion 1.5相当的生成先验和图像恢复质量**。

### 一、 使用的数据集
实验覆盖了7类低层视觉任务，使用了对应的合成与真实世界基准数据集：

1.  **图像超分辨率 (SR)**:
    *   **训练**: LSDIR, FFHQ (前10K张人脸)
    *   **测试**: DIV2K-Val, RealSR, DRealSR
2.  **人脸修复 (Face Restoration)**:
    *   **训练/测试**: FFHQ, CelebA-Test (合成), Wider-Test, LFW-Test, WebPhoto-Test (真实)
3.  **图像去模糊 (Deblurring)**:
    *   **训练**: GoPro
    *   **测试**: RealBlur-J
4.  **图像去雾 (Dehazing)**:
    *   **训练**: RESIDE
    *   **测试**: RTTS
5.  **图像去雨 (Deraining)**:
    *   **训练**: 合并训练集
    *   **测试**: 真实测试集
6.  **图像去雪 (Desnowing)**:
    *   **训练**: Snow100K
    *   **测试**: 真实测试集
7.  **单目深度估计 (Monocular Depth Estimation)**:
    *   **训练**: Hypersim, Virtual KITTI
    *   **测试**: NYUv2, KITTI

### 二、 使用的评价指标
采用了全面的全参考和无参考指标，以进行综合评估：

*   **保真度指标**: PSNR, SSIM (在YCbCr的Y通道计算)
*   **感知质量指标**: LPIPS, DISTS
*   **分布相似性指标**: FID (与Ground Truth或SD1.5教师模型输出比较)
*   **无参考图像质量指标**: NIQE, MUSIQ
*   **深度估计专用指标**: 平均绝对相对误差 (AbsRel), δ1准确度
*   **效率指标**: 参数量 (M), 乘加运算量 (GMACs), **在设备实测延迟 (ms)** (在Qualcomm NPU和Apple Neural Engine上测量)
*   **先验保持指标**: 教师对齐FID (taFID), 潜空间插值平滑性, CLIP嵌入相似度

### 三、 对比的基线方法
论文与当前最先进的轻量化和非轻量化方法进行了全面对比：

1.  **轻量化超分辨率方法**: Edge-SD-SR, AdcSR, TinySR, PocketSR
2.  **非轻量化/高性能超分辨率方法**: StableSR, DiffBIR, SeeSR, ResShift, SinSR, OSEDiff, S3Diff
3.  **人脸修复方法**: PGDiff, DifFace, DiffBIR, OSDFace
4.  **通用图像恢复方法 (作为插件框架)**: SD 1.5, InstructPix2Pix, Null-Text, ControlNet, Diff-Plugin
5.  **深度估计方法**: MiDAS, LeRes, Omnidata, HDN, DPT, Marigold
6.  **轻量化扩散模型基线**: Segmind TinySD, 手工调整的SD 1.5基线

### 四、 关键性能提升与结论

#### 1. **核心效率与帕累托最优性**
*   **参数量**: NanoSD家族模型参数量在 **130M 到 315M** 之间，远小于SD 1.5 (860M+) 和其他大型扩散模型。
*   **推理延迟**: 在Qualcomm NPU上，处理128x128输入块的延迟最低可达 **12ms** (NanoSD 5)，选定的平衡模型NanoSD-Prime (Model 2) 延迟为 **27ms**，实现了**实时推理**。
*   **帕累托前沿**: 通过贝叶斯优化得到的7个NanoSD变体构成了**帕累托最优前沿**，在taFID（质量）与延迟/参数量（效率）的权衡上全面优于手工调整的基线和Segmind TinySD（见图2e, 2f）。

#### 2. **下游任务性能**
论文将NanoSD作为骨干网络，嵌入到不同的先进框架中，在保持高效的同时取得了有竞争力的性能：

*   **超分辨率 (Nano-OSEDiff / Nano-S3Diff)**:
    *   在DIV2K-Val上，Nano-OSEDiff取得了**最好的PSNR (24.29) 和 SSIM (0.628)**。
    *   Nano-S3Diff取得了**最好的无参考指标NIQE (4.09) 和 MUSIQ (70.44)**，以及**第二好的FID (22.34)**。
    *   两者的计算量 (MACs: 285G-340G) 远低于原版OSEDiff (2265G) 和 S3Diff (2621G)，与最轻量的方法（如PocketSR: 225G）相当。

*   **人脸修复 (Nano-OSDFace)**:
    *   在CelebA-Test上，其感知质量指标 (LPIPS, DISTS, NIQE, MUSIQ) 与最先进的OSDFace**几乎持平**。
    *   计算量 (**479 GMACs**) 和参数量 (**415M**) 远低于原版OSDFace (2465 GMACs, 1887M)。

*   **通用图像恢复 (Nano-Diff-Plugin)**:
    *   在去雾、去雨、去雪、去模糊四个任务上，其FID、KID等指标与原始Diff-Plugin**结果相近**。
    *   模型大小 (**712M**) 和计算量 (**17120 GMACs/20步**) 显著低于原版Diff-Plugin (1256M, 30400 GMACs)。

*   **深度估计 (Nano-Marigold)**:
    *   在NYUv2和KITTI数据集上，其性能优于传统方法 (MiDAS, LeRes)，与轻量级SOTA方法 (如DPT, HDN) **具有可比性**，但显著轻于原版Marigold。

#### 3. **生成先验的有效保持**
*   **定量证据**: NanoSD与SD 1.5输出之间的CLIP嵌入相似度 (0.84) 远高于回归U-Net基线 (0.41)，且LPIPS距离接近SD 1.5自身两次生成的差异（见表6）。
*   **定性证据**: 潜空间插值显示，NanoSD保持了与SD 1.5同样平滑、语义连贯的过渡，证明其**潜流形结构得以保留**（见图8）。

#### 4. **硬件效率与泛化性**
*   **参数量与延迟脱钩**: 实验证明，单纯减少参数量并不能保证延迟降低。论文通过**硬件感知的块级剖析**，直接优化在目标NPU上的实测延迟。
*   **跨平台泛化**: 在Qualcomm NPU上搜索得到的NanoSD模型，**未经修改**在Apple A17 Pro Neural Engine上仍保持一致的效率排序趋势，证明了方法对异构硬件的泛化能力（见表8）。

### 总结结论
NanoSD通过**硬件感知的网络手术、特征级生成式蒸馏和多目标贝叶斯优化**，成功地从SD 1.5中蒸馏出一个**帕累托最优的扩散基础模型家族**。该模型在**大幅降低计算成本和内存占用（参数量减少60%-85%，延迟降低至20-40ms级）** 的同时，**有效保留了原始模型的强大生成先验**，从而能够在移动端NPU上实现实时的高质量图像恢复与生成，并在超分辨率、人脸修复、去模糊、深度估计等多个任务上达到或接近当前最先进轻量化方法的性能。这项工作为将强大的生成式先验部署到资源受限的边缘设备提供了可行的技术路径。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2601.09823v2)
- [HTML 版本](https://arxiv.org/html/2601.09823v2)
