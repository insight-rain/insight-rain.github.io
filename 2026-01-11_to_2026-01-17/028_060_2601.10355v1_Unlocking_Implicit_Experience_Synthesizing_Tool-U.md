# Unlocking Implicit Experience: Synthesizing Tool-Use Trajectories from Text

**相关性评分**: 6.0/10

**排名**: #28


---


## 基本信息

- **arXiv ID**: [2601.10355v1](https://arxiv.org/abs/2601.10355v1)
- **发布时间**: 2026-01-15T12:58:46Z
- **相关性评分**: 6.0/10
- **是否相关**: 是

## 作者

Zhihao Xu, Rumei Li, Jiahuan Li, Rongxiang Weng, Jingang Wang, Xunliang Cai, Xiting Wang

## 关键词

Inference Efficiency, Lightweight Architecture, Inference Acceleration

## 一句话总结

这篇论文提出了一种从文本中合成多轮工具使用轨迹的数据生成方法，通过训练专门的轨迹合成器来提高推理效率，但与视觉-语言-动作模型和机器人应用的相关性较弱。

## 摘要

Enabling Large Language Models (LLMs) to effectively utilize tools in multi-turn interactions is essential for building capable autonomous agents. However, acquiring diverse and realistic multi-turn tool-use data remains a significant challenge. In this work, we propose a novel text-based paradigm. We observe that textual corpora naturally contain rich, multi-step problem-solving experiences, which can serve as an untapped, scalable, and authentic data source for multi-turn tool-use tasks. Based on this insight, we introduce GEM, a data synthesis pipeline that enables the generation and extraction of multi-turn tool-use trajectories from text corpora through a four-stage process: relevance filtering, workflow & tool extraction, trajectory grounding, and complexity refinement. To reduce the computational cost, we further train a specialized Trajectory Synthesizer via supervised fine-tuning. This model distills the complex generation pipeline into an efficient, end-to-end trajectory generator. Experiments demonstrate that our GEM-32B achieve a 16.5% improvement on the BFCL V3 Multi-turn benchmark. Our models partially surpass the performance of models trained on τ - bench (Airline and Retail) in-domain data, highlighting the superior generalization capability derived from our text-based synthesis paradigm. Notably, our Trajectory Synthesizer matches the quality of the full pipeline while significantly reducing inference latency and costs.

## 详细分析

## 论文摘要：《解锁隐性经验：从文本合成工具使用轨迹》

### 1. 研究背景和动机
构建能够有效利用工具完成多轮交互的自主智能体是实现通用人工智能（AGI）的关键。然而，获取高质量、多样化且真实的多轮工具使用数据是当前的主要瓶颈。现有方法通常依赖于**预定义的工具集**进行模拟和合成，这不仅成本高昂，且生成的数据多样性和真实性受限，难以支撑智能体在开放世界中的泛化能力。本文提出一个根本性问题：能否绕过对预定义工具的依赖，直接从真实世界的文本中合成高质量的工具使用轨迹？

### 2. 核心方法和技术创新
本文提出了一个全新的 **“文本到轨迹”** 数据合成范式。其核心洞察是：用于预训练大语言模型的大规模文本语料库中，天然蕴含着丰富的、多步骤的人类问题解决经验（如“医院报销流程”），这些可以被提取并转化为多轮工具使用数据。

基于此，作者提出了 **GEM** 数据合成流水线，包含四个阶段：
- **文本筛选**：识别包含多步骤操作流程的文本片段。
- **工作流与工具提取**：从文本中提取结构化的工作流，并设计相应的API工具定义。
- **轨迹生成**：利用强大的教师模型（如GLM-4.6），将文本、抽象工作流和工具集一次性合成为具体的多轮用户-智能体交互轨迹。
- **复杂性精炼**：通过增加工具多样性、提升用户请求的模糊性和复杂性等方式，增强轨迹的难度和质量。

为降低合成成本，作者进一步通过监督微调训练了一个**专用的轨迹合成器模型**，将复杂的多阶段流水线蒸馏为一个高效的端到端生成器。

### 3. 主要实验结果
- **性能提升显著**：使用GEM合成的数据微调的模型在**BFCL V3多轮基准测试**上取得了显著提升。其中，Qwen3-32B-GEM模型达到了44.88%的总体准确率，相比基础模型提升了16.5%，甚至超越了GPT-4.1等闭源大模型。
- **强大的泛化能力**：在**τ²-bench**（航空和零售领域）测试中，尽管GEM的训练数据是**领域外**的，但其性能与使用领域内数据（如APIGEN-MT、Simia）训练的模型相当甚至更优，证明了文本范式带来的卓越泛化能力。
- **合成器高效可靠**：训练的轨迹合成器模型在生成质量上媲美完整的GEM流水线，同时**显著降低了推理延迟和成本**。
- **数据质量分析**：合成的轨迹平均包含8.6个不同工具、46轮对话和16.3次工具调用，其复杂度和交互深度远超现有开源数据集。

### 4. 研究意义和价值
本研究具有重要的理论和实践价值：
- **范式创新**：首次提出并验证了直接从无结构文本中提取工具使用轨迹的可行性，为智能体训练数据合成开辟了一个**全新、可扩展且真实的来源**。
- **解决数据瓶颈**：有效缓解了高质量多轮工具使用数据稀缺的问题，利用海量文本中蕴含的“隐性经验”，生成了多样化、高质量的训练数据。
- **推动智能体发展**：实验证明，基于此范式合成的数据能显著提升模型在复杂、真实场景下的工具调用和推理能力，为构建更强大、更通用的自主智能体提供了关键支持。
- **降本增效**：提出的专用轨迹合成器模型实现了低成本、大规模的高质量数据生成，具有很高的实用价值。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析

### **核心问题**
当前训练能够**有效使用工具**的自主智能体（AI Agent）面临一个关键瓶颈：**缺乏高质量、多样化、真实的多轮次工具使用轨迹数据**。现有方法主要依赖**预定义的工具集**来模拟生成数据，这导致数据多样性受限、成本高昂，且难以覆盖真实世界的复杂场景。

### **核心创新点**
本文提出了一个**范式转变**：从“**基于预定义工具模拟数据**”转向“**从文本语料库中直接提取工具使用轨迹**”。

1.  **新范式（Text to Trajectory）**：
    - **洞察**：发现用于预训练大语言模型（LLM）的原始文本语料库（如网页文档、教程）中，天然蕴含了大量**多步骤问题解决的经验**（例如“医院报销流程”、“照片编辑步骤”）。这些文本虽未明确描述AI代理行为，但包含了构建工具使用轨迹所需的三个核心要素：**用户查询、环境工具描述、多步骤工作流**。
    - **价值**：解锁了一个**未被开发、可扩展、真实**的代理训练数据源，其多样性和真实性远超基于有限API集模拟的数据。

2.  **具体实现：GEM 数据合成管道**：
    为了实践这一范式，作者设计了 **GEM**（一个四阶段管道），将原始文本转化为结构化的多轮工具使用轨迹：
    - **阶段1：文本筛选** - 识别包含多步骤操作描述的文本片段。
    - **阶段2：工作流与工具提取** - 从文本中提取结构化的抽象工作流，并据此设计符合OpenAI格式的API工具定义。
    - **阶段3：轨迹生成** - 使用强教师模型（如GLM-4.6），结合文本、工作流和工具定义，一次性生成完整的多轮对话轨迹（包括系统提示、用户请求、助手响应/工具调用、工具观察结果）。
    - **阶段4：精炼与验证** - **（关键步骤）** 增加轨迹的复杂性（如更多工具、更模糊的用户请求、更长的上下文）和真实性，并通过**规则检查+LLM评判**严格过滤掉存在幻觉或错误的轨迹。

3.  **效率优化：轨迹合成器**：
    - **问题**：上述多阶段管道计算成本高。
    - **解决方案**：使用GEM生成的高质量数据，通过监督微调（SFT）训练一个专门的 **“轨迹合成器”** 模型。
    - **效果**：该模型学会了从文本到轨迹的端到端映射，**在保持合成质量的同时，显著降低了推理延迟和成本**，实现了大规模、低成本的数据生成。

### **解决方案总结**
论文通过 **“洞察文本价值 -> 设计提取管道（GEM） -> 优化生成效率（合成器）”** 的三步走策略，系统性地解决了高质量多轮工具使用数据稀缺的问题：
1.  **源头创新**：将数据来源从有限的模拟环境转向无限的、真实的文本世界。
2.  **方法保证**：通过严谨的多阶段管道确保从文本中提取的轨迹兼具**真实性、复杂性和正确性**。
3.  **工程落地**：训练专用模型降低生成成本，使该范式具备实际应用和推广的可行性。

### **实际价值**
- **对于AI Agent开发**：提供了一种获取**大规模、高质量、跨领域**训练数据的新途径，有望显著提升智能体在复杂、真实场景中的工具使用和泛化能力。
- **对于学术研究**：开辟了“**从文本中挖掘隐式经验**”这一新的研究方向，为数据合成和智能体训练提供了新思路。
- **实验结果佐证**：使用GEM数据微调的模型（如Qwen3-32B-GEM）在BFCL V3多轮基准上取得了**16.5%** 的性能提升，甚至在部分任务上**超越了使用领域内数据训练的模型**，证明了其强大的泛化能力。轨迹合成器也达到了与完整管道相近的数据质量。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文旨在解决训练自主智能体时**高质量、多轮次工具使用数据稀缺**的核心瓶颈。为此，作者提出了一种创新的 **“文本到轨迹”范式**，直接从大规模文本语料库中提取和合成多轮工具使用轨迹，绕过了传统方法对预定义工具集的依赖。其核心方法是开发了一个名为 **GEM 的四阶段数据合成管道**（文本过滤、工作流与工具提取、轨迹生成、复杂性精炼），并进一步训练了一个高效的端到端轨迹合成器模型。实验表明，使用该方法合成的数据微调后的模型，在 BFCL V3 和 τ²-bench 等多个基准测试上取得了显著性能提升（例如，Qwen3-32B-GEM 在 BFCL V3 上整体准确率提升 16.5%），其泛化能力甚至能媲美使用领域内数据训练的模型，证明了该范式的有效性和可扩展性。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文创新点分析

这篇论文《Unlocking Implicit Experience: Synthesizing Tool-Use Trajectories from Text》提出了一种从文本中合成多轮工具使用轨迹的新范式，其核心创新点如下：

### 1. **范式创新：从“工具中心”到“文本中心”的数据合成范式**
- **相比以往方法的改进/不同之处**：
    - **以往方法（工具中心范式）**：如APIGen-MT、ToolACE等，依赖于**预定义的工具/API集合**来生成用户任务并模拟交互。数据合成的多样性和真实性受限于预定义工具集的覆盖范围。
    - **本文方法（文本中心范式）**：直接从**大规模、非结构化的文本语料库**（如Ultra-fineweb）中提取和合成多轮工具使用轨迹。不依赖于任何预定义的工具集。
- **解决的具体问题/带来的优势**：
    - **解决数据稀缺与多样性瓶颈**：预定义工具集难以覆盖真实世界中所有场景，导致训练数据多样性不足。文本语料库天然包含跨领域的、真实的人类问题解决经验，提供了一个**可扩展、多样化且真实**的数据源。
    - **提升智能体泛化能力**：从文本中提取的“隐式经验”覆盖了更广泛的场景和逻辑，使训练出的智能体在面对未见过的环境和任务时，具备更强的**泛化能力**。实验表明，使用本文方法合成的**领域外数据**，其性能可媲美甚至超越使用**领域内数据**训练的基线模型。

### 2. **方法创新：GEM四阶段数据合成流水线**
- **相比以往方法的改进/不同之处**：
    - **以往方法**：数据合成流程通常围绕预定义API进行任务蓝图设计和对话模拟，流程相对单一。
    - **本文方法**：提出了一个系统化的四阶段流水线（GEM）：
        1.  **相关性过滤**：筛选包含多步骤操作描述的文本。
        2.  **工作流与工具提取**：从文本中解析出结构化的工作流，并**反向设计**出支持该工作流的工具集（符合OpenAI格式）。
        3.  **轨迹生成**：使用强教师模型（如GLM-4.6），基于文本、抽象工作流和工具集，**单次生成**完整的多轮交互轨迹（包含系统提示、用户查询、助手响应、工具调用及结果）。
        4.  **复杂性精炼与验证**：对初始轨迹进行增强（增加工具多样性、请求模糊性、错误恢复等），并通过**规则检查+LLM评判**严格过滤幻觉和不一致数据。
- **解决的具体问题/带来的优势**：
    - **确保数据质量与真实性**：**精炼阶段**显著提升了轨迹的复杂性和挑战性（实验表明，精炼后轨迹的平均消息数、工具数、工具调用数大幅增加），使模型能学习处理更真实的复杂交互。**严格的验证机制**有效减少了数据中的幻觉，保证了合成数据的可靠性。
    - **实现从“描述”到“可执行交互”的转化**：该流水线成功地将文本中隐含的**过程性知识**，转化为了包含具体工具调用、参数传递和环境反馈的**可执行智能体轨迹**，为训练提供了高质量的监督信号。

### 3. **效率创新：端到端的轨迹合成器**
- **相比以往方法的改进/不同之处**：
    - **以往方法**：依赖复杂的多阶段流水线（如GEM本身）生成数据，每次生成都需要调用多个大型模型，**计算成本高、延迟大**。
    - **本文方法**：利用GEM流水线生成的高质量数据，**监督微调**出一个专门的**轨迹合成器模型**。该模型学习“文本→轨迹”的端到端映射，能够直接接收文本输入并输出完整的工具定义和多轮轨迹。
- **解决的具体问题/带来的优势**：
    - **大幅降低数据合成成本与延迟**：轨迹合成器**蒸馏**了完整的GEM流水线能力，实现了高效、低成本的大规模数据生成。实验表明，其生成的数据质量与原始多阶段流水线相当，但推理成本显著降低。
    - **增强方法的实用性与可扩展性**：这使得从海量文本中持续、经济地合成训练数据成为可能，为持续改进智能体能力提供了可持续的数据供给方案。

### 总结
本文的核心贡献在于**转变了数据合成的源头和范式**。通过挖掘文本中蕴含的丰富“隐式经验”，并设计系统化的提取、生成、精炼流程，成功解决了多轮工具使用数据**稀缺、多样性不足、真实性有限**的关键瓶颈。最终，通过训练一个高效的轨迹合成器，进一步将这一范式**产品化、低成本化**，为训练具备强大泛化能力的自主智能体提供了新的、可扩展的路径。实验在BFCL V3和τ²-bench等权威基准上的显著性能提升，验证了该范式的有效性和优越性。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 实验效果总结

该论文通过提出的 **GEM 数据合成范式** 和 **Trajectory Synthesizer 模型**，在多个基准测试上显著提升了大型语言模型（LLM）的多轮工具使用能力。实验表明，从文本语料库中提取的“隐式经验”能够生成高质量、多样化的训练数据，有效解决多轮工具使用数据稀缺的瓶颈。

### 1. 使用的数据集与评价指标

#### **数据集**
*   **训练数据源**：
    *   **Ultra-fineweb**： 作为主要文本语料库，用于 GEM 管道合成轨迹。
    *   **Wikihow**： 用于验证 Trajectory Synthesizer 模型的泛化能力。
*   **合成数据**： 使用 GEM 管道（基于 GLM-4.6）从 Ultra-fineweb 生成了 **10K** 条多轮工具使用轨迹，用于监督微调（SFT）。

#### **评价基准与指标**
1.  **BFCL V3 Multi-turn Benchmark**：
    *   **评估内容**： 在基于 Python API 的环境中评估多轮工具调用能力。
    *   **子任务**： Multi Turn Base, Miss Func, Miss Param, Long Context（各200个任务）。
    *   **核心指标**： **总体准确率 (Overall Accuracy)**。

2.  **τ²-bench (Airline and Retail)**：
    *   **评估内容**： 在特定领域（航空、零售）评估用户-智能体交互的全面性。
    *   **核心指标**：
        *   **Avg@4**： 平均成功率。
        *   **Pass@4**： 任务通过率。

### 2. 对比的基线方法

论文与以下开源合成数据集训练的模型进行了对比：
*   **APIGEN-MT**： 基于预定义API生成的多轮对话数据。
*   **TOUCAN**： 从真实MCP服务器爬取并合成的工具使用数据。
*   **MUA**： 基于多轮用户交互智能体强化学习的数据。
*   **Simia-Tau**： 在 τ-bench 环境内生成的领域内数据（仅用于 τ²-bench 对比）。
*   **专有/大规模模型**： 作为性能上限参考，包括 **GPT-4.1**, **DeepSeek-V3.2-Exp**, **Gemini-2.5-Flash**。

### 3. 关键性能提升与结论

#### **BFCL V3 基准测试结果**
*   **显著提升**： 使用 GEM 合成数据微调的模型在 **32B** 和 **8B** 规模上均取得最佳性能。
    *   **Qwen3-32B-GEM** 达到 **44.88%** 的总体准确率，相比基础模型 (**28.35%**) 绝对提升 **16.53%**。
    *   该性能甚至超过了 GPT-4.1 (38.88%) 和 DeepSeek-V3.2-Exp (37.38%) 等专有模型。
    *   **Qwen3-8B-GEM** 达到 **30.25%**，相比基础模型 (18.00%) 提升显著，并超越其他开源基线。

#### **τ²-bench 基准测试结果**
*   **强大的泛化能力**： 尽管 GEM 的训练数据是**领域外**的（非航空/零售），但其模型性能与使用**领域内**数据（如 APIGEN-MT, Simia）训练的模型**相当甚至更优**。
    *   在 **Retail** 领域，**Qwen3-32B-GEM** 的 Pass@4 达到 **86.84%**，显著优于所有对比基线。
    *   在 **Airline** 领域，其性能（Pass@4: 56.00%）与最佳基线模型相当。
    *   这证明了文本提取范式能赋予模型更**根本的工具使用推理能力**，从而更好地泛化到未见过的真实领域。

#### **Trajectory Synthesizer 的有效性**
*   **质量接近，成本大降**： 通过 SFT 训练的 Trajectory Synthesizer (基于 Qwen3-8B) 能够**端到端**地将文本映射为轨迹。
    *   使用该合成器生成的数据微调的模型，在 BFCL V3 上达到 **28.38%** 的准确率，与使用昂贵 GLM-4.6 全管道生成数据的效果（30.25%）**非常接近**。
    *   这为大规模、低成本生成高质量工具使用数据提供了可行方案。

#### **消融实验结论**
*   **精炼阶段 (Refinement) 至关重要**： 移除该阶段导致 Qwen3-32B 性能从 44.88% 大幅下降至 32.50%。该阶段通过增加工具多样性、请求模糊性和对话复杂性，显著提升了合成数据的质量。
*   **LLM-Based 幻觉检测有效**： 该检查机制能过滤掉包含虚构参数或矛盾的轨迹，对保证数据质量有积极贡献（尤其在 8B 模型上效果明显）。

### 4. 数据复杂性分析
论文合成的轨迹在复杂性上远超现有开源数据集：
*   **平均对话轮数**： 46 轮 (对比：APIGEN-MT ~18.5轮，TOUCAN ~6.24轮)。
*   **平均使用工具数**： 8.6 个。
*   **平均工具调用次数**： 16.3 次 (对比：APIGEN-MT ~4.3次)。
这确保了模型能学习到在长上下文、多步骤规划场景下的稳健工具使用能力。

**总结**： 论文通过实验定量证明了其提出的“文本到轨迹”范式的有效性。GEM 合成数据能显著提升 LLM 的多轮工具调用性能，并展现出优异的跨领域泛化能力。同时，其提出的 Trajectory Synthesizer 模型在保证数据质量的前提下，大幅降低了数据生成成本，为训练更强大的自主智能体提供了可扩展的高质量数据源。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2601.10355v1)
- [HTML 版本](https://arxiv.org/html/2601.10355v1)
