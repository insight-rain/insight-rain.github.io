# Real-Time In-Cabin Driver Behavior Recognition on Low-Cost Edge Hardware

**相关性评分**: 7.0/10

**排名**: #17


---


## 基本信息

- **arXiv ID**: [2512.22298v2](https://arxiv.org/abs/2512.22298v2)
- **发布时间**: 2025-12-26T00:54:24Z
- **相关性评分**: 7.0/10
- **是否相关**: 是

## 作者

Vesal Ahsani, Babak Hossein Khalaj, Hamed Shah-Mansouri

## 关键词

Inference Efficiency, Lightweight Architecture, Edge Deployment

## 一句话总结

该论文提出了一种在低成本边缘硬件上实时识别驾驶员行为的系统，专注于推理效率和边缘部署，但未直接涉及视觉-语言-动作模型或机器人应用。

## 摘要

In-cabin driver monitoring systems (DMS) must recognize distraction- and drowsiness-related behaviors with low latency under strict constraints on compute, power, and cost. We present a single-camera in-cabin driver behavior recognition system designed for deployment on two low-cost edge platforms: Raspberry Pi 5 (CPU-only) and the Google Coral development board with an Edge Tensor Processing Unit (Edge TPU) accelerator. The proposed pipeline combines (i) a compact per-frame vision model, (ii) a confounder-aware label taxonomy to reduce confusions among visually similar behaviors, and (iii) a temporal decision head that triggers alerts only when predictions are both confident and sustained. The system supports 17 behavior classes. Training and evaluation use licensed datasets plus in-house collection (over 800,000 labeled frames) with driver-disjoint splits, and we further validate the deployed system in live in-vehicle tests. End-to-end performance reaches approximately 16 FPS on Raspberry Pi 5 using 8-bit integer (INT8) inference (per-frame latency <60 ms) and approximately 25 FPS on Coral Edge TPU (end-to-end latency ~40 ms), enabling real-time monitoring and stable alert generation on embedded hardware. Finally, we discuss how reliable in-cabin perception can serve as an upstream signal for human-centered vehicle intelligence, including emerging agentic vehicle concepts.

## 详细分析

## 论文摘要

**1. 研究背景和动机**
驾驶员监控系统（DMS）是提升道路安全的关键，但现有研究常侧重于离线精度，忽略了在低成本边缘硬件上实时部署的实际挑战。这些挑战包括：计算、功耗和成本的严格限制，以及真实驾驶环境中光照突变、振动、遮挡和视觉相似行为（混淆项）导致的误报。本研究旨在填补这一鸿沟，设计一个能在低成本边缘硬件上实现**稳定、实时**行为识别与警报的端到端系统。

**2. 核心方法和技术创新**
本文提出一个面向部署的端到端单摄像头DMS管道，其核心创新在于系统级设计：
- **混淆项感知的行为分类法**：定义了17类行为，不仅包含分心/困倦等关键行为，还**显式纳入了**（如整理头发、操作控制面板等）常见视觉混淆行为作为独立类别，从源头减少系统性误报。
- **时序决策头**：引入基于**置信度与持续性**的门控机制，将噪杂的逐帧预测转换为稳定的事件级警报，有效抑制瞬态手势和遮挡引发的误触发。
- **边缘优化部署**：采用紧凑的逐帧视觉模型，并针对**Raspberry Pi 5（仅CPU）** 和**Google Coral（带Edge TPU加速器）** 两个低成本平台，进行了完整的INT8量化与编译优化，实现系统级端到端实时处理。

**3. 主要实验结果**
- **性能**：在实车测试中，系统在Raspberry Pi 5上达到约16 FPS（端到端延迟<60毫秒），在Coral Edge TPU上达到约25 FPS（延迟~40毫秒），满足实时性要求。
- **有效性**：消融实验表明，结合混淆项感知分类和时序决策头的完整系统，相比基线显著提升了宏F1分数（达0.82），并将误警报率降至0.3次/分钟，生成了更稳定、可用的警报流。
- **鲁棒性**：定性评估显示，系统在光照变化、振动、部分遮挡等真实驾驶干扰下，仍能保持稳定的警报输出。

**4. 研究意义和价值**
本研究的意义在于**将DMS从离线原型推向可实际部署的系统**。它证明了通过精心设计的系统级策略（混淆项建模、时序门控），能够在严苛的资源限制下实现可靠、实时的车内感知。这为成本敏感的车载试点项目提供了可行的技术基础，并且其产生的**结构化、时序稳定的事件级信号**，可作为上游输入，服务于更高级别的人本车辆智能（如座舱状态感知、代理车辆决策），具有重要的实际应用价值。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析

### **核心问题**
论文旨在解决一个关键的**落地鸿沟**：如何在**低成本、计算资源受限的边缘硬件**上，实现一个**真正可部署、稳定可靠**的驾驶员行为监控系统。传统研究往往只关注离线帧级精度，而忽略了实际部署中必须应对的挑战：
1.  **实时性约束**：必须在低功耗、低成本的嵌入式设备上达到实时帧率。
2.  **鲁棒性需求**：必须应对真实驾驶舱内复杂多变的环境（光照突变、振动模糊、部分遮挡）。
3.  **误报率控制**：必须减少因视觉相似行为（混淆项）引发的频繁误报警，确保警报流的**稳定性和可用性**。

### **核心创新点**
论文的创新是一个**系统级解决方案**，而非单一的模型改进。它通过三个紧密耦合的设计，共同解决了上述问题：

1.  **混淆项感知的17类行为分类体系**
    - **创新**：在标签设计中**显式地包含了常见但安全风险较低的混淆行为**（如“整理头发/化妆”、“操作控制面板/GPS”）。
    - **解决什么问题**：传统系统容易将这类良性动作误判为“使用手机”等高危分心行为，导致大量误报。通过为混淆项设立独立类别，系统可以将其识别为“合理的替代解释”，从而**从根源上减少系统性误报**。

2.  **基于置信度与持续性的时序决策头**
    - **创新**：将**帧级识别**与**事件级报警**解耦。引入一个决策模块，只有当某个行为类别的预测置信度在连续一段时间窗口（如~1秒）内都保持高位且稳定时，才触发警报。
    - **解决什么问题**：直接使用逐帧最大概率输出会产生抖动、碎片化的警报，无法应对短暂的视线转移、手势或遮挡。该机制**滤除了瞬时干扰**，输出稳定、有意义的行为“事件”，更适合下游集成和驾驶员反馈。

3.  **面向边缘部署的端到端系统优化**
    - **创新**：在模型选择、训练到部署的全流程中，始终以**边缘硬件的实际约束**（算力、内存、算子兼容性、量化稳定性）为设计准则。
    - **解决什么问题**：确保学术原型能在真实硬件上高效运行。论文在**树莓派5（仅CPU）** 和**Google Coral（带Edge-TPU加速器）** 两款低成本硬件上实现了端到端（从图像采集到警报输出）的实时性能，并提供了详细的量化、编译和性能剖析方法。

### **解决方案的总体架构**
论文的解决方案是一个完整的处理流水线：
```
单目摄像头 → 图像预处理 → 紧凑型帧分类模型 → 后处理（含混淆项处理）→ 时序决策头 → 稳定的事件警报输出
```
**关键技术手段**包括：
- **模型**：采用基于YOLOv8分类模块的紧凑卷积网络，输入分辨率权衡后定为320x320。
- **训练**：使用**焦点损失**处理类别不平衡问题。
- **部署**：采用**INT8整数量化**，并在Coral平台上完成了全算子到Edge-TPU的映射，避免CPU回退导致的性能抖动。
- **验证**：不仅在超过80万帧的离线数据集（遵循驾驶员不相交划分）上测试，还进行了**实车路测**，验证系统在真实扰动下的表现。

### **实际价值与意义**
1.  **工程落地价值**：证明了精细化的驾驶员行为识别（17类）可以在**极低成本**的边缘设备上达到实用级的实时性能（树莓派5：~16 FPS， Coral：~25 FPS），为大规模商用提供了可行的技术路径。
2.  **系统设计范式**：提出了一个以**部署鲁棒性**为核心的设计范式，强调混淆项建模和时序警报稳定化，这对任何需要连续感知并与人交互的系统都具有借鉴意义。
3.  **上游信号基础**：论文将可靠的舱内感知定位为更高级别**车辆智能（如Agentic Vehicle）的上游信号**。稳定的行为事件流可以为“驾驶员接管准备度判断”、“风险分级预警”等决策提供高质量输入，推动了从单纯报警到以人为中心的车辆智能的演进。

**总结**：这篇论文的核心贡献在于，它成功地将一个复杂的计算机视觉任务，通过一系列**以部署为中心的系统性创新**，转化为一个能在严苛资源限制下稳定工作的产品级解决方案，弥合了学术研究与工业应用之间的鸿沟。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文旨在解决在低成本边缘硬件上实现**实时、稳定、可部署**的车内驾驶员行为识别系统的核心挑战，该挑战不仅要求高精度，更需在真实驾驶扰动（如光照变化、振动、遮挡）下产生低误报、稳定的警报事件。为此，论文提出了一个端到端的系统框架，其核心创新在于**三重设计**：1) 一个紧凑的逐帧视觉模型；2) 一个包含17类行为的**混淆项感知**标签体系，将易混淆的良性行为（如整理头发、操作控制面板）单独设类以减少视觉误判；3) 一个**时态决策头**，通过置信度和持续性门控将逐帧预测转化为稳定的事件级警报。最终，该系统在树莓派5（CPU）和Coral Edge TPU开发板上分别实现了约16 FPS和25 FPS的端到端实时性能，并在真实车载测试中验证了其能生成稳定、可操作的警报流，为低成本嵌入式硬件上的可靠驾驶员监控提供了实用方案。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文创新点分析

这篇论文提出了一套面向低成本边缘硬件部署的实时车内驾驶员行为识别系统。其核心创新点并非单一算法突破，而是一套**系统级的设计理念和工程化方案**，旨在弥合学术原型与可部署系统之间的差距。以下是其明确的创新点：

### 1. **系统级设计：从“帧级精度”到“事件级警报”的转变**
- **改进/不同之处**：以往多数研究侧重于在受控环境下优化单帧图像的分类准确率（帧级精度）。本文则强调将部署视为一个**端到端的系统问题**，其最终输出是**稳定的事件级警报**，而非逐帧的、可能充满噪声的标签。
- **解决的具体问题/优势**：
    - **解决了“高精度但不可用”的问题**：即使一个分类器帧级精度很高，在真实驾驶的振动、遮挡、光照突变下，其逐帧预测也可能频繁跳动，产生大量令人厌烦的误报警，导致系统无法被驾驶员接受。
    - **带来了稳定、可集成的输出**：通过引入**时态决策头**，系统只在预测结果既**高置信度**又**持续一段时间**（如约1秒）后才触发警报。这抑制了瞬时手势、短暂遮挡引起的误触发，产出的警报流更符合下游人机交互（HMI）或高级驾驶辅助系统（ADAS）集成的需求。

### 2. **混淆因素感知的17类行为分类法设计**
- **改进/不同之处**：传统的驾驶员监控系统（DMS）分类法通常只关注直接的危险行为（如使用手机、疲劳）。本文的标签设计**显式地包含了常见的、视觉上相似的“混淆行为”**作为独立类别，例如“化妆/整理头发”、“操作控制面板/GPS”。
- **解决的具体问题/优势**：
    - **解决了系统性误报问题**：在真实驾驶中，驾驶员用手整理头发或操作中控屏的动作，在视觉上与使用手机发短信非常相似。如果不加区分，这些良性行为会频繁被误判为危险行为，导致误报警率飙升。
    - **将“假阳性”转化为“正确识别”**：通过将这些混淆行为设为独立类别，模型学习到了区分它们的视觉特征。原本会导致误报的帧，现在被正确归类为“整理头发”或“操作控制面板”，从而**显著降低了安全关键类别的误报率**，提升了系统的可用性和可靠性。

### 3. **面向低成本边缘硬件的端到端部署验证与性能优化**
- **改进/不同之处**：许多研究仅在服务器GPU上报告性能。本文**明确针对两种低成本边缘硬件**（树莓派5和Google Coral开发板）进行全栈优化和**实车实测**。优化包括模型选择、INT8量化、算子兼容性编译，并测量了从图像采集到警报输出的**端到端延迟和吞吐量**。
- **解决的具体问题/优势**：
    - **解决了理论与实践的脱节**：证明了细粒度（17类）行为识别在严格的计算、功耗和成本限制下是可行的。例如，在仅CPU的树莓派5上达到~16 FPS（端到端延迟<60ms），在带Edge TPU的Coral上达到~25 FPS（~40ms延迟）。
    - **提供了可复现的部署路径**：论文详细描述了从PyTorch模型到TFLite再到Edge TPU编译的完整流程，并强调了算子映射、量化校准等实际部署中的关键步骤，为工业界在类似硬件上部署DMS提供了宝贵的工程参考。

### 4. **结合大规模数据集与实车验证的评估方法**
- **改进/不同之处**：评估不仅包含在大型（>80万帧）、驾驶员独立的离线测试集上的帧级和事件级指标，还包含了**在真实行驶车辆中的实时系统定性评估**。这捕捉了离线数据难以完全复现的分布偏移，如振动模糊、卷帘快门效应、安装视角微小变化等。
- **解决的具体问题/优势**：
    - **揭示了系统在真实扰动下的鲁棒性**：离线高精度不代表实车好用。通过实车测试，论文验证了其系统设计（特别是混淆因素感知和时态决策头）能够有效应对真实驾驶中的光照剧变、运动模糊和部分遮挡，产生稳定的警报事件。
    - **强调了“部署即系统”的理念**：这种评估方式将摄像头I/O、预处理、推理、后处理等所有环节的延迟和抖动都纳入考量，反映了系统作为整体的实时性能，这与行业评估标准（如Euro NCAP）的要求更为一致。

### 总结
本文的核心创新在于其**强烈的部署导向**。它通过**混淆因素感知的分类法**和**时态决策头**解决了DMS在连续运行中**误报率高**和**警报不稳定**这两个关键痛点，并通过**针对低成本硬件的深度优化和实车验证**，证明了其方案在**严苛资源约束下的可行性**。这些创新共同将驾驶员行为识别从一个“实验室算法”推向了一个更接近实际应用的“可部署系统”。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 论文实验与评估效果总结

该论文在实验与评估中，最终实现了一个能够在低成本边缘硬件上**实时、稳定运行**的驾驶员行为识别系统。其核心效果不仅是离线分类精度，更在于**端到端的部署性能**和**事件级警报的稳定性**。

### 一、 使用的数据集
论文构建并使用了大规模、多样化的驾驶员行为数据集，以确保模型的鲁棒性和泛化能力。
- **数据规模**：总计超过 **800,000** 张已标注图像。
- **数据来源**：
    1.  **授权/商业数据集**：未公开具体名称，但整合了现有资源。
    2.  **内部采集数据**：作者团队自行收集，以补充现实驾驶场景。
- **数据特点与处理**：
    - **类别**：覆盖论文定义的 **17 种行为类别**（见表1）。
    - **多样性**：涵盖了不同**驾驶员**（年龄、性别、配饰如眼镜/口罩）、**车辆类型**（超过10种）、**光照条件**（白天、夜晚、黄昏、隧道等）和**环境**（城市街道、高速公路）。
    - **数据划分**：采用**驾驶员不相交**的划分方式（训练/验证/测试集分别包含150/15/20位不同的驾驶员），以防止身份信息泄露，更好地评估泛化能力。
    - **难点样本增强**：针对小物体（手机、香烟、杯子）和易混淆行为（如短暂看后视镜 vs. 长时间左顾右盼）进行了数据增强和标签细化。

### 二、 使用的评价指标
评估分为两个层面，以反映实际部署需求：

1.  **帧级识别指标**（评估分类模型本身）：
    - **宏平均F1分数**：对各类别的F1分数取未加权平均，能更好地反映在类别不平衡下的整体性能。
    - **平衡准确率**：对各类别的召回率取平均，减少“正常驾驶”这类大类别的主导影响。
    - **每类F1分数**：用于分析特定类别（尤其是易混淆行为）的识别效果。

2.  **事件级警报指标**（评估整个系统的输出质量）：
    - **误报率**：每分钟产生的未匹配到真实事件的错误警报数量。**这是衡量系统可用性的关键指标**。
    - **检测时间**：从真实事件开始到系统发出警报的延迟。
    - **警报碎片化**：一个真实事件被分割成多个预测警报的数量（越低越好，表明警报更稳定）。

### 三、 对比的基线方法
论文与以下几种基线方法进行了对比，以凸显其系统设计的价值：

1.  **仅帧级预测**：直接使用每帧的 `argmax` 类别作为警报（即 `K=1`）。这代表了最简单的在线系统，但会产生大量因瞬时动作导致的碎片化和误报。
2.  **时序平滑（非门控）**：
    - **滑动窗口多数投票**：对近期硬标签进行多数表决。
    - **指数移动平均**：对类别概率进行平滑，然后阈值化。
    - 这类方法能减少高频标签切换，但无法像**持续性门控**那样有效抑制短暂手势触发的警报。
3.  **基于关键点的启发式方法**：使用 MediaPipe 等工具提取面部关键点，并应用启发式规则（如持续闭眼）来检测困倦。此基线主要用于对比在遮挡（如手遮脸、太阳镜）和低光条件下，基于外观的模型相对于传统方法的鲁棒性优势。

### 四、 关键性能结果与结论

#### 1. 帧级识别性能
- **宏平均F1分数**：完整系统（包含混淆物感知分类和时序决策头）在测试集上达到了 **0.82**。
- **消融实验证明有效性**（见表4）：
    - **无混淆物类别 + 无时序头**：宏F1为 0.71，误报率高达 1.80 次/分钟。
    - **仅含混淆物类别**：宏F1提升至 0.78，误报率降至 1.20 次/分钟。**这表明显式建模易混淆行为能有效减少系统性误判**。
    - **仅有时序决策头**：宏F1为 0.74，误报率大幅降至 0.55 次/分钟。**这表明持续性门控是抑制瞬时误报的核心机制**。
    - **完整系统**：结合两者优势，实现了最高的宏F1 (0.82) 和最低的误报率 (0.30 次/分钟)。

#### 2. 端到端部署性能（核心创新与价值）
论文在**真实车载环境**下测量了完整流水线的性能，这是其评估的关键亮点。

| 部署平台 | 端到端延迟 (中位数) | 可持续吞吐量 (FPS) | 关键说明 |
| :--- | :--- | :--- | :--- |
| **Raspberry Pi 5 (仅CPU)** | **< 60 ms** | **~16 FPS** | 使用 INT8 量化，满足近实时要求。 |
| **Google Coral (Edge TPU)** | **~40 ms** | **~25 FPS** | 模型完全在 TPU 上运行，无 CPU 回退，延迟和吞吐量更优。 |

- **与早期MVP对比**：早期版本仅 5-8 FPS，延迟 125-200 ms，**无法支持稳定的持续性警报逻辑**。优化后的部署实现了质的飞跃。
- **对警报逻辑的实际意义**：设定的持续性窗口 `K=25` 帧，在不同 FPS 下对应不同的实际时间窗口（Pi 5: ~1.56秒，Coral: 1.0秒）。论文强调，**实现的 FPS 不仅关乎速度，更直接决定了警报触发的时间分辨率**。

#### 3. 定性评估与鲁棒性
- **警报稳定性**：在包含振动、光照突变、部分遮挡的真实驾驶视频中，系统产生的**事件级警报连贯、稳定**，避免了因短暂手势或遮挡造成的警报“闪烁”。
- **混淆物处理效果**：例如，“整理头发/手放头上”这类行为不再被误报为“手机使用”，显著降低了特定场景下的误报。

### 五、 主要结论
1.  **技术创新点得到验证**：**混淆物感知的标签设计**和**基于置信度与持续性的时序决策头**被证明能显著提升系统级的可用性（高宏F1、低误报率），而不仅仅是帧级精度。
2.  **实际部署价值得以实现**：论文成功在**极低成本**的边缘硬件（树莓派5和Coral开发板）上实现了**端到端的实时推理**（16-25 FPS），并生成了稳定的警报流。这证明了精细化的车内行为监控可以脱离昂贵的计算平台或云端依赖，具备大规模实际应用的潜力。
3.  **系统级评估的重要性**：论文强调并实践了从“仅看推理速度”到“衡量端到端系统延迟与稳定性”的评估范式转变，其报告的**包含摄像头I/O、预处理、后处理等全流程的延迟数据**，对工业部署具有直接的参考价值。

总之，该论文的评估不仅给出了有竞争力的分类精度，更重要的是通过系统级的设计和车载实测，证明了其方案在**低成本、高鲁棒性、可部署**方面的突出效果，为其从研究原型走向实际应用奠定了坚实基础。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2512.22298v2)
- [HTML 版本](https://arxiv.org/html/2512.22298v2)
