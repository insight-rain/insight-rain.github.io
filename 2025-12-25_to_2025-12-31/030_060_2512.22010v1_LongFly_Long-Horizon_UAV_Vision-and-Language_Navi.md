# LongFly: Long-Horizon UAV Vision-and-Language Navigation with Spatiotemporal Context Integration

**相关性评分**: 6.0/10

**排名**: #30


---


## 基本信息

- **arXiv ID**: [2512.22010v1](https://arxiv.org/abs/2512.22010v1)
- **发布时间**: 2025-12-26T12:09:40Z
- **相关性评分**: 6.0/10
- **是否相关**: 是

## 作者

Wen Jiang, Li Wang, Kangyao Huang, Wei Fan, Jinyuan Liu, Shaoyu Liu, Hongwei Duan, Bin Xu, Xiangyang Ji

## 关键词

Vision-Language-Action Model, VLA for Robotics, Inference Efficiency, Lightweight Architecture, Inference Acceleration, Edge Deployment

## 一句话总结

LongFly 是一个用于无人机长时程视觉-语言导航的时空上下文建模框架，通过历史感知策略提升语义对齐和路径规划性能，但未明确强调轻量化或边缘部署。

## 摘要

Unmanned aerial vehicles (UAVs) are crucial tools for post-disaster search and rescue, facing challenges such as high information density, rapid changes in viewpoint, and dynamic structures, especially in long-horizon navigation. However, current UAV vision-and-language navigation(VLN) methods struggle to model long-horizon spatiotemporal context in complex environments, resulting in inaccurate semantic alignment and unstable path planning. To this end, we propose LongFly, a spatiotemporal context modeling framework for long-horizon UAV VLN. LongFly proposes a history-aware spatiotemporal modeling strategy that transforms fragmented and redundant historical data into structured, compact, and expressive representations. First, we propose the slot-based historical image compression module, which dynamically distills multi-view historical observations into fixed-length contextual representations. Then, the spatiotemporal trajectory encoding module is introduced to capture the temporal dynamics and spatial structure of UAV trajectories. Finally, to integrate existing spatiotemporal context with current observations, we design the prompt-guided multimodal integration module to support time-based reasoning and robust waypoint prediction. Experimental results demonstrate that LongFly outperforms state-of-the-art UAV VLN baselines by 7.89\% in success rate and 6.33\% in success weighted by path length, consistently across both seen and unseen environments.

## 详细分析

## 论文《LongFly: Long-Horizon UAV Vision-and-Language Navigation with Spatiotemporal Context Integration》详细摘要

### 1. 研究背景和动机
无人机在灾后搜救等复杂任务中至关重要，但现有的**无人机视觉语言导航**方法在**长时程导航**中面临严峻挑战。复杂环境下的高信息密度、视角快速变化和动态结构，使得现有方法难以对长时程的**时空上下文**进行有效建模，导致语义对齐不准确和路径规划不稳定。因此，亟需一种能够整合历史视觉和轨迹信息、实现稳健长时程推理的导航框架。

### 2. 核心方法和技术创新
本文提出了 **LongFly**，一个用于长时程无人机视觉语言导航的**时空上下文建模框架**。其核心创新在于提出了一种**历史感知的时空建模策略**，将碎片化、冗余的历史数据转化为结构化、紧凑且富有表现力的表示。具体包含三个关键模块：
- **基于槽位的历史图像压缩模块**：通过循环槽位更新机制，将多视角历史观测动态压缩为固定长度的上下文表示，实现高效的长时程视觉记忆建模。
- **时空轨迹编码模块**：将历史航点编码为相对运动表示，并融入时间嵌入，以捕获无人机运动的时空动态。
- **提示引导的多模态集成模块**：设计结构化提示，将语言指令、压缩后的历史视觉记忆和轨迹上下文与当前观测对齐，并输入多模态大语言模型进行推理，实现稳健的连续航点预测。

### 3. 主要实验结果
在**OpenUAV**基准测试上，LongFly在**已见**和**未见**环境中均显著优于现有最先进方法：
- 在整体测试集上，**成功率**提升7.89%，**路径长度加权成功率**提升6.33%。
- 在最具挑战性的**困难**场景中，性能提升最为显著，证明了其对长时程、复杂语义任务的有效性。
- 消融实验证实了每个模块（SHIC, STE, PGM）的贡献，并展示了模型对**未见物体**的良好泛化能力（优于对**未见地图**的泛化）。

### 4. 研究意义和价值
LongFly通过显式地建模和整合时空上下文，显著提升了无人机在复杂3D环境中执行长时程、语义化导航任务的能力。其提出的**结构化历史信息压缩与融合范式**，为解决长时程依赖、视角变化和语义漂移等核心难题提供了新思路。该框架不仅推动了无人机自主导航技术的发展，也为更广泛的具身智能和机器人长时程决策任务提供了有价值的参考。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析：LongFly

### 一、 论文旨在解决的核心问题
这篇论文旨在解决**无人机视觉与语言导航（UAV VLN）中的长时程依赖问题**。具体而言，现有方法在复杂、动态的3D环境中进行长距离导航时，面临两大关键挑战：

1.  **历史信息处理低效**：长距离飞行会持续积累大量冗余的视觉观测和轨迹数据。现有方法难以从不断增长的历史序列中，自适应地提取与当前指令和决策最相关的信息，并有效抑制噪声。
2.  **多模态时空上下文对齐与整合困难**：视觉观测、飞行轨迹和语言指令本质上是割裂的。简单的特征堆叠无法捕捉“过去运动”与“当前目标”之间的逻辑联系，导致无人机在长距离导航中容易失去空间上下文感知，产生不一致的导航行为。

### 二、 核心技术创新点
论文提出了 **LongFly**，一个**时空上下文建模框架**。其核心创新在于提出了一种 **“历史感知的时空建模策略”** ，将碎片化、冗余的历史数据转化为结构化、紧凑且富有表现力的表示。具体通过三个核心模块实现：

1.  **基于槽位的历史图像压缩模块**
    *   **创新点**：引入动态的、**槽位（Slot）** 机制来压缩历史视觉观测。
    *   **如何解决**：
        *   维护一组固定数量的“语义槽位”作为视觉记忆。
        *   通过**循环注意力机制**，让这些槽位像查询一样，与每个新时间步的多视角视觉特征进行交互，动态地吸收和更新信息。
        *   使用**门控循环单元（GRU）** 进行槽位状态的迭代更新。
    *   **价值**：将可变长度的历史视觉序列压缩为固定长度的紧凑表示，计算复杂度从 `O(t)` 降至 `O(1)`，形成了持续演化的动态语义记忆，能捕捉长时程导航中的持久地标和空间布局。

2.  **时空轨迹编码模块**
    *   **创新点**：显式地对无人机飞行轨迹的**时空动态**进行编码，而不仅仅是存储坐标点。
    *   **如何解决**：
        *   将历史航点转换为**相对运动表示**（位移向量、方向、步长），降低对全局位置漂移的敏感性。
        *   为每个运动描述符添加**时间嵌入**，以编码时序顺序。
        *   通过一个MLP编码器将时间感知的运动表示投影为**轨迹令牌**。
    *   **价值**：为下游推理提供了明确的运动先验，捕获了长时程路径的演化规律，增强了模型对自身运动状态的理解。

3.  **提示引导的多模态整合模块**
    *   **创新点**：采用**结构化提示**，而非额外的特征融合层，来整合多模态上下文。
    *   **如何解决**：
        *   将语言指令、压缩后的历史视觉记忆、编码后的历史轨迹以及当前观测，组织成一个结构化的文本提示。
        *   将此提示与当前视觉图像一同输入到一个**多模态大语言模型**中。
        *   MLLM直接基于这个富含时空上下文的提示进行推理，并预测下一个连续的3D航点。
    *   **价值**：利用MLLM强大的推理和指令跟随能力，实现了语言、历史（视觉+轨迹）、当前观测的自然对齐与联合推理，简化了模型架构，提升了可解释性。

### 三、 解决方案的总体思路
LongFly的解决方案是一个**端到端的框架**，其工作流程清晰体现了“压缩-编码-整合”的思想：
```
长距离飞行 → 积累大量历史数据 → 
1. 视觉历史 → SHIC模块 → 压缩为固定槽位表示（动态视觉记忆）
2. 轨迹历史 → STE模块 → 编码为轨迹令牌（显式运动先验）
3. 当前指令+观测 → 与1、2的结果一起 → PGM模块组织为结构化提示 → MLLM推理 → 预测下一航点
```
**核心思想**：不是被动地存储所有历史数据，而是主动地、结构化地**提炼**历史中的精华（关键语义和运动模式），并将其与当前任务目标（语言指令）进行**深度对齐**，从而支持稳定、一致的长时程决策。

### 四、 实际价值与效果
*   **性能提升**：在OpenUAV基准测试中，LongFly在**成功率（SR）** 上超越之前最优方法7.89%，在**路径长度加权成功率（SPL）** 上提升6.33%。在最具挑战性的“困难”场景中提升尤为显著。
*   **泛化能力强**：在未见过的环境、物体和地图上均表现出良好的泛化性能，特别是在处理**新物体**时表现优异。
*   **技术贡献**：为长时程UAV VLN提供了一个有效的时空上下文建模范式，证明了**显式地、结构化地建模历史时空信息**对于提升导航鲁棒性、准确性和语义理解至关重要。这项工作推动了UAV在复杂任务（如灾后搜救）中自主导航能力的发展。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文针对**无人机视觉-语言导航（VLN）在长航时任务中因缺乏时空上下文建模而导致语义对齐不准和路径规划不稳**的核心问题，提出了一个名为**LongFly**的时空上下文建模框架。该框架通过三个核心模块系统性地整合历史信息：**基于槽位的历史图像压缩模块（SHIC）** 将冗余的多视角历史观测动态蒸馏为紧凑的语义表示；**时空轨迹编码模块（STE）** 捕捉无人机轨迹的时空动态；**提示引导的多模态融合模块（PGM）** 将历史上下文与当前观测对齐，以支持基于时间的推理。实验结果表明，LongFly在OpenUAV基准测试中显著超越了现有最佳方法，在**成功率（SR）** 和**路径长度加权成功率（SPL）** 上分别提升了7.89%和6.33%，尤其在复杂的长航时场景中优势最为明显，证明了其时空上下文建模的有效性和鲁棒性。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文《LongFly: Long-Horizon UAV Vision-and-Language Navigation with Spatiotemporal Context Integration》的创新点分析

这篇论文针对长航时无人机视觉-语言导航（UAV VLN）中的核心挑战——**长时依赖建模**，提出了一个名为LongFly的创新框架。其核心创新在于提出了一种**历史感知的时空上下文建模策略**，将碎片化、冗余的历史数据转化为结构化、紧凑且富有表现力的表示。以下是其相对于已有工作的明确创新点：

### 1. **提出了基于槽位的历史图像压缩模块**
   - **改进/不同之处**：
     - **以往方法**：许多现有方法（如CityNavAgent、OpenFly）虽然引入了记忆机制，但通常将历史视觉信息视为静态线索进行存储或简单检索，缺乏动态压缩和结构化。这导致计算开销随历史长度线性增长，且难以有效抑制冗余和噪声。
     - **LongFly的SHIC模块**：引入了一种**基于槽位的循环更新机制**。它将多视角的历史观测图像动态地“蒸馏”到一个固定数量（K个）的语义槽位中。这些槽位作为可学习的参数，通过注意力机制与每个新时间步的视觉特征交互并更新（使用GRU），最终形成一个紧凑的、固定容量的视觉记忆。
   - **解决的问题/带来的优势**：
     - **解决了历史视觉信息冗余和计算效率问题**：将可变长度的历史视觉序列压缩为固定长度的表示，将推理时的内存和计算复杂度从O(t)降低到O(1)，使其更适合长航时任务。
     - **增强了语义一致性和信息密度**：槽位机制能够持续演化，捕捉长航时导航中持久的语义地标和空间布局，形成动态的语义记忆，而不仅仅是静态的图像堆叠。
     - **保留了视角特异性**：为不同相机视角维护独立的槽位集合，确保在压缩过程中不丢失视角特有的语义线索。

### 2. **设计了时空轨迹编码模块**
   - **改进/不同之处**：
     - **以往方法**：对历史轨迹的处理可能较为简单，例如直接使用绝对坐标序列或简单的RNN编码，未能显式地建模运动的时空动力学和结构。
     - **LongFly的STE模块**：**显式地编码了无人机轨迹的时空动态**。它首先将绝对航点转换为相对运动表示（位移向量，分解为方向向量和步长），然后融入时间嵌入，最后通过一个MLP编码器生成轨迹令牌序列。这提供了明确的运动先验。
   - **解决的问题/带来的优势**：
     - **解决了轨迹信息与视觉、语言模态的对齐难题**：将连续的空间运动转化为结构化的、富含时空信息的令牌，使其能够与视觉记忆和语言指令在统一的表示空间中进行融合和推理。
     - **增强了对路径演化的理解**：相对运动表示降低了对全局位置漂移的敏感性，时间嵌入则捕捉了顺序信息，共同帮助模型理解“过去如何移动”，为长距离的路径一致性规划提供了关键依据。

### 3. **提出了提示引导的多模态集成模块**
   - **改进/不同之处**：
     - **以往方法**：多模态融合常采用特征级拼接、注意力融合等机制，这些方法可能难以捕捉“过去运动”与“当前目标”之间的复杂逻辑联系，导致导航行为在长距离上不一致。
     - **LongFly的PGM模块**：**创新性地采用结构化提示词进行融合**。它将语言指令、压缩后的历史视觉记忆、编码后的历史轨迹以及当前观测，组织成一个结构化的导航提示模板，然后直接输入到一个多模态大语言模型（如Qwen2.5-3B）中进行端到端的推理和航点预测。
   - **解决的问题/带来的优势**：
     - **解决了多模态上下文的有效对齐与集成问题**：通过精心设计的提示模板，显式地区分了不同来源的信息（指令、历史航点、历史图像、当前图像），引导MLLM理解它们之间的逻辑关系，实现了跨模态的、基于时间的推理。
     - **简化了架构，利用了MLLM的强大能力**：无需设计复杂的自定义融合网络，直接利用预训练MLLM的通用推理和生成能力，降低了模型设计的复杂性，同时可能获得了更好的泛化性和语义理解深度。
     - **支持鲁棒的连续航点预测**：直接输出3D空间中的连续航点，更符合无人机实际飞行的连续控制需求，相比离散动作选择更具灵活性和精确性。

### 4. **整体框架创新：统一的时空上下文建模策略**
   - **改进/不同之处**：
     - **以往方法**：现有UAV VLN方法在长航时任务中表现不佳，根源在于**缺乏统一的时空上下文建模**。历史信息往往被单独处理、静态使用，与导航过程的时空结构及语言指令关联较弱。
     - **LongFly的整体策略**：**首次系统性地提出并实现了一个“历史感知的时空上下文建模框架”**。它不是简单增加记忆模块，而是通过SHIC、STE、PGM三个子模块的协同工作，主动地将碎片化的历史视觉和轨迹数据转化为**结构化、紧凑、富有表达力且与指令对齐的时空上下文表示**。
   - **解决的问题/带来的优势**：
     - **从根本上应对长航时依赖挑战**：该框架使无人机能够在复杂3D环境中进行**一致的全局决策**。它解决了两个关键问题：(1) 从不断增长的历史序列中自适应提取与当前指令最相关的信息，抑制冗余噪声；(2) 有效对齐并集成多模态时空上下文，建立过去与现在的逻辑联系。
     - **带来了显著的性能提升**：在OpenUAV基准测试中，LongFly在**成功率（SR）** 和**路径长度加权成功率（SPL）** 上均大幅超越现有最优方法（分别提升7.89%和6.33%），尤其在困难的长航时任务中优势最为明显。这证明了统一时空建模对于提升导航稳定性、准确性和语义对齐的有效性。
     - **展现了良好的泛化能力**：在未见过的环境、物体和地图上均表现优异，表明学到的时空上下文建模能力具有一定的可迁移性。

**总结**：LongFly的核心创新在于其**系统性的时空上下文建模思想**及实现该思想的三个关键技术模块。它不再将历史视为被动的、静态的数据池，而是将其主动地构建为与当前任务紧密耦合的动态、结构化知识，从而显著提升了无人机在长航时、复杂环境下的VLN能力。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 论文实验与评估效果分析

### 一、 实验数据集与评价指标

#### 1. 数据集
- **主要数据集**：**OpenUAV** 数据集。
    - 专为无人机目标搜索与导航任务设计。
    - 包含 **12,149** 条人工操作的飞行轨迹，轨迹长度在 **50至400米** 之间。
    - 每条轨迹包含：多视角（前、后、左、右、底部）RGB图像、专家精炼的文本目标描述、对应的航点序列。
    - 涵盖 **89** 个物体类别（车辆、人、动物等），提供多样化的户外场景，用于评估复杂、GPS拒止环境下的长时程推理、多模态对齐和泛化能力。
- **实验环境**：在 **AirSim** 高保真仿真器中进行，该平台提供逼真的物理、天气和光照条件，支持定制化场景。

#### 2. 评价指标
论文采用VLN任务中广泛使用的四个标准指标进行评估：
- **导航误差 (Navigation Error, NE)**：最终预测航点与目标位置之间的欧氏距离（越低越好）。
- **成功率 (Success Rate, SR)**：最终航点落在目标 **20米** 范围内的任务比例（越高越好）。
- **最优成功率 (Oracle Success Rate, OSR)**：在轨迹中任意点距离目标 **20米** 内的任务比例（越高越好）。
- **路径长度加权成功率 (Success weighted by Path Length, SPL)**：结合成功率和路径效率的综合性指标（越高越好）。

### 二、 对比的基线方法
论文将 **LongFly** 与以下基线方法进行了全面对比：
1.  **Random Action**：随机采样航点，无规划。
2.  **Fixed Action**：将指令映射为确定性宏动作。
3.  **CMA (Cross-Modal Attention)**：经典VLN方法，为适应本任务，将其离散动作头替换为航点序列解码器。
4.  **TravelUAV**：基于OpenUAV平台的UAV-VLN基线，使用统一多模态表示和动作预测头。
5.  **TravelUAV-DA**：TravelUAV的变体，增加了DAgger风格的数据聚合以改进闭环训练。
6.  **NavFoM (Navigation Foundation Model)**：通用导航基础模型，输入多视角视频和自然语言指令，无需任务特定微调。
7.  **BS (Ours, Base System)**：**论文自身的消融基线**，一个仅使用当前观测和指令进行航点预测的Qwen-based模型（**不包含**SHIC和STE模块）。

### 三、 关键性能提升与结论

#### 1. 总体性能表现
LongFly在**所有测试集**（Seen和Unseen）上均**显著优于**所有基线方法，证明了其框架的有效性和泛化能力。

#### 2. 在“Seen”环境下的性能（表II，图6）
- **核心结论**：LongFly在**复杂、长时程任务（Hard子集）上优势最大**，表明其时空上下文建模对长时程推理特别有效。
- **关键数据对比 (Full子集)**：
    - **vs. 最佳基线 (NavFoM)**：
        - **NE降低**：`93.05 -> 60.02` (**降低33.03m**)
        - **SR提升**：`29.17% -> 36.39%` (**提升7.22%**)
        - **SPL提升**：`25.03% -> 31.07%` (**提升6.04%**)
    - **vs. 自身基线 (BS)**：
        - **NE降低**：`85.17 -> 60.02` (**降低25.15m**)
        - **SR提升**：`22.50% -> 36.39%` (**提升13.89%**)
        - **SPL提升**：`19.12% -> 31.07%` (**提升11.95%**)

#### 3. 在“Unseen”环境下的泛化能力（表I，图7）
- **核心结论**：LongFly在**未见过的环境、物体和地图**上均表现出强大的泛化能力，尤其在处理**新物体**时表现优于处理**新地图**，说明环境分布偏移是更大的挑战。
- **关键数据对比 (Unseen Full子集)**：
    - **vs. 最佳基线 (NavFoM)**：
        - **NE降低**：`118.34 -> 91.84` (**降低26.50m**)
        - **SR提升**：`15.63% -> 24.19%` (**提升8.56%**)
        - **SPL提升**：`14.21% -> 20.84%` (**提升6.63%**)
    - **vs. 自身基线 (BS)**：
        - **NE降低**：`106.08 -> 91.84` (**降低14.24m**)
        - **SR提升**：`13.99% -> 24.19%` (**提升10.20%**)
        - **SPL提升**：`12.16% -> 20.84%` (**提升8.68%**)

#### 4. 消融实验验证（表V）
- **模块贡献**：**SHIC（视觉历史压缩）和STE（轨迹编码）模块均带来显著提升**，且二者结合（即完整的LongFly）效果最佳，证明了多模态历史信息整合的必要性。
    - `BS+STE` 和 `BS+SHIC` 均优于 `BS`。
    - `BS+STE+SHIC (LongFly)` 在所有指标上达到最优。
- **关键设计验证**：
    - **提示词引导融合 (PGM)** 至关重要。移除提示词引导，仅简单拼接历史信息，导致性能大幅下降（SR从24.19%降至15.06%）。
    - **历史长度**：使用全部历史帧（`all-frame`）性能最佳，说明更丰富的时序上下文对长时程推理尤其有益。
    - **SHIC槽位数**：槽位数 `K=32` 时达到最佳性能平衡。

### 四、 总结
论文通过系统的实验评估，**定量且令人信服地证明了LongFly框架的优越性**：
1.  **性能领先**：在OpenUAV基准测试的**Seen**和**Unseen**环境下，**SR绝对提升7.89%，SPL绝对提升6.33%**，全面超越现有SOTA方法。
2.  **优势场景明确**：在**长时程、布局复杂、指令模糊的“Hard”任务**上提升幅度最大，凸显了其时空上下文建模的核心价值。
3.  **泛化能力强**：能够有效适应未见过的物体和地图，具备实际部署潜力。
4.  **模块有效性得到验证**：通过消融研究证实了SHIC、STE和PGM每个模块的独立贡献及其组合的必要性。

这些结果共同表明，LongFly通过将碎片化的历史数据转化为**结构化、紧凑且富有表现力的时空上下文表示**，成功解决了长时程UAV-VLN中的语义对齐和路径规划稳定性问题。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2512.22010v1)
- [HTML 版本](https://arxiv.org/html/2512.22010v1)
