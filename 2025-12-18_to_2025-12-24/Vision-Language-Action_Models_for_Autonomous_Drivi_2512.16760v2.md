# Vision-Language-Action Models for Autonomous Driving: Past, Present, and Future

**相关性评分**: 8.0/10

**排名**: #7


---


## 基本信息

- **arXiv ID**: [2512.16760v2](https://arxiv.org/abs/2512.16760v2)
- **发布时间**: 2025-12-18T16:57:44Z
- **相关性评分**: 8.0/10
- **是否相关**: 是

## 作者

Tianshuai Hu, Xiaolu Liu, Song Wang, Yiyao Zhu, Ao Liang, Lingdong Kong, Guoyang Zhao, Zeying Gong, Jun Cen, Zhiyu Huang, Xiaoshuai Hao, Linfeng Li, Hang Song, Xiangtai Li, Jun Ma, Shaojie Shen, Jianke Zhu, Dacheng Tao, Ziwei Liu, Junwei Liang

## 关键词

Vision-Language-Action Model, VLA for Robotics, Inference Efficiency, Lightweight Architecture, Inference Acceleration, Edge Deployment

## 一句话总结

这篇论文综述了自动驾驶中Vision-Language-Action（VLA）模型的演变、范式和应用，强调其在提升推理效率和部署方面的潜力。

## 摘要

Autonomous driving has long relied on modular "Perception-Decision-Action" pipelines, where hand-crafted interfaces and rule-based components often break down in complex or long-tailed scenarios. Their cascaded design further propagates perception errors, degrading downstream planning and control. Vision-Action (VA) models address some limitations by learning direct mappings from visual inputs to actions, but they remain opaque, sensitive to distribution shifts, and lack structured reasoning or instruction-following capabilities. Recent progress in Large Language Models (LLMs) and multimodal learning has motivated the emergence of Vision-Language-Action (VLA) frameworks, which integrate perception with language-grounded decision making. By unifying visual understanding, linguistic reasoning, and actionable outputs, VLAs offer a pathway toward more interpretable, generalizable, and human-aligned driving policies. This work provides a structured characterization of the emerging VLA landscape for autonomous driving. We trace the evolution from early VA approaches to modern VLA frameworks and organize existing methods into two principal paradigms: End-to-End VLA, which integrates perception, reasoning, and planning within a single model, and Dual-System VLA, which separates slow deliberation (via VLMs) from fast, safety-critical execution (via planners). Within these paradigms, we further distinguish subclasses such as textual vs. numerical action generators and explicit vs. implicit guidance mechanisms. We also summarize representative datasets and benchmarks for evaluating VLA-based driving systems and highlight key challenges and open directions, including robustness, interpretability, and instruction fidelity. Overall, this work aims to establish a coherent foundation for advancing human-compatible autonomous driving systems.

## 详细分析

## 论文摘要：《自动驾驶中的视觉-语言-动作模型：过去、现在与未来》

### 1. 研究背景和动机
传统的自动驾驶系统通常采用模块化的“感知-决策-动作”流水线，其依赖于手工设计的接口和规则，在复杂或长尾场景中容易失效，且感知误差会级联传播，影响下游规划与控制。**视觉-动作模型**虽能直接从视觉输入映射到动作，但缺乏可解释性、泛化能力弱，且无法进行结构化推理或遵循人类指令。随着大语言模型和多模态学习的进展，**视觉-语言-动作模型**应运而生，它通过整合视觉理解、语言推理和可执行动作输出，为驾驶策略提供了一个更可解释、更通用且更符合人类意图的新范式。

### 2. 核心方法和技术创新
本文对VLA模型进行了系统性的梳理与分类：
- **架构分类**：提出了一个清晰的分类法，将现有VLA方法分为**端到端VLA**（单一模型整合感知、推理与规划）和**双系统VLA**（慢速的VLM负责高层推理，快速的专用规划器负责安全关键的执行）。
- **技术细分**：进一步区分了**文本动作生成器**（输出语言命令或元动作）与**数值动作生成器**（输出连续轨迹或控制信号），以及**显式动作引导**与**隐式表征迁移**等子类。
- **全面回顾**：系统回顾了支撑VLA发展的**数据集与评测基准**，涵盖了从传统VA数据集到新兴的VLA多模态数据集，以及开环与闭环评测指标。

### 3. 主要实验结果
论文在多个主流基准上对比了VA与VLA模型的性能：
- 在**nuScenes**开环规划基准上，先进的VLA模型（如Drive-R1）能达到0.31m的L2误差和0.09的碰撞率，展示了语言推理对提升规划准确性与安全性的潜力。
- 在**NAVSIM**和**Bench2Drive**等闭环仿真基准中，VLA模型（如SimLingo, AutoVLA）在驾驶评分、成功率等综合指标上表现出色，证明了其在交互式、目标导向驾驶任务中的有效性。
- 在专注于长尾安全场景的**WOD-E2E**基准上，VLA模型通过结合人类偏好评分，展现了在复杂、罕见场景下更拟人、更可靠的决策能力。

### 4. 研究意义和价值
本工作为自动驾驶VLA研究领域建立了首个系统性的基础框架。其价值在于：
- **梳理脉络**：清晰勾勒了从VA到VLA的技术演进路径，阐明了范式转变的内在动机。
- **提供蓝图**：提出的分类体系和分析为未来研究提供了清晰的架构设计指南和比较基准。
- **指明方向**：深入探讨了当前VLA模型在**实时性、泛化性、可解释性、长时序一致性**等方面面临的挑战，并展望了**统一的世界模型、更丰富的多模态融合、社会常识推理**等未来方向，对推动构建更安全、可靠、人性化的下一代自动驾驶系统具有重要的指导意义。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析

### **核心问题**
论文旨在解决传统自动驾驶“感知-决策-执行”模块化流水线以及纯视觉-动作模型的根本性缺陷：
1.  **模块化系统**：依赖手工规则和接口，在复杂、长尾场景中容易失效；感知误差会级联传播，影响下游规划与控制。
2.  **纯视觉-动作模型**：虽实现了端到端映射，但缺乏**可解释性**、对分布偏移**鲁棒性差**、缺少**链式推理**能力，且无法理解和遵循**人类语言指令**。

### **核心创新点**
论文并非提出单一新模型，而是对新兴的**视觉-语言-动作模型范式**进行了首次系统性、结构化的**综述、分类与展望**。其核心创新在于：

1.  **提出了清晰的VLA范式演进与分类体系**
    *   **历史脉络**：清晰梳理了从**VA模型**（纯视觉到动作）到**VLA模型**（融入语言推理）的演进路径。
    *   **核心分类**：提出了一个层次化的VLA架构分类法，将现有方法划分为两大范式：
        *   **端到端VLA**：单一模型直接完成感知、推理和规划。
        *   **双系统VLA**：借鉴“快慢思考”理论，将**慢速、深思熟虑的VLM推理**与**快速、安全的专用规划器**解耦。

2.  **深入的技术子类剖析**
    *   在两大范式下，进一步细分子类，使技术脉络更清晰：
        *   **端到端VLA**：按输出形式分为**文本动作生成器**（输出语言命令/元动作）和**数值动作生成器**（输出连续轨迹/控制信号）。
        *   **双系统VLA**：按VLM与规划器的交互方式分为**显式动作引导**（VLM输出元动作或粗轨迹）和**隐式表示传递**（VLM作为教师模型，通过知识蒸馏或特征融合指导规划器）。

3.  **构建了面向VLA的评估生态系统全景图**
    *   系统总结了支持VLA训练与评估的**数据集**和**基准测试**，并区分了**开环**与**闭环**、**轨迹**与**文本**等不同评估模式。
    *   在多个主流基准（如nuScenes, NAVSIM, Bench2Drive, WOD-E2E）上对VA和VLA模型进行了**横向性能对比与分析**，为领域提供了重要的性能参照系。

### **解决方案路径**
论文通过构建这一理论框架，为领域指明了解决上述核心问题的技术方向：

1.  **提升可解释性与人机交互**：通过引入**语言**作为中间媒介，VLA模型能够生成决策**理由**（Chain-of-Thought），并理解自然语言**指令**，使系统行为更透明、更易与人类对齐。
2.  **增强泛化与长尾场景处理能力**：利用在大规模图文数据上预训练的**VLM骨干网络**，模型继承了丰富的世界知识和常识推理能力，有望更好地处理训练数据中罕见的“长尾”场景。
3.  **平衡性能与安全**：通过**双系统架构**，将需要大量计算、但具有强推理能力的VLM与保证实时性、安全性的传统规划器结合，在追求智能的同时不牺牲关键的安全底线。

### **实际价值**
1.  **领域路线图**：为研究人员和工程师提供了理解VLA领域的“导航图”，明确了技术分支、优势与挑战。
2.  **促进标准化**：提出的分类法和基准总结有助于统一领域术语和评估标准，推动更公平、更有意义的比较。
3.  **指明未来方向**：文末总结的挑战（如实时性、幻觉、长时序一致性）和未来方向（如统一的世界模型、社会意识驾驶、持续学习），为后续研究提供了清晰的议程。

**总结**：这篇论文的核心贡献是**概念化、系统化**了自动驾驶中的VLA范式。它精准地定义了该领域亟待解决的问题，并通过创建一个层次分明、论据丰富的分类框架，不仅梳理了现有技术，更实质性地**规划了实现更智能、可解释、人性化自动驾驶系统的技术路径**。这是一篇具有奠基性和指导意义的综述。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文旨在解决传统模块化自动驾驶系统在复杂、长尾场景下因手工规则和级联误差传播导致的泛化性差、可解释性弱、难以遵循人类指令等核心问题。为此，论文系统性地梳理并提出了 **Vision-Language-Action (VLA)** 这一新兴范式，该范式通过整合视觉-语言大模型的推理能力，将感知、语言理解和决策规划统一起来。论文的核心贡献是构建了一个清晰的VLA研究体系，将其主要架构划分为**端到端VLA**（单一模型直接输出动作）和**双系统VLA**（VLM负责慢思考与高层指导，专用规划器负责快执行）两大类，并进一步细分子类。通过对大量现有方法、数据集和评测基准的综述与分析，论文指出VLA模型在提升决策可解释性、指令跟随能力和对未知场景的泛化性方面展现出巨大潜力，但同时也面临着实时性、安全性保障、幻觉以及长时序推理等关键挑战，为未来研究指明了方向。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文创新点分析

这篇题为《Vision-Language-Action Models for Autonomous Driving: Past, Present, and Future》的综述论文，其核心创新点并非提出新的算法或模型，而在于为自动驾驶领域新兴的“视觉-语言-行动”范式提供了一个**系统性的、结构化的、领域聚焦的分析框架**。相较于已有的相关工作，其创新性主要体现在以下几个方面：

### 1. **领域聚焦的深度分析**
   - **改进/不同之处**： 以往的VLA综述（如 Ma et al., 2024b; Sapkota et al., 2025）或更广泛的具身智能VLA综述（如 Shao et al., 2024a）通常覆盖机器人、具身AI等多个领域。本文**将分析范围严格限定在自动驾驶领域**。
   - **解决的问题/带来的优势**： 这使得论文能够深入探讨自动驾驶特有的挑战（如安全关键性、实时性、长尾场景、多传感器融合）、数据集特性（如nuScenes, Waymo）和评估基准（如闭环仿真）。它提供了一个**领域专家所需的精细粒度**，而非泛泛而谈。

### 2. **历史脉络与概念演进的清晰梳理**
   - **改进/不同之处**： 论文没有孤立地介绍VLA模型，而是采用了 **“过去-现在-未来”的叙事框架**。它系统性地追溯了从早期**视觉-行动模型**到现代**视觉-语言-行动模型**的技术演进路径。
   - **解决的问题/带来的优势**：
     - **明确了技术动机**： 清晰地解释了为何要从VA转向VLA（如解决VA模型的可解释性差、缺乏推理能力、无法理解语言指令等根本缺陷）。
     - **建立了技术连续性**： 将VLA定位为VA自然演进的下一个阶段，而非凭空出现的技术，帮助读者理解领域发展的内在逻辑。

### 3. **提出层次化、精细化的VLA架构分类法**
   - **改进/不同之处**： 相较于以往工作的高层概述（如 Zhou et al., 2024; Yang et al., 2024d），本文提出了一个**两层分类体系**，并对子类进行了深入辨析。
     1.  **第一层：核心范式**
         - **端到端VLA**： 单一模型直接完成感知、推理、规划。
         - **双系统VLA**： 分离“慢思考”（VLM负责高层推理）和“快执行”（专用规划器负责安全关键的低层控制）。
     2.  **第二层：子类细分**
         - **端到端VLA**下，按输出形式分为**文本动作生成器**（输出语言命令）和**数值动作生成器**（输出轨迹或控制信号）。
         - **双系统VLA**下，按VLM与规划器的交互方式分为**显式动作指导**（VLM输出元动作或粗略路径点）和**隐式表示传递**（VLM作为教师模型，通过知识蒸馏或特征融合影响规划器）。
   - **解决的问题/带来的优势**：
     - **提供了清晰的研究地图**： 帮助研究人员快速定位自己工作的位置，理解不同技术路线的设计哲学、优缺点及适用场景。
     - **促进了对比分析**： 使得不同架构之间的权衡（如端到端的简洁性 vs. 双系统的安全性，文本输出的可解释性 vs. 数值输出的精确性）变得一目了然。

### 4. **对数据集与评估基准的整合与结构化分析**
   - **改进/不同之处**： 论文不仅列出数据集，还将其明确划分为 **“视觉-行动数据集”** 和 **“视觉-语言-行动数据集”** ，并详细说明了各类数据集如何支持VLA模型的训练与评估。同时，系统总结了**开环评估**与**闭环评估**的指标及其含义。
   - **解决的问题/带来的优势**：
     - **指明了数据需求**： 强调了VLA模型发展对高质量、多模态对齐数据（视觉-语言-动作三元组）的依赖。
     - **统一了评估标准**： 整理了从轨迹精度（L2, ADE）到驾驶分数（DS, PDMS），再到语言质量（BLEU, CIDEr）的全套指标，为公平比较不同VLA模型提供了基础。

### 5. **基于架构分类的挑战与未来方向论述**
   - **改进/不同之处**： 论文对挑战和未来方向的讨论并非泛泛而谈，而是紧密围绕其提出的分类体系展开。例如，指出端到端VLA的**实时性挑战**、双系统VLA中**显式指导的可靠性问题**、以及**隐式传递中可解释性丧失**的弊端。
   - **解决的问题/带来的优势**：
     - **使讨论更具针对性和洞察力**： 未来的研究方向（如“统一视觉-语言-世界模型”、“更丰富的多模态融合”、“社会意识驾驶”）被自然地关联到当前架构的局限性上，为后续研究提供了明确的着力点。

### 总结
总而言之，这篇论文的核心创新在于其**系统性、结构化和领域深度**。它成功地将快速发展的VLA for AD领域“地图化”，通过一个精心设计的分类框架，整合了历史脉络、现有方法、数据集和未来挑战。这为领域内的研究人员和从业者提供了一个**不可或缺的参考框架和路线图**，有助于引导资源投向最关键的问题，并促进不同技术路线之间的对话与融合。其价值不在于提出某个具体算法，而在于为整个子领域建立了清晰的认知体系。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 论文实验与评估效果分析

该论文是一篇综述性文章（Survey），**并未提出新的模型或方法**，因此**没有进行传统的定量实验来验证某个具体模型的性能**。论文的核心贡献在于对现有Vision-Language-Action (VLA) 模型领域进行系统性的梳理、分类和总结。

然而，论文通过**系统性的文献综述和基准测试结果汇总**，清晰地展示了VLA模型领域的发展现状、性能水平和未来挑战。其“实验与评估”部分实质上是**对现有主流方法在关键基准测试上的表现进行横向对比和分析**。

### 1. 使用的数据集与评价指标
论文在第5节（Datasets & Benchmark）和第5.3节（Quantitative Experiments & Analyses）中，详细汇总并分析了用于训练和评估VA/VLA模型的主流数据集和评价指标。

#### **核心数据集**
论文将数据集分为两大类，并在表4中进行了详细总结：

*   **Vision-Action (VA) 数据集**：为传统端到端驾驶提供感知-动作对。
    *   **nuScenes**：多传感器数据，用于开环规划评估。
    *   **nuPlan**：包含长时序轨迹和仿真接口，用于**闭环评估**。
    *   **Waymo Open Dataset**：大规模真实世界数据。
    *   **Bench2Drive**：基于CARLA的仿真**闭环评估**基准。
    *   **NAVSIM**：基于nuPlan的**闭环仿真**环境，提供综合驾驶评分。

*   **Vision-Language-Action (VLA) 数据集**：在VA数据基础上增加了语言标注（指令、问答、推理链等）。
    *   **BDD-X**：带有驾驶员行为解释（Rationale）。
    *   **DriveLM**：图结构的视觉问答（VQA），用于推理评估。
    *   **ImpromptuVLA**：专注于**长尾和 corner cases** 的大规模VLA数据集。
    *   **CoVLA**：提供图像-轨迹-描述三元组。

#### **核心评价指标**
论文在表9中系统总结了评价指标，主要分为两类：

*   **轨迹/控制信号评估**：
    *   **开环指标**：衡量预测轨迹与专家轨迹的差异。
        *   **L2误差**：轨迹点之间的平均欧氏距离。
        *   **碰撞率 (CR)**：预测轨迹与其他交通参与者发生碰撞的比例。
        *   **平均位移误差 (ADE)** / **最终位移误差 (FDE)**。
    *   **闭环指标**：衡量在仿真环境中执行策略的综合表现。
        *   **驾驶分数 (DS)**：路线完成度与违规惩罚的加权。
        *   **成功率 (SR)**：成功完成导航任务的比例。
        *   **NAVSIM的PDMS**：聚合了无碰撞、驾驶可接受性、时间到碰撞、自我进度和舒适度等多个子分数的综合指标。
        *   **WOD-E2E的RFS**：基于**人类偏好标注**的轨迹质量评分，更关注驾驶行为的人类对齐性。

*   **文本/语言评估**：
    *   用于评估模型生成的语言指令或解释的质量。
    *   指标包括：**CIDEr, BLEU, ROUGE, METEOR, VQA准确率**等。

### 2. 对比的基线方法与性能分析
论文在第5.3节通过多个表格（表5, 6, 7, 8）汇总了在四大主流基准上，**代表性VA模型与VLA模型的性能对比**。这实质上构成了一个全面的“方法竞赛”成绩单。

#### **关键对比与结论**
1.  **nuScenes 开环规划基准（表5）**：
    *   **对比方法**：包括顶级VA模型（如UniAD, VAD）和新兴VLA模型（如Drive-R1, OpenDriveVLA, S4-Driver）。
    *   **主要结论**：性能最佳的VLA模型（如Reasoning-VLA, VDrive）在L2误差上已经达到或超越了顶级VA模型。这表明**融合语言推理能力并不一定以牺牲轨迹精度为代价**，甚至可以通过更好的场景理解来提升精度。例如，Reasoning-VLA取得了0.22m的平均L2误差，是表中最佳成绩之一。

2.  **WOD-E2E 长尾场景基准（表6）**：
    *   **对比方法**：包含Waymo官方基线、VA模型（DiffusionDrive）和VLA模型（AutoVLA, Poutine, dVLM-AD）。
    *   **主要结论**：这是最能体现VLA价值的测试。一些VLA模型（如Poutine）在**人类偏好评分（RFS）** 上取得了最高分（7.99），甚至超过了纯VA模型。这表明在复杂的、安全关键的长尾场景中，**具备推理能力的VLA模型能产生更符合人类预期的驾驶行为**。然而，也有部分VLA模型（如OpenEMMA）表现不佳，说明**如何有效对齐语言推理与动作生成仍是挑战**。

3.  **NAVSIM 闭环规划基准（表7）**：
    *   **对比方法**：涵盖了各类世界模型和VLA模型。
    *   **主要结论**：表现最好的模型是VLA模型**ReflectDrive (PDMS: 94.7)** 和 **AutoVLA (PDMS: 92.1)**，它们显著超过了多数VA世界模型。这证明**将语言推理与规划结合，在需要安全、长远考量的闭环决策中具有优势**。

4.  **Bench2Drive 闭环驾驶基准（表8）**：
    *   **对比方法**：在CARLA仿真中测试闭环驾驶能力。
    *   **主要结论**：VLA模型**SimLingo**取得了最高的驾驶分数（85.94）和成功率（67.27%），显著优于传统VA模型。这突出了**语言指令跟随和动作对齐在完成具体导航任务时的价值**。

### 3. 综合性能提升与核心结论
通过对这些汇总数据的分析，论文揭示了VLA模型相对于传统VA模型的**核心优势与现状**：

*   **性能相当或更优**：在标准开环轨迹精度指标（如L2误差）上，最好的VLA模型已经与最好的VA模型持平甚至略有超越，打破了“引入语言会降低精度”的顾虑。
*   **长尾与复杂场景优势**：在WOD-E2E等包含大量 corner cases 的基准上，VLA模型通过**人类偏好评分（RFS）** 展现出了独特优势，说明其决策更符合人类常识和预期，在处理罕见、模糊场景时潜力更大。
*   **闭环决策与安全性**：在NAVSIM和Bench2Drive等闭环基准上，领先的VLA模型在综合安全、进度、舒适度的指标（如PDMS, DS）上表现突出，表明**语言赋能的高层推理有助于做出更安全、更合理的序列决策**。
*   **核心挑战依然存在**：汇总结果也显示VLA模型性能**方差较大**。部分模型表现不佳，反映出在**实时效率、推理-动作对齐、对抗幻觉**等方面仍存在重大挑战。VLA模型的成功高度依赖于精心的架构设计、训练策略和高质量数据。

**总结**：这篇论文虽然没有进行原创性实验，但通过**系统性梳理和对比现有文献的评估结果**，强有力地论证了VLA范式在自动驾驶领域的价值：它在不损失基础性能的前提下，为系统带来了**可解释性、更好的长尾泛化能力、人类指令跟随能力以及更人类对齐的决策风格**。同时，论文也客观地指出了该范式在落地前必须解决的效率、可靠性等关键问题。所有分析和结论都基于对现有公开基准测试结果的汇总和解读。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2512.16760v2)
- [HTML 版本](https://arxiv.org/html/2512.16760v2)
