# Unifying Deep Predicate Invention with Pre-trained Foundation Models

**相关性评分**: 6.0/10

**排名**: #34


---


## 基本信息

- **arXiv ID**: [2512.17992v1](https://arxiv.org/abs/2512.17992v1)
- **发布时间**: 2025-12-19T18:59:56Z
- **相关性评分**: 6.0/10
- **是否相关**: 是

## 作者

Qianwei Wang, Bowen Li, Zhanpeng Luo, Yifan Xu, Alexander Gray, Tom Silver, Sebastian Scherer, Katia Sycara, Yaqi Xie

## 关键词

Vision-Language-Action Model, VLA for Robotics, Inference Efficiency, Lightweight Architecture, Edge Deployment

## 一句话总结

UniPred框架通过结合大型语言模型和视觉基础模型，统一了自上而下和自下而上的谓词学习方法，提升了机器人任务的成功率和学习速度，但未明确强调推理效率或轻量级架构。

## 摘要

Long-horizon robotic tasks are hard due to continuous state-action spaces and sparse feedback. Symbolic world models help by decomposing tasks into discrete predicates that capture object properties and relations. Existing methods learn predicates either top-down, by prompting foundation models without data grounding, or bottom-up, from demonstrations without high-level priors. We introduce UniPred, a bilevel learning framework that unifies both. UniPred uses large language models (LLMs) to propose predicate effect distributions that supervise neural predicate learning from low-level data, while learned feedback iteratively refines the LLM hypotheses. Leveraging strong visual foundation model features, UniPred learns robust predicate classifiers in cluttered scenes. We further propose a predicate evaluation method that supports symbolic models beyond STRIPS assumptions. Across five simulated and one real-robot domains, UniPred achieves 2-4 times higher success rates than top-down methods and 3-4 times faster learning than bottom-up approaches, advancing scalable and flexible symbolic world modeling for robotics.

## 详细分析

## 论文摘要：UniPred——基于预训练基础模型的深度谓词发明统一框架

### 1. 研究背景和动机
长期机器人任务因连续的状态-动作空间和稀疏反馈而极具挑战。符号世界模型通过将任务分解为捕捉物体属性和关系的离散谓词，为解决此问题提供了高效且可泛化的框架。现有方法要么采用**自上而下**的方式（依赖基础模型提示，缺乏数据基础），要么采用**自下而上**的方式（从演示中学习，缺乏高层先验）。这两种方法在效率、鲁棒性和泛化性上各有局限。本文旨在**统一这两种范式**，提出一个能够高效、鲁棒地发明并学习符号谓词的框架。

### 2. 核心方法和技术创新
本文提出了 **UniPred**，一个双层学习框架，其核心创新在于：
- **基于基础模型的统一双层学习**：利用大型语言模型（LLM）提出谓词及其效果分布的初始假设，作为监督信号来训练基于低级数据的神经谓词分类器。同时，分类器的训练损失作为反馈，迭代地修正LLM的假设，形成一个高效的闭环学习过程，避免了繁琐的领域特定提示工程。
- **感知可泛化的谓词分类器**：在图像领域，UniPred利用强大的视觉基础模型（如DINOv3）提取物体中心特征，并在此之上优化神经谓词分类器，使其在杂乱场景中也能保持鲁棒性。
- **派生感知的谓词选择**：明确区分**基本谓词**（由分类器直接判断）和**派生谓词**（由基本谓词通过量词等逻辑运算派生）。在谓词选择阶段，将派生谓词视为派生关系约束进行处理，从而能够为超越经典STRIPS假设的复杂领域（如包含“擦桌子”这种需要全局条件判断的操作）构建有效的符号世界模型。

### 3. 主要实验结果
在**5个模拟域**（涵盖位姿、点云、图像等状态表示）和**1个真实机器人桌面清理域**上进行了全面评估：
- **与自上而下方法相比**：UniPred在真实图像域上取得了**2~4倍**的成功率提升，因为它学习的谓词能更好地在数据中落地，且不依赖精心设计的提示。
- **与自下而上方法相比**：UniPred的学习速度提升了**3~4倍**，这得益于LLM先验知识对搜索空间的引导。
- **泛化能力**：得益于学习到的关系型符号世界模型，UniPred在涉及未见物体组合和配置的测试任务上表现出强大的泛化能力，显著优于基于行为克隆的模型无关基线。

### 4. 研究意义和价值
UniPred是迈向**可扩展、灵活的机器人符号世界建模**的关键一步。它**创造性地统一了基础模型的常识先验与数据驱动的具体学习**，在保持自下而上方法可靠性的同时，大幅提升了学习效率。这项工作表明，将基础模型作为**引导者而非执行者**，并与低级学习形成闭环，是解决长期规划中抽象学习难题的有效途径，为构建更通用、更高效的机器人智能系统提供了新思路。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析：UniPred

### **一、 核心问题**
论文旨在解决**机器人长时程任务规划**中的一个根本性难题：如何自动、高效地从低级感知数据（如图像、点云）中学习出鲁棒且富有表达力的**符号谓词**，以构建支持分层规划的符号世界模型。

- **背景**：传统分层规划（如任务与运动规划，TAMP）依赖手工设计的符号模型（如谓词、操作符），这限制了其可扩展性。
- **现有方法的局限**：
    1.  **自上而下方法**：利用预训练的基础模型（如LLM、VLM）零样本生成谓词。**问题**：依赖精心设计的提示词，在专业领域或杂乱场景中不稳定，缺乏数据基础。
    2.  **自下而上方法**：仅从演示数据中优化学习谓词。**问题**：谓词搜索空间组合爆炸，学习效率极低，且通常局限于满足STRIPS假设的简单领域。

### **二、 核心创新点**
论文提出了 **UniPred** 框架，其核心创新在于**统一了自上而下的先验知识与自下而上的数据驱动学习**，形成了一个双层学习闭环。

#### **1. 基于基础模型的统一双层学习框架**
- **机制**：利用**大语言模型** 根据任务描述和部分PDDL域定义，提出候选谓词及其在操作符中的**效应分布**。这些效应分布作为伪标签，用于监督**神经谓词分类器** 从低级数据中学习。
- **关键闭环**：分类器的训练损失作为**反馈**，回传给LLM，指导其修正和优化后续的谓词提案。这避免了繁琐的提示工程，并显著提升了探索效率。
- **视觉特征增强**：在图像领域，利用强大的**视觉基础模型** 提取物体中心特征，并在此特征上优化谓词分类器，从而在少量演示数据下获得具有感知泛化能力的鲁棒谓词。

#### **2. 派生感知的谓词选择方法**
- **洞察**：在复杂领域（如“擦桌子”），**派生谓词**（如 `∀?toy. ¬OnTable(?toy)`）对于规划至关重要，但它们通常不遵循STRIPS假设（即不会作为操作符的直接效应出现）。
- **解决方案**：在谓词选择阶段，明确区分**基本谓词**和**派生谓词**。
    - 仅将基本谓词加入操作符的效应集。
    - 将派生谓词视为由基本状态**推导得出的关系约束**。在规划评估时，先通过操作符更新基本原子状态，再通过“派生闭包”计算派生原子的真值。
- **价值**：使得学习到的符号世界模型能够表达更复杂的全局概念和量化关系，从而适用于更广泛的非STRIPS领域。

### **三、 解决方案架构**
UniPred 的工作流程分为四个主要阶段：
1.  **数据准备**：收集离线演示数据，提取物体中心的状态表示。
2.  **谓词候选学习**：执行上述的LLM-in-the-loop双层学习，生成基本动态谓词候选池。
3.  **谓词选择与操作符学习**：使用派生感知的爬山搜索算法，从候选池中选择对规划最有价值的谓词子集（包括基本谓词和有用的派生谓词），并据此学习操作符和采样器。
4.  **推理与闭环规划**：在新任务中，用学习到的分类器从观测图像中提取符号状态，进行符号规划，并在执行失败时利用更新后的状态进行重规划。

### **四、 实际价值与效果**
- **性能提升**：在5个模拟和1个真实机器人领域上的实验表明：
    - 相比纯自上而下方法（如Pix2Pred），**成功率提高2~4倍**。
    - 相比纯自下而上方法（如IVNTR），**学习速度快3~4倍**。
- **泛化能力强**：学习的谓词和符号模型能够泛化到演示中未见过的新物体组合、更多物体数量和更复杂的初始状态。
- **实用性高**：
    - **免于提示工程**：通过反馈循环减少了对领域特定提示的依赖。
    - **支持复杂领域**：派生感知选择使其能处理包含非STRIPS操作符的现实任务。
    - **感知鲁棒**：利用VFM特征，能在杂乱的真实图像场景中有效工作。

### **结论**
UniPred 通过**创造性地将基础模型的常识先验与数据驱动的神经学习相结合**，并引入**派生感知的谓词选择机制**，成功解决了高效、鲁棒地自动发明符号谓词这一关键问题。它推动了面向机器人长时程规划的可扩展、灵活的符号世界建模技术的发展，是神经符号AI和具身智能领域的一项重要进展。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文针对机器人长时程任务规划中符号谓词（predicate）自动发明这一核心难题，提出了一种名为UniPred的双层学习框架，旨在统一“自上而下”（利用基础模型先验）和“自下而上”（从低级数据学习）两种传统方法的优势。其核心方法是通过大语言模型（LLM）提出谓词及其效果分布的初始假设，以此作为监督信号来训练神经谓词分类器；同时，分类器的训练损失又作为反馈，迭代地引导LLM修正其假设，形成一个闭环的“LLM在环”学习过程。此外，该方法还引入了“派生感知”的谓词选择机制，以处理非STRIPS领域的复杂规划问题。实验结果表明，UniPred在多个模拟和真实机器人领域取得了显著效果：相比纯自上而下的方法，其任务成功率提高了2-4倍；相比纯自下而上的方法，其学习速度提升了3-4倍，从而实现了更高效、更鲁棒且无需大量领域特定提示工程的符号世界建模。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文创新点分析

这篇论文提出的 **UniPred** 框架，在深度谓词发明领域做出了多项明确的创新，旨在统一“自上而下”和“自下而上”两种范式，以解决长视野机器人任务规划中的核心挑战。以下是其核心创新点及其与以往工作的对比和优势：

### 1. **基于基础模型的统一双层学习框架**
- **改进/不同之处**：
    - **以往方法**：
        - **自上而下方法**（如Pix2Pred）：直接使用预训练的大型语言模型（LLM）或视觉语言模型（VLM）进行零样本谓词提议和分类。它们依赖精心设计的提示词，且模型冻结，无法从领域数据中学习。
        - **自下而上方法**（如IVNTR）：完全从低级数据（如演示轨迹）中通过组合搜索和基于效果的监督来优化神经谓词分类器，不利用任何高层先验知识。
    - **UniPred**：创造性地将两者结合，形成一个**迭代的、闭环的双层学习系统**。LLM作为“提议者”，根据任务描述和部分PDDL域生成初始谓词及其效果分布假设。这些假设作为伪标签，用于监督从低级数据中学习神经谓词分类器。然后，分类器的训练损失作为**反馈**返回给LLM，指导其修正和细化后续的谓词提议。
- **解决的问题/带来的优势**：
    - **解决了提示工程依赖和领域适应性问题**：不再需要为每个新领域精心设计提示词。LLM的提议通过数据反馈进行校准，使其生成的谓词更贴合特定机器人任务的实际动态。
    - **大幅提升了学习效率**：LLM的先验知识极大地缩小了组合爆炸的谓词搜索空间。相比纯自下而上的方法（如IVNTR），UniPred实现了 **3~4倍的加速**，因为避免了从零开始的盲目搜索。
    - **提高了在杂乱场景中的鲁棒性**：与纯自上而下、依赖冻结VLM进行零样本分类的方法相比，UniPred学习的神经分类器在特定领域数据上进行了优化，对场景变化和视觉噪声更具鲁棒性。

### 2. **派生感知的谓词选择机制**
- **改进/不同之处**：
    - **以往方法**：在谓词选择阶段（通常使用爬山算法优化规划驱动目标），将基本谓词（如 `OnTable(?toy)`）和派生谓词（如 `∀?toy. ¬OnTable(?toy, ?table)`）**同等对待**，都视为可由操作符效果直接修改的原子。这在**非STRIPS领域**会导致问题，因为派生谓词（尤其是包含量词的）通常不直接出现在任何操作符的“增加/删除效果”集中。
    - **UniPred**：明确区分**基本动态谓词**和**派生动态谓词**。在学习和构建操作符模型时，只将基本谓词放入效果集。在规划评估过程中，采用**派生闭包**策略：先通过操作符更新基本谓词的真值，再根据派生谓词的定义（如全称量词）**推导**出派生谓词的真值。
- **解决的问题/带来的优势**：
    - **支持非STRIPS领域建模**：这是关键突破。使得系统能够学习并利用表达全局状态或复杂关系的谓词（例如，“桌子上没有玩具了”是执行“擦桌子”动作的关键前提）。以往方法（如IVNTR）在此类领域完全失效（成功率为0），而UniPred可以成功建模。
    - **获得更具表达力的符号世界模型**：能够捕捉到仅靠基本关系无法描述的抽象概念，从而支持更复杂、更智能的规划。

### 3. **在视觉基础模型特征上优化谓词分类器**
- **改进/不同之处**：
    - **以往方法**：
        - 在图像领域，要么使用冻结的VLM特征进行零样本分类（不稳定），要么从零开始训练分类器（数据效率低）。
        - 使用手工设计的特征或简单网络处理图像。
    - **UniPred**：提出在强大的、预训练的**视觉基础模型（如DINOv3）提取的对象中心特征之上**，来优化（微调）谓词分类器。首先利用对象检测器获取图像块，然后用VFM编码为丰富的特征向量，最后在这些特征上训练轻量级的MLP分类器。
- **解决的问题/带来的优势**：
    - **实现了感知层面的高效泛化**：DINOv3等VFM提供的特征本身就编码了丰富的几何和语义信息，为谓词分类提供了强大的初始化。这使得UniPred能够**仅用约20条演示轨迹**，就在真实的杂乱桌面清理场景中学习到泛化能力强的谓词分类器。
    - **提升了在真实图像上的性能**：相比直接使用VLM进行像素到符号的映射（Pix2Pred），这种“VFM特征 + 数据驱动优化”的方案对视觉变化、遮挡和噪声的鲁棒性更强，从而在真实机器人任务上取得了显著更高的成功率。

### 总结
UniPred的核心创新在于**系统性整合**：
1.  **用LLM的常识先验引导搜索**，解决了自下而上方法的效率瓶颈。
2.  **用数据驱动的反馈修正LLM**，解决了自上而下方法的领域不匹配和提示工程难题。
3.  **用派生感知的选择机制**，突破了符号模型对STRIPS假设的依赖，扩展了应用范围。
4.  **用VFM特征作为学习基础**，解决了从少量真实图像数据中快速学习鲁棒感知抽象的问题。

这些创新共同作用，使得UniPred在模拟和真实场景中，既能达到接近自下而上方法的**高精度**，又能获得接近自上而下方法的**高效率**，同时还在复杂领域实现了以往方法无法完成的**建模能力**，为机器人可扩展、灵活的符号世界建模推进了重要一步。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 实验与评估效果总结

论文通过全面的实验评估了UniPred框架在多个机器人规划领域的性能，证明了其在**学习效率、泛化能力和任务成功率**方面的显著优势。

### 一、 使用的数据集与评价指标

1.  **数据集（6个规划领域）**：
    *   **5个模拟领域**：涵盖多种状态表示。
        *   **Satellites**：SE(2)位姿状态，卫星协作任务。
        *   **Blocks**：3D向量状态，积木堆叠任务。
        *   **Tools**：点云状态，工具使用任务。
        *   **Packing**：图像+位姿状态，约束装箱任务。
        *   **Table Clean Sim**：SE(2)位姿状态，桌面清洁任务（核心示例）。
    *   **1个真实机器人领域**：
        *   **Table Clean Real**：RGB图像状态，真实桌面清洁任务。

2.  **评价指标**：
    *   **核心指标**：**任务成功率**。在训练任务分布 (`𝒯_train`) 和更具挑战性的测试任务分布 (`𝒯_test`) 上分别评估。
    *   **效率指标**：**总学习时间 `τ` (秒)**。包括谓词发明 (`τ_predinv`)、谓词选择 (`τ_predsel`) 和技能学习 (`τ_skill`) 的时间。
    *   **真实机器人评估**：除了离线任务规划成功率，还报告了在物理系统上执行的**平均分数成功率**（衡量任务完成度）。

### 二、 对比的基线方法

论文与两大类基线方法进行了系统对比：

1.  **纯自底向上方法**：
    *   **IVNTR**：基于神经损失引导符号效应搜索的谓词发明方法。是UniPred最主要的效率对比对象。
    *   **Grammar**：基于预定义语法规则的谓词发明方法。
    *   **GNN / Transformer**：基于关系神经网络或Transformer的行为克隆策略，作为非符号化、端到端方法的代表。

2.  **纯自顶向下方法**：
    *   **Pix2Pred及其变体**：利用视觉-语言模型进行零样本谓词提议和标注的顶层方法。论文评估了其原始版本、提供真实谓词集的版本、以及部分提供真实标注的版本。
    *   **ViLa及其变体**：直接基于VLM进行图像到规划的端到端方法。包括零样本、少样本和经过大量提示工程优化的版本。
    *   **ACT**：端到端的视觉运动模仿学习方法，作为非分层规划的基线。

### 三、 关键性能提升与结论

1.  **相对于纯自顶向下方法（Pix2Pred, ViLa）的显著成功率提升**：
    *   **在真实图像领域（Table Clean Real）**，UniPred取得了**94.0%**（训练）和**92.0%**（测试）的离线任务规划成功率。
    *   相比之下，最强的Pix2Pred变体（提供真实谓词+部分真实标注）成功率为**87.3%**（训练）和**73.3%**（测试）。
    *   经过大量提示工程的ViLa-HPE成功率仅为**20.7%**（训练）和**11.3%**（测试）。
    *   **结论**：UniPred通过数据驱动的神经分类器学习和闭环反馈，克服了纯VLM方法在**专业领域提示依赖性强、场景杂乱时标注不稳定**的缺陷，实现了**2~4倍的成功率提升**。

2.  **相对于纯自底向上方法（IVNTR）的显著学习效率提升**：
    *   在**Tools**（点云）领域，UniPred达到了与IVNTR相同的100%成功率，但总学习时间 (`τ`) 仅为 **11,779.2秒**，而IVNTR需要 **45,167.2秒**，实现了**近4倍的加速**。
    *   在**Satellites**和**Blocks**领域也观察到**3~4倍**的学习速度优势。
    *   **结论**：UniPred利用LLM的先验知识高效引导谓词空间探索，避免了IVNTR完全从零开始的组合搜索，**大幅提升了学习效率**。

3.  **在非STRIPS域的有效性证明**：
    *   在需要派生谓词（如“所有玩具都不在桌上”）的**Table Clean Sim**域，UniPred成功率为**96.0%**（训练）和**93.4%**（测试）。
    *   IVNTR和未使用派生感知选择的UniPred变体在该域的成功率均为**0%**。
    *   **结论**：UniPred提出的**派生感知谓词选择**机制对于在复杂、非STRIPS假设的规划域中构建有效的符号世界模型至关重要。

4.  **强大的跨领域和跨模态泛化能力**：
    *   UniPred在**所有五个模拟领域**（涵盖位姿、点云、图像等状态表示）均取得了接近Oracle的高成功率（训练>96%，测试>81.6%）。
    *   行为克隆基线（GNN/Transformer）在训练集上表现尚可，但在测试集上**泛化能力急剧下降**（如Satellites域测试成功率从92.4%跌至11.6%），凸显了符号抽象对于组合泛化的价值。

5.  **真实机器人部署成功**：
    *   在真实机器人执行中，UniPred取得了**0.777**的平均分数成功率，显著优于最强基线Pix2Pred变体的**0.521**，证明了框架从仿真到实物的有效迁移和闭环执行的鲁棒性。

**总结**：UniPred通过统一自顶向下先验与自底向上数据反馈的双层学习框架，在**不依赖精细提示工程**的前提下，实现了**媲美纯自底向上方法的性能**和**媲美纯自顶向下方法的效率**，成功解决了长视野机器人任务规划中谓词发明的核心挑战，并在模拟和真实场景中得到了全面验证。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2512.17992v1)
- [HTML 版本](https://arxiv.org/html/2512.17992v1)
