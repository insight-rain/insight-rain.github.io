# Single-View Shape Completion for Robotic Grasping in Clutter

**相关性评分**: 6.0/10

**排名**: #35


---


## 基本信息

- **arXiv ID**: [2512.16449v1](https://arxiv.org/abs/2512.16449v1)
- **发布时间**: 2025-12-18T12:11:05Z
- **相关性评分**: 6.0/10
- **是否相关**: 是

## 作者

Abhishek Kashyap, Yuxuan Yang, Henrik Andreasson, Todor Stoyanov

## 关键词

Vision-Language-Action Model, VLA for Robotics, Inference Efficiency, Lightweight Architecture, Inference Acceleration, Edge Deployment

## 一句话总结

该论文提出了一种基于扩散模型的单视图形状补全方法，用于提升杂乱场景中机器人抓取的成功率，但未直接涉及视觉-语言-动作模型或边缘部署等关键词。

## 摘要

In vision-based robot manipulation, a single camera view can only capture one side of objects of interest, with additional occlusions in cluttered scenes further restricting visibility. As a result, the observed geometry is incomplete, and grasp estimation algorithms perform suboptimally. To address this limitation, we leverage diffusion models to perform category-level 3D shape completion from partial depth observations obtained from a single view, reconstructing complete object geometries to provide richer context for grasp planning. Our method focuses on common household items with diverse geometries, generating full 3D shapes that serve as input to downstream grasp inference networks. Unlike prior work, which primarily considers isolated objects or minimal clutter, we evaluate shape completion and grasping in realistic clutter scenarios with household objects. In preliminary evaluations on a cluttered scene, our approach consistently results in better grasp success rates than a naive baseline without shape completion by 23% and over a recent state of the art shape completion approach by 19%. Our code is available at https://amm.aass.oru.se/shape-completion-grasping/.

## 详细分析

## 论文摘要

**论文标题：** 用于杂乱场景中机器人抓取的单视角形状补全

### 1. 研究背景和动机
在基于视觉的机器人操作中，单视角相机只能捕捉到物体的一面，而杂乱场景中的遮挡进一步限制了可见性，导致观测到的几何形状不完整。这使得抓取估计算法性能下降，容易产生碰撞或依赖不存在的表面。现有研究多针对孤立物体或简单场景，在真实、杂乱的家庭环境中的抓取效果不佳。因此，需要一种能够从部分观测中推理出完整物体几何形状的方法，以提升抓取成功率。

### 2. 核心方法和技术创新
本文提出了一种**系统级、模块化**的解决方案，用于杂乱场景下的物体抓取。其核心创新在于**利用扩散模型进行类别级的三维形状补全**。具体流程如下：
- **物体分割**：利用语言引导的实例分割模型（LangSAM）从RGB-D数据中分割出目标物体。
- **形状补全**：将分割得到的**部分、未对齐的点云**输入到基于**扩散模型**的形状补全网络（Diffusion-SDF）中。该网络使用符号距离场（SDF）表示，并针对不同物体类别（如瓶子、碗、盒子）分别训练，以解决几何相似物体的歧义问题，从而生成完整的3D形状。
- **抓取估计**：将补全后的完整形状输入到最先进的抓取生成网络（GraspGen）中预测抓取位姿，并通过多尝试策略提升鲁棒性。

### 3. 主要实验结果
在真实机器人（Franka Emika Panda）上进行了抓取实验评估：
- **形状补全质量**：在ReOcS数据集上，虽然Chamfer距离略高于对比方法ZeroGrasp，但本文方法的**重建成功率达到了100%**（ZeroGrasp为62-70%），能稳定生成有效网格。
- **抓取成功率**：在包含苹果、瓶子、碗等六类家庭物品的杂乱场景中，本文方法（结合形状补全）的平均抓取成功率达到**80%**。这显著优于**不使用形状补全的基线方法（56.67%）**，也超过了**最新的ZeroGrasp方法（61.67%）**，分别提升了约23%和19%。
- **推理时间**：完整流程在消费级GPU上约需4-5秒，具备实际应用潜力。

### 4. 研究意义和价值
本研究首次将**扩散模型驱动的形状补全**系统性地集成到机器人杂乱场景抓取中，并通过详实的真实机器人实验验证了其有效性。其价值在于：
- **技术贡献**：证明了从单视角、未对齐的局部点云进行**类别级形状补全**，能为抓取规划提供更丰富的几何上下文，是提升杂乱环境下抓取可靠性的有效途径。
- **实用价值**：模块化设计增强了系统的灵活性和可扩展性，为家庭服务机器人等需要在非结构化环境中可靠操作的任务提供了切实可行的解决方案。未来可通过语言对齐模型等方式进一步提升泛化能力。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析

### **研究问题**
论文旨在解决**机器人视觉抓取在杂乱场景中的核心挑战**：单视角RGB-D相机只能捕捉物体的部分表面，而场景中的遮挡进一步限制了可见几何信息。这导致基于不完整几何信息的抓取规划容易失败（例如，抓取点位于不可见表面或发生碰撞）。

### **核心创新点**
1.  **系统级集成方案**：首次将**扩散模型驱动的单视角三维形状补全**与机器人抓取完整流程（分割→补全→抓取规划）集成，专门针对**真实家庭杂乱场景**进行优化和验证。
2.  **面向真实场景的形状补全**：提出一种**类别级**的形状补全方法，使用扩散模型（Diffusion-SDF）从**任意位姿、部分遮挡**的点云中重建完整物体几何。与先前工作不同，该方法强调在**实际遮挡和噪声**下的鲁棒性。
3.  **全面的真实机器人验证**：在真实的家庭物品杂乱场景中，进行了从RGB-D输入到抓取执行的端到端系统评估，证明了形状补全对提升抓取成功率的实际价值。

### **解决方案（技术方法）**
论文采用模块化流水线解决该问题：

1.  **场景获取与物体分割**：
    - 使用静态RGB-D相机（Intel Realsense D435i）获取场景。
    - 利用**LangSAM**（基于语言提示的实例分割模型）根据文本指令（如“红色碗”）分割出目标物体，并提取其部分点云。

2.  **单视角物体重建（形状补全）**：
    - **表示方法**：采用**符号距离场（SDF）** 隐式表示三维形状。
    - **核心模型**：使用**Diffusion-SDF**模型进行形状补全。该模型结合了：
        - **GenSDF**：学习可泛化的SDF。
        - **变分自编码器（VAE）**：将形状压缩为潜在表示。
        - **扩散网络**：在潜在空间中进行去噪，从部分点云预测完整形状。
    - **关键设计**：采用**类别级**训练策略，为每个物体类别（如瓶子、碗、盒子）训练独立的模型，以解决不同类别间局部几何特征相似导致的歧义问题。

3.  **抓取位姿估计与执行**：
    - 将补全后的完整物体点云输入**GraspGen**（扩散模型抓取生成网络）预测候选抓取位姿及分数。
    - 设计**抓取选择策略**：优先选择接近垂直方向（40°锥角内）的抓取以降低碰撞风险，并采用多尝试（Top-K）策略应对运动规划失败。
    - 使用标准运动规划器（MoveIt2）执行抓取。

### **实际价值与效果**
- **性能提升**：在真实机器人实验中，使用形状补全的完整系统比**不使用形状补全的基线**抓取成功率平均提升 **23%**，比近期先进方法（ZeroGrasp）提升 **19%**。
- **鲁棒性**：在ReOcS数据集上的评估显示，其形状补全方法实现了 **100% 的重建成功率**，而对比方法存在约30-35%的失败案例。
- **实用性**：整个流水线在消费级GPU上推理时间约为 **4-5秒**，展示了在实际机器人系统中部署的可行性。

**总结**：该论文的核心贡献在于**将前沿的扩散生成模型（Diffusion-SDF）实用化地集成到机器人抓取系统中**，通过补全被遮挡的几何信息，显著提升了在真实、杂乱场景下的抓取可靠性，并通过详尽的真实实验验证了其有效性。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文旨在解决机器人视觉抓取中，由于单视角观测和场景遮挡导致的物体几何信息不完整问题，从而提升杂乱环境下抓取的成功率。论文提出了一种模块化系统框架，依次通过语言引导的开放词汇分割、基于扩散模型的类别级三维形状补全（使用SDF表示和Diffusion-SDF模型），以及抓取位姿估计网络（GraspGen），从单视角深度观测中恢复完整物体形状以辅助抓取规划。实验结果表明，该方法在真实机器人杂乱场景抓取任务中，相比不使用形状补全的基线方法，平均抓取成功率提升了23%，并优于最新的形状补全方法ZeroGrasp约19%，验证了完整几何信息对于提升抓取可靠性的实际价值。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文创新点分析

这篇论文《Single-View Shape Completion for Robotic Grasping in Clutter》在机器人杂乱场景抓取领域提出了多项明确的创新，主要体现在系统集成、方法设计和实验验证三个方面。

### 1. **首个面向真实杂乱场景的完整系统级集成方案**
   - **改进/不同之处**：以往工作（如3DSGrasp、SCARP、SceneGrasp）大多在**简化环境**（无遮挡或最小化杂乱）中评估，或仅在仿真中进行。本文首次构建了一个**从RGB-D输入到抓取执行**的完整流水线，专门针对**真实家庭杂乱场景**。
   - **解决的问题/优势**：解决了**实际机器人操作中因遮挡和视角限制导致几何信息不完整**的核心问题。通过集成开放词汇分割、扩散模型形状补全和模块化抓取生成，系统能够在真实噪声和遮挡下可靠工作，提升了实际应用的可行性。

### 2. **首次将扩散模型用于机器人操作中的形状补全**
   - **改进/不同之处**：首次将**基于扩散的生成模型（Diffusion-SDF）** 引入机器人抓取领域，用于从**单视角、未对齐的局部点云**中补全三维形状。相比以往使用自编码器或GAN的方法，扩散模型能生成更高质量和多样化的完整几何。
   - **解决的问题/优势**：解决了**局部观测中形状模糊性**问题。扩散模型利用类别先验知识，能**推理并补全被遮挡或不可见的表面**，为抓取规划提供了更完整的几何上下文，从而减少因几何缺失导致的碰撞或抓取失败。

### 3. **针对类别级形状补全的鲁棒性训练策略**
   - **改进/不同之处**：采用**按类别训练的集成模型**（每个类别一个独立模型），而非单一通用模型。训练时使用**虚拟相机光线投射模拟真实遮挡**，而非简单的距离过滤。
   - **解决的问题/优势**：解决了**跨类别几何相似性导致的歧义**问题（例如，曲面块可能属于瓶子、杯子或碗）。类别专用模型提供了更强的形状先验，而逼真的遮挡模拟提升了模型对**真实世界传感器噪声和复杂遮挡**的鲁棒性，确保补全形状的合理性。

### 4. **在真实机器人实验中进行全面抓取验证**
   - **改进/不同之处**：在**真实机器人平台**（Franka Emika Panda）上，使用**实际RGB-D相机观测**，对**多种家庭物品**在**设计的高遮挡杂乱场景**中进行了系统的抓取成功率评估。相比之下，基线方法ZeroGrasp虽在真实世界测试，但其重建质量较差且部分失败。
   - **解决的问题/优势**：提供了**切实的性能证据**，而非仅仿真或简化场景结果。实验证明，形状补全预处理使平均抓取成功率比无补全基线提升23%，比近期先进方法（ZeroGrasp）提升19%，**直接验证了该方法在实际应用中的价值**。

### 5. **模块化流水线设计，支持组件灵活替换**
   - **改进/不同之处**：将任务分解为**分割、补全、抓取推断**三个独立模块。这与需要端到端重新训练的“单体式”方法不同。
   - **解决的问题/优势**：解决了**系统灵活性和可扩展性**问题。允许单独改进或替换某个模块（例如，使用更先进的分割或抓取网络），而无需重新训练整个系统，**降低了开发成本并便于未来升级**。

### 总结
本文的核心创新在于**将前沿的扩散生成模型与机器人抓取的实际需求紧密结合**，并通过**系统级的集成和严格的真实世界验证**，证明了形状补全在提升杂乱场景抓取性能中的关键作用。其方法不仅**性能更优**，而且对**真实世界的噪声、遮挡和物体多样性**更具鲁棒性。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 论文实验与评估效果分析

该论文通过**真实机器人实验**和**重建质量评估**，全面验证了所提出的基于扩散模型的单视角形状补全系统在提升杂乱场景中抓取成功率方面的有效性。

### 一、 使用的数据集
1.  **训练数据集**：为训练类别级形状补全模型，作者从三个合成模型库中筛选并构建了自定义数据集：
    *   **3DNet**
    *   **ShapeNetCore**
    *   **HouseCat6D**
    *   **涉及类别**：苹果 (`apple`)、瓶子 (`bottle`)、碗 (`bowl`)、盒子 (`box`)、罐子 (`can`)、锤子 (`hammer`)。（详见表1）

2.  **评估数据集**：
    *   **ReOcS 数据集**：用于评估**形状补全质量**。该数据集包含真实世界家居物品，并按杂乱和遮挡程度分为 `easy`、`normal`、`hard` 三个难度等级。
    *   **真实机器人实验场景**：作者设计了两种不同的真实场景布局（图4），以模拟适当的遮挡水平，对所有训练类别进行公平的抓取评估。这些场景的难度被评估为介于 ReOcS 的 `normal` 和 `hard` 之间。

### 二、 评价指标
1.  **形状补全质量**：
    *   **主要指标**：**双向倒角距离 (Bidirectional Chamfer Distance)**，单位毫米 (mm)，数值越低表示重建形状与真实形状越接近。
    *   **辅助指标**：**重建成功率 (%)**，定义为能够成功生成有效网格（或点云）的样本比例。

2.  **抓取性能**：
    *   **主要指标**：**抓取成功率 (%)**。在每种物体类别上进行10次试验，成功标准是目标物体被抓取并抬起后能保持超过5秒。

### 三、 对比的基线方法
论文与以下基线方法进行了对比：
1.  **无形状补全的基线**：直接使用 **GraspGen** 抓取网络在**原始分割出的部分点云**上进行抓取预测。这代表了不进行任何形状补全的“朴素”方法。
2.  **当前先进的形状补全方法**：**ZeroGrasp**。这是一个同时进行形状补全和抓取预测的最新工作，并在真实世界设置中进行了评估。论文将其作为**主要的形状补全对比基线**。

### 四、 关键性能结果与结论

#### 1. 形状补全质量 (在ReOcS数据集上)
*   **重建成功率**：本文方法 (`Ours`) 在 `bottle`、`box`、`can` 三个类别上的**重建成功率达到100%**，而 ZeroGrasp 的成功率在62%-70%之间（表2）。这表明本文方法在**鲁棒性**上具有显著优势。
*   **重建精度**：在双方都能成功重建的样本上，ZeroGrasp 报告的倒角距离数值更低（表2）。然而，作者指出 ZeroGrasp 的公开模型存在大量重建失败案例，且其成功样本的重建质量在视觉上存在明显缺陷（图5），因此其较低的倒角距离可能不具有完全的代表性。本文方法虽然倒角距离稍高，但能稳定输出**视觉上更合理、更完整**的几何形状（图3, 图5）。

#### 2. 抓取成功率 (在真实机器人实验中)
这是论文最核心的评估，结果总结于表3。
*   **与无补全基线对比**：使用本文形状补全后，**整体平均抓取成功率从56.67%提升至80%**，**绝对提升了23.33个百分点**。这表明形状补全为抓取规划提供了至关重要的完整几何上下文。
*   **与先进方法ZeroGrasp对比**：本文方法的**整体平均抓取成功率为80%**，**优于ZeroGrasp的61.67%**，**绝对提升了18.33个百分点**。在 `bottle`、`bowl`、`hammer` 等几何形状复杂或易受遮挡的类别上，优势尤为明显。
*   **关键结论**：
    *   **形状补全对抓取至关重要**：在杂乱场景中，利用扩散模型补全被遮挡的几何形状，能显著提升抓取算法的成功率。
    *   **方法的有效性与鲁棒性**：本文提出的**类别级扩散模型**结合**模块化系统管道**，能够在真实世界的杂乱和遮挡下，生成更可靠、更完整的物体形状，从而直接转化为更高的抓取成功概率。
    *   **系统级验证的价值**：与许多先前工作仅在仿真或简单设置中评估不同，本文通过从RGB-D输入到机器人抓取执行的完整系统在真实场景中的验证，证明了其**实际应用价值**。

#### 3. 推理时间
*   本文全管道（分割+补全+对齐+抓取估计）在笔记本GPU上耗时约 **4-5秒**。
*   ZeroGrasp 更快（2-3秒），但如前所述，其重建质量和抓取成功率均不及本文方法。论文指出，未来工作需致力于**减少推理时间**以实现实时应用。

**总结**：论文通过严谨的实验设计，在真实机器人任务中定量地证明了其基于扩散模型的形状补全系统能带来**约23%**（相比无补全）和**约19%**（相比先进方法ZeroGrasp）的抓取成功率提升，并强调了高重建成功率和合理几何形状输出对于下游抓取任务的实际价值。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2512.16449v1)
- [HTML 版本](https://arxiv.org/html/2512.16449v1)
