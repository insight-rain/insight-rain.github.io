# CoDrone: Autonomous Drone Navigation Assisted by Edge and Cloud Foundation Models

**相关性评分**: 8.0/10

**排名**: #1


---


## 基本信息

- **arXiv ID**: [2512.19083v2](https://arxiv.org/abs/2512.19083v2)
- **发布时间**: 2025-12-22T06:48:12Z
- **相关性评分**: 8.0/10
- **是否相关**: 是

## 作者

Pengyu Chen, Tao Ouyang, Ke Luo, Weijie Hong, Xu Chen

## 关键词

Vision-Language-Action Model, VLA for Robotics, Inference Efficiency, Lightweight Architecture, Inference Acceleration, Edge Deployment

## 一句话总结

CoDrone是一个云-边-端协同计算框架，通过集成基础模型和轻量化架构，提升无人机自主导航的推理效率和边缘部署能力。

## 摘要

Autonomous navigation for Unmanned Aerial Vehicles faces key challenges from limited onboard computational resources, which restrict deployed deep neural networks to shallow architectures incapable of handling complex environments. Offloading tasks to remote edge servers introduces high latency, creating an inherent trade-off in system design. To address these limitations, we propose CoDrone - the first cloud-edge-end collaborative computing framework integrating foundation models into autonomous UAV cruising scenarios - effectively leveraging foundation models to enhance performance of resource-constrained unmanned aerial vehicle platforms. To reduce onboard computation and data transmission overhead, CoDrone employs grayscale imagery for the navigation model. When enhanced environmental perception is required, CoDrone leverages the edge-assisted foundation model Depth Anything V2 for depth estimation and introduces a novel one-dimensional occupancy grid-based navigation method - enabling fine-grained scene understanding while advancing efficiency and representational simplicity of autonomous navigation. A key component of CoDrone is a Deep Reinforcement Learning-based neural scheduler that seamlessly integrates depth estimation with autonomous navigation decisions, enabling real-time adaptation to dynamic environments. Furthermore, the framework introduces a UAV-specific vision language interaction module incorporating domain-tailored low-level flight primitives to enable effective interaction between the cloud foundation model and the UAV. The introduction of VLM enhances open-set reasoning capabilities in complex unseen scenarios. Experimental results show CoDrone outperforms baseline methods under varying flight speeds and network conditions, achieving a 40% increase in average flight distance and a 5% improvement in average Quality of Navigation.

## 详细分析

## 论文《CoDrone：由边缘和云端基础模型辅助的自主无人机导航》详细摘要

**1. 研究背景和动机**
自主无人机（UAV）导航面临严峻挑战：机载计算资源有限，导致部署的深度神经网络（DNN）模型浅层，难以应对复杂环境；而将任务卸载到远程边缘服务器又会引入高延迟。现有方法（如纯机载DNN或边缘辅助框架）在**计算效率、环境感知鲁棒性和实时性**之间存在难以调和的矛盾。为突破这些限制，本文提出首个**云-边-端协同计算框架**，旨在将强大的基础模型（Foundation Models）智能地集成到资源受限的无人机平台中，以提升其在动态复杂环境中的自主导航性能。

**2. 核心方法和技术创新**
CoDrone框架的核心创新在于分层协同与智能调度：
*   **分层感知与决策**：
    *   **端（无人机）**：采用**灰度图像**输入和轻量级DNN导航模型，大幅降低计算与传输开销。
    *   **边（服务器）**：部署深度估计基础模型（Depth Anything V2），生成**一维占据栅格地图**，为导航提供细粒度空间感知，增强障碍物距离判断。
    *   **云**：集成视觉语言模型（VLM，如Qwen-VL-Max），在遇到极端或未知复杂场景时，提供**语义级环境理解和高层决策指导**。
*   **智能协同调度**：
    *   设计了一个**基于深度强化学习（DRL）的神经调度器**，能根据实时网络带宽、碰撞概率等状态，动态决策任务执行位置（机载/边缘）、图像压缩率和深度模型激活时机。
    *   提出了一个**无人机专用的视觉语言交互模块**，将低级飞行指令（如转向、移动）封装为VLM可调用的函数，使VLM能直接生成可执行控制命令，减少解析延迟。

**3. 主要实验结果**
在AirSim仿真环境中的大量实验表明，CoDrone显著优于基线方法（如AdaDrone）：
*   **导航性能提升**：在多种飞行速度和网络条件下，平均飞行距离**提升40%**，导航质量（QoN）平均**改善5%**。
*   **自适应能力**：神经调度器能有效适应网络带宽波动，在带宽下降时自动增加本地计算或图像压缩，保持较低的平均端到端延迟。
*   **VLM价值验证**：在复杂场景（如误入灌木丛）中，VLM能通过多轮函数调用成功引导无人机返回正确路径，其集成使系统在平均飞行距离和QoN上相比无VLM的消融版本有显著提升。

**4. 研究意义和价值**
本研究首次系统性地将云、边基础模型与端侧设备协同用于无人机自主导航，具有重要价值：
*   **技术层面**：为解决“有限机载资源”与“强大环境感知需求”之间的矛盾提供了创新架构，通过**灰度处理、一维占据栅格、函数调用**等一系列设计，在引入基础模型强大能力的同时，有效控制了延迟与开销。
*   **应用层面**：为无人机在物流、巡检、应急响应等低空经济关键场景中实现更**安全、可靠、智能**的自主巡航提供了可行的技术方案，推动了边缘智能与具身智能（Embodied AI）在无人系统领域的融合与发展。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析：CoDrone

### **一、 论文旨在解决的核心问题**
论文旨在解决**资源受限的无人机（UAV）在复杂动态环境中实现鲁棒、高效自主导航**的根本性矛盾。具体表现为三个关键挑战：

1.  **计算与感知的矛盾**：无人机机载计算资源有限，通常只能运行轻量级神经网络，导致环境感知能力不足，在复杂或未知场景中容易失效。
2.  **实时性与性能的矛盾**：将计算任务卸载到边缘服务器可以借助更强算力，但会引入网络延迟和带宽波动，影响导航的实时性和安全性。
3.  **语义理解缺失**：传统的基于视觉或深度估计的导航方法缺乏对环境的**高层语义理解**能力，在遇到前所未见的障碍物或需要遵循高级指令时（如“飞向红色大门”），决策能力受限。

### **二、 核心创新点**
论文提出了 **“云-边-端”协同计算框架**，首次将**基础模型**系统性地集成到无人机自主导航任务中，通过多层次、自适应的任务调度与协作来解决上述问题。其创新性主要体现在以下四个方面：

1.  **首创的协同计算架构**：
    - **创新**：首次提出并实现了融合**云端视觉语言模型**、**边缘深度估计模型**和**机载轻量导航模型**的三层协同框架。
    - **价值**：打破了传统方案要么“全机载”（性能差）要么“全卸载”（延迟高）的二元对立，实现了计算负载、感知精度和实时响应的动态平衡。

2.  **基于一维占据栅格的深度感知导航方法**：
    - **创新**：在边缘服务器部署Depth Anything V2模型进行深度估计，并创新性地提出 **DEGAGE算法**，将二维深度图转换为**一维占据栅格图**。
    - **价值**：
        - **数据简化**：一维表示极大降低了数据量，减少了传输和处理开销。
        - **决策优化**：结合**控制调整算法**，能更精确地识别“可通行区域”、“低风险区”和“高风险区”，从而动态调整无人机速度和转向角，显著提升避障精度。

3.  **基于深度强化学习的神经调度器**：
    - **创新**：设计了一个DRL智能体作为核心调度器，其**状态**（转向角、碰撞率、带宽等）和**动作**（执行位置、是否启用深度模型、图像压缩率）经过精心设计。
    - **价值**：能够在线学习并动态做出最优调度决策，在**网络波动**和**环境复杂度变化**时，自适应地选择在机载执行还是边缘卸载、是否启用深度辅助，最大化导航质量。

4.  **面向无人机的视觉语言交互模块**：
    - **创新**：
        - **函数调用机制**：将无人机底层飞控指令（如 `turn_left`, `move_forward`）封装为可调用函数，供云端VLM直接调用，避免了自然语言输出解析带来的延迟。
        - **结构化提示工程**：设计了包含工具描述、任务描述、历史记录等模块的提示词，使VLM能基于当前图像、历史状态和任务指令进行序列化推理。
        - **智能调用策略**：与神经调度器联动，仅在碰撞风险骤增或深度模型连续报警等**关键复杂场景**下才调用昂贵的云端VLM。
    - **价值**：为无人机赋予了**开放集推理和语义级环境理解**能力，使其能处理“未见过的障碍物”或执行基于高级语义指令的导航，极大增强了系统的鲁棒性和适应性。

### **三、 解决方案的总体思路**
论文通过一个**分层、自适应、协同**的系统（CoDrone）来整合上述创新点：

1.  **端侧（无人机）**：
    - 运行**轻量级导航DNN**，输入为**灰度图像**以降低计算和传输开销。
    - 负责图像采集、初步避障决策，并承载**神经调度器**。

2.  **边侧（边缘服务器）**：
    - 部署**深度估计模型**，在调度器指令下，为无人机提供精细的深度感知和占据栅格信息，增强避障能力。
    - 作为计算加速平台，处理部分导航推理任务。

3.  **云端**：
    - 部署**大型视觉语言模型**，在系统遇到极端复杂、语义模糊的场景时被**智能调用**。
    - 通过函数调用机制，直接生成可执行的飞控指令，解决传统方法无法处理的导航死锁或高级任务。

4.  **协同与调度**：
    - **神经调度器**是系统大脑，根据实时网络带宽、碰撞概率、环境复杂度等信息，动态决策**在哪里计算**、**是否使用深度信息**、**是否求助云端VLM**。
    - 整个系统以**导航质量**为优化目标，实现资源的最优配置。

### **四、 实际价值与验证**
- **性能提升**：在AirSim仿真环境中，相比基线方法（如AdaDrone），CoDrone实现了**平均飞行距离提升40%**，**平均导航质量提升5%**，并在不同速度和网络条件下均表现出更优的适应性和鲁棒性。
- **应用前景**：该框架为低空经济中无人机的物流配送、基础设施巡检、农业监测、应急救援等复杂任务提供了可行的**高智能、低功耗、强适应**的自主导航解决方案，推动了无人机从“自动化”向“智能化”的演进。

**总结**：CoDrone的核心贡献在于构建了一个智能的资源协同与任务调度生态系统，让计算受限的无人机能够按需、高效地利用边缘和云端强大的基础模型能力，从而在现实世界复杂动态环境中实现安全、可靠、智能的自主飞行。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文旨在解决资源受限的无人机在复杂环境中实现鲁棒、实时自主导航的难题，其核心矛盾在于轻量级机载模型感知能力不足与将计算卸载到边缘/云端所引入的高延迟之间的权衡。为此，论文提出了 **CoDrone** 框架，这是一个首创的云-边-端协同计算系统，其核心创新在于**分层式地集成基础模型来增强导航**：在终端使用灰度图像和轻量DNN进行基础避障；在边缘服务器动态调用深度估计模型（Depth Anything V2）生成一维占据栅格图，以提供精细的空间感知；在云端，则通过一个专为无人机设计的视觉语言模型（VLM）交互模块，在遇到极端或未知场景时提供高层语义推理和指令。整个系统由一个基于深度强化学习的神经调度器进行统一协调，动态决策任务执行位置、图像压缩率和模型调用时机。实验结果表明，该框架能有效协同不同层级模型，在动态网络和复杂环境下，相比基线方法平均飞行距离提升40%，导航质量提升5%，显著提高了无人机的自主导航性能和适应性。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文创新点分析

这篇论文《CoDrone: Autonomous Drone Navigation Assisted by Edge and Cloud Foundation Models》提出了一种创新的无人机自主导航框架。其核心创新点在于**首次系统性地将边缘与云端的基础模型（Foundation Models）协同集成到无人机导航中**，以解决资源受限平台在复杂环境中实现鲁棒、高效导航的难题。以下是其明确的创新点及其与以往方法的对比和优势：

---

### 1. **首创“云-边-端”协同的基础模型辅助导航框架**
- **改进/不同之处**：
    - **以往方法**：通常采用单一计算范式，要么完全依赖机载轻量级DNN（计算能力有限，环境感知粗糙），要么完全卸载到边缘服务器（受网络延迟和稳定性制约），或者尝试使用云端大模型但面临高延迟问题。这些方法未能**系统性地协同利用不同层级（端、边、云）的异构计算资源和不同能力（几何感知、语义理解）的模型**。
    - **CoDrone的创新**：提出了一个**分层协同计算框架**，将任务智能地分配给不同层级：
        - **端（无人机）**：运行极轻量的导航DNN，处理灰度图像，负责实时、高频的基础避障。
        - **边（边缘服务器）**：部署**深度估计基础模型（Depth Anything V2）**，在需要时提供精细的几何环境感知（深度图）。
        - **云**：部署**视觉语言模型（VLM，如Qwen-VL-Max）**，在极端复杂或未知场景下提供高层语义理解和推理。
- **解决的问题/带来的优势**：
    - **解决了“计算能力与感知精度”的根本矛盾**。它没有在“轻量但能力弱”和“强大但延迟高”之间二选一，而是通过协同让三者互补。
    - **实现了感知粒度的按需扩展**：从机载的“有无障碍”二元判断，到边缘的“障碍距离”几何感知，再到云端的“障碍是什么、该如何绕行”的语义理解，形成了递进式的环境认知能力。
    - **优势**：在保证实时性的前提下，大幅提升了无人机在动态、复杂、甚至前所未见环境中的导航鲁棒性和适应性。

### 2. **基于灰度图像与新型一维占据栅格的导航效率优化**
- **改进/不同之处**：
    - **以往方法**：导航模型通常处理RGB图像（3通道），计算和传输开销较大。环境感知多依赖二维分割图或原始深度图，数据量大且处理复杂。
    - **CoDrone的创新**：
        1.  **导航模型使用灰度图像（1通道）**：论文指出，颜色信息对障碍物本质特征贡献有限，但将输入通道减少66%，显著降低了机载计算量和向边缘传输的数据量。
        2.  **提出一维占据栅格地图（DEGAGE算法）**：将边缘服务器生成的深度图，通过垂直离散化，压缩成一个一维的“可飞行性”向量。这个向量直接对应无人机前方水平方向的障碍物分布。
- **解决的问题/带来的优势**：
    - **解决了资源受限下的计算与通信瓶颈**。灰度图像处理降低了端侧和边侧的核心计算负载。一维占据栅格相比二维深度图，**数据量极大减少，表征更简单**，使得基于它的控制调整算法（CAA）可以快速执行。
    - **优势**：在几乎不损失关键距离信息的前提下，实现了**更低的端到端延迟和更高的处理效率**，为实时导航决策赢得了宝贵时间。

### 3. **基于深度强化学习（DRL）的神经调度器**
- **改进/不同之处**：
    - **以往方法**：任务调度（如决定在端还是边执行、是否使用辅助模型）多基于启发式规则或静态策略，无法适应网络带宽、碰撞概率、转向角等多维度动态变化的状态。
    - **CoDrone的创新**：将调度问题建模为**马尔可夫决策过程（MDP）**，并设计了一个轻量的DRL智能体（A2C算法）作为神经调度器。它根据实时状态（碰撞率、转向角、平均碰撞率、网络带宽）来决策：`执行位置（端/边）`、`是否激活深度估计模型`、`图像压缩率`。
- **解决的问题/带来的优势**：
    - **解决了动态不确定环境下的自适应优化问题**。传统数学优化方法难以处理非平滑、高维、动态的调度目标。
    - **优势**：调度器能够**在线学习并执行最优策略**，在网络条件波动和环境复杂度变化时，动态平衡计算精度、通信开销和实时性，从而最大化导航质量（QoN）。如图17所示，它能根据带宽骤降自适应地切换计算位置或调整压缩率。

### 4. **面向无人机的、基于函数调用的视觉语言交互模块**
- **改进/不同之处**：
    - **以往方法**：将VLM用于无人机导航时，通常将其作为独立的指令生成模块，其输出是自然语言，需要额外的解析模块翻译成控制指令，流程冗长、延迟高、且容易出错。
    - **CoDrone的创新**：
        1.  **设计了无人机专属的低级飞行原语**（如 `move_forward`, `turn_left(angle)`, `get_current_position`），并将其封装为**可调用函数**。
        2.  **利用VLM的函数调用（Function Calling）能力**：精心设计的提示词（Prompt）让VLM直接输出**函数名和参数**，系统可直接执行，**省去了自然语言解析的步骤**。
        3.  **引入历史模块**：在Prompt中融入之前的图像和函数调用记录，支持VLM进行**序列推理**，避免决策循环或矛盾。
- **解决的问题/带来的优势**：
    - **解决了大模型与实时控制系统高效、准确对接的难题**。避免了“语言歧义”和“二次解析延迟”。
    - **优势**：实现了**云VLM对无人机控制的“无缝”、低延迟介入**。当无人机陷入传统方法无法处理的死局（如误入灌木丛）时，VLM能通过多轮函数调用（分析-行动-再分析）像“飞行员”一样将其引导回正确路径（如图18案例），极大地增强了系统在开放集场景下的处置能力。

### 5. **深度估计与导航决策的深度融合与量化评估**
- **改进/不同之处**：
    - **以往方法**：深度估计常作为独立的感知模块，其信息如何定量地影响和提升导航决策的安全性缺乏理论分析和清晰机制。
    - **CoDrone的创新**：
        1.  **理论分析**：论文通过公式推导（公式6,7）证明了在相同条件下，使用深度估计辅助的导航方法，其期望碰撞概率低于仅使用RGB图像的方法，因为深度估计的风险识别准确率 `R_depth >= R_rgb`。
        2.  **机制设计**：通过控制调整算法（CAA），将一维占据栅格信息直接用于**实时修正导航模型输出的转向角和速度**（如遇到高风险区域则紧急刹停，低风险区域则减速）。
- **解决的问题/带来的优势**：
    - **解决了辅助模型与主任务“两张皮”的问题**，提供了将增强感知可靠转化为安全增益的**明确方法论和量化依据**。
    - **优势**：不仅“用了”深度模型，更“用好”了它，使其贡献可衡量、可解释，确保了系统安全性的**实质性提升**。

---

**总结**：CoDrone的核心创新在于其**系统性、自适应性和协同性**。它不是单个技术的突破，而是通过一个精巧的框架，将**灰度图像处理、边缘深度估计、云端语义理解、DRL智能调度、函数调用交互**等一系列技术有机融合，创造了一个能够根据环境复杂度、网络条件和自身状态，在“轻量快速”、“精细几何”、“高层语义”三种模式间**无缝切换、协同工作**的智能导航系统。实验数据（平均飞行距离提升40%，导航质量提升5%）有力地验证了该框架相对于传统单一范式或简单组合方法的显著优势。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 论文实验与评估效果总结

### 一、 实验设置与数据集
1.  **仿真环境**：
    - 使用 **AirSim**（基于Unreal Engine的高保真无人机仿真器）进行实验。
    - 主要测试场景为 **“Coastline”** 环境，模拟具有真实感的沿海地形。

2.  **网络条件模拟**：
    - 使用 **HSDPA数据集** 模拟无人机与边缘服务器之间波动的无线网络带宽。
    - 实验设置了四种不同的带宽波动场景，以评估系统在不同网络条件下的鲁棒性。

3.  **硬件与模型配置**：
    - **机载设备**：Jetson Nano。
    - **边缘服务器**：配备 Intel CPU 和 NVIDIA RTX 4090 GPU 的工作站。
    - **深度估计模型**：**Depth Anything V2**，用于高效深度图生成。
    - **视觉语言模型**：**Qwen-VL-Max**，部署在云端，用于高级语义推理。

### 二、 评价指标
论文使用以下三个核心指标来全面评估导航系统的性能：

| 指标 | 说明 | 计算公式/含义 |
| :--- | :--- | :--- |
| **导航质量** | 衡量导航决策满足安全阈值的比例，反映导航的可靠性和精确度。 | `QoN = (满足 SLO 的决策次数) / 总决策次数 (τ)` |
| **飞行距离** | 从起飞到安全降落或发生碰撞/偏航所飞行的总距离，直接反映系统的持久导航能力。 | 在相同环境下进行多次飞行取平均值。 |
| **端到端延迟** | 从发出导航指令到系统稳定执行所需的时间，关键影响实时避障能力。 | 测量多次飞行中每次推理的平均延迟。 |

### 三、 基线方法对比
论文设计了 **5个基线方法** 与完整的 **CoDrone** 系统及其消融版本进行对比：

| 基线方法 | 核心策略 | 设计目的 |
| :--- | :--- | :--- |
| **1. AdaDrone** | 基于DRL的神经调度器，使用RGB图像，动态调整分辨率、执行位置和图像编码质量。 | 代表先进的、自适应的边缘辅助导航基线。 |
| **2. CoDrone w/o VLM** | CoDrone的消融版本，**移除云端VLM模块**，保留其他所有组件（灰度图、深度估计、神经调度器）。 | 用于评估**VLM模块**的独立贡献。 |
| **3. Local** | 非自适应方法。强制在机载设备上运行所有模型（包括导航和深度估计），随机概率使用深度估计辅助。 | 模拟机载计算资源充足但无边缘/云辅助的场景。 |
| **4. Offload** | 非自适应方法。优先在边缘服务器运行所有模型，固定使用RGB图像和一定概率的深度估计辅助，**从不调用VLM**。 | 模拟网络稳定但机载资源不足的场景。 |
| **5. Offload w/o Depth Map** | **Offload** 的进一步消融，**禁用深度估计和VLM**，仅由边缘服务器基于原始图像进行轻量导航。 | 用于评估**深度估计模块**的独立贡献。 |

### 四、 关键性能提升与结论
实验结果表明，CoDrone在多个维度上显著优于所有基线方法。

#### 1. **整体性能优势（CoDrone vs. 所有基线）**
- **飞行距离**：CoDrone实现了**平均飞行距离提升40%**。
- **导航质量**：CoDrone实现了**平均QoN提升5%**。
- **结论**：这证明了**云-边-端协同框架**及**基础模型（深度估计+VLM）的集成**能有效提升无人机在复杂动态环境中的自主导航能力和鲁棒性。

#### 2. **深度估计模块的贡献（回答 Q1 & Q4）**
- **对比 `Offload` vs `Offload w/o Depth Map`**：
    - 在速度提升时，无深度估计的方法最小飞行距离急剧下降，易发生碰撞。
    - **使用深度估计可将飞行距离延长多达80米**。
- **对比 `CoDrone w/o VLM` vs `AdaDrone`**：
    - 得益于深度图提供的精细环境感知，`CoDrone w/o VLM` 的**平均飞行距离比AdaDrone最多延长86米**，**最大飞行距离最多延长173米**。
    - **QoN最大提升达7%**。
- **结论**：深度估计模型通过提供精确的障碍物距离信息，显著增强了系统的**避障能力和导航安全性**。

#### 3. **神经调度器的自适应能力（回答 Q2）**
- **端到端延迟**：如图16所示，CoDrone在四种带宽条件下的**平均和最小延迟均低于AdaDrone和纯本地/纯卸载方法**。
- **案例分析**：图17展示了在一次300秒的飞行中，神经调度器能根据**实时碰撞率和带宽波动**，动态调整：
    - **任务执行位置**（本地 or 边缘）。
    - **图像压缩率**。
    - **是否激活深度估计模型**。
- **结论**：基于DRL的神经调度器能有效协调任务卸载和模型调用，在**动态变化的网络和环境条件下保证低延迟和高性能**。

#### 4. **视觉语言模型的贡献（回答 Q3 & Q4）**
- **复杂场景处理**：如图18案例所示，当无人机误入路旁灌木丛时，VLM通过分析图像和历史数据，**连续调用 `turn_right`, `move_right`, `turn_left` 等低级飞行原语**，成功将无人机引导回正确路径。
- **性能提升**：对比完整的 **CoDrone** 与消融版 **CoDrone w/o VLM**：
    - 在不同带宽下，**平均飞行距离最大提升62米**，**平均QoN最大提升3%**。
    - 在不同速度下，**平均飞行距离最大提升53米**，**平均QoN最大提升3%**。
- **结论**：VLM为系统提供了**开放集推理和高级语义理解能力**，使其能够处理**前所未见的复杂场景**，并在传统方法可能失败时进行有效干预，从而**显著提升了系统的整体自主性和环境适应性**。

### 总结
CoDrone通过创新的**云-边-端协同架构**，集成了**深度估计**和**视觉语言模型**两类基础模型，并辅以**智能神经调度器**。实验在AirSim仿真环境和HSDPA网络数据集上验证了其有效性。与多种基线方法相比，CoDrone在**飞行距离、导航质量和实时延迟**等关键指标上均取得显著提升，证明了该框架在解决资源受限无人机于复杂动态环境中实现鲁棒、智能自主导航问题上的**实际价值和技术优势**。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2512.19083v2)
- [HTML 版本](https://arxiv.org/html/2512.19083v2)
