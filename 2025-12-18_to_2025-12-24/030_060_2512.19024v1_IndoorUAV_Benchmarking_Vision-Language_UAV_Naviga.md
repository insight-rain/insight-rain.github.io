# IndoorUAV: Benchmarking Vision-Language UAV Navigation in Continuous Indoor Environments

**相关性评分**: 6.0/10

**排名**: #30


---


## 基本信息

- **arXiv ID**: [2512.19024v1](https://arxiv.org/abs/2512.19024v1)
- **发布时间**: 2025-12-22T04:42:35Z
- **相关性评分**: 6.0/10
- **是否相关**: 是

## 作者

Xu Liu, Yu Liu, Hanshuo Qiu, Yang Qirong, Zhouhui Lian

## 关键词

Vision-Language-Action Model, VLA for Robotics, Inference Efficiency, Lightweight Architecture, Inference Acceleration, Edge Deployment

## 一句话总结

该论文提出了一个针对室内无人机视觉语言导航的基准和方法，涉及VLA模型和机器人应用，但未明确讨论推理效率、轻量架构或边缘部署。

## 摘要

Vision-Language Navigation (VLN) enables agents to navigate in complex environments by following natural language instructions grounded in visual observations. Although most existing work has focused on ground-based robots or outdoor Unmanned Aerial Vehicles (UAVs), indoor UAV-based VLN remains underexplored, despite its relevance to real-world applications such as inspection, delivery, and search-and-rescue in confined spaces. To bridge this gap, we introduce \textbf{IndoorUAV}, a novel benchmark and method specifically tailored for VLN with indoor UAVs. We begin by curating over 1,000 diverse and structurally rich 3D indoor scenes from the Habitat simulator. Within these environments, we simulate realistic UAV flight dynamics to collect diverse 3D navigation trajectories manually, further enriched through data augmentation techniques. Furthermore, we design an automated annotation pipeline to generate natural language instructions of varying granularity for each trajectory. This process yields over 16,000 high-quality trajectories, comprising the \textbf{IndoorUAV-VLN} subset, which focuses on long-horizon VLN. To support short-horizon planning, we segment long trajectories into sub-trajectories by selecting semantically salient keyframes and regenerating concise instructions, forming the \textbf{IndoorUAV-VLA} subset. Finally, we introduce \textbf{IndoorUAV-Agent}, a novel navigation model designed for our benchmark, leveraging task decomposition and multimodal reasoning. We hope IndoorUAV serves as a valuable resource to advance research on vision-language embodied AI in the indoor aerial navigation domain.

## 详细分析

## 论文摘要：IndoorUAV: 面向连续室内环境的视觉-语言无人机导航基准

**1. 研究背景和动机**
视觉-语言导航（VLN）旨在让智能体根据自然语言指令在复杂环境中导航。现有研究主要集中在**地面机器人**或**室外无人机（UAV）** 上，而**室内无人机VLN**这一具有实际应用价值（如巡检、搜救）的领域仍未被充分探索。室内环境具有空间结构复杂、障碍物密集、需要精细三维操控等特点，与地面或室外场景存在显著差异，现有基准无法满足其需求。为此，本文提出了首个面向室内无人机VLN的大规模基准**IndoorUAV**。

**2. 核心方法和技术创新**
*   **基准构建**：从Habitat模拟器中精选了**1000多个**多样化的高质量3D室内场景。通过模拟真实的4自由度（前/后、左/右、上/下、偏航）无人机动力学，手动采集并增强（如轨迹反转）了大量3D飞行轨迹。
*   **自动化标注**：设计了一个基于GPT-4的自动化流水线，为每条轨迹生成**多粒度自然语言指令**。由此构建了两个子集：
    *   **IndoorUAV-VLN**：包含**超过1.6万条**长视距导航轨迹，指令复杂，侧重于高层语义理解和长程规划。
    *   **IndoorUAV-VLA**：通过关键帧分割从VLN子集衍生，包含**近3.5万条**短视距轨迹，指令简洁（对应1-3个动作），侧重于低层精细飞行控制。
*   **导航智能体**：提出了**IndoorUAV-Agent**，一种新颖的分层导航模型。它利用大语言模型（如GPT-4o）将复杂的VLN指令**分解为一系列简短的VLA子指令**，然后由基于`π₀`架构的VLA模型依次执行每个子任务，实现了任务分解与多模态推理的结合。

**3. 主要实验结果**
*   在**IndoorUAV-VLA**任务上，微调后的`π₀`模型取得了最佳性能（成功率SR: 27.16%），显著优于传统VLN模型和NaVid等基线。
*   在更具挑战的**IndoorUAV-VLN**任务上，提出的**IndoorUAV-Agent**在已见和未见环境中均取得了最优的综合性能（例如，在已见环境中SR: 7.29%， NDTW: 17.19%），相比未使用任务分解的`π₀`基线有显著提升（SR提升+4.37%），验证了指令分解策略的有效性。
*   实验结果揭示了当前最先进模型与真实室内无人机导航需求之间仍存在**显著性能差距**，凸显了该任务的挑战性。

**4. 研究意义和价值**
IndoorUAV是**首个**专注于室内无人机VLN的大规模基准，填补了该领域的研究空白。它通过提供大规模、高质量、多粒度的指令-轨迹对数据，以及一个具有挑战性的评估平台，将有力推动**具身AI**在三维空间理解、语言 grounding 和精细运动控制方面的研究。该工作对实现室内巡检、物资配送、灾难救援等现实应用具有重要的基础性价值。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析

### **核心问题**
论文旨在解决一个被现有研究忽视的关键领域：**室内无人机（UAV）的视觉-语言导航（VLN）**。现有VLN研究主要集中于地面机器人（室内）或室外无人机，而室内无人机VLN面临独特挑战（如密集障碍物、精细三维机动、垂直空间推理），缺乏专门的基准数据集和方法。

### **核心创新点**

1.  **首个面向室内无人机VLN的大规模基准数据集 `IndoorUAV`**
    *   **场景与规模**：从Habitat模拟器中精选了**1,075个**多样化、结构丰富的3D室内场景（来源包括Matterport3D、Gibson等），远超以往数据集的场景数量。
    *   **数据构成**：包含两个互补的子集：
        *   **`IndoorUAV-VLN`**：专注于**长视野导航**，包含超过16,000条指令-轨迹对，指令复杂，轨迹长，要求高级语义理解和多步规划。
        *   **`IndoorUAV-VLA`**：专注于**短视野动作执行**，由长轨迹分割而来，包含34,925条子轨迹，每条指令对应1-3个可执行动作，强调低级飞行控制。
    *   **数据生成管道**：
        *   **轨迹收集**：模拟真实无人机4自由度（前/后、左/右、上/下、偏航）动力学，手动控制收集轨迹，并通过**轨迹反转和子轨迹重组**进行数据增强。
        *   **指令标注**：设计**自动化流水线**，利用**GPT-4o**根据轨迹关键帧生成不同粒度的自然语言指令（详细描述和简洁目标），确保了高质量和规模。

2.  **针对室内无人机VLN任务的新型智能体 `IndoorUAV-Agent`**
    *   **核心思路**：采用**分层任务分解**策略，将复杂的长期规划问题转化为可执行的短期控制问题。
    *   **架构设计**：
        *   **高层规划器（LLM）**：使用**GPT-4o** 将复杂的长期导航指令**分解**为一系列简单的、VLA风格的子指令。
        *   **低层控制器（VLA模型）**：采用微调后的 **`π₀` 模型**，根据当前视觉观察和子指令，**直接预测并执行连续的低级轨迹**（未来若干步的3D坐标和偏航角）。
        *   **协同执行**：子指令被顺序执行，上一个子任务的最终状态作为下一个子任务的初始视觉上下文，保证了时序连续性和减少了误差累积。

3.  **对现有研究空白的系统性填补与挑战揭示**
    *   **定位独特**：明确指出并构建了介于“室内地面VLN”和“室外空中VLN”之间的新领域。
    *   **挑战量化**：通过大量实验表明，即使是当前最先进的模型（如`π₀`、NaVid），在`IndoorUAV`基准上的表现（成功率SR最高仅27.16% for VLA, 7.29% for VLN）也远未达到实用要求，**凸显了该任务的难度和未来研究的迫切性**。

### **解决方案总结**
论文通过 **“构建基准数据集 + 提出基线方法”** 的组合拳来解决该问题：
1.  **定义问题与收集数据**：首先明确定义了室内无人机VLN的任务范式和挑战，然后通过精心设计的模拟环境、手动控制、数据增强和基于大模型的自动化标注，构建了大规模、高质量、多粒度的数据集 `IndoorUAV`，为后续研究提供了可靠的评估平台。
2.  **提出基线方法**：针对数据集中揭示的长视野规划难题，提出了 `IndoorUAV-Agent`。该方法的核心创新在于**利用大语言模型（LLM）的语义理解能力进行任务分解，再结合视觉语言动作（VLA）模型的精细控制能力进行执行**，形成了一种可解释、模块化的分层导航框架，有效提升了长视野任务的性能。

### **实际价值**
*   **推动领域发展**：为室内无人机自主导航（如巡检、搜救、物流）的关键技术——**结合自然语言交互的智能控制**——提供了首个专门的测试床和评估标准。
*   **方法启发性**：提出的“LLM规划器 + VLA执行器”的分层架构，为处理复杂具身AI任务提供了一种有效范式。
*   **开源资源**：公开了数据集和代码，降低了研究门槛，能加速相关算法的创新与比较。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文旨在解决**室内无人机视觉语言导航（VLN）领域缺乏专门基准和有效方法**的核心问题。针对现有研究多集中于地面机器人或室外无人机，而室内环境具有三维空间复杂、障碍物密集、需要精细操控等独特挑战，作者提出了 **IndoorUAV 基准**和 **IndoorUAV-Agent 方法**。该基准通过从 Habitat 模拟器中精选大量 3D 室内场景，模拟真实无人机动力学并辅以数据增强，构建了包含长航程（VLN）和短航程（VLA）任务的大规模指令-轨迹数据集。提出的方法采用**任务分解框架**，利用大语言模型（如 GPT-4o）将复杂的长指令分解为一系列可执行的短指令子任务，再交由一个基于 **π₀ 架构**的视觉语言动作模型进行细粒度轨迹预测与执行。实验表明，该基准对现有模型构成了显著挑战，而所提出的 IndoorUAV-Agent 在长航程导航任务上取得了最佳性能，验证了任务分解策略对于处理复杂室内空中导航的有效性。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文创新点分析

这篇论文《IndoorUAV: Benchmarking Vision-Language UAV Navigation in Continuous Indoor Environments》针对室内无人机视觉语言导航（VLN）这一未被充分探索的领域，提出了一个系统的基准和方法。其核心创新点如下：

### 1. **首创面向室内无人机VLN的大规模基准数据集**
   - **改进/不同之处**：
     - **领域聚焦**：现有VLN数据集主要集中于**地面机器人**（如R2R、RxR）或**室外无人机**（如AVDN、AerialVLN）。本文首次构建了专门针对**室内、连续、3D环境**的无人机VLN基准。
     - **场景规模与多样性**：整合了Matterport3D、Gibson、HM3D、Replica四个来源的**1075个高质量室内场景**，远超以往任何VLN数据集（通常<100个场景）。提供了超过5万条轨迹。
     - **动作空间设计**：定义了**4自由度（4-DoF）**的无人机动作空间（前进、垂直移动、横向移动、偏航旋转），并引入了**双尺度动作**（如`fly_forward_small/large`），以支持室内精细操控。
   - **解决的问题/优势**：
     - 填补了**室内空中导航**研究的数据空白。
     - 模拟了真实室内飞行的核心挑战：**三维自由运动、密集障碍物、狭窄空间、需要垂直推理**。
     - 细粒度动作空间使基准能更好地评估**低层控制与避障能力**。

### 2. **提出双层任务划分与数据构建流程**
   - **改进/不同之处**：
     - **任务分层**：将导航任务明确划分为：
       - **长视距VLN** (`IndoorUAV-VLN`): 包含超过1.6万条轨迹，指令复杂、路径长，关注**高层语义理解和多步规划**。
       - **短视距VLA** (`IndoorUAV-VLA`): 从VLN轨迹中分割出近3.5万条子轨迹，指令简洁（1-3个动作），关注**细粒度动作执行和即时控制**。
     - **自动化标注流水线**：利用**GPT-4o**，通过“关键帧提取 -> 图像描述生成 -> 指令合成”的流程，自动为每条轨迹生成**多粒度自然语言指令**，保证了数据的规模和质量。
   - **解决的问题/优势**：
     - 解决了单一任务设定（只关注高层规划或只关注底层控制）无法全面评估智能体能力的问题。
     - **VLA子集**为研究**视觉语言动作模型**在无人机控制上的应用提供了直接支持。
     - 自动化流水线克服了人工标注海量3D轨迹指令的昂贵成本问题。

### 3. **提出一种层次化分解的导航智能体（IndoorUAV-Agent）**
   - **改进/不同之处**：
     - **架构设计**：采用**任务分解**策略。对于长视距VLN任务，首先使用**GPT-4o将复杂指令分解为一系列简短的VLA风格子指令**，然后由基于`π₀`模型的VLA模块**顺序执行**每个子任务。
     - **上下文传递**：执行第`i`个子任务时，使用第`i-1`个子任务预测的最终观测图像作为初始输入，保持了**跨子任务的时空连续性**，缓解了误差累积。
   - **解决的问题/优势**：
     - 解决了端到端模型在**长序列、多步骤指令**上规划能力不足的问题。
     - **模块化设计**提高了系统的**可解释性**和**鲁棒性**。语言模型负责高层分解，VLA模型负责可靠的低层控制。
     - 实验表明，该设计显著提升了在复杂VLN任务上的成功率（相比未分解的`π₀`基线，在已见场景中SR提升+4.37%）。

### 4. **设计了更全面的评估指标**
   - **改进/不同之处**：
     - **针对VLA任务的改进NDTW**：传统NDTW仅衡量3D坐标路径对齐度。本文提出**融合空间路径与偏航角序列**的NDTW计算方式，根据轨迹的**路径长度和累计旋转角度**进行自适应加权。这更符合无人机在室内频繁转向的特点。
     - **分层的成功率标准**：对VLA和VLN任务设定了**不同的成功阈值**（VLA：位置误差<0.5m且角度误差<π/4；VLN：位置误差<2m），更贴合各自的任务目标。
   - **解决的问题/优势**：
     - 避免了纯转向任务因路径长度为零而导致传统空间NDTW失效的问题。
     - 提供了对智能体**位姿估计精度**和**轨迹平滑度**更细致、公平的评估。

### 总结
本文的核心创新在于**系统性地定义并构建了一个全新的研究问题域（室内无人机VLN）**，并为此提供了**配套的大规模基准数据集、分层任务定义、一个有效的基线模型以及更合理的评估体系**。它明确指出并尝试解决从室外到室内、从地面到空中所带来的**三维空间推理、精细运动控制和长程规划**等一系列新挑战，为后续研究奠定了重要的基础。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 实验与评估效果分析

### 1. 使用的数据集
- **核心数据集**：论文提出的 **IndoorUAV** 基准数据集，包含两个子集：
    - **IndoorUAV-VLN**：专注于**长时程导航**，包含 16,040 条轨迹，平均指令长度 112 词，平均轨迹长度 21.6 米。
    - **IndoorUAV-VLA**：专注于**短时程精细控制**，包含 34,925 条短轨迹，平均指令长度 14.5 词，平均轨迹长度 2.2 米。
- **环境来源**：数据集构建于 1,075 个高质量 3D 室内场景，来源于 Matterport3D (MP3D)、Gibson、HM3D 和 Replica 四个广泛使用的室内数据集，并在 Habitat 模拟器中实现。

### 2. 评价指标
论文针对 VLA 和 VLN 两类任务，采用了四组核心指标进行评估：

| 指标 | 全称 | 适用任务 | 核心定义 |
| :--- | :--- | :--- | :--- |
| **SR** | 成功率 | VLA & VLN | **VLA**：终点与目标距离 < 0.5m **且** 偏航角差 < π/4。<br>**VLN**：终点与目标距离 < 2m。 |
| **NDTW** | 归一化动态时间规整 | VLA & VLN | 衡量预测轨迹与参考轨迹的**路径对齐度**。VLA任务额外考虑了偏航角序列的对齐。 |
| **NE** | 导航误差 | VLN | 预测轨迹终点与目标点的**欧氏距离**（米）。 |
| **OSR** | 先知成功率 | VLN | 预测轨迹上**任意一点**满足成功条件（距离<2m）即视为成功。 |

### 3. 对比的基线方法
论文与两大类基线模型进行了全面对比：

#### **VLA 模型 (短时程控制)**
- **`π₀` 及 `π₀`-FAST**：基于预训练VLM的连续控制模型，使用扩散式解码。
- **OpenVLA**：开源离散令牌VLA模型，在大量真实机器人数据上训练。
- **NaVid**：基于视频的VLM，专为地面VLN设计。
- **传统VLN模型**：Seq2Seq, CMA (LSTM风格模型，输出连续路径点)。

#### **VLN 模型 (长时程导航)**
- **`π₀` (作为基线)**：直接使用VLA模型处理长指令，**无任务分解**。
- **NaVid**：视频VLM模型。
- **OpenFly-Agent**：基于OpenVLA的空中导航模型。
- **Seq2Seq, CMA**：传统VLN模型。
- **GPT-4o (零样本)**：直接作为规划器使用。

### 4. 关键性能结果与结论

#### **在 IndoorUAV-VLA (短时程) 上的结果**
- **最佳模型**：经过微调的 **`π₀` 模型** 表现最佳。
    - **整体SR**：达到 **27.16%**，NDTW为 9.44%。
    - **按难度**：在简单任务上SR高达 **46.58%**，在中等和困难任务上分别为21.64%和7.55%，均显著领先。
- **关键结论**：
    1. 传统VLN模型（Seq2Seq, CMA）完全无法适应低层控制任务，SR低于3%。
    2. 专为地面导航设计的NaVid模型表现有所提升，但仍远不及专为连续控制设计的`π₀`模型。
    3. 这证明了**室内无人机精细控制需要专门的VLA架构**。

#### **在 IndoorUAV-VLN (长时程) 上的结果**
- **最佳模型**：论文提出的 **IndoorUAV-Agent** (基于任务分解的框架) 全面领先。
- **关键性能提升** (TEST SEEN 场景)：
    - **vs. `π₀` 基线**：SR从 **2.92%** 提升至 **7.29%** (**+4.37%**)，NDTW从11.87%提升至17.19%。
    - **vs. 其他最佳基线**：显著优于OpenFly-Agent (SR 4.12%) 和所有其他模型。
- **泛化能力** (TEST UNSEEN 场景)：
    - IndoorUAV-Agent 的SR为 **5.06%**，同样优于`π₀`基线的2.83%和其他模型。
- **关键结论**：
    1. **任务分解策略有效**：通过GPT-4o将长指令分解为短子指令，再由`π₀`模型依次执行，显著提升了长时程导航的成功率。这证明了**分层规划**在复杂室内空中导航中的必要性。
    2. **现有模型性能低下**：即使是表现最好的模型，SR也仅在7%左右，**揭示了当前技术在真实室内无人机导航任务上面临的巨大挑战**。
    3. **NaVid的局限性**：虽然其OSR较高（~15%），但SR极低（<1%），原因是其经常无法正确预测“停止”动作，导致飞越目标点。这说明**为地面设计的模型难以直接迁移到空中3D连续控制场景**。

### 5. 总结
论文通过系统的实验评估表明：
1. **IndoorUAV基准极具挑战性**：现有SOTA模型在该基准上的性能（SR < 10%）远未达到实用水平，突显了在**3D空间理解、细粒度控制和长时程规划**方面仍需重大突破。
2. **方法有效性得到验证**：提出的IndoorUAV-Agent通过**大语言模型任务分解 + 视觉语言动作模型执行**的分层框架，在长时程导航任务上取得了当前最佳性能，为后续研究提供了一个有效的基线架构。
3. **领域差距明显**：实验清晰地展示了室内空中VLN与地面或室外空中VLN的本质不同，强调了为该领域开发专用模型和基准的重要性。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2512.19024v1)
- [HTML 版本](https://arxiv.org/html/2512.19024v1)
