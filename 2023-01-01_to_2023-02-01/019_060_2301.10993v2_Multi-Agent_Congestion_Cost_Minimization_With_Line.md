# Multi-Agent Congestion Cost Minimization With Linear Function Approximations

**相关性评分**: 6.0/10

**排名**: #19


---


## 基本信息

- **arXiv ID**: [2301.10993v2](https://arxiv.org/abs/2301.10993v2)
- **发布时间**: 2023-01-26T08:45:44Z
- **相关性评分**: 6.0/10
- **是否相关**: 是

## 作者

Prashant Trivedi, Nandyala Hemachandra

## 关键词

multi-agent RL, CTDE methods, decentralized control, reinforcement learning (RL), privacy preservation, linear function approximations, regret analysis

## 一句话总结

这篇论文提出了一种基于多智能体强化学习的去中心化拥堵成本最小化算法，适用于网络路径规划，但与四足机器人或人形机器人等具体机器人控制应用无直接关联。

## 摘要

This work considers multiple agents traversing a network from a source node to the goal node. The cost to an agent for traveling a link has a private as well as a congestion component. The agent's objective is to find a path to the goal node with minimum overall cost in a decentralized way. We model this as a fully decentralized multi-agent reinforcement learning problem and propose a novel multi-agent congestion cost minimization (MACCM) algorithm. Our MACCM algorithm uses linear function approximations of transition probabilities and the global cost function. In the absence of a central controller and to preserve privacy, agents communicate the cost function parameters to their neighbors via a time-varying communication network. Moreover, each agent maintains its estimate of the global state-action value, which is updated via a multi-agent extended value iteration (MAEVI) sub-routine. We show that our MACCM algorithm achieves a sub-linear regret. The proof requires the convergence of cost function parameters, the MAEVI algorithm, and analysis of the regret bounds induced by the MAEVI triggering condition for each agent. We implement our algorithm on a two node network with multiple links to validate it. We first identify the optimal policy, the optimal number of agents going to the goal node in each period. We observe that the average regret is close to zero for 2 and 3 agents. The optimal policy captures the trade-off between the minimum cost of staying at a node and the congestion cost of going to the goal node. Our work is a generalization of learning the stochastic shortest path problem.

## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2301.10993v2)
- [HTML 版本](https://arxiv.org/html/2301.10993v2)
