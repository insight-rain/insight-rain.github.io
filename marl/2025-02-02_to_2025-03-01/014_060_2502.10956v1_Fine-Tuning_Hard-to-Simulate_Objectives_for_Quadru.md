# Fine-Tuning Hard-to-Simulate Objectives for Quadruped Locomotion: A Case Study on Total Power Saving

**相关性评分**: 6.0/10

**排名**: #14


---


## 基本信息

- **arXiv ID**: [2502.10956v1](https://arxiv.org/abs/2502.10956v1)
- **发布时间**: 2025-02-16T02:22:50Z
- **相关性评分**: 6.0/10
- **是否相关**: 是

## 作者

Ruiqian Nai, Jiacheng You, Liu Cao, Hanchen Cui, Shiyuan Zhang, Huazhe Xu, Yang Gao

## 关键词

Robot control, quadruped robot locomotion, Edge Deployment, local observational information

## 一句话总结

该论文提出了一种数据驱动框架，针对四足机器人运动中的难以模拟目标（如电池功耗）进行微调，通过真实世界数据建模并在仿真中优化策略，实现了显著的功耗降低。

## 摘要

Legged locomotion is not just about mobility; it also encompasses crucial objectives such as energy efficiency, safety, and user experience, which are vital for real-world applications. However, key factors such as battery power consumption and stepping noise are often inaccurately modeled or missing in common simulators, leaving these aspects poorly optimized or unaddressed by current sim-to-real methods. Hand-designed proxies, such as mechanical power and foot contact forces, have been used to address these challenges but are often problem-specific and inaccurate.
  In this paper, we propose a data-driven framework for fine-tuning locomotion policies, targeting these hard-to-simulate objectives. Our framework leverages real-world data to model these objectives and incorporates the learned model into simulation for policy improvement. We demonstrate the effectiveness of our framework on power saving for quadruped locomotion, achieving a significant 24-28\% net reduction in total power consumption from the battery pack at various speeds. In essence, our approach offers a versatile solution for optimizing hard-to-simulate objectives in quadruped locomotion, providing an easy-to-adapt paradigm for continual improving with real-world knowledge. Project page https://hard-to-sim.github.io/.

## 详细分析

## 论文摘要

### 1. 研究背景和动机
当前基于学习的足式机器人运动策略主要依赖于**仿真到现实**的迁移范式。然而，许多对实际应用至关重要的目标，如**电池总功耗**、步进噪音和安全性，在常用物理仿真器中要么缺失，要么建模不准确。传统方法通常使用手工设计的代理（如机械功率）来近似这些目标，但这需要专业知识且精度有限。因此，如何有效优化这些**难以仿真的目标**，是提升机器人实际性能的关键挑战。

### 2. 核心方法和技术创新
本文提出了一种**数据驱动的微调框架**，用于优化难以仿真的目标。其核心创新在于：
- **数据驱动的测量模型**：在真实世界中收集数据，训练一个模型（如LSTM网络）来从仿真可观测状态（如关节扭矩、角速度）预测难以仿真的目标（如电池电流）。
- **仿真集成与迭代优化**：将学得的测量模型集成到仿真中，作为奖励函数的一部分，指导策略优化。整个过程采用**迭代循环**：真实数据收集 → 测量模型训练 → 仿真策略微调 → 策略分层筛选。
- **关键技术设计**：为防止策略偏离数据分布导致模型失效，引入了**KL散度惩罚**来约束策略更新步长；并采用**分层策略选择**（先仿真评估，再真实世界验证）来应对仿真与现实间的差距。

### 3. 主要实验结果
该方法在Unitree Go1四足机器人上以**总功耗节约**为案例进行了验证，取得了显著效果：
- 在不同速度（0.5, 0.8, 1.1 m/s）下，实现了 **24-28% 的净功耗降低**（总功耗降低约20%）。
- 显著优于使用传统**解析代理**（机械功率模型）的基线方法（后者仅实现最高约12%的净降低）。
- **真实场景测试**表明，优化后的策略能有效延长电池续航里程，且机器人步态表现出更高的柔顺性和自然性。

### 4. 研究意义和价值
本研究的意义在于：
- **方法论价值**：为解决仿真中难以建模的复杂目标优化问题，提供了一个通用、易适配的**数据驱动范式**。该方法对现有仿真到现实流程改动最小，具备“即插即用”的潜力。
- **实际应用价值**：显著提升了四足机器人的**能源效率**，直接延长了单次充电的作业时间，对于巡逻、救援等实际任务至关重要。
- **前瞻性**：该框架理论上可扩展至其他难以仿真的目标（如噪音、电机温升），为持续利用真实世界知识改进机器人性能开辟了新途径。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析

### 一、 拟解决的核心问题
论文旨在解决**四足机器人运动控制中“难以精确仿真”的目标优化问题**。具体而言，当前主流的“仿真到现实”方法依赖于物理仿真器，但仿真器通常无法准确建模或完全忽略一些对实际应用至关重要的因素，例如：
- **电池总功耗**：涉及电机复杂动力学（如永磁同步电机PMSM）、控制策略（如磁场定向控制FOC）及子系统间能量交互，难以精确仿真。
- **其他现实因素**：如踏步噪音、电机过热、安全性等。

传统方法使用**手工设计的代理指标**（如机械功率、足端接触力）作为奖励函数来近似这些目标，但存在**问题特异性强、准确性不足、依赖专家知识、需要大量调参**等局限。

### 二、 核心创新点
论文提出了一个**数据驱动的策略微调框架**，其核心创新在于：
1. **方法论创新**：将难以仿真的目标优化问题，转化为一个**利用真实世界数据构建测量模型，并将其集成到仿真中进行策略迭代改进**的范式。
2. **框架通用性**：该框架被设计为**目标无关**，理论上可适用于优化各种难以仿真的目标（不仅是功耗），为持续利用真实世界知识改进策略提供了一个易于适配的范式。
3. **关键技术组合**：
    - **数据驱动的测量模型**：使用真实机器人数据训练模型（如LSTM），根据仿真中可观测的状态（如关节扭矩、角速度）预测难以仿真的目标值（如电池电流）。
    - **仿真内策略微调**：将训练好的测量模型作为奖励函数的一部分引入仿真，对预训练策略进行微调。
    - **迭代式闭环流程**：包含“真实数据收集 -> 测量模型训练 -> 仿真内策略微调 -> 分层策略选择”的迭代循环，逐步提升性能。
    - **分层策略选择机制**：先根据仿真性能筛选一批候选策略，再通过少量真实世界评估从中选出最佳策略，以应对仿真到现实的差异。

### 三、 解决方案（框架流程）
如图1和算法1所示，解决方案是一个迭代过程：

1.  **初始化**：从一个在仿真中预训练好的基础策略开始。
2.  **迭代循环**：
    - **真实世界数据收集**：使用当前的一批精英策略在真实机器人上运行，收集`(仿真可观测状态， 真实难以仿真测量值)`配对数据。
    - **测量模型训练与更新**：利用累积的所有历史数据，训练/更新一个模型，使其能够从仿真状态预测真实测量值。
    - **仿真内策略微调**：
        - **目标函数**：在仿真中优化组合奖励 `r = r_sim + λ * r_hard-to-sim`，其中 `r_hard-to-sim` 由测量模型预测值计算得出。
        - **约束探索**：使用KL散度惩罚项，约束新策略与锚点策略（如上轮最佳策略或预训练策略）的差异，防止过度偏离测量模型可靠的数据分布。
        - **超参数扫描**：在每轮迭代中，对奖励权重 `λ` 和KL约束 `c` 进行扫描，生成大量候选策略。
    - **分层策略选择**：
        - **仿真筛选**：从候选策略中，根据仿真中的综合表现（兼顾任务性能与优化目标）选出Top-K精英策略。
        - **现实评估**：将精英策略部署到真实机器人进行少量评估，选出**真实表现最佳**的策略作为下一轮的锚点。

3.  **终止与输出**：达到预期性能或收敛后，输出最终优化后的策略。

### 四、 实际价值与验证
- **有效性验证（案例研究）**：以**降低电池总功耗**为目标进行实验。
    - **结果**：在Unitree Go1机器人上，在不同速度下实现了 **24-28% 的净功耗降低**，显著优于使用传统机械功率代理指标的基线方法（仅实现约5-12%的降低）。
    - **行为改变**：优化后的策略展现出步态更柔顺、关节扭矩曲线更平滑、腿部姿态更自然等节能行为特征。
    - **野外测试**：在室内外长距离测试中，优化策略显著延长了电池续航里程。
- **框架优势**：
    - **高准确性**：数据驱动的测量模型比手工代理更能反映真实的功耗情况。
    - **实用性**：只需对现有仿真到现实流程进行最小改动，即可集成真实世界数据。
    - **持续改进潜力**：迭代框架允许不断融入新数据，持续优化策略。

**总结**：该论文的核心创新是提出了一套**系统化、数据驱动、可泛化**的框架，用于优化那些在仿真中无法被准确建模但对机器人实际应用至关重要的性能指标。它通过“**用真实数据建模，在仿真中优化**”的混合范式，有效弥合了仿真与现实的鸿沟，并以显著的功耗节约证明了其实际价值。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文针对四足机器人运动控制中**难以精确仿真建模的优化目标**（如电池总功耗、步态噪声等）提出了一个**数据驱动的微调框架**。该框架的核心是**利用真实世界数据训练一个测量模型来预测这些难以仿真的目标**，并将其作为奖励函数集成到仿真环境中进行策略迭代优化。通过一个以**降低总功耗**为目标的案例研究，该方法在多种速度下实现了**24-28%的净功耗降低**，显著优于依赖手工设计代理奖励（如机械功率）的传统方法，证明了该框架能有效利用真实世界知识持续优化仿真中难以建模的关键性能指标。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文创新点分析

这篇论文提出了一种针对四足机器人运动控制中“难以模拟的目标”进行微调的数据驱动框架，并以“总功耗节省”为案例进行了验证。其核心创新点可归纳为以下几条：

---

### 1. **提出“数据驱动的测量模型”替代“手工设计的代理目标”**
   - **相比以往方法的改进/不同之处**：
     - **以往方法**：为了优化能量消耗、噪音等难以在物理仿真器中精确建模的目标，通常依赖**手工设计的代理奖励函数**（例如，使用机械功率、关节接触力来近似能量消耗或噪音）。这些代理目标需要大量专家知识进行设计，且其准确性有限，与真实目标（如电池总功耗）存在显著差距。
     - **本文方法**：提出训练一个**数据驱动的测量模型**（如LSTM网络），直接从真实世界数据中学习从仿真可观测状态（如关节扭矩、角速度）到难以模拟的目标（如电池电流/功耗）的映射关系。该模型随后被集成到仿真中，作为奖励函数的一部分来指导策略优化。
   - **解决的具体问题/带来的优势**：
     - **解决了代理目标不准确的问题**：直接建模真实世界的测量值，避免了手工代理模型固有的简化误差。实验表明，数据驱动模型预测的节能效果与真实世界结果呈正相关，而传统分析代理模型则呈负相关（见图6）。
     - **提高了优化目标的保真度**：使得在仿真中优化的目标（基于模型的预测）更贴近真实世界的优化目标，从而能发现更有效的节能行为。
     - **方法通用**：该框架是“目标无关的”，理论上可适用于任何能通过真实数据测量的难以模拟的目标（如噪音、电机温度）。

### 2. **设计“迭代式策略微调与分层策略选择”闭环框架**
   - **相比以往方法的改进/不同之处**：
     - **以往方法**：许多sim-to-real工作要么直接在真实世界从头学习（效率低、性能差），要么在仿真中预训练后直接部署，缺乏一个系统的、利用真实数据持续改进仿真策略的闭环。一些在线微调方法主要解决**动力学**的sim-to-real差距，而非针对**未在仿真中定义的新目标**进行优化。
     - **本文方法**：构建了一个**迭代循环**（见图1，算法1）：
       1. **真实数据收集**：使用当前精英策略在真实机器人上运行并收集数据（仿真状态与难以模拟的测量值对）。
       2. **测量模型更新**：用累积的所有数据重新训练测量模型，提高其准确性和泛化能力。
       3. **仿真内微调**：将更新的测量模型作为奖励引入仿真，从不同锚点策略（预训练策略或上一轮最佳策略）出发，在**KL散度约束**下，使用不同的奖励权重和约束系数进行策略微调，生成大量候选策略。
       4. **分层策略选择**：
          - **第一层（仿真内筛选）**：根据仿真中的综合表现（尤其是节能奖励）选出Top-K精英策略。
          - **第二层（真实世界评估）**：将精英策略部署到真实机器人上，根据**真实功耗测量**选出本轮最佳策略，用于下一轮迭代。
   - **解决的具体问题/带来的优势**：
     - **解决了数据分布偏移和模型利用问题**：通过KL散度约束，限制策略更新幅度，使策略探索保持在测量模型训练数据分布附近，保证了模型预测的可靠性。
     - **解决了仿真与真实性能不一致问题**：分层选择机制先通过仿真高效筛选，再通过少量真实测试确认最终性能，平衡了评估成本与效果，克服了纯仿真评估因sim-to-real gap可能导致的误选。
     - **实现了持续、稳定的性能提升**：迭代过程允许策略和测量模型协同进化。实验显示，节能效果随着迭代轮次稳步提升（见图5）。

### 3. **首次针对“电池总功耗”这一复杂系统级目标进行数据驱动优化**
   - **相比以往方法的改进/不同之处**：
     - **以往方法**：关于四足机器人能量优化的研究大多集中于**硬件设计**或在控制器层面优化**分析性功耗模型**（如机械功率、焦耳热）。这些模型忽略了电机（特别是永磁同步电机PMSM）的复杂动态、驱动器控制策略（如磁场定向控制FOC）以及子系统间耦合带来的损耗，因此与从电池包测量的**总功耗**差异很大。
     - **本文方法**：明确将优化目标定义为从**电池包直接测量**的总功耗（通过测量电流），并使用数据驱动模型对其进行端到端建模。在奖励函数中直接使用负的预测电流作为节能奖励。
   - **解决的具体问题/带来的优势**：
     - **直接优化了影响机器人续航的关键实用指标**：总功耗直接决定了单次充电的运行时间，对巡逻、救援等实际应用至关重要。
     - **发现了传统方法无法找到的节能行为**：通过优化更准确的模型，策略学会了更柔顺的步态、更平滑的扭矩曲线以及将前腿收拢更贴近身体的姿态（见图4），这些行为直接带来了显著的功耗下降。
     - **取得了显著的性能提升**：在Unitree Go1机器人上，在不同速度（0.5, 0.8, 1.1 m/s）下实现了**24-28%的净功耗降低**，远超使用分析性代理目标的基线方法（仅实现3.9-8.3%的净功耗降低）（见表I）。野外长距离测试也验证了其能有效延长电池续航（见图2）。

### 4. **提供了一个“即插即用”的通用框架，对现有Sim-to-Real流程改动小**
   - **相比以往方法的改进/不同之处**：
     - **以往方法**：一些针对特定目标（如能量）的优化方法需要深度整合到学习算法中，或需要重新设计整个奖励架构，通用性较差。
     - **本文方法**：作者强调其框架**仅需对现有sim-to-real流程进行最小改动**。核心是增加一个从真实数据学习测量模型的模块，并将其输出作为一项额外的奖励项加入现有的仿真训练奖励函数中。策略优化算法（如PPO）本身无需改变。
   - **解决的具体问题/带来的优势**：
     - **降低了应用门槛**：便于研究者和工程师将针对各种难以模拟目标（如噪音、安全性、热管理）的优化快速集成到已有的机器人运动控制管道中。
     - **促进了持续学习**：为利用真实世界知识进行持续的策略改进提供了一个易于适配的范式。

---

**总结**：本文的核心创新在于**方法论层面**的贡献——通过构建一个**数据驱动建模、迭代微调、分层验证**的闭环系统，巧妙地解决了在基于仿真的强化学习范式中优化那些仿真器无法准确建模的实用目标这一难题。案例研究在“总功耗节省”上取得的卓越效果，强有力地证明了该框架的有效性和实用价值。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 论文实验与评估效果分析

该论文提出了一种针对“难以模拟目标”的数据驱动微调框架，并以四足机器人**总功耗节省**为具体案例进行了验证。其实验设计严谨，评估结果清晰。

### 1. 核心实验效果
论文的主要实验成果是**显著降低了四足机器人的总功耗**。
- **关键定量结果**：在Unitree Go1机器人上，以不同速度（0.5, 0.8, 1.1 m/s）行走时，相比预训练策略，该方法实现了：
    - **净功耗降低（Net Reduction）**：**24% 至 28%**。
    - **总功耗降低（Gross Reduction）**：**19.4% 至 20.3%**。
- **定性行为改变**：微调后的策略表现出步态更柔顺、关节力矩曲线更平滑、前腿姿态更自然（更靠近身体）等特征，这些行为变化是节能的内在原因。
- **野外（In-the-Wild）长距离测试**：在室内400米和室外500米的长距离行走测试中，使用该方法微调的策略在相同行驶距离后，电池剩余电量（SoC）最高，**有效延长了实际续航时间**。

### 2. 使用的数据集与评价指标
- **数据集**：
    - **来源**：在真实机器人上，使用当前迭代的精英策略集（`Π_elites`）进行 rollout 收集。
    - **内容**：数据对 `{𝐬_t^sim, 𝐬_t}`，即仿真中可用的状态（如关节角度、速度、扭矩）与真实世界中难以模拟的测量值（**电池电流**）。
    - **累积性**：采用迭代方式，每一轮收集的新数据都会与历史数据合并，用于训练更新的测量模型。
- **主要评价指标**：
    1.  **功耗降低百分比（ΔP）**：
        ```math
        ΔP = (P_pretrained - P_finetuned) / P_pretrained × 100%
        ```
        - `P_pretrained`：预训练策略的平均功耗。
        - `P_finetuned`：微调后策略的平均功耗。
        - 区分了**总功耗降低（Gross）**和**净功耗降低（Net）**，后者扣除了电机空闲时的基础功耗，更能反映运动本身的能效提升。
    2.  **电池电量（SoC） vs. 行驶距离**：用于长距离野外测试，直观展示续航能力提升。
    3.  **速度跟踪精度**：确保节能优化不以牺牲核心移动任务（遵循速度指令）为代价。评估时只统计速度误差在±10%以内的数据段。

### 3. 对比的基线方法
论文与一个**基于解析代理（Analytical Proxy）的微调方法**进行了对比。
- **基线方法详情**：
    - **代理奖励函数**：使用经典的机械功率 + 焦耳热模型作为功耗的近似，奖励函数为：
        ```math
        r_energy = -∑ max(τ_i * q˙_i + (r/k²) * τ_i², 0)
        ```
        其中 `τ_i` 为扭矩，`q˙_i` 为角速度，`r, k` 为电机常数。
    - **微调流程**：在仿真中使用此代理奖励对相同的预训练策略进行微调，并进行了广泛的超参数搜索（`λ` 和 `c`）。最终在真实世界中评估表现最好的24个策略。
- **对比目的**：验证数据驱动模型相比手工设计的、不完美的物理代理模型的优越性。

### 4. 关键性能提升与结论
1.  **能效大幅超越基线**：
    - 如表I所示，在0.5m/s速度下，基线方法净功耗降低仅为11.8%，而本文方法达到28.4%。在更高速度下（1.1m/s），基线效果骤降至5.0%，而本文方法仍保持24.2%的显著降低。
    - **结论**：数据驱动的测量模型比解析代理模型**能更准确、更一致地反映真实功耗**，从而使策略优化更有效。

2.  **策略选择可靠性**：
    - 图6分析表明，本文数据驱动模型预测的节能效果与真实世界测量结果呈**正相关**，而基线解析代理的预测则呈**负相关**（即预测能节能的策略实际可能更耗电）。
    - **结论**：这证明了使用数据驱动模型作为仿真中优化目标和初步策略筛选依据的**可靠性**，同时也凸显了进行最终真实世界评估（分层策略选择）的必要性。

3.  **迭代框架的有效性**：
    - 图5显示，随着迭代进行（数据积累和模型更新），节能效果稳步提升，在4次迭代后（约38.4万真实样本）收敛。
    - **结论**：**迭代式的数据收集、模型训练、策略微调循环**对于持续改进难以模拟目标的性能是有效且必要的。

**总结**：该论文通过严谨的实验证明，其提出的数据驱动微调框架能够**显著优化仿真中难以精确建模的目标（如总功耗）**，效果大幅优于依赖传统手工代理模型的方法，并在真实世界的长距离测试中验证了其实际应用价值。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2502.10956v1)
- [HTML 版本](https://arxiv.org/html/2502.10956v1)
