# Think on your feet: Seamless Transition between Human-like Locomotion in Response to Changing Commands

**相关性评分**: 6.0/10

**排名**: #26


---


## 基本信息

- **arXiv ID**: [2502.18901v1](https://arxiv.org/abs/2502.18901v1)
- **发布时间**: 2025-02-26T07:28:55Z
- **相关性评分**: 6.0/10
- **是否相关**: 是

## 作者

Huaxing Huang, Wenhao Cui, Tonghe Zhang, Shengtao Li, Jinchao Han, Bangyu Qin, Tianchu Zhang, Liang Zheng, Ziyang Tang, Chenxu Hu, Ning Yan, Jiahao Chen, Shipu Zhang, Zheyuan Jiang

## 关键词

Robot control, quadruped robot locomotion, mujoco

## 一句话总结

该论文提出了一种改进模仿学习的方法，通过集成人类运动转移和精确速度跟踪，实现人形机器人在多变命令下的无缝运动过渡和泛化能力。

## 摘要

While it is relatively easier to train humanoid robots to mimic specific locomotion skills, it is more challenging to learn from various motions and adhere to continuously changing commands. These robots must accurately track motion instructions, seamlessly transition between a variety of movements, and master intermediate motions not present in their reference data. In this work, we propose a novel approach that integrates human-like motion transfer with precise velocity tracking by a series of improvements to classical imitation learning. To enhance generalization, we employ the Wasserstein divergence criterion (WGAN-div). Furthermore, a Hybrid Internal Model provides structured estimates of hidden states and velocity to enhance mobile stability and environment adaptability, while a curiosity bonus fosters exploration. Our comprehensive method promises highly human-like locomotion that adapts to varying velocity requirements, direct generalization to unseen motions and multitasking, as well as zero-shot transfer to the simulator and the real world across different terrains. These advancements are validated through simulations across various robot models and extensive real-world experiments.

## 详细分析

## 论文详细摘要

**论文标题**：Think on your feet: Seamless Transition between Human-like Locomotion in Response to Changing Commands

### 1. 研究背景和动机
人形机器人因其适应人类环境的潜力而备受关注，但其运动控制面临巨大挑战，如高重心、多自由度导致的动态平衡困难。传统的强化学习（RL）方法虽能习得基本运动，但常导致步态不自然、能耗高；而模仿学习（IL）方法虽能生成类人运动，但其泛化能力有限，且严重依赖高质量专家数据，难以适应连续变化的运动指令。因此，本文旨在解决一个核心问题：**如何使人形机器人能够根据不断变化的指令，在不同类人运动（如行走、奔跑）之间实现无缝、流畅的过渡**。

### 2. 核心方法和技术创新
本文提出了一种新颖的人形机器人运动学习框架，将模仿学习与强化学习深度融合，并引入多项关键技术改进：

- **混合内部模型（Hybrid Internal Model, HIM）**：该模块从历史观测中估计隐藏状态和速度，为策略提供更丰富的环境与自身状态信息，显著提升了运动稳定性和对指令的适应性。
- **Wasserstein散度准则（WGAN-div）**：用于改进模仿学习中的对抗训练。相比传统GAN，WGAN-div能有效缓解“模式崩溃”问题，鼓励策略生成更多样化的关节动作，从而学习到更广泛的运动模式，为无缝过渡打下基础。
- **好奇心奖励机制**：基于哈希网络（HashNet）实现，通过奖励访问频率低的状态-动作对，鼓励智能体探索未知的运动空间，有助于发现专家数据中未包含的中间过渡动作。
- **系统集成**：在近端策略优化（PPO）框架下，整合了任务奖励（如速度跟踪、防滑）、风格奖励（来自WGAN-div判别器）和好奇心奖励，共同训练策略网络和价值网络。

### 3. 主要实验结果
研究在仿真（Isaac Gym, MuJoCo）和现实世界（Noetix N1机器人）中进行了广泛验证：

- **运动性能与适应性**：完整方法（AMPw-HIM+）在基本运动任务奖励、速度指令跟踪精度上均显著优于纯模仿学习（AMP）基线。机器人能精准跟踪从-0.5 m/s到0.75 m/s的突变速度指令。
- **类人性**：通过动态时间规整（DTW）距离评估，虽然引入RL模块会轻微降低与专家数据的相似度，但WGAN-div和好奇心奖励有效缓解了此问题，在保持运动自然流畅的同时，赋予了机器人更强的适应性。
- **强大的泛化能力**：
    - **零样本迁移**：在仿真中训练的策略可直接部署到另一仿真器（MuJoCo）和真实机器人上，无需调整。
    - **动作泛化**：仅使用直线行走和奔跑的专家数据训练后，机器人能自主泛化出**倒退走、侧移、旋转奔跑**等未见动作。
    - **地形与硬件泛化**：策略能适应不同机器人模型（N1, Dora）及复杂地形（崎岖路面、斜坡）。

### 4. 研究意义和价值
本研究在人形机器人运动控制领域取得了重要进展：
- **技术价值**：成功地将模仿学习“类人”的优势与强化学习“适应与泛化”的能力相结合，并通过HIM、WGAN-div、好奇心奖励等创新模块解决了传统方法的固有问题，为实现**指令驱动、无缝过渡、高度类人**的运动控制提供了系统性的解决方案。
- **实际应用价值**：证明了算法具备出色的**仿真到现实（Sim2Real）零样本迁移能力**，大大降低了实际部署的工程门槛。机器人展现出的多任务执行能力和复杂地形适应性，为其在服务、救援、工业等真实场景中的应用铺平了道路。
- **未来方向**：该框架为后续研究奠定了基础，可扩展至更复杂的运动技能（如跳跃、上下楼梯）及全身协同任务（如手部操作）。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析

### **一、 想解决的核心问题**
论文旨在解决**双足人形机器人**在模仿学习中的三个关键挑战：
1.  **指令适应性差**：传统模仿学习（IL）方法训练的机器人只能精确复现训练数据中的特定动作（如固定速度的行走），无法根据**连续变化的运动指令**（如速度、转向命令）进行实时、平滑的调整。
2.  **动作过渡生硬**：在不同运动模式（如从走到跑）之间切换时，动作不连贯、不自然，缺乏人类运动的流畅性。
3.  **泛化能力有限**：模型严重依赖高质量专家数据，难以泛化到**未见过的运动**（如侧向行走、后退跑）或**不同的机器人本体与地形**。

**核心目标**：实现一种能够根据变化指令，在多种高度拟人化运动之间**无缝、自然过渡**的通用人形机器人运动控制方法。

### **二、 核心创新点**
论文提出了一套整合了模仿学习与强化学习的**新颖框架**，其创新性主要体现在以下三个技术模块的协同设计上：

1.  **基于WGAN-div的模仿学习模块**：
    - **创新**：采用**Wasserstein散度**作为生成对抗网络（GAN）的损失函数，替代传统的GAN或均方误差损失。
    - **作用**：有效缓解GAN训练中常见的**模式崩溃**问题，使生成器能学习到更**多样、连续**的专家动作分布。这为机器人探索更丰富的关节姿态组合、生成训练数据中未出现的“中间状态”动作（如从走到跑的过渡姿态）奠定了基础。

2.  **混合内部模型**：
    - **创新**：引入一个**混合内部模型**，它同时具备**速度估计器**和**隐状态估计器**。
    - **作用**：
        - **速度估计器**：从历史观测中直接估计机器人当前速度，为精确跟踪外部速度指令提供了关键反馈，解决了纯模仿学习“盲从数据、无视指令”的问题。
        - **隐状态估计器**：通过对比学习，构建对机器人内部隐藏状态（如关节位置、速度等）的结构化表征。这增强了机器人对自身状态和环境的理解，提升了**运动稳定性和环境适应性**。

3.  **基于好奇心哈希网络的探索奖励**：
    - **创新**：在强化学习的目标函数中，增加了一个**好奇心奖励项**。该奖励通过一个哈希网络将连续状态映射为离散编码，并奖励访问频率低的状态。
    - **作用**：主动鼓励策略探索**未被充分访问的状态-动作空间**，防止训练陷入局部最优。这帮助机器人发现更多样、更节能、更适应其机械结构的运动模式，特别是在需要组合基础动作单元形成新动作时。

### **三、 解决方案：框架整合**
论文的解决方案是将上述创新点**系统性地整合**进一个以**近端策略优化**为骨干的强化学习框架中：

- **训练流程**：策略网络接收历史观测和速度指令，输出动作。其训练受到**四重监督/激励**：
    1.  **基础任务奖励**：奖励跟踪指令、减少滑脚、保持平滑等基本运动能力。
    2.  **风格奖励**：由WGAN-div判别器提供，奖励生成动作与人类专家数据的相似性，确保“拟人化”。
    3.  **内部模型辅助**：HIM提供的速度估计和状态表征作为策略网络的额外输入，极大增强了其对指令和自身状态的感知与响应能力。
    4.  **好奇心奖励**：推动策略探索新动作，促进泛化。

- **关键技术组合**：**AMP + HIM + WGAN-div + Curiosity**。这并非简单堆叠，而是让IL（AMP）负责“形似人类”，RL（PPO）负责“适应指令与实体”，HIM提供“状态感知”，WGAN-div保证“动作多样性”，好奇心驱动“探索未知”，最终实现了 **“形神兼备”且“灵活听话”** 的运动控制。

### **四、 实际价值与验证**
- **强泛化能力**：实验表明，该方法能实现**零样本**迁移到不同仿真器（Isaac Gym → MuJoCo）和**真实世界**，且无需调整控制器参数。
- **多任务与运动生成**：仅用“走”和“跑”的专家数据训练，机器人便能泛化出**后退、侧移、旋转跑**等未见运动。
- **复杂地形适应性**：成功在模拟和真实的崎岖路面、斜坡上稳定运动。
- **推动实用化**：显著缩小了“仿真-现实”差距，提供了一种能产出**即插即用、高度拟人、响应指令**的机器人运动策略的端到端方案，对人形机器人在非结构化环境中的实际部署具有重要价值。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文旨在解决人形机器人如何根据**实时变化的运动指令**，实现**类人、流畅且无缝**的多种步态（如走、跑、旋转）切换这一核心挑战。为此，作者提出了一个**融合模仿学习与强化学习**的创新框架，其核心改进包括：引入**混合内部模型**来估计隐藏状态和速度以增强稳定性和适应性；采用**Wasserstein散度**作为对抗性模仿学习的损失函数以防止模式崩溃，生成更多样化的动作；以及加入**好奇心奖励**来鼓励策略探索未见过的状态空间。该方法最终使机器人能够在**零样本**的情况下，成功将策略从仿真环境迁移到真实世界，不仅能高精度跟踪变化的速度指令，还能泛化到训练数据中未出现的中间运动模式（如侧步、后退跑）及不同复杂地形上，实现了高度类人且适应性强的运动控制。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文创新点分析

这篇论文提出了一种新颖的人形机器人运动学习方法，旨在实现**在响应变化指令时，在不同类人运动之间进行无缝、自然的过渡**。其核心创新点在于对经典模仿学习框架进行了一系列改进，并整合了强化学习，以解决现有方法在泛化性、指令跟踪和运动自然度方面的局限性。

以下是论文相对于已有工作的明确创新点：

### 1. **新颖的架构：结合混合内部模型与WGAN-div的框架**
   - **改进/不同之处**：论文没有单独使用模仿学习或强化学习，而是构建了一个**混合架构**。该架构的核心是**混合内部模型**，它从历史观测中估计隐藏状态和速度；同时，使用**Wasserstein散度生成对抗网络**作为模仿学习模块，提供风格奖励。
   - **解决的问题/带来的优势**：
     - **混合内部模型**解决了在部分可观测环境中状态估计不准的问题，通过结构化地估计隐藏状态和速度，**增强了移动稳定性和对环境变化的适应性**，使机器人能更好地理解自身状态与指令的关系。
     - **WGAN-div模块**替代了传统GAN，旨在解决模仿学习中**模式崩溃**问题，使生成的动作分布更加多样，避免了僵硬、单一的运动模式。
     - **整体架构**将模仿学习的“类人”优势与强化学习的“适应性”优势相结合，使机器人既能模仿人类的自然步态，又能精确跟踪不断变化的速度指令。

### 2. **引入Wasserstein散度损失以增强泛化性**
   - **改进/不同之处**：在模仿学习模块中，采用了**WGAN-div损失函数**，而非传统的GAN损失（如JS散度）或其变体。
   - **解决的问题/带来的优势**：
     - 传统GAN在训练中容易发生模式崩溃，导致生成器只学习到专家数据中的少数几种模式，限制了动作的多样性。WGAN-div提供了**更连续、平滑的梯度**，即使在动作与专家演示差异较大时也能稳定训练。
     - 这使得机器人能够**探索更广阔的状态-动作空间**，学习到更多样的关节位置组合。如图4所示，WGAN-div能捕捉专家分布中的多个峰值，从而帮助机器人**组合出未见过的中间运动**，实现运动之间的无缝过渡，解决了经典模仿学习方法泛化性差、无法处理指令连续变化的问题。

### 3. **通过好奇心奖励机制促进探索**
   - **改进/不同之处**：在标准任务奖励之外，引入了一个基于**好奇心HashNet**的额外奖励 `r^c`。该奖励与状态-动作对的访问频率成反比，访问越少，奖励越高。
   - **解决的问题/带来的优势**：
     - 在模仿学习框架下，机器人容易局限于模仿已有的专家动作，缺乏对未知状态空间的探索。好奇心奖励**主动鼓励策略探索访问频率低的区域**。
     - 这帮助机器人**跳出局部最优解**，发现更多样、更适应其自身硬件结构的运动模式。如图6所示，好奇心奖励与WGAN-div结合，能引导策略在探索得到的新空间中进行优化，最终获得更高的任务回报，提升了学习效率和最终性能。

### 4. **系统性整合与验证带来的综合能力提升**
   - **改进/不同之处**：论文并非简单堆砌技术，而是将HIM、WGAN-div、好奇心奖励与PPO算法**系统性地整合**到一个训练流程中（AMPw-HIM+），并进行了全面的仿真与实物验证。
   - **解决的问题/带来的优势**：
     - **解决了“模仿”与“控制”的脱节问题**：纯模仿学习（如AMP）虽动作自然但无法跟踪新指令；纯强化学习动作可能不自然。本方法实现了**在精确跟踪任意速度指令的同时，保持高度类人的运动风格**。
     - **实现了强大的零样本泛化能力**：该方法展示了在多个维度上的泛化能力：
       - **跨机器人硬件**：策略可迁移到不同结构的人形机器人（如Noetix N1和Dora）。
       - **跨仿真环境**：在Isaac Gym训练的策略可直接在MuJoCo中运行。
       - **仿真到现实**：使用相同的控制器参数，可实现**零样本**从仿真到真实世界的转移。
       - **运动技能泛化**：仅使用行走和奔跑的专家数据，训练出的策略能完成**倒退走、侧移、旋转奔跑**等未见过的复杂动作组合（多任务）。
       - **复杂地形适应**：能够应对崎岖路面、斜坡等非结构化地形。

**总结**：该论文的核心创新在于通过一个精心设计的混合学习框架，巧妙地平衡了“模仿人类运动自然性”和“响应指令控制精确性”这对矛盾。其每一项技术创新（HIM、WGAN-div、好奇心奖励）都针对现有方法的某个关键短板，而它们的协同作用最终赋予了人形机器人**像人类一样“随机应变”** 的能力——即根据变化的指令，流畅、自然地在各种步态间切换和过渡，并适应多样化的真实环境。这为人形机器人在动态、非结构化环境中的实际部署迈出了重要一步。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 论文实验与评估效果分析

该论文通过详尽的仿真与真实世界实验，系统性地验证了所提出方法在实现**类人、自适应、可泛化**的双足机器人运动控制方面的卓越效果。

### 一、 使用的数据集与评价指标

#### 1. 数据集
- **专家数据来源**：使用**动作捕捉（MoCap）** 采集的人类运动数据作为参考。
- **数据内容**：包含多种基础运动模式，如行走、跑步等。论文明确指出，训练数据**仅包含直线行走和跑步**的专家数据，旨在测试方法对未见运动的泛化能力。
- **数据处理**：通过**运动重定向（Motion Retargeting）** 技术，将人类关键点运动缩放并利用逆运动学适配到目标机器人（Noetix N1）的体型和关节结构上。

#### 2. 核心评价指标
论文从四个关键维度评估算法性能，每个维度对应不同的指标：

| 评估维度 | 具体指标与说明 |
| :--- | :--- |
| **1. 基础运动能力** | **任务奖励（Task Reward）**：综合多个子奖励的加权和，包括：<br>- **足部滑移/接触力**：评估运动稳定性。<br>- **线性/角速度跟踪**：评估对指令的跟随精度。<br>- **躯干加速度/动作平滑度**：评估运动的自然性与能耗。 |
| **2. 类人性** | **动态时间规整距离（DTW Distance）**：将机器人生成的运动轨迹与对应的人类专家运动轨迹进行比较。**距离越小，相似度越高**，类人性越好。 |
| **3. 速度跟踪能力** | **速度跟踪误差**：在仿真中施加超出专家数据范围（`[-0.5m/s, 0.75m/s]`）的突变速度指令，计算机器人实际速度与指令速度之间的误差。 |
| **4. 泛化能力** | **定性展示与零样本迁移**：通过多种实验场景综合评估：<br>- **硬件适配**：在不同机器人模型（N1, Dora）上的表现。<br>- **仿真器迁移**：在Isaac Gym训练后，零样本迁移到MuJoCo。<br>- **仿真到现实**：使用相同策略和PD参数，零样本部署到真实机器人。<br>- **运动泛化**：执行训练中未见的运动（如后退、侧移、旋转跑）。<br>- **复杂地形**：在崎岖路面、斜坡上的通过性。 |

### 二、 对比的基线方法
论文构建了一个清晰的消融实验框架，以验证各个模块的贡献：

1.  **AMP**：基础基线。仅使用**对抗性运动先验（Adversarial Motion Prior）** 进行模仿学习。擅长模仿但泛化与指令跟踪能力差。
2.  **AMP-HIM**：在AMP基础上加入**混合内部模型（Hybrid Internal Model）**。旨在提升状态估计和指令跟踪能力。
3.  **AMPw-HIM**：将AMP-HIM中的GAN损失函数替换为**Wasserstein散度（WGAN-div）**。旨在解决模式崩溃，增加动作多样性。
4.  **AMPw-HIM+**：**完整方法**。在AMPw-HIM基础上加入**好奇心奖励（Curiosity Bonus）**。鼓励探索，优化策略。
5.  **AMPw**（补充对比）：仅使用WGAN-div的模仿学习，用于凸显HIM模块的必要性。

### 三、 关键性能提升与结论

#### 1. 基础运动与任务奖励（定量结果）
- **结论**：RL辅助的方法（AMP-HIM, AMPw-HIM, AMPw-HIM+）在任务奖励上**持续显著优于**纯模仿学习基线（AMP）。
- **证据**：图5训练曲线显示，AMP基线任务奖励收敛值低；图6消融实验表明，加入HIM、WGAN-div和好奇心奖励均带来**显著的均值提升**。
- **核心提升**：**AMPw-HIM+**（完整方法）获得了最高的平均任务回报，表明其能更好地平衡稳定性、指令跟踪与能量效率。

#### 2. 类人性（定量结果）
- **结论**：纯模仿方法（AMP）在DTW距离上最优，但牺牲了适应性。HIM模块的引入会**轻微损害类人性**，但WGAN-div和好奇心奖励能有效**缓解这种损害**，在保持适应性的同时尽可能保留人类运动风格。
- **证据**：表IV显示，在引入HIM的各组中，**AMPw-HIM和AMPw-HIM+在多数运动类别上取得了最低（最好）的DTW距离**（加粗显示），证明了WGAN-div和好奇心对“人类风味”的校正作用。

#### 3. 速度跟踪能力（定量与定性结果）
- **结论**：**HIM模块是提升速度跟踪能力的决定性因素**。纯IL方法（AMP, AMPw）无法跟踪训练数据范围外的速度指令，而引入HIM的方法可以。
- **证据**：图7显示，面对突变的超范围速度指令，AMP组机器人速度被“卡”在窄区间内，而AMP-HIM组能有效跟踪。图6的消融实验也表明，移除HIM会导致速度跟踪性能大幅下降。

#### 4. 泛化能力（定性展示为主）
- **结论**：完整方法（AMPw-HIM+）展现了**强大的多维度零样本泛化能力**。
- **证据**：
    - **硬件泛化**：成功控制不同构型的机器人N1和Dora（图1，图8）。
    - **仿真器泛化**：Isaac Gym训练的策略可直接在MuJoCo中运行（图1，图8）。
    - **仿真到现实**：相同策略与控制器参数可零样本部署到真实N1机器人，在室内外稳定行走、跑步（图1，图10）。
    - **运动泛化**：仅用行走和跑步数据训练，机器人能自主组合出**后退、侧移、旋转跑**等复杂未见运动（图8）。
    - **地形泛化**：能在仿真和现实的崎岖路面、斜坡上稳定运动（图9）。

#### 5. 技术创新点的验证
- **WGAN-div的作用**：图4显示，相比原始AMP，WGAN-div能捕捉专家分布中**多个峰值**，生成更多样化的关节姿态，这是实现运动泛化和流畅过渡的基础。
- **好奇心奖励的作用**：帮助策略逃离局部最优，在WGAN-div开拓的更大动作空间中进行更有效的优化（图4，图6）。

### 总结
该论文通过系统的消融实验和丰富的定性展示，全面验证了其方法的有效性。**核心结论**是：通过**混合内部模型（HIM）** 解决状态估计与指令跟踪问题，结合**WGAN-div** 避免模仿学习的模式崩溃以增加多样性，再辅以**好奇心奖励**促进探索，最终实现了一个既能高度模仿人类运动风格，又能**无缝、自适应地响应连续变化指令**的双足机器人控制系统，并具备卓越的跨平台、跨任务、跨地形的零样本泛化能力。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2502.18901v1)
- [HTML 版本](https://arxiv.org/html/2502.18901v1)
