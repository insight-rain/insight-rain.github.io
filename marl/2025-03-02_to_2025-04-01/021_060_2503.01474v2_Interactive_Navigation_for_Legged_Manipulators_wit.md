# Interactive Navigation for Legged Manipulators with Learned Arm-Pushing Controller

**相关性评分**: 6.0/10

**排名**: #21


---


## 基本信息

- **arXiv ID**: [2503.01474v2](https://arxiv.org/abs/2503.01474v2)
- **发布时间**: 2025-03-03T12:29:48Z
- **相关性评分**: 6.0/10
- **是否相关**: 是

## 作者

Zhihai Bi, Kai Chen, Chunxin Zheng, Yulin Li, Haoang Li, Jun Ma

## 关键词

Robot control, quadruped robot locomotion, multi-agent RL, CTDE methods, Edge Deployment, mujoco, local observational information

## 一句话总结

这篇论文提出了一种基于强化学习的臂推控制器，用于腿式机器人在受限空间中的交互导航，通过主动推离障碍物来提高路径效率。

## 摘要

Interactive navigation is crucial in scenarios where proactively interacting with objects can yield shorter paths, thus significantly improving traversal efficiency. Existing methods primarily focus on using the robot body to relocate large obstacles (which could be comparable to the size of a robot). However, they prove ineffective in narrow or constrained spaces where the robot's dimensions restrict its manipulation capabilities. This paper introduces a novel interactive navigation framework for legged manipulators, featuring an active arm-pushing mechanism that enables the robot to reposition movable obstacles in space-constrained environments. To this end, we develop a reinforcement learning-based arm-pushing controller with a two-stage reward strategy for large-object manipulation. Specifically, this strategy first directs the manipulator to a designated pushing zone to achieve a kinematically feasible contact configuration. Then, the end effector is guided to maintain its position at appropriate contact points for stable object displacement while preventing toppling. The simulations validate the robustness of the arm-pushing controller, showing that the two-stage reward strategy improves policy convergence and long-term performance. Real-world experiments further demonstrate the effectiveness of the proposed navigation framework, which achieves shorter paths and reduced traversal time. The open-source project can be found at https://github.com/Zhihaibi/Interactive-Navigation-for-legged-manipulator.git.

## 详细分析

## 论文摘要

**论文标题：** 具有学习型臂推控制器的腿式操纵器交互式导航

### 1. 研究背景和动机
在复杂环境中，机器人主动与环境中的**可移动障碍物**进行交互（如推开箱子）可以开辟更短的路径，从而显著提升导航效率。现有的交互式导航方法主要依赖机器人**本体**去推挤障碍物，这在机器人尺寸受限的狭窄或约束空间中效果不佳。因此，本文旨在为**腿式操纵器**开发一种新颖的交互导航框架，使其能够利用灵活的机械臂主动推开障碍物，以在空间受限环境中实现更高效的通行。

### 2. 核心方法和技术创新
本文提出了一个集成的交互导航框架，其核心创新在于一个基于**强化学习**训练的臂推控制器：
- **导航框架**：结合了传统的无碰撞路径规划（Hybrid A*算法）和一个主动的臂推机制。当检测到路径被可移动障碍物阻挡时，系统会触发臂推控制器将障碍物推至采样得到的最佳目标位置，然后重新规划路径。
- **两阶段奖励策略的臂推控制器**：针对推动**大型物体**（尺寸与机器人相当）时面临的3D空间推理和策略敏感性问题，设计了创新的两阶段奖励函数。
    1. **第一阶段**：引导机械臂末端执行器先无接触地移动到一个预定义的“推动区域”，确保形成运动学上可行的接触配置。
    2. **第二阶段**：在进入推动区域后，激活任务级奖励，鼓励末端执行器保持在区域内稳定推动物体至目标位置，同时防止物体倾倒。
- **其他关键技术**：采用课程学习加速训练，并通过**域随机化**（随机化物体质量、摩擦系数等）和添加观测噪声来实现从仿真到实物的鲁棒迁移。底层结合全身控制器以扩大机械臂工作空间。

### 3. 主要实验结果
- **臂推控制器评估**：仿真实验表明，控制器能适应训练分布外不同尺寸、质量、摩擦系数甚至**圆柱体**形状的物体，成功率达76%以上。消融实验证明，**两阶段奖励策略**相比单阶段或稀疏奖励基线，能显著提升策略收敛速度和长期性能。
- **整体导航框架验证**：在真实世界的腿式机器人（Unitree B2 + Z1 Pro机械臂）上进行测试，设置了三种场景对比：
    - **（A）使用臂推交互**：机器人能主动推开障碍物，路径更短（5.42米），到达时间更快（58.20秒）。
    - **（B）无交互的避障导航**：机器人需绕行，路径更长（10.70米），耗时几乎翻倍（113.50秒）。
    - **（C）使用本体交互**：在狭窄空间中因缺乏精确操控能力而任务失败。
- **额外验证**：展示了控制器在推动过程中能与物体产生**多次自适应接触**以调整方向，并验证了当障碍物无法被推动时的**重规划策略**有效性。

### 4. 研究意义和价值
本研究的意义和价值主要体现在：
- **技术创新**：首次为腿式操纵器提出了集成学习型臂推控制的交互导航框架，并设计了针对大物体推动难题的两阶段奖励策略，有效解决了稀疏奖励和探索困难的问题。
- **实际应用价值**：显著提升了机器人在**杂乱、狭窄空间**中的导航能力和效率，使机器人不仅能“绕开”障碍物，更能“改造”环境以创造通路，更贴近实际应用需求（如仓库、灾后救援）。
- **开源与可扩展性**：项目已开源，为社区提供了研究基准。框架目前专注于“推”的技能，为未来集成更丰富的**非抓取操作**能力（如拉、拨）奠定了基础，推动了腿式机器人在移动操作领域的发展。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析

### **一、 研究问题**
论文旨在解决**移动机器人在狭窄、受限环境中进行交互式导航的难题**。传统方法主要依赖机器人**本体**去推挤障碍物，但在空间小于机器人本体的狭窄区域（如走廊、门口），机器人无法有效接触并移动障碍物，导致导航失败或效率低下。

### **二、 核心创新点**
本文提出了一个**集成主动臂推机制的腿式操纵器交互式导航框架**，其核心创新在于：

1.  **新颖的交互范式**：首次为腿式操纵器系统性地设计了**利用机械臂主动推挤**大型可移动障碍物的导航框架，突破了传统依赖机器人本体交互的空间限制。
2.  **基于强化学习的臂推控制器**：针对**大型物体**（尺寸与机器人相当）的3D空间推挤任务，设计了一个鲁棒的强化学习控制器。
3.  **两阶段奖励策略**：这是**关键技术贡献**。该策略将学习过程分解为两个引导性阶段，有效解决了大型物体推挤任务中探索困难、策略对空间关系敏感的问题：
    - **第一阶段**：引导机械臂末端执行器无碰撞地移动到预定义的“推挤区域”，确保形成运动学上可行的接触构型。
    - **第二阶段**：在进入推挤区域后激活，引导末端执行器保持在合适接触点，稳定推挤物体至目标位置，同时防止物体倾倒。
4.  **分层控制与仿真到现实的迁移**：训练的高层臂推策略与**全身控制器**结合，扩展了机械臂工作空间。通过**领域随机化**（随机化质量、摩擦、观测噪声等）实现了从仿真到真实世界的成功迁移。

### **三、 解决方案**
论文通过一个完整的系统框架解决了上述问题：

1.  **整体框架**：
    - **路径规划**：使用混合A*算法进行全局规划，并为可移动障碍物添加推挤时间成本，鼓励规划器选择更高效的路径。
    - **障碍物重定位决策**：当机器人进入可移动障碍物的“交互区域”时，触发推挤。通过采样和可行性检查，选择最优的推挤目标位置（通常是最近的可行点）。
    - **推挤执行与重规划**：调用训练好的臂推控制器移动障碍物。如果推挤失败（如障碍物被卡住），则将其重新归类为静态障碍物并触发路径重规划。

2.  **臂推控制器训练**：
    - **强化学习设置**：在Isaac Gym仿真环境中，使用PPO算法进行训练。将任务构建为**目标条件化的部分可观测马尔可夫决策过程**。
    - **观察空间**：包含物体、目标、末端执行器的相对位姿等信息，并使用LSTM网络编码历史信息以隐式估计物体动力学。
    - **课程学习**：将最终推挤目标分解为多个中间目标，分阶段训练，加速收敛。
    - **仿真到现实**：通过随机化物理参数和添加噪声，确保策略的鲁棒性和泛化能力。

### **四、 实际价值与验证**
- **性能提升**：真实世界实验表明，与**无交互的碰撞避免导航**相比，本文方法将路径长度缩短了约50%（5.42米 vs. 10.70米），遍历时间减少了约49%（58.2秒 vs. 113.5秒）。与**机器人本体交互**的方法相比，后者在狭窄空间中完全失败，而本文方法成功。
- **鲁棒性与泛化性**：仿真实验验证了臂推控制器对不同**尺寸、质量、摩擦系数甚至不同形状（如圆柱体）** 的物体均具有良好的适应性和成功率（76%-92%）。
- **开源贡献**：公开了项目代码与页面，促进了相关领域的研究复现与应用。

**总结**：本文的核心价值在于，通过“**机械臂作为主动推挤工具**”这一创新思路和“**两阶段奖励策略**”这一关键技术，使腿式机器人在**狭窄受限环境**中的导航能力实现了质的飞跃，从“绕行或卡住”变为“主动清理道路”，显著提升了导航效率和可行性。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文旨在解决**足式机械臂在狭窄、受限环境中导航效率低下的问题**。传统方法依赖机器人本体推动障碍物，但在空间受限时难以施展。为此，论文提出了一个**融合主动臂推机制的交互式导航框架**。其核心创新在于设计了一个**基于强化学习的臂推控制器**，并采用**两阶段奖励策略**来引导机械臂先到达可行的“推动区域”，再稳定地将大型障碍物推至目标位置。仿真和实物实验表明，该方法能有效处理不同物理属性的障碍物，使机器人在复杂受限环境中通过主动交互开辟更短路径，显著减少了导航时间和路径长度。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文创新点分析

这篇论文针对**空间受限环境中腿式操纵器的交互式导航**问题，提出了一套完整的解决方案。其核心创新点主要体现在**系统框架设计**和**控制策略优化**两个层面，具体如下：

### 1. 提出了一种新颖的、集成主动臂推机制的交互式导航框架
- **相比以往方法的改进/不同之处**：
    - **以往方法**：现有的交互式导航研究主要依赖机器人**本体**（如四足机器人的身体）去推动或接触障碍物（如文献[6]），或者使用**固定姿态的机械臂**辅助交互（如文献[7]）。这些方法都需要机器人有足够的空间来建立有效接触。
    - **本文方法**：创新性地将**主动的、可自由运动的机械臂**作为主要的交互工具，集成到腿式机器人的导航框架中。框架包含三个关键阶段：路径规划、可移动障碍物推离、以及重规划。
- **解决的具体问题/带来的优势**：
    - **解决了空间受限环境下的交互难题**：在狭窄或机器人本体尺寸大于可用空间的环境中（如图1所示），传统依靠本体接触的方法会失效。机械臂提供了更高的灵活性和更精细的操作能力，使得机器人能够在**受限和复杂环境中高效地清除障碍物**。
    - **实现了更优的导航效率**：通过主动推离障碍物来“创造”路径，相比传统无碰撞导航的绕行策略，能够生成**更短、更直接的路径**，从而显著**减少到达目标的行程距离和总时间**（如表IV所示，路径长度减少约50%，时间减少约49%）。

### 2. 设计了一种基于强化学习（RL）的、采用两阶段奖励策略的臂推控制器
- **相比以往方法的改进/不同之处**：
    - **以往方法**：
        1.  **传统RL方法**：针对桌面小物体推动设计的奖励策略（如文献[11]）通常较为简单，对于推动与机器人尺寸相当的大型物体时，由于稀疏奖励和复杂的3D空间关系（如碰撞风险、物体倾倒），会导致探索效率低下、策略收敛困难。
        2.  **单阶段或稀疏奖励**：要么从一开始就混合所有奖励（导致引导不清晰），要么仅使用稀疏的任务完成奖励（导致探索几乎无效）。
    - **本文方法**：提出了一种**结构化的两阶段奖励策略**。
        - **第一阶段**：引导机械臂末端执行器到达一个预定义的“**推动区域**”（Pushing Zone），而不接触物体。该区域根据物体和目标位置动态计算，确保一个运动学上可行的接触构型。
        - **第二阶段**：仅在末端执行器进入推动区域后激活，奖励机械臂**保持在该区域内稳定推动物体**向目标移动，同时防止物体倾倒。
- **解决的具体问题/带来的优势**：
    - **解决了大物体推动中的探索与收敛难题**：两阶段策略将复杂的推动任务**分解**，为智能体提供了清晰的、渐进式的学习目标。这极大地**加速了策略的收敛过程**，并**提升了长期性能**（如图4所示，其收敛性和最终性能均优于两个基线方法）。
    - **提升了控制的鲁棒性和适应性**：训练过程中加入了**课程学习**（分阶段逼近目标）和**领域随机化**（随机化物体质量、摩擦系数、臂杆质量等），使得学习到的策略能够**泛化到不同物理属性（大小、质量、摩擦、形状）的物体**上（如表III所示），并实现了较好的**从仿真到现实的迁移**。

### 3. 实现了基于全身控制（WBC）的全身协同推离操作
- **相比以往方法的改进/不同之处**：
    - **以往方法**：大多数推动控制研究将机械臂视为独立系统，或者机器人的移动与操纵是解耦或简单叠加的。
    - **本文方法**：将训练好的臂推策略作为**高层运动规划器**，输出末端执行器的目标位姿。然后，利用一个**全身控制器**来跟踪这个位姿，协调腿式底盘和机械臂的所有自由度。
- **解决的具体问题/带来的优势**：
    - **扩展了机械臂的有效工作空间**：通过腿部的主动调整，机器人可以扩大机械臂能够到达和施力的范围，从而能够处理更多样化的推离场景。
    - **增强了推动的稳定性和力量**：全身协调运动可以使机器人更好地对抗反作用力，实现更稳定、更有力的推动，尤其对于较重或摩擦力较大的物体。

### 4. 集成了针对交互失败的鲁棒重规划机制
- **相比以往方法的改进/不同之处**：
    - **以往方法**：许多交互式导航方法假设交互动作（如推动）总是成功，缺乏对失败情况的处理。
    - **本文方法**：在框架中明确加入了**重规划策略**。当机器人尝试推动某个障碍物但失败时（例如，障碍物被卡住），系统会将该障碍物**重新归类为静态障碍物**，并立即触发全局路径的重新规划。
- **解决的具体问题/带来的优势**：
    - **提高了系统在动态不确定环境中的鲁棒性**：解决了因环境意外变化（如障碍物变得不可移动）而导致任务卡死的问题，确保了导航任务的**最终可完成性**（如图7所示）。

---

**总结**：本文的核心创新在于**“主动精细交互”** 思想的工程化实现。它通过**臂推替代体推**解决了空间约束问题，通过**两阶段RL奖励**解决了大物体操控的学习难题，再通过**全身控制与重规划**提升了系统的整体性能和鲁棒性。这些创新点共同使得腿式操纵器能够在真实、杂乱、受限的环境中执行更高效、更智能的导航任务。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 论文实验与评估效果分析

该论文通过**仿真**和**真实世界实验**，系统性地验证了所提出的**基于学习的臂推控制器**和**交互式导航框架**的有效性、鲁棒性和实际性能提升。

### 一、 使用的数据集与评价指标

论文**未使用**传统的离线数据集。其评估主要基于**自主构建的仿真环境**和**真实物理机器人平台**上的测试。

1.  **仿真环境**：
    *   **训练环境**：在 **Isaac Gym** 中构建自定义的物体推动训练环境，用于训练强化学习策略。
    *   **测试环境**：在 **Gazebo** 仿真器中构建测试场景，用于评估控制器的**适应性**和**鲁棒性**。

2.  **真实世界平台**：
    *   **机器人**：Unitree B2 四足机器人 + Unitree Z1 Pro 6自由度机械臂。
    *   **感知**：使用**运动捕捉系统**获取机器人及可移动障碍物的精确位姿。
    *   **场景**：构建尺寸为 8m × 6.8m 的已知地图环境，包含静态和可移动障碍物。

3.  **核心评价指标**：
    *   **对于臂推控制器**：
        *   **成功率**：在多次重复试验中，物体质心与目标位置距离小于 0.1m 的比例。
        *   **平均奖励曲线**：用于对比不同奖励策略的训练收敛性和长期性能。
    *   **对于整体导航框架**：
        *   **路径长度**：机器人从起点到终点的实际运动轨迹长度。
        *   **遍历时间**：机器人完成整个导航任务所花费的总时间。

### 二、 对比的基线方法

论文在两个方面设置了基线对比：

1.  **臂推控制器的奖励策略对比（仿真）**：
    *   **Baseline 1 (单阶段奖励)**：采用类似推动小物体任务的常见单阶段奖励设计，从一开始就同时施加引导奖励和任务级奖励。
    *   **Baseline 2 (稀疏任务奖励)**：仅使用稀疏的任务级奖励（如物体到目标的距离），探索效率低。
    *   **对比方法**：**本文提出的两阶段奖励策略**。

2.  **整体导航框架的性能对比（真实实验）**：
    *   **方法A：基于臂推的交互式导航**：本文提出的完整框架，主动使用机械臂推开障碍物。
    *   **方法B：无交互的避障导航**：传统方法，将可移动障碍物视为静态障碍物进行绕行（类似文献[1]）。
    *   **方法C：基于机器人本体的交互导航**：模仿文献[6]的方法，尝试用机器人身体（而非机械臂）去推开障碍物。

### 三、 关键性能提升与结论

#### 1. 臂推控制器的性能
*   **鲁棒性与泛化性**：在Gazebo中测试了控制器对不同物体属性（尺寸、质量、摩擦系数、形状）的适应性。
    *   **尺寸变化**：对训练分布外的物体尺寸（如45×50×50 cm³），成功率仍达 **82%**。
    *   **物理属性变化**：在不同质量（1.0-3.0 kg）和摩擦系数（0.5-1.0）下，成功率均 **超过76%**。
    *   **形状泛化**：对训练中未见的**圆柱体**，推动成功率仍达到 **80%**。这证明了策略通过域随机化获得了良好的泛化能力。
*   **两阶段奖励的有效性**：
    *   如图4所示，与两个基线相比，本文的两阶段奖励策略在**收敛速度**和**最终获得的平均奖励**上均表现更优。它通过分阶段引导（先接近推动区，再执行推动），有效解决了大物体推动任务中探索困难、奖励稀疏的问题。

#### 2. 整体导航框架的性能
在真实机器人实验中，三种导航方法的对比结果总结如下表（数据来自多次重复实验的平均值）：

| 评估指标 | 基于臂推的交互导航 (Ours) | 无交互的避障导航 | 基于本体的交互导航 |
| :--- | :--- | :--- | :--- |
| **平均遍历时间** | **58.20 秒** | 113.50 秒 | 任务失败 |
| **平均路径长度** | **5.42 米** | 10.70 米 | 任务失败 |
| **结论** | **高效、成功** | 低效、绕远路 | **无效、被困住** |

*   **核心结论**：
    *   **效率显著提升**：与传统的非交互式导航相比，本文框架将**路径长度缩短了约49%**，**遍历时间减少了约49%**。这直接验证了主动交互在提升狭窄、杂乱环境中导航效率的巨大价值。
    *   **方法优势明显**：基于本体推动的方法在狭窄空间中完全失败，凸显了使用**机械臂进行精细、主动操作的必要性和优越性**。机械臂提供了更大的工作空间和更精确的力控制。
    *   **系统实用性**：框架集成的**重规划策略**（当障碍物无法被推动时）在实际实验中被验证有效，保证了系统的鲁棒性。

### 总结
论文通过详尽的仿真和实物实验，提供了**强有力的定量和定性证据**。结果表明：
1.  **技术创新有效**：两阶段奖励策略确实加速了训练并提升了策略性能；基于学习的臂推控制器具有良好的鲁棒性和泛化性。
2.  **实际价值突出**：所提出的交互式导航框架能够使足式机械臂机器人在真实、受限的环境中，通过主动操作显著优化路径、缩短时间，解决了传统方法效率低下或完全失效的问题。这为机器人在仓储、救援等复杂场景中的实用化提供了重要的技术思路。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2503.01474v2)
- [HTML 版本](https://arxiv.org/html/2503.01474v2)
