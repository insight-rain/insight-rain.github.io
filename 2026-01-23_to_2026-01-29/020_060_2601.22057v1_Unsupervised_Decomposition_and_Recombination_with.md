# Unsupervised Decomposition and Recombination with Discriminator-Driven Diffusion Models

**相关性评分**: 6.0/10

**排名**: #20


---


## 基本信息

- **arXiv ID**: [2601.22057v1](https://arxiv.org/abs/2601.22057v1)
- **发布时间**: 2026-01-29T17:57:06Z
- **相关性评分**: 6.0/10
- **是否相关**: 是

## 作者

Archer Wang, Emile Anand, Yilun Du, Marin Soljačić

## 关键词

Diffusion, fine tune, world model

## 一句话总结

该论文提出一种基于判别器驱动的扩散模型，用于无监督分解和重组复杂数据，在图像和机器人视频轨迹中实现组件重用和生成，提升状态空间覆盖。

## 摘要

Decomposing complex data into factorized representations can reveal reusable components and enable synthesizing new samples via component recombination. We investigate this in the context of diffusion-based models that learn factorized latent spaces without factor-level supervision. In images, factors can capture background, illumination, and object attributes; in robotic videos, they can capture reusable motion components. To improve both latent factor discovery and quality of compositional generation, we introduce an adversarial training signal via a discriminator trained to distinguish between single-source samples and those generated by recombining factors across sources. By optimizing the generator to fool this discriminator, we encourage physical and semantic consistency in the resulting recombinations. Our method outperforms implementations of prior baselines on CelebA-HQ, Virtual KITTI, CLEVR, and Falcor3D, achieving lower FID scores and better disentanglement as measured by MIG and MCC. Furthermore, we demonstrate a novel application to robotic video trajectories: by recombining learned action components, we generate diverse sequences that significantly increase state-space coverage for exploration on the LIBERO benchmark.

## 详细分析

## 论文摘要

**论文标题：** 基于判别器驱动的扩散模型的无监督分解与重组

### 1. 研究背景和动机
表示学习和生成模型是机器学习的两个互补支柱。许多领域（如视觉、机器人）的数据具有组合性结构，即由可重用的独立因子（如背景、光照、物体属性、动作基元）组合而成。无监督地学习这种因子化表示，并能够通过跨样本重组因子来合成新颖且合理的数据，对于提升模型的组合泛化能力至关重要。然而，完全无监督的解耦被证明是不可能的，且先前的组合生成方法（如Decomp Diffusion）在重组时可能产生不合理或脱离数据流形的样本。因此，需要一种机制来引导模型学习支持高质量重组的表示。

### 2. 核心方法和技术创新
本文提出了一种**判别器驱动的对抗训练信号**，以改进基于扩散模型的因子化表示学习和组合生成质量。核心创新在于引入一个判别器，该判别器被训练以区分**来自单一数据源的生成样本**与**通过混合多个源数据的潜在因子后生成的“重组样本”**。生成器（编码器-扩散模型）则被优化以“欺骗”该判别器，使得重组样本在判别器看来与单源样本无法区分。这种方法为目标函数增加了一项对抗损失（`ℒ_adv`），与标准的扩散重建损失（`ℒ_MSE`）共同优化，从而鼓励重组结果在物理和语义上保持一致。

### 3. 主要实验结果
方法在多个图像数据集（CelebA-HQ, Virtual KITTI, CLEVR, Falcor3D）和机器人视频数据集（LIBERO）上进行了验证：
*   **图像生成质量：** 在重组样本的Fréchet Inception Distance (FID) 指标上显著优于基线方法Decomp Diffusion。
*   **解耦性能：** 在Falcor3D数据集上，解耦度量（MIG, MCC）得到提升，表明学习到的潜在因子更具独立性。
*   **机器人应用：** 将方法应用于机器人演示视频，通过重组学习到的动作组件，能够生成多样且物理上合理的视频轨迹。执行这些生成的计划能**显著扩大智能体在状态空间中的探索范围**（在LIBERO基准测试中覆盖度提升最高达73.8%）。

### 4. 研究意义和价值
本研究的意义在于：
*   **方法论价值：** 提出了一种通用、可扩展的框架，通过内部生成的对抗性反馈来引导无监督的组合表示学习，无需外部标注或昂贵的环境交互。
*   **实际应用价值：** 在图像领域提升了组合编辑的保真度；在机器人领域，展示了如何利用生成模型合成新颖、可行的行为来增强探索和数据覆盖，为基于模型的强化学习和规划提供了新思路。
*   **理论启示：** 通过理论分析表明，对重组样本的优化压力会促使潜在空间结构趋向笛卡尔积形式，并降低因子间的统计依赖性，这与解耦的目标相一致。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析

### **研究问题**
论文旨在解决**无监督学习中的组合生成与表示解耦**这一核心挑战。具体而言，它关注如何在没有因子级监督（即没有标注哪些数据变化对应哪些语义因子）的情况下，让基于扩散的生成模型：
1.  **发现**数据中可分解的、有意义的潜在因子（如人脸图像中的背景、光照、发型；机器人视频中的可重用动作基元）。
2.  **支持**对这些学到的因子进行跨样本的重新组合，以生成新颖且**物理/语义一致**的样本。

### **核心创新点**
论文的核心创新在于引入了一种**基于判别器的对抗性训练信号**，以同时改进**潜在因子的发现**和**组合生成的质量**。

1.  **创新机制：判别器驱动的重组一致性约束**
    *   **传统方法的局限**：以往的无监督分解方法（如β-VAE、Decomp Diffusion）主要依靠重建损失和统计正则化（如鼓励潜在变量独立）来学习表示。然而，这并不能保证学到的因子在跨样本重组时能产生合理（位于数据流形上）的结果。
    *   **本文方案**：论文引入一个判别器 `D_ψ`，其任务是区分“单源生成”（使用来自单个样本的所有潜在因子生成）和“重组生成”（混合来自两个不同样本的潜在因子生成）。生成器（编码器+扩散模型）则被训练以“欺骗”这个判别器，使重组样本看起来与单源样本无法区分。
    *   **关键公式**：
        *   判别器损失：`ℒ_clf(ψ) = -E[log D_ψ(x̂_single) + log(1 - D_ψ(x̂_recomb))]`
        *   生成器对抗损失：`ℒ_adv(θ, φ; ψ) = -E[log D_ψ(x̂_recomb)]`
        *   总生成器损失：`ℒ_gen = ℒ_MSE + λ * ℒ_adv`

2.  **理论洞见与实践价值**
    *   **理论连接**：论文将判别器的反馈解释为一种**隐式正则化**，它鼓励潜在空间支持在坐标（因子）子集上的重组操作，这理论上会促使潜在支持集趋近于笛卡尔积结构（`𝒵 = π_1(𝒵) × ... × π_K(𝒵)`），并降低潜在变量间的互信息（见附录E）。
    *   **实践优势**：判别器作为一个可学习的、**感知合理性的代理**，能够检测并惩罚重组时产生的低级不一致性（如纹理错位、光照矛盾），从而引导模型学习更模块化、更可组合的表示。

3.  **应用拓展：从静态图像到机器人视频规划**
    *   论文创新性地将该框架应用于**机器人演示视频**。模型学习将视频轨迹分解为可重用的动作组件。
    *   通过重组这些组件，可以生成**新颖的、物理上合理的视频计划**，用于引导机器人进行**探索**。实验表明，这种方法能显著增加智能体在状态空间中的覆盖范围。

### **解决方案的流程**
1.  **基础框架**：建立在“分解扩散模型”（Decomp Diffusion）上，该模型通过让去噪网络的输出是多个因子条件下去噪预测的均值（`ϵ_θ(x_t, t) = (1/K) Σ_k ϵ_θ(x_t, t, z_k)`）来实现组合生成。
2.  **训练循环**：
    ```python
    # 算法核心（简化版）
    while not converged:
        # 1. 采样两个数据点 x^A, x^B
        # 2. 编码得到潜在因子 z^A, z^B
        # 3. 随机生成重组掩码S，混合得到重组潜在 z̃
        # 4. 对x^A加噪得到 x_t^A
        # 5. 生成单源预测 x̂_single = G(x_t^A, t, z^A)
        # 6. 生成重组预测 x̂_recomb = G(x_t^A, t, z̃)
        # 7. 更新判别器：区分 x̂_single（真）和 x̂_recomb（假）
        # 8. 更新生成器/编码器：最小化重建损失 + λ * 对抗损失（让重组样本骗过判别器）
    ```
3.  **评估验证**：
    *   **图像**：在CelebA-HQ、Falcor3D等多个数据集上，其方法在**FID分数**（衡量生成质量）和**MIG/MCC**（衡量解耦度）上均优于基线模型（如Decomp Diffusion）。
    *   **机器人视频**：在LIBERO仿真环境中，使用重组视频计划引导探索，实现了比使用原始演示或简单打乱基线**高得多的状态空间覆盖率**（Scene5提升35.8%，Scene6提升73.8%）。

### **总结**
这篇论文的核心贡献是提出了一种**简单而有效**的对抗性训练机制，将**组合生成的质量**直接作为训练信号来**塑造潜在表示的学习**。它不再仅仅依赖于重建和统计独立性假设，而是通过要求“重组结果必须看起来逼真”这一**实用性目标**，来驱动模型发现更具组合性、更解耦的因子。这为解决无监督解耦中“什么才是好表示”这一根本问题提供了一个新颖且有力的思路，并在静态图像生成和动态视频规划两个领域验证了其价值。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文旨在解决**无监督学习场景下，如何让生成模型（特别是扩散模型）自动发现数据中可分解、可重组的潜在因子，并确保这些因子在跨样本重组后能生成物理和语义一致的新样本**这一核心问题。为此，论文提出了一个**基于判别器驱动的对抗训练框架**：在训练因子化扩散模型的同时，引入一个判别器来区分“由单一源样本生成的图像”和“由多个源样本的潜在因子重组后生成的图像”，并通过对抗训练迫使生成器（编码器/解码器）产生能够“欺骗”判别器的、更逼真的重组样本。该方法在多个图像数据集（CelebA-HQ, Virtual KITTI等）上显著提升了重组样本的感知质量（FID分数更低）和潜在因子的解耦程度（MIG和MCC指标更优），并成功应用于机器人视频轨迹生成，通过重组学习到的动作组件，生成了多样化的新轨迹，有效扩大了智能体在环境中的探索范围。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文创新点分析

这篇论文《Unsupervised Decomposition and Recombination with Discriminator-Driven Diffusion Models》在无监督分解与重组学习领域提出了多项明确的技术创新。其核心思想是**引入一个判别器驱动的对抗性训练信号，以提升因子化潜在空间的发现能力和组合生成的质量**。以下是其相对于已有工作的主要创新点：

---

### 1. **引入判别器驱动的对抗性反馈机制**
- **改进/不同之处**：
    - **以往方法**：如Decomp Diffusion、COMET等无监督分解方法，主要依赖于重构损失（如MSE）和特定的模型结构（如能量函数求和、去噪预测平均）来鼓励解耦。它们缺乏一个明确的机制来确保**跨样本重组后的生成样本在物理和语义上的一致性**。
    - **本文方法**：在标准扩散重构损失之外，引入了一个额外的对抗性损失项。该损失由一个判别器提供，该判别器被训练以区分“单源生成样本”（使用来自单个输入的所有潜在因子）和“重组生成样本”（使用来自多个输入的因子混合）。生成器（编码器/解码器）则被训练以“欺骗”该判别器，使重组样本难以被区分。
- **解决的问题/带来的优势**：
    - **解决的核心问题**：无监督模型中，简单的潜在因子重组常常会生成偏离真实数据流形、物理上不合理或语义上不一致的样本（即“重组伪影”）。
    - **具体优势**：
        1. **提升重组样本质量**：判别器作为一个可学习的、针对重组一致性的正则化器，迫使模型学习到支持**可组合性**的潜在表示。重组样本在视觉上更连贯，物理上更合理（如图像中的光照/几何一致性，视频中的动作连贯性）。
        2. **改善解耦效果**：对抗性反馈间接鼓励了潜在因子之间的统计独立性。论文的理论分析（附录E）表明，对重组样本的惩罚会收缩潜在分量间的互信息，从而促进解耦。
        3. **提供可扩展的替代反馈**：相比依赖于昂贵环境交互或人工标注的反馈，判别器提供了一种**可扩展的、自监督的代理信号**，用于评估和提升组合的合理性。

### 2. **将判别器反馈无缝集成到扩散模型训练框架中**
- **改进/不同之处**：
    - **技术实现**：判别器并非作用于最终生成的清晰样本（那样计算成本高），而是作用于**单步去噪预测** `\hat{x}_0`（受ReFL启发）。在训练时，对同一噪声输入 `x_t`，分别用单源潜在和重组潜在进行单步去噪，得到 `\hat{x}_single` 和 `\hat{x}_recomb`，并在此之上训练判别器和生成器。
    - **与纯能量模型对比**：避免了COMET等能量模型需要内部迭代优化（如图像梯度下降）带来的计算复杂性和不稳定性，利用了扩散模型隐式执行能量梯度下降的稳定性和可扩展性。
- **解决的问题/带来的优势**：
    - **计算效率**：单步预测提供了关于重组质量的**可微分且高效的代理信号**，无需在训练循环中进行完整的多步采样，大大降低了计算开销。
    - **训练稳定性**：将对抗性训练与扩散模型的去噪训练（`ℒ_MSE`）相结合，通过超参数 `λ` 平衡重构保真度与组合一致性，避免了对抗训练常见的模式崩溃问题（论文通过消融实验展示了 `λ` 的倒U型影响）。

### 3. **在机器人视频轨迹生成与探索中的新颖应用**
- **改进/不同之处**：
    - **应用领域拓展**：首次将无监督分解与重组框架系统性地应用于**机器人演示视频**，以生成多样化的、物理上可行的新轨迹。
    - **具体方法**：模型将视频编码为 `K` 个潜在因子（可能对应不同的动作基元或物体交互），并通过**重组不同演示视频的潜在因子**来合成新的视频计划。生成过程以第一帧为条件，确保场景上下文一致。
- **解决的问题/带来的优势**：
    - **解决数据稀缺与覆盖不足问题**：机器人演示数据集通常狭窄。通过重组学习到的动作组件，可以生成大量**未见过的、但物理合理的轨迹**，从而显著扩大智能体在状态空间中的探索范围。
    - **提供动作层面的评估指标**：不仅使用视觉质量指标（如FID），还引入了**物理一致性损失**（`L_phys`，比较生成帧与执行帧的差异）和**状态空间覆盖率**（`Cov_Δ`）等**基于动作的评估指标**，直接衡量生成计划的可执行性和探索有效性。
    - **实证结果**：在LIBERO基准测试中，该方法生成的重组视频计划，相比使用原始演示、其他演示或帧重排等基线方法，能带来**显著更高的状态空间覆盖率**（在Scene5和Scene6上分别提升35.8%和73.8%）。

### 4. **通过合成实验与理论分析阐明机制**
- **改进/不同之处**：
    - **机制隔离实验**：设计了一个**合成数据实验**，其中解码器固定且已知，仅训练一个线性重参数化矩阵 `W` 来应对判别器的反馈。该实验剥离了扩散训练和高容量生成器的影响，**纯粹地验证了“判别器反馈可以重塑表示以支持重组”这一核心机制**。
    - **理论贡献**：在附录E中提供了理论分析，表明：
        1. **加性能量模型等价于专家乘积**，解释了重组不一致性可能源于专家约束冲突。
        2. **在数据流形上对任意子集重组的闭包性，意味着潜在空间具有笛卡尔积结构**，这为解耦提供了理论依据。
        3. **随机重组会收缩潜在分量间的互信息**，从理论上解释了对抗性反馈如何促进解耦。
- **解决的问题/带来的优势**：
    - **增强解释性**：合成实验和理论分析使方法的有效性不再仅仅是经验性的，而是提供了**直观和数学上的解释**，增强了工作的深度和可信度。
    - **指导模型设计**：理论分析指出了实现良好重组需要满足的结构性条件（如潜在空间的乘积结构），为未来模型设计提供了指导。

---

## 总结
| 创新点 | 相比以往方法的改进 | 解决的具体问题/带来的优势 |
| :--- | :--- | :--- |
| **1. 判别器驱动的对抗性反馈** | 在无监督重构损失外，新增一个针对重组样本一致性的对抗性正则项。 | 提升重组样本的物理/语义一致性；间接改善解耦；提供可扩展的自监督反馈。 |
| **2. 基于单步去噪预测的集成** | 判别器作用于扩散过程的中间单步预测，而非最终样本，实现高效集成。 | 保证计算效率；维持训练稳定性；与扩散框架自然结合。 |
| **3. 应用于机器人视频规划与探索** | 将框架拓展至视频域，通过重组潜在动作因子生成新轨迹，并用于增强探索。 | 缓解演示数据稀缺问题；大幅提升状态空间覆盖率；引入动作层面的评估指标。 |
| **4. 合成实验与理论分析** | 设计隔离实验验证核心机制，并提供理论分析阐明重组闭包性与解耦的关系。 | 增强方法解释性；为模型有效性提供理论支撑；指导未来研究方向。 |

这些创新点共同构成了一个**系统性的进展**：不仅提出了一种提升无监督组合生成质量的新方法，还通过严谨的实验设计（从合成数据到真实图像再到复杂视频）和理论分析，深入阐述了其工作原理，并展示了其在具有挑战性的机器人学习任务中的实用价值。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 论文实验效果总结

该论文通过系统的实验，在图像和机器人视频两个领域验证了所提出的**基于判别器的扩散模型（Discriminator-Driven Diffusion Models）** 在无监督分解与重组任务上的有效性。实验表明，该方法在**生成质量**、**解耦度**和**探索覆盖率**等多个维度上均优于现有基线。

### 一、 实验设置与评估指标

#### 1. 使用的数据集
*   **图像数据集**:
    *   **CelebA-HQ**: 高质量人脸图像，用于评估外观属性（如发型、表情）的分解与重组。
    *   **Falcor3D**: 合成3D场景数据集，提供真实因子标注，是**解耦度评估**的关键基准。
    *   **Virtual KITTI (VKITTI)**: 逼真的合成驾驶场景，用于评估复杂全局场景因子（如视角、光照）的重组。
    *   **CLEVR**: 合成物体中心数据集，用于评估物体级属性（形状、颜色、位置）的分解。
*   **机器人视频数据集**:
    *   **LIBERO** (Scene 5 & 6): 桌面操作模拟基准，包含“将杯子放到盘子”和“将物体放置于盘子旁”等任务，用于评估动作组件的重组与探索。

#### 2. 使用的评价指标
*   **图像生成质量**: **Fréchet Inception Distance (FID)**。用于衡量重组生成的图像分布与真实数据分布之间的差异，**值越低越好**。
*   **解耦度评估**:
    *   **互信息间隙 (Mutual Information Gap, MIG)**: 衡量每个真实因子信息被集中编码到单个潜在维度的程度，**值越高越好**。
    *   **平均相关系数 (Mean Correlation Coefficient, MCC)**: 衡量潜在变量与真实因子之间的对齐程度，**值越高越好**。
    *   **总相关性 (Total Correlation, TC)** 和 **块间相关性 (Block Correlation)**: 衡量潜在变量之间的统计依赖性，**值越低越好**。
*   **机器人视频评估**:
    *   **物理一致性损失 (`L_phys`)**: 衡量生成视频帧与执行生成动作后实际环境帧之间的L2误差，**值越低越好**。
    *   **状态空间覆盖率 (`Cov_Δ`)**: 在离散化的机器人关节状态空间中，衡量执行重组计划所访问的不同状态单元数量，**值越高越好**。

#### 3. 对比的基线方法
*   **图像任务主要基线**: **Decomp Diffusion**。这是当前最先进的无监督扩散分解方法，论文在其基础上进行改进和对比。
*   **其他参考基线** (在Falcor3D解耦度表格中): InfoGAN, β-VAE, MONet, COMET。这些是经典的解耦表示学习方法，用于提供性能背景参考。
*   **机器人视频任务基线**:
    *   **Demo-Self**: 使用同一演示的剩余帧作为目标视频（无重组）。
    *   **Demo-Other**: 使用同一任务不同演示的视频作为目标。
    *   **Shuffle-Self**: 在同一演示视频内局部打乱帧序。

### 二、 关键实验结果与性能提升

#### 1. 图像重组质量 (FID)
论文方法在**所有四个图像数据集**上均显著降低了重组样本的FID分数，表明生成图像的感知质量更高、更接近真实数据分布。

| 数据集 | Decomp Diffusion (FID ↓) | **Ours (FID ↓)** | 相对提升 |
| :--- | :--- | :--- | :--- |
| **CelebA-HQ** | 82.70 ± 19.39 | **43.98 ± 0.78** | **~46.8%** |
| **Falcor3D** | 157.11 ± 9.53 | **130.19 ± 3.62** | **~17.1%** |
| **VKITTI** | 88.46 ± 3.81 | **84.22 ± 0.19** | **~4.8%** |
| **CLEVR** | 25.70 ± 3.75 | **24.16 ± 0.16** | **~6.0%** |

**结论**: 判别器反馈有效引导模型生成更逼真、物理一致的重组图像，减少了基线方法中常见的重组伪影（如纹理错乱、光照不一致）。

#### 2. 解耦表示学习 (MIG & MCC)
在提供真实因子的**Falcor3D**数据集上，论文方法在解耦度指标上超越了Decomp Diffusion基线。

| 模型 | MIG (↑) | MCC (↑) |
| :--- | :--- | :--- |
| Decomp Diffusion* | 0.065 ± 0.019 | 0.657 ± 0.025 |
| **Ours* (λ=0.005)** | **0.118 ± 0.012** | **0.707 ± 0.011** |
| **Ours* (λ=0.02)** | **0.141 ± 0.031** | 0.640 ± 0.038 |

(*表示在论文代码库中重新实现和评估)
**结论**: 适度的判别器权重（λ=0.005）在提升解耦度（MIG）的同时保持了良好的因子相关性（MCC）。这表明对抗性重组信号不仅改善了生成质量，还促使模型学习到**更独立、更语义化的潜在因子**。

#### 3. 机器人视频重组与探索
在**LIBERO**基准测试中，论文方法通过重组学习到的动作组件，生成了多样且物理可行的视频计划，从而显著提升了智能体的**状态空间探索覆盖率**。

*   **定性结果**: 如图4所示，模型能够将来自不同场景（如“红杯放右盘”和“巧克力布丁放盘左”）的潜在组件重组，生成一个全新的、合理的动作序列（如“尝试将布丁放在盘子边缘”）。
*   **定量结果** (状态空间覆盖率):
    *   **Scene 5**: 最佳判别器权重（λ=0.001）将覆盖率从基线的9440提升至**12816**，提升约**35.8%**。
    *   **Scene 6**: 同样设置下，覆盖率从5400提升至**9385**，提升约**73.8%**。
*   **物理一致性**: 随着判别器权重λ的增加，动作 grounded L2 损失 (`L_phys`) 呈现先降后升的“倒U型”曲线，表明存在一个最优的λ值，能在保证重组多样性的同时最大化物理合理性。

**结论**: 该方法能够**无监督地发现可重用的动作基元**，并通过重组这些基元创造出训练集中未见过但物理上可行的行为，从而大幅扩展了策略的探索范围，为基于模型的强化学习提供了高质量的数据增强途径。

### 三、 核心创新与价值体现

1.  **技术创新**: 首次将**对抗性训练信号**引入无监督因子化扩散模型。通过训练一个判别器来区分“单源生成”和“跨源重组生成”，并以此优化生成器，从而**隐式地强制重组样本的物理和语义一致性**。这是一种可扩展的、替代昂贵环境反馈的实用方法。
2.  **实际价值**:
    *   **对于生成模型**: 提供了一种提升组合生成质量和表示解耦度的通用框架，可应用于图像编辑、内容创作等领域。
    *   **对于机器人学习**: 展示了一条通过**无监督视频分解与重组来增强探索**的新路径。生成的多样化、合理的轨迹可以作为计划目标或模拟经验，有效缓解示范数据稀缺问题，提升策略在未见状态下的泛化能力。

**局限性**: 论文指出，当前方法在训练时，判别器评估的重组样本是基于**单个源图像的噪声状态**生成的，这与完全自洽的生成过程略有偏差。未来工作可探索更对齐的噪声条件机制。此外，判别器未显式考虑扩散时间步，这也是一个可改进的方向。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2601.22057v1)
- [HTML 版本](https://arxiv.org/html/2601.22057v1)
