# ReViP: Reducing False Completion in Vision-Language-Action Models with Vision-Proprioception Rebalance

**相关性评分**: 8.0/10

**排名**: #10


---


## 基本信息

- **arXiv ID**: [2601.16667v1](https://arxiv.org/abs/2601.16667v1)
- **发布时间**: 2026-01-23T11:31:07Z
- **相关性评分**: 8.0/10
- **是否相关**: 是

## 作者

Zhuohao Li, Yinghao Li, Jian-Jian Jiang, Lang Zhou, Tianyu Zhang, Wei-Shi Zheng

## 关键词

Vision-Language-Action Model, VLA for Robotics, fine tune

## 一句话总结

ReViP通过视觉-本体感觉再平衡技术减少VLA模型中的虚假完成错误，提升机器人操作的鲁棒性和成功率。

## 摘要

Vision-Language-Action (VLA) models have advanced robotic manipulation by combining vision, language, and proprioception to predict actions. However, previous methods fuse proprioceptive signals directly with VLM-encoded vision-language features, resulting in state-dominant bias and false completions despite visible execution failures. We attribute this to modality imbalance, where policies over-rely on internal state while underusing visual evidence. To address this, we present ReViP, a novel VLA framework with Vision-Proprioception Rebalance to enhance visual grounding and robustness under perturbations. The key insight is to introduce auxiliary task-aware environment priors to adaptively modulate the coupling between semantic perception and proprioceptive dynamics. Specifically, we use an external VLM as a task-stage observer to extract real-time task-centric visual cues from visual observations, which drive a Vision-Proprioception Feature-wise Linear Modulation to enhance environmental awareness and reduce state-driven errors. Moreover, to evaluate false completion, we propose the first False-Completion Benchmark Suite built on LIBERO with controlled settings such as Object-Drop. Extensive experiments show that ReViP effectively reduces false-completion rates and improves success rates over strong VLA baselines on our suite, with gains extending to LIBERO, RoboTwin 2.0, and real-world evaluations.

## 详细分析

## 论文摘要：ReViP: 通过视觉-本体感觉再平衡减少视觉-语言-动作模型中的误完成

### 1. 研究背景和动机
视觉-语言-动作模型在机器人操作任务中取得了显著进展，但现有方法通常将本体感觉信号与视觉-语言特征直接融合，导致模型过度依赖内部状态（如关节位置、任务进度），而**忽视视觉证据**。这种**模态失衡**引发了“误完成”现象：即使执行明显失败（如目标物体掉落），机器人仍会基于内部状态惯性执行原计划并错误宣告任务完成。本文旨在解决这一关键问题，提升VLA模型在扰动下的视觉感知能力和鲁棒性。

### 2. 核心方法和技术创新
本文提出 **ReViP** 框架，其核心是通过**视觉-本体感觉再平衡**来增强视觉感知。主要创新点包括：
- **任务阶段观察器**：利用一个**冻结的外部视觉语言模型**（如Qwen 2.5-VL）作为实时“观察者”，从当前视觉观测和指令中提取**任务中心的视觉线索**（如“物体已掉落”），为策略提供额外的环境先验知识。
- **任务阶段增强器**：设计了一种**任务阶段特征线性调制机制**，将上述视觉线索以特征调制（TS-FiLM）的方式自适应地注入到VLA主干网络中，从而在特征层面**重新平衡视觉流和本体感觉流的影响**，抑制状态主导的偏差。
- **首个误完成评测基准**：在LIBERO平台上构建了一个包含**物体掉落、干扰物交换、场景重布局**三种可控扰动设置的基准测试套件，用于系统评估VLA模型对误完成现象的鲁棒性。

### 3. 主要实验结果
实验表明ReViP在多个基准测试中均取得显著提升：
- **误完成基准测试**：ReViP将平均成功率提升至**62%**，显著优于基线模型（如π0和π0-Fast），**误完成率大幅降低**。在物体掉落任务中，ReViP能有效检测失败并执行重新抓取。
- **通用仿真基准**：在标准LIBERO和双臂RoboTwin 2.0基准测试中，ReViP取得了**最先进的任务成功率**（LIBERO平均96.7%），证明了其方法在无扰动任务中也具有优越的泛化能力。
- **真实世界实验**：在包含掉落、干扰物等复杂场景的真实机器人操作中，ReViP的成功率（**60%**）远超基线模型，验证了其在实际应用中的有效性和鲁棒性。

### 4. 研究意义和价值
本研究首次系统性地揭示并解决了VLA模型中的**模态失衡与误完成问题**。所提出的ReViP框架通过引入外部VLM提供的**任务感知视觉先验**，并设计自适应的特征再平衡机制，为构建更**可靠、感知驱动**的机器人策略提供了新思路。同时，发布的误完成评测基准为社区评估模型鲁棒性提供了重要工具。这项工作推动了VLA模型从“状态驱动”向“证据驱动”的演进，对实现能在动态、不确定环境中安全可靠工作的下一代机器人系统具有重要价值。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析：ReViP

### **一、 研究问题：模态失衡与“虚假完成”**
论文旨在解决**视觉-语言-动作模型**中的一个关键缺陷：**模态失衡**及其导致的**“虚假完成”**问题。

- **问题定义**：在机器人执行任务过程中，如果发生意外扰动（如目标物体掉落），VLA模型会**过度依赖内部本体感觉状态**，而**忽视当前视觉证据**，继续执行原计划甚至错误地宣告任务成功。这种现象被称为“虚假完成”。
- **根本原因**：现有VLA模型通常将视觉-语言特征与本体感觉信号进行简单融合，导致策略产生了**状态主导的偏差**。模型更信任“我计划做什么”（本体感觉进度），而非“我实际看到了什么”（视觉反馈）。

### **二、 核心创新点**
论文提出了 **ReViP** 框架，其核心创新在于通过**视觉-本体感觉再平衡**来增强模型的视觉感知和鲁棒性。

1.  **提出“虚假完成”这一关键失败模式**：首次系统性地定义、分析了VLA模型因模态失衡导致的“虚假完成”现象，并指出了其普遍性和危害性。
2.  **引入任务感知的环境先验**：创新性地使用一个**外部的大型视觉语言模型作为“任务阶段观察器”**。
    - **功能**：实时分析当前观测图像和任务指令，提取**任务中心的视觉线索**（例如：“奶油芝士未被机械臂抓取”）。
    - **作用**：这些线索作为高层次的、语义丰富的环境状态先验，为策略提供了明确的、与任务进度相关的视觉反馈。
3.  **设计特征级调制机制**：提出了**任务阶段增强器**，采用**任务阶段特征线性调制（TS-FiLM）**。
    - **过程**：将TSO提取的语义线索转换为调制参数 `[γ, β]`，在特征层面对VLA骨干网络中的视觉-语言前缀特征进行自适应调制。
    - **效果**：动态地**增强与当前任务相关的视觉特征，抑制无关或误导性的内容**，从而在决策时刻重新平衡视觉流和本体感觉流的影响权重。
4.  **构建首个“虚假完成”评测基准**：在LIBERO平台上创建了一个系统化的基准测试套件，包含三种受控扰动场景：
    - **物体掉落**：测试执行中突发故障的检测与恢复能力。
    - **干扰物交换**：测试在视觉相似物体间的实例级 grounding 能力。
    - **场景重布局**：测试空间推理和适应新环境配置的能力。

### **三、 解决方案：ReViP框架工作流程**
1.  **感知阶段（Task-Stage Observer）**：
    - 输入当前多视角观测 `O_t` 和语言指令 `l`。
    - 使用冻结的Qwen2.5-VL模型分析，输出结构化的任务阶段语义线索 `z_t`（如物体状态、阶段意图）。

2.  **调制与决策阶段（Task-Stage Enhancer + VLA骨干）**：
    - 将语义线索 `z_t` 通过一个小型网络映射为TS-FiLM参数 `[γ_t, β_t]`。
    - 将这些参数应用于VLA骨干的视觉-语言前缀特征 `P_t`，得到调制后的特征 `\tilde{P}_t`。公式化表示为：
        ```math
        \tilde{P}_t = (P_t + α(γ_t ⊙ P_t + β_t)) ⊙ M_t
        ```
    - 调制后的特征与本体感觉状态 `S_t` 融合，最终通过一个基于流匹配的动作解码器预测动作块。

3.  **效果**：当发生扰动（如物体掉落）时，TSO提供的线索（“物体已掉落”）会通过TS-FiLM机制强烈调制视觉特征，迫使策略关注这一视觉失败证据，从而触发重新抓取等纠正动作，避免“虚假完成”。

### **四、 实际价值与效果**
- **显著提升鲁棒性**：在提出的False-Completion Benchmark上，ReViP将平均成功率提升至**62%**，远超最佳基线（π₀-Fast的44%），尤其在物体掉落任务上表现突出。
- **泛化性能强**：在标准LIBERO基准测试和更具挑战性的双臂RoboTwin 2.0基准测试中，ReViP均达到了**最先进的成功率**，证明其改进不仅限于应对扰动，也提升了通用操作能力。
- **具备即插即用潜力**：作者将ReViP的核心机制应用于另一个VLA骨干（π₀.₅），同样带来了显著性能提升，表明**视觉-本体感觉再平衡**是一个可迁移的通用设计原则。
- **推动评测标准化**：提出的False-Completion Benchmark为社区提供了一个**系统化评估VLA模型在扰动下鲁棒性**的工具，有助于推动更可靠、更安全的机器人学习模型发展。

**总结**：ReViP的核心贡献在于**诊断了VLA模型的一个关键病理（模态失衡），并提出了一个优雅的“开方”方案（通过外部VLM注入任务语义先验进行特征级再平衡）**，同时建立了相应的“诊断标准”（评测基准），在仿真和现实世界中均验证了其有效性。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文针对视觉-语言-动作模型中存在的**模态失衡问题**——即策略过度依赖内部本体感知状态而忽视视觉证据，导致在任务执行失败时仍错误宣告完成的**虚假完成**现象。为此，论文提出了 **ReViP** 框架，其核心创新在于引入一个基于外部视觉语言模型的**任务阶段观察器**来提取实时任务中心视觉线索，并通过一个**任务阶段增强器**，利用特征级线性调制技术，将这些线索作为环境先验自适应地重新平衡视觉流与本体感知流在决策中的权重。实验结果表明，该方法在作者构建的虚假完成基准测试以及LIBERO、RoboTwin 2.0等多个仿真与真实世界基准上，均能有效**降低虚假完成率并提升任务成功率**，验证了视觉-本体感知再平衡机制的有效性。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文《ReViP》的创新点分析

这篇论文针对视觉-语言-动作（VLA）模型在机器人操作中存在的“虚假完成”问题，提出了一套系统的解决方案。其核心创新点可以归纳为以下四个方面：

### 1. **问题定义与诊断：首次系统性地识别并定义了“虚假完成”这一失败模式**
   - **相比以往方法的改进/不同之处**：
     - 以往研究主要关注VLA模型的泛化能力、效率或架构设计，但**没有深入探究其内部多模态（视觉与本体感觉）融合的失衡问题**。
     - 本文首次明确指出，现有VLA模型存在**状态主导偏差**：即策略过度依赖内部本体感觉（如关节位置、任务阶段进度）的时序信号，而**未能充分利用实时视觉证据**来验证任务状态。
   - **解决的具体问题/带来的优势**：
     - **精准定位了VLA模型的一个关键失败根源**：当执行过程中发生意外扰动（如物体掉落）时，模型会无视视觉上明显的失败迹象，继续执行原计划并错误地宣告任务完成。
     - 为后续的算法设计提供了清晰的目标：**必须重新平衡视觉与本体感觉在决策中的权重**，增强模型的视觉感知和基于环境的实时反馈能力。

### 2. **核心算法框架：提出“视觉-本体感觉再平衡”框架ReViP**
   - **相比以往方法的改进/不同之处**：
     - **引入外部VLM作为“任务阶段观察器”**：与以往使用VLM仅进行任务规划（分解指令）或作为成功判别器不同，ReViP利用一个**冻结的、强大的外部VLM（如Qwen 2.5-VL）** 实时分析当前观测和指令，提取**任务中心的视觉线索**（例如：“奶油芝士未被机械臂抓取”）。
     - **设计“任务阶段增强器”进行特征级调制**：提出**任务阶段特征线性调制**模块，将上述提取的视觉线索作为辅助的环境先验，动态地调制VLA骨干网络中视觉-语言特征与本体感觉特征的耦合关系。这不同于简单的特征拼接或后期融合。
   - **解决的具体问题/带来的优势**：
     - **动态增强视觉流的重要性**：当发生扰动时，TS-FiLM模块能放大与当前任务阶段相关的视觉证据特征，抑制无关或误导性的状态特征，从而**迫使策略关注视觉现实而非惯性执行**。
     - **解决了模态失衡问题**：通过注入明确的、基于语义的视觉反馈，有效纠正了状态主导偏差，使模型能**检测执行失败并触发重新规划**（如物体掉落后重新抓取），从而将“虚假完成”转化为“真实完成”。

### 3. **评估基准：构建首个“虚假完成基准测试套件”**
   - **相比以往方法的改进/不同之处**：
     - 现有的机器人基准（如LIBERO、RLBench）主要评估标准场景下的任务成功率，**缺乏专门针对模型在扰动下“错误宣告成功”这一行为的系统性评测**。
     - 本文在LIBERO平台上构建了一个包含**三种受控扰动场景**的基准套件：
       1. **物体掉落**：评估模型对执行中动态失败的检测与恢复能力。
       2. **干扰物交换**：评估模型在视觉相似物体间的实例级 grounding 能力。
       3. **场景重布局**：评估模型对空间配置变化的适应与重新规划能力。
   - **解决的具体问题/带来的优势**：
     - **提供了精准的诊断工具**：该基准能**隔离并量化**VLA模型因状态主导偏差而产生的“虚假完成”行为。
     - **推动了更鲁棒的模型研发**：为社区提供了一个专注于评估模型**视觉 grounding 鲁棒性和持续进度监控能力**的标准测试平台，弥补了现有评估体系的空白。

### 4. **验证的广泛性与有效性：在仿真与真实世界均取得显著性能提升**
   - **相比以往方法的改进/不同之处**：
     - **全面的实验验证**：不仅在提出的虚假完成基准上测试，还在**标准LIBERO基准、双臂操作的RoboTwin 2.0基准以及真实机器人实验**中进行了验证。
     - **即插即用的通用性**：实验表明，ReViP的核心机制（任务观察器+增强器）可以**无缝集成到不同的VLA骨干网络**（如 π₀ 和 π₀.₅）中，均能带来性能提升，证明了其架构的通用性。
   - **解决的具体问题/带来的优势**：
     - **证明了方法的多场景有效性**：ReViP不仅在解决“虚假完成”这一特定问题上表现优异（在虚假完成基准上平均成功率提升18-26%），**也普遍提升了标准任务的成功率**（在LIBERO上达到SOTA，96.7%）。
     - **验证了实际应用价值**：真实世界实验表明，该方法能有效处理物体掉落、视觉干扰等复杂情况，**显著提高了机器人在非结构化环境中的任务可靠性和自主纠错能力**。

---

**总结**：本文的核心贡献在于，从一个新颖的**问题视角（模态失衡导致虚假完成）** 出发，提出了一套**创新的算法框架（基于外部VLM反馈的视觉-本体感觉再平衡）**，并配套建立了**专门的评估基准**，最终通过**广泛的实验**证明了该方案能有效提升VLA模型的鲁棒性和实用性。其创新是系统性的，涵盖了问题定义、方法设计、评估体系和实证验证的全链条。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 论文实验与评估效果总结

该论文通过系统的实验设计，验证了所提出的 **ReViP** 框架在减少“虚假完成”和提升任务成功率方面的有效性。实验涵盖了仿真基准测试和真实世界验证。

### 一、 使用的数据集与评价指标

#### 1. 核心评估基准：虚假完成基准套件
*   **基础平台**：基于 **LIBERO** 仿真平台构建。
*   **扰动类型**：包含三种旨在诱发“虚假完成”的受控扰动设置：
    *   **物体掉落**：评估模型对执行过程中动态干扰（如目标物体掉落）的响应和恢复能力。
    *   **干扰物交换**：评估模型在视觉相似物体干扰下的实例级 grounding 能力。
    *   **场景重布局**：评估模型在目标物体和目标区域位置同时变化时的空间推理和适应性。
*   **任务数量**：共 **8个任务**，覆盖上述三种扰动。

#### 2. 通用性能评估基准
*   **LIBERO 基准**：包含四个标准任务套件（Spatial, Object, Goal, 10），用于评估模型在未受扰动情况下的通用操作性能。
*   **RoboTwin 2.0 基准**：一个专注于**双臂操作**的仿真基准，用于评估模型在接触丰富、双机械臂场景下的泛化能力和鲁棒性（在“困难模式”下评估）。
*   **真实世界实验**：在真实的6自由度机械臂平台上进行，包含拾放和抽屉操作等任务，并引入了掉落和干扰物等扰动。

#### 3. 主要评价指标
*   **成功率**：任务成功完成的比率。这是所有实验中的核心指标。
*   **虚假完成率**：在虚假完成基准中，通过对比策略的完成声明与视觉目标谓词来间接衡量。**ReViP 的目标是降低此现象的发生，从而提升成功率**。
*   **平均排名**：在多个任务或套件上，比较不同方法成功率的排名情况。

### 二、 对比的基线方法

论文与一系列代表性的 **VLA** 模型进行了对比，涵盖了不同的技术路线：

1.  **基于 `π` 系列的方法**：
    *   **`π₀`**：作为 ReViP 的主要骨干网络和关键基线。
    *   **`π₀`-Fast**：`π₀` 的高效版本。
    *   **`π₀.₅`**：更新的 VLA 模型。
2.  **其他主流 VLA 方法**：
    *   **OpenVLA** 及 **OpenVLA-OFT**（其调优版本）。
    *   **SpatialVLA**（探索空间表征）。
    *   **CoT-VLA**（集成思维链推理）。
    *   **TriVLA**（基于三重系统的模型）。
    *   **UniVLA**（学习以任务为中心的潜在动作）。
3.  **双臂操作基线**（针对 RoboTwin 2.0）：
    *   **DP3**
    *   **RDT**
4.  **真实世界实验基线**：
    *   **`π₀`** 和 **`π₀`-Fast**。

### 三、 关键性能提升与结论

#### 1. 在“虚假完成基准”上的表现（核心贡献验证）
*   **总体提升**：ReViP 在8个任务上的**平均成功率达到了62%**，显著优于所有基线。
    *   相比最强的基线 `π₀`-Fast（44%）**提升了18个百分点**。
    *   相比骨干模型 `π₀`（36%）**提升了26个百分点**。
*   **分项优势**：
    *   **物体掉落任务**：平均成功率 **65.2%**，优势明显，证明其能有效检测执行失败并重新规划。
    *   **干扰物交换任务**：成功率 **46%**，比 `π₀` 和 `π₀`-Fast 分别高出15和40个百分点，显示其优异的实例区分能力。
    *   **重布局任务**：成功率 **88%**，展现出强大的空间推理和对视觉配置的依赖。

#### 2. 在通用LIBERO基准上的表现
*   ReViP 在四个LIBERO套件上取得了 **96.7%** 的平均成功率，位列所有方法**第一**。
*   在最具挑战性的 **LIBERO-10**（长视野任务）上，成功率达到 **92.2%**，比其骨干网络 `π₀`（85.2%）**提升了7个百分点**，证明了其提升的长期执行稳定性。

#### 3. 在双臂RoboTwin 2.0基准上的表现
*   在“困难模式”下，ReViP 取得了 **14%** 的平均成功率，优于 `π₀`（7%）、RDT（4%）和DP3（4%）。
*   这表明其**任务阶段反馈机制能有效扩展到更复杂的双臂操作场景**，并在严重环境扰动下保持鲁棒性。

#### 4. 真实世界实验表现
*   在包含掉落扰动的真实任务中，ReViP 取得了 **60%** 的平均成功率，远高于 `π₀`（34%）和 `π₀`-Fast（18%）。
*   定性实验显示，ReViP 能够检测到物体掉落并自主执行重新抓取，而基线模型则忽略视觉失败迹象，继续执行原计划导致失败。

#### 5. 补充分析（插拔式能力验证）
*   论文将 ReViP 的视觉-本体感觉再平衡机制应用到另一个骨干网络 `π₀.₅` 上，构建了 **ReViP₀.₅**。
*   实验表明，该机制能带来一致的性能提升（如在物体掉落任务上提升13.8%），证明了其设计具有**良好的通用性和插拔式适用性**，不依赖于特定骨干网络。

### 总结结论

通过上述系统的实验评估，论文得出明确结论：**ReViP 框架通过引入任务阶段观察器和增强器，实现了视觉与本体感觉的再平衡，有效缓解了VLA模型中的“状态主导偏差”，显著降低了“虚假完成”现象的发生率，并同时在标准操作任务和充满挑战的双臂、真实世界场景中取得了最先进的任务成功率。** 这验证了其核心技术创新（利用外部VLM提供任务先验并进行特征级调制）的实际价值。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2601.16667v1)
- [HTML 版本](https://arxiv.org/html/2601.16667v1)
