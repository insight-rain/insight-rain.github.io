# DynamicVLA: A Vision-Language-Action Model for Dynamic Object Manipulation

**相关性评分**: 8.0/10

**排名**: #1


---


## 基本信息

- **arXiv ID**: [2601.22153v1](https://arxiv.org/abs/2601.22153v1)
- **发布时间**: 2026-01-29T18:59:51Z
- **相关性评分**: 8.0/10
- **是否相关**: 是

## 作者

Haozhe Xie, Beichen Wen, Jiarui Zheng, Zhaoxi Chen, Fangzhou Hong, Haiwen Diao, Ziwei Liu

## 关键词

Vision-Language-Action Model, VLA for Robotics, Inference Acceleration, Edge Deployment, fine tune

## 一句话总结

DynamicVLA 是一个用于动态物体操作的视觉-语言-动作模型，通过紧凑架构、连续推理和潜在感知动作流实现快速推理和适应，并引入新基准数据集。

## 摘要

Manipulating dynamic objects remains an open challenge for Vision-Language-Action (VLA) models, which, despite strong generalization in static manipulation, struggle in dynamic scenarios requiring rapid perception, temporal anticipation, and continuous control. We present DynamicVLA, a framework for dynamic object manipulation that integrates temporal reasoning and closed-loop adaptation through three key designs: 1) a compact 0.4B VLA using a convolutional vision encoder for spatially efficient, structurally faithful encoding, enabling fast multimodal inference; 2) Continuous Inference, enabling overlapping reasoning and execution for lower latency and timely adaptation to object motion; and 3) Latent-aware Action Streaming, which bridges the perception-execution gap by enforcing temporally aligned action execution. To fill the missing foundation of dynamic manipulation data, we introduce the Dynamic Object Manipulation (DOM) benchmark, built from scratch with an auto data collection pipeline that efficiently gathers 200K synthetic episodes across 2.8K scenes and 206 objects, and enables fast collection of 2K real-world episodes without teleoperation. Extensive evaluations demonstrate remarkable improvements in response speed, perception, and generalization, positioning DynamicVLA as a unified framework for general dynamic object manipulation across embodiments.

## 详细分析

## 论文摘要：DynamicVLA: 用于动态物体操作的视觉-语言-动作模型

**1. 研究背景和动机**
动态物体操作（如抓取、放置移动物体）是机器人学中一个基础但尚未充分探索的领域。现有的视觉-语言-动作模型在静态操作中表现出色，但在动态场景中，由于推理延迟导致感知与执行错位，难以满足快速感知、时序预测和连续控制的需求。同时，缺乏大规模、标准化的动态操作数据集也阻碍了相关研究的发展。

**2. 核心方法和技术创新**
本文提出了 **DynamicVLA** 框架，通过三项关键技术解决动态操作中的时序对齐问题：
- **紧凑的0.4B参数VLA模型**：采用卷积视觉编码器进行高效空间压缩，结合轻量级语言骨干，实现快速多模态推理。
- **连续推理**：将推理与执行过程重叠，消除动作块间的等待时间，实现低延迟的闭环控制。
- **潜在感知动作流**：通过丢弃过时动作并优先执行最新预测，强制对齐感知与执行的时间线，弥补推理延迟带来的错位。
此外，为解决数据稀缺问题，本文构建了**动态物体操作基准**，通过自动化流水线在仿真和真实世界中高效收集了大规模动态操作数据。

**3. 主要实验结果**
在仿真与真实世界（Franka和PiPER机器人）的广泛评估表明，DynamicVLA在动态交互、感知和泛化能力上均显著优于现有VLA基线模型。例如，在DOM基准测试的交互维度上，其成功率比最强基线平均提升**188.1%**。消融实验证实了连续推理和潜在感知动作流对性能的关键贡献。

**4. 研究意义和价值**
本工作首次系统性地揭示了**感知-执行时序错位**是VLA模型在动态操作中的主要失效模式，而非感知模糊。DynamicVLA作为一个统一的框架，通过**延迟感知的架构与执行机制**，为通用动态物体操作提供了可行的解决方案。同时，开源的DOM基准为未来研究提供了重要的数据基础和评估标准，推动了机器人动态操作领域的发展。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析：DynamicVLA

### **一、 核心问题**
论文旨在解决**动态物体操控**这一机器人学中长期存在的开放挑战。具体而言，现有的大多数视觉-语言-动作模型在静态场景中表现出色，但在动态场景中面临三大核心难题：
1.  **感知-执行延迟**：模型推理耗时导致其基于“过去”的观测来执行动作，无法与快速变化的物体状态对齐。
2.  **缺乏时序推理**：现有VLA模型缺乏对物体未来运动的预测能力，无法在动作执行前进行“预判”。
3.  **数据稀缺**：现有机器人数据集主要针对静态场景，缺乏大规模、高质量的动态操控数据用于模型训练与评估。

### **二、 核心创新点**
论文提出了 **DynamicVLA** 框架，通过三大关键技术设计和一个新基准，系统性地解决了上述问题。

#### **1. 模型架构创新：紧凑高效的0.4B参数VLA**
- **目标**：在保证性能的前提下，**极大降低推理延迟**，为实时闭环控制奠定基础。
- **关键设计**：
    - **轻量级骨干网络**：采用仅0.4B参数的模型（基于SmolLM2-360M语言模型），显著小于主流VLA模型（通常3B-7B）。
    - **卷积视觉编码器**：使用 **FastViT** 替代传统的Transformer视觉编码器。其优势在于：
        - **空间高效压缩**：避免多帧输入时Transformer的二次方token增长。
        - **结构保真度高**：更好地保留对操控至关重要的空间结构信息。
    - **扩散动作专家**：采用基于流匹配的扩散模型来生成动作序列，能更好地建模复杂的连续动作分布。

#### **2. 推理与执行机制创新**
- **连续推理**
    - **问题**：传统VLA采用“推理 -> 完整执行 -> 等待 -> 下一次推理”的串行模式，产生“块间等待”，在动态场景中导致响应迟缓。
    - **解决方案**：采用**流水线执行**。一旦上一次推理完成，立即触发下一次推理，**让推理与动作执行重叠**。这样，新的动作序列会在当前序列执行完之前就绪，消除了等待时间。
- **潜在感知动作流**
    - **问题**：即使采用连续推理，由于推理延迟 `m`，在时间 `t` 开始推理得到的动作序列 `A_t`，到 `t+m` 时才可用。此时，序列中前 `m` 个动作（对应时间 `t` 到 `t+m-1`）已经“过时”。
    - **解决方案**：设计了一个显式的执行策略：
        1.  **丢弃过时动作**：对于在 `t+m` 时刻可用的动作序列 `A_t`，直接丢弃其前 `m` 个动作。
        2.  **优先最新预测**：当新旧动作序列在时间上有重叠时，**优先执行最新推理周期产生的动作**。这确保了执行始终基于最新的环境状态。

#### **3. 数据与基准创新：动态物体操控基准**
- **问题**：缺乏用于训练和评估动态操控的大规模数据。
- **解决方案**：构建了 **动态物体操控基准**，包含自动化的仿真和真实世界数据收集流水线。
    - **仿真数据**：在Isaac Sim中，利用**状态机控制器**（基于实时物体6D位姿和速度）自动生成20万条交互轨迹，涵盖2.8K个场景和206个物体。
    - **真实世界数据**：创新性地构建了“**真实世界模拟器**”。使用双RGB相机进行3D物体跟踪，估计6D位姿和速度，并驱动**相同的状态机控制器**进行自主数据收集。**无需示教**，高效收集了2K条真实世界轨迹。
    - **多维度评估**：DOM基准从**交互**、**感知**、**泛化**三个维度（共9个子项）系统评估模型的动态操控能力。

### **三、 解决方案总结**
论文通过 **“高效模型 + 智能执行机制 + 大规模数据”** 三位一体的方式，系统性地攻克了动态物体操控的挑战：

1.  **模型层面**：设计了一个极其紧凑（0.4B）但高效的VLA，核心是**卷积视觉编码器**，实现了低延迟的多模态推理。
2.  **系统层面**：提出了 **连续推理** 和 **潜在感知动作流** 两个执行机制，从系统层面**补偿和掩盖了固有的推理延迟**，实现了感知与执行的时序对齐。
3.  **数据与评估层面**：创建了DOM基准，不仅提供了训练数据，更重要的是为领域建立了**标准化、可复现的评估体系**，填补了空白。

### **四、 实际价值与意义**
- **技术推动**：首次为VLA模型在**严格实时约束下的精细动态操控**提供了可行的框架，将VLA的应用边界从静态/粗粒度交互拓展到动态/细粒度操控。
- **基准贡献**：DOM基准将成为该领域未来研究的重要基础设施，促进公平比较和算法进步。
- **方法论启示**：明确指出动态操控的核心失败模式是**时序未对齐**而非感知模糊，并为解决此问题提供了“降低延迟”和“系统补偿延迟”两条清晰的技术路径。其执行机制（CI & LAAS）被证明可泛化到其他VLA模型，具有普适价值。

**简而言之，DynamicVLA 的核心是认识到“时间”是动态操控的关键，并通过一个从模型、系统到数据评估的全栈式设计方案，让VLA模型能够“跟上”快速变化的世界。**


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文旨在解决**动态物体操控**这一机器人学中的核心挑战，即现有视觉-语言-动作模型在静态场景中泛化能力强，但在物体持续运动、需要快速感知、时序预测和连续控制的动态场景中，因推理延迟导致感知与执行失配而表现不佳。为此，论文提出了 **DynamicVLA 框架**，其核心创新在于通过三个关键设计整合了时序推理与闭环适应能力：1）一个采用卷积视觉编码器的紧凑型0.4B参数VLA模型，以实现快速多模态推理；2）**连续推理**机制，通过重叠推理与执行窗口来降低延迟；3）**潜在感知动作流**机制，通过丢弃过时动作、优先执行最新预测来强制对齐感知与执行的时序。为了填补动态操控数据空白，论文还构建了**动态物体操控基准**，通过自动化流程收集了大规模仿真与现实数据。实验表明，该框架在响应速度、感知能力和泛化性上均取得了显著提升，在动态操控任务上的成功率远超现有基线方法，成功将其定位为一个适用于多种机器人平台的通用动态物体操控统一框架。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文《DynamicVLA: A Vision-Language-Action Model for Dynamic Object Manipulation》的创新点分析

这篇论文针对动态物体操控这一机器人学中的开放挑战，提出了一套完整的解决方案。其核心创新点不仅在于模型架构，还涵盖了推理执行机制和基准数据集，形成了一个统一的框架。以下是逐条列出的明确创新点及其与以往方法的对比和优势：

### 1. **紧凑高效的0.4B参数VLA模型架构**
   - **改进/不同之处**：
     - **模型规模**：与早期依赖3B-7B大型视觉语言主干网络的VLA模型（如OpenVLA）相比，DynamicVLA将总参数量压缩至0.4B。
     - **视觉编码器**：摒弃了Transformer-based视觉编码器，采用了卷积网络**FastViT**。这避免了处理多帧视觉输入时token数量的二次增长，实现了更高效的空间压缩和结构保持。
     - **主干网络截断**：借鉴SmolVLA，将语言主干网络（SmolLM2-360M）截断至前16层Transformer，显著降低推理延迟。
   - **解决的具体问题/带来的优势**：
     - **核心问题**：动态操控对推理延迟极其敏感，传统大模型推理速度慢，导致感知与执行严重脱节。
     - **优势**：该设计实现了**显著更快的多模态推理速度**（在RTX A6000上约88Hz），为实时闭环控制提供了基础。紧凑的模型在保持必要推理能力的同时，极大降低了计算开销和内存占用（仅需1.8GB GPU显存）。

### 2. **连续推理机制**
   - **改进/不同之处**：
     - 传统VLA模型采用**串行**的“推理-执行”模式：必须等上一个动作序列完全执行完毕，才触发下一次推理。这会产生“块间等待”。
     - DynamicVLA引入了**流水线化**的**连续推理**：一旦上一次推理完成，立即触发下一次推理，**让推理与执行重叠进行**。
   - **解决的具体问题/带来的优势**：
     - **核心问题**：串行模式在动态场景下会导致控制流“卡顿”，机器人无法及时响应物体运动。
     - **优势**：**消除了块间等待**，实现了不间断的动作流生成。这使得系统能保持更低的**整体延迟**和更高的响应速度，能够及时适应物体的连续运动。

### 3. **潜在感知的动作流机制**
   - **改进/不同之处**：
     - 现有工作忽略了推理延迟导致的**时间错位**问题：在推理的`m`个时间步内，环境状态已发生变化，导致推理开始时预测的前`m`个动作在可用时已经“过时”。
     - DynamicVLA提出了一个显式的执行策略：1) **丢弃过时动作**：丢弃新动作序列中时间戳早于其可用时间点（`t+m`）的动作；2) **优先级覆盖**：当新旧动作序列在相同时间步上重叠时，优先执行最新推理周期产生的动作。
   - **解决的具体问题/带来的优势**：
     - **核心问题**：“感知-执行”间隙和重叠动作块之间的冲突，导致执行的动作基于过时的观测，从而失败。
     - **优势**：**强制恢复了感知与执行之间的时间对齐**。它确保机器人执行的始终是基于最新环境状态预测的最相关动作，从而在存在固有推理延迟的情况下，仍能实现**时间一致的控制**。

### 4. **动态物体操控基准数据集**
   - **改进/不同之处**：
     - **填补空白**：现有机器人数据集（如BridgeData V2, Open X-Embodiment）主要关注静态场景，缺乏大规模、专注于**动态物体操控**的标准基准。
     - **自动化采集**：构建了全自动的数据采集管道，包含仿真与真实世界两部分，**无需示教**。
       - **仿真**：利用Isaac Sim和状态机控制器，基于物体6D位姿和速度自动生成20万条交互轨迹。
       - **真实世界**：创新性地构建了一个“真实世界模拟器”，通过双RGB视图进行3D物体跟踪，估计6D状态和速度，驱动相同的状态机控制器进行自主试验采集，避免了人类反应速度跟不上动态物体的问题。
   - **解决的具体问题/带来的优势**：
     - **核心问题**：缺乏用于训练和评估动态操控策略的大规模、高质量数据。
     - **优势**：
       1. **提供了首个大规模动态操控基准**，包含20万仿真和2000真实世界轨迹，支持多机器人本体。
       2. **实现了高效、可扩展的数据收集**，特别是解决了真实世界动态数据难以通过示教获取的难题。
       3. **定义了系统的评估维度**，从**交互**、**感知**、**泛化**三个层面全面评测动态操控能力。

### 5. **统一的框架设计与问题界定**
   - **改进/不同之处**：
     - 论文明确将**开放式的动态物体操控**界定为一个独立且未被解决的问题，强调其与**静态操控**和**已有动态任务**（如击球、乒乓球）的关键区别：需要处理**不确定运动**、**精确接触**和**紧密的感知-动作对齐**。
     - 将上述创新点（紧凑模型、连续推理、潜在感知动作流）整合为一个**统一框架**，共同应对动态操控的核心矛盾——**时间错位**。
   - **解决的具体问题/带来的优势**：
     - **核心问题**：以往工作要么局限于静态场景，要么只能处理容许较大时空误差的动态任务（如用球拍击球），未能系统解决需要6DoF精确控制的通用动态操控。
     - **优势**：提出了一个**端到端的解决方案**，不仅提升了单项性能，更重要的是证明了通过协同设计模型、推理机制和执行策略，VLA模型能够胜任真正意义上的**通用动态物体操控**。实验表明，DynamicVLA在DOM基准测试中**全面大幅超越**现有SOTA VLA模型（例如，在交互性任务上相对最强基线提升最高达440%）。

---

**总结**：DynamicVLA的核心创新在于认识到动态操控的**主要失败模式并非感知模糊，而是时间错位**。因此，它没有一味追求更大的模型，而是通过**轻量化架构**、**重叠式推理**和**时间对齐执行**这一组合拳，系统性地压缩和补偿了从感知到执行整个 pipeline 中的延迟。同时，其贡献的**DOM基准**为未来该方向的研究提供了至关重要的数据和评估标准。这些创新共同将VLA模型的能力边界从静态和宽松动态场景，推进到了需要实时、精确控制的通用动态物体操控领域。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 实验与评估效果总结

### 一、 评估数据集与评价指标

#### 1. 数据集
论文构建并使用了全新的 **Dynamic Object Manipulation (DOM) 基准测试**，这是首个专注于动态物体操作的大规模数据集。
- **模拟数据**：在Isaac Sim中，通过自动化流水线收集了 **200K个合成演示片段**，覆盖 **2.8K个不同的3D场景** 和 **206个物体**。
- **真实世界数据**：通过一个“真实世界模拟器”流水线（使用双RGB视图进行3D物体跟踪），无需遥操作，高效收集了 **2K个真实世界演示片段**。
- **多机器人平台**：数据收集和验证覆盖了 **Franka Emika Panda** 和 **AgileX PiPER** 两种机器人本体。

#### 2. 评价指标
实验使用了三个核心指标进行量化评估：
- **成功率**：成功完成指令操作（无物体掉落或超时）的试验比例。
- **路径长度**：执行过程中末端执行器的总轨迹长度（米）。更短的路径通常意味着更高效、更直接的控制。
- **任务完成时间**：从物体开始运动到任务终止（成功、超时或失败）所经过的时间（秒）。更短的时间代表更快的响应和更高的效率。

### 二、 对比的基线方法
论文在模拟和真实世界环境中与一系列代表性的VLA模型进行了广泛对比，涵盖了不同类型的方法：
1.  **Diffusion Policy**：基于扩散模型的通用策略。
2.  **OpenVLA-OFT**：开源VLA模型。
3.  **π₀**：基于流匹配的通用VLA模型。
4.  **π₀.₅**：π₀的改进版本，具有更强的开放世界泛化能力。
5.  **SmolVLA**：专注于高效、轻量化的VLA模型。
6.  **GR00T-N1.5**：面向通用人形机器人的开源基础模型。
7.  **VLA-Adapter-Pro**：通过适配器范式实现的高效小规模VLA。
8.  **VLASH**：通过异步推理实现实时交互的VLA模型。

### 三、 关键性能提升与结论

#### 1. 整体性能表现（模拟环境）
在DOM基准测试的9个子维度（涵盖交互、感知、泛化三大类）上，DynamicVLA取得了**压倒性的性能优势**。

| 方法 | 平均成功率 | 路径长度 | 任务完成时间 |
| :--- | :--- | :--- | :--- |
| **DynamicVLA** | **47.06%** | 2.50 m | **8.53 s** |
| 最佳基线 (VLA-Adapter-Pro) | 13.61% | 1.51 m | 9.98 s |
| **性能提升** | **+245.8%** | - | **-14.5%** |

- **核心结论**：DynamicVLA的平均成功率（47.06%）远超所有基线方法（最高13.61%），证明了其在动态操作任务上的卓越有效性。
- **效率权衡**：DynamicVLA的路径长度略长于部分基线，但**任务完成时间显著更短**。这表明其通过更主动、更及时的调整来成功完成任务，而非因失败而提前终止。

#### 2. 分维度性能分析（模拟环境）
- **交互能力**：在**闭环反应性**、**动态适应**和**长时程序列**任务上，DynamicVLA分别达到60.5%、38.5%和40.5%的成功率，相比最强基线提升幅度高达 **188.1% 到 440.0%**。这直接验证了**连续推理**和**潜在感知动作流**在应对快速变化物体运动时的关键作用。
- **感知能力**：在**视觉理解**、**空间推理**和**运动感知**任务上，DynamicVLA同样大幅领先（51.5%， 48.0%， 33.5%），表明其紧凑的0.4B模型在保持高效推理的同时，并未牺牲多模态理解能力。
- **泛化能力**：在**视觉泛化**和**运动泛化**到未见过的物体和运动模式时，DynamicVLA表现出强大的鲁棒性（59.5%， 65.0%）。然而，在**抗干扰鲁棒性**上表现相对较弱（26.5%），论文指出这是未来需要改进的方向。

#### 3. 真实世界验证
在Franka和PiPER机器人上进行的6项动态操作任务评估中，DynamicVLA的**平均成功率显著高于所有对比基线**（具体数值在图表中显示，论文未给出汇总表格的精确平均值，但趋势明确）。
- **结论**：DynamicVLA成功地从模拟环境迁移到真实世界，在多种机器人本体上均实现了可靠的动态物体抓取与放置。

#### 4. 消融实验结论
通过系统的消融研究，论文验证了其每个核心设计的价值：
- **模型容量**：360M参数的SmolLM2语言主干在推理效率和模型能力之间取得了最佳平衡。
- **视觉编码器**：卷积编码器**FastViT**在降低编码延迟和保持结构信息方面优于Transformer编码器。
- **连续推理**：禁用后成功率从47.06%降至39.72%，证明了重叠推理与执行对消除块间等待、提升响应速度至关重要。
- **潜在感知动作流**：禁用后成功率降至36.11%，证明了其解决感知-执行时序错位、优先执行最新预测的核心价值。
- **二者结合**：同时禁用CI和LAAS导致性能暴跌至30.27%，说明二者在动态操作中缺一不可，且具有互补性。

### 总结
**DynamicVLA通过其创新的轻量化架构、连续推理和潜在感知动作流，在全新的DOM基准测试上实现了对现有VLA模型的革命性性能提升。** 它不仅显著提高了动态物体操作的成功率，还通过降低任务完成时间证明了其在实际机器人控制中的高效性和实时性。这项工作清晰地表明，**对于动态操作，解决感知与动作之间的时序失配问题比单纯提升静态感知能力更为关键**。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2601.22153v1)
- [HTML 版本](https://arxiv.org/html/2601.22153v1)
