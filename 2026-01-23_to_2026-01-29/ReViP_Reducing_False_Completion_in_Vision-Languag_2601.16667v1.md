# ReViP: Reducing False Completion in Vision-Language-Action Models with Vision-Proprioception Rebalance

**相关性评分**: 8.0/10

**排名**: #6


---


## 基本信息

- **arXiv ID**: [2601.16667v1](https://arxiv.org/abs/2601.16667v1)
- **发布时间**: 2026-01-23T11:31:07Z
- **相关性评分**: 8.0/10
- **是否相关**: 是

## 作者

Zhuohao Li, Yinghao Li, Jian-Jian Jiang, Lang Zhou, Tianyu Zhang, Wei-Shi Zheng

## 关键词

Vision-Language-Action Model, VLA for Robotics, fine tune, world model

## 一句话总结

ReViP通过视觉-本体感觉再平衡机制减少VLA模型中的虚假完成错误，提升机器人操作的鲁棒性和视觉基础能力。

## 摘要

Vision-Language-Action (VLA) models have advanced robotic manipulation by combining vision, language, and proprioception to predict actions. However, previous methods fuse proprioceptive signals directly with VLM-encoded vision-language features, resulting in state-dominant bias and false completions despite visible execution failures. We attribute this to modality imbalance, where policies over-rely on internal state while underusing visual evidence. To address this, we present ReViP, a novel VLA framework with Vision-Proprioception Rebalance to enhance visual grounding and robustness under perturbations. The key insight is to introduce auxiliary task-aware environment priors to adaptively modulate the coupling between semantic perception and proprioceptive dynamics. Specifically, we use an external VLM as a task-stage observer to extract real-time task-centric visual cues from visual observations, which drive a Vision-Proprioception Feature-wise Linear Modulation to enhance environmental awareness and reduce state-driven errors. Moreover, to evaluate false completion, we propose the first False-Completion Benchmark Suite built on LIBERO with controlled settings such as Object-Drop. Extensive experiments show that ReViP effectively reduces false-completion rates and improves success rates over strong VLA baselines on our suite, with gains extending to LIBERO, RoboTwin 2.0, and real-world evaluations.

## 详细分析

## 论文摘要：ReViP: 通过视觉-本体感觉再平衡减少视觉-语言-动作模型中的错误完成

### 1. 研究背景和动机
视觉-语言-动作模型在机器人操作任务中取得了显著进展，但现有方法通常将本体感觉信号与视觉-语言特征直接融合，导致模型过度依赖内部状态（状态主导偏差），而**忽视视觉证据**。这引发了一种被称为 **“错误完成”** 的失败模式：即使任务目标在视觉上明显未达成（如物体意外掉落），机器人仍会错误地宣告任务完成并终止动作。本文认为其根源在于**模态不平衡**，并旨在通过重新平衡视觉感知与本体感觉动态来解决此问题。

### 2. 核心方法和技术创新
本文提出了 **ReViP** 框架，其核心创新在于引入**任务感知的环境先验**来动态调节语义感知与本体感觉动态之间的耦合。具体包含两个关键模块：
- **任务阶段观察器**：利用一个外部的大型视觉-语言模型作为实时“观察者”，从当前视觉观测和指令中提取**任务中心的视觉线索**（如物体状态、空间位置）。
- **任务阶段增强器**：通过一种新颖的**视觉-本体感觉特征线性调制机制**，将上述线索以特征级注入到VLA骨干网络中，从而自适应地增强视觉流的影响，抑制状态主导偏差。

此外，本文还构建了首个**错误完成基准测试套件**，基于LIBERO平台设置了物体掉落、干扰物交换和环境重布局三种受控扰动场景，用于系统评估模型鲁棒性。

### 3. 主要实验结果
在提出的错误完成基准上，ReViP将平均成功率提升至**62%**，显著优于基线模型（如π0）。在标准LIBERO基准和双臂操作的RoboTwin 2.0基准上，ReViP也达到了**最先进的成功率**（LIBERO平均96.7%）。**真实世界实验**进一步验证了其有效性，ReViP在存在掉落和干扰物的复杂场景中，成功率（60%）远超基线模型。实验表明，ReViP能有效检测执行失败、触发重新规划，从而将“错误完成”转化为“真实完成”。

### 4. 研究意义和价值
本研究首次系统性地揭示并定义了VLA模型中的“错误完成”问题及其模态不平衡的根源。ReViP框架为解决该问题提供了一种通用且有效的方法，其**任务中心视觉线索注入与再平衡机制**显著提升了模型对视觉证据的利用和抗扰动鲁棒性。所提出的基准套件为未来相关研究提供了重要的评估工具。这项工作推动了更可靠、更符合人类常识的机器人决策系统的发展，对实现复杂动态环境中稳健的机器人操作具有重要价值。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析：ReViP

### **核心问题：模态失衡与“虚假完成”**
论文指出，现有**视觉-语言-动作模型** 在机器人操作中存在一个关键缺陷：**模态失衡**。模型在决策时过度依赖内部本体感觉状态，而**未能充分利用视觉证据**。这导致了一种被称为 **“虚假完成”** 的失败模式：
- **定义**：当机器人因干扰（如物体掉落）而未能完成任务时，其内部策略却基于预设的动作流程“宣布”任务完成。
- **后果**：机器人无视明显的视觉失败线索（如目标物体仍在地上），继续执行无效动作或提前终止，导致任务失败。

### **核心创新点**
论文提出了 **ReViP** 框架，其核心创新在于通过 **“视觉-本体感觉再平衡”** 机制，增强模型的视觉感知能力，从而减少虚假完成。

1.  **问题定义与基准构建**
    - **首次系统性地定义并研究了VLA模型中的“虚假完成”现象**，将其根源归结为模态失衡。
    - **提出了首个“虚假完成基准测试套件”**，基于LIBERO平台构建了三种受控扰动场景（物体掉落、干扰物交换、场景重布局），为评估模型鲁棒性提供了标准化测试环境。

2.  **方法创新：双阶段再平衡框架**
    ReViP通过两个核心组件动态调整视觉与本体感觉信息的权重：

    - **任务阶段观察器**
        - **功能**：利用一个**外部的大型视觉语言模型**（如Qwen 2.5-VL）作为“观察员”，实时分析当前视觉观测和任务指令。
        - **输出**：提取**任务中心的视觉线索**（例如：“奶油芝士未被机械臂抓取”），并将其编码为紧凑的语义特征向量 `z_t`。这为策略提供了明确的、基于当前环境的先验知识。

    - **任务阶段增强器**
        - **功能**：将观察器提取的视觉线索 `z_t` 注入到VLA主干网络中。
        - **关键技术**：采用 **任务阶段特征线性调制**：
            ```python
            # TS-FiLM 操作
            [γ_t, β_t] = MLP(z_t) # 从视觉线索生成调制参数
            P̃_t = (P_t + α * (γ_t ⊙ P_t + β_t)) ⊙ M_t # 调制视觉-语言前缀特征
            ```
        - **效果**：在特征层面自适应地**增强与当前任务相关的视觉通道，抑制无关或导致状态主导偏差的通道**，从而在决策时重新平衡视觉和本体感觉流的影响。

### **解决方案总结**
ReViP通过一个**轻量级、可插拔的反馈环路**解决了虚假完成问题：
1.  **感知**：使用强大的外部VLM实时“解读”场景，提供人类常识级别的任务进度和状态判断。
2.  **调制**：将这些高层语义信息作为控制信号，直接调节VLA模型内部的特征表示，迫使策略更多地“关注”视觉证据。
3.  **决策**：经过调制的特征驱动动作生成器，使其在遇到扰动时能基于视觉反馈进行重新规划（如物体掉落后执行重新抓取），而非盲目遵循预设的本体感觉轨迹。

### **实际价值**
- **提升机器人操作的鲁棒性**：使机器人能像人类一样，在任务执行受阻时“发现问题”并尝试恢复，而非僵化地走完流程。
- **提供可复现的评估标准**：提出的基准套件使VLA模型的“盲点”和鲁棒性变得可量化、可比较。
- **方法通用**：实验表明，ReViP的再平衡机制可以作为一种**即插即用模块**，有效提升不同VLA主干模型（如 `π_0`, `π_0.5`）在多种仿真基准（LIBERO, RoboTwin 2.0）和真实世界任务中的性能与成功率。

**简言之，ReViP的核心是让机器人“学会用眼睛看”，而不仅仅是“凭感觉走”，从而显著提高了在动态、不确定环境中的任务完成可靠性。**


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文针对视觉-语言-动作模型中存在的**模态失衡问题**（即策略过度依赖内部本体感觉状态而忽视视觉证据）所导致的**虚假完成**现象（例如目标物体掉落时，机器人仍按原计划执行并错误宣告任务完成），提出了一种名为**ReViP**的新型框架。其核心方法是引入一个**任务阶段观察器**（基于外部VLM）来提取实时任务中心视觉线索，并通过一个**任务阶段增强器**（采用特征级线性调制技术）将这些线索作为环境先验自适应地注入到策略中，从而重新平衡视觉与本体感觉在决策中的权重。实验结果表明，ReViP在作者构建的虚假完成基准测试、标准LIBERO基准、RoboTwin 2.0双臂基准以及真实世界实验中，均能有效**降低虚假完成率并提升任务成功率**，证明了其方法的有效性和泛化能力。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文《ReViP》的创新点分析

这篇论文针对视觉-语言-动作模型在机器人操作中存在的“虚假完成”问题，提出了一套系统的解决方案。其核心创新点可归纳为以下四个方面：

### 1. **问题定义与诊断：首次系统性地识别并定义了“虚假完成”这一失败模式**
   - **相比以往方法的改进/不同之处**：
     - 以往研究主要关注VLA模型的泛化能力、效率或架构设计，但**未深入探究其内部多模态（视觉与本体感觉）融合的失衡问题**。
     - 本文首次明确指出，现有VLA模型在决策时存在**状态主导偏差**：即模型过度依赖内部本体感觉信号（如关节位置、任务执行进度），而**未能充分利用实时视觉证据**来监控任务状态。
   - **解决的具体问题/带来的优势**：
     - **精准定位了VLA模型的一个关键失败根源**。当环境中出现意外扰动（如物体掉落、干扰物交换）时，模型会无视视觉上明显的失败迹象，继续执行原计划或错误地宣告任务成功。
     - 为后续的算法设计提供了清晰的目标：**必须重新平衡视觉与本体感觉在决策中的权重**，以增强模型对动态环境的感知和鲁棒性。

### 2. **方法创新：提出“视觉-本体感觉再平衡”框架与“任务阶段增强器”**
   - **相比以往方法的改进/不同之处**：
     - **引入外部VLM作为“任务阶段观察器”**：与以往使用VLM仅进行任务规划或成功判断不同，ReViP利用一个**冻结的、强大的外部VLM**实时分析观测图像和指令，提取**任务中心的视觉线索**（如“物体已掉落在地板上”）。
     - **设计“任务阶段增强器”进行特征级调制**：提出**任务阶段特征线性调制**模块，将上述视觉线索以自适应参数（γ, β）的形式，注入到VLA骨干网络的视觉-语言前缀特征中。这是一种**细粒度的、特征层面的融合与再平衡机制**。
   - **解决的具体问题/带来的优势**：
     - **动态增强视觉流的重要性**。TS-FiLM机制能根据当前任务阶段和视觉证据，动态调整视觉特征与本体感觉特征的耦合强度，迫使策略更多地关注当前视觉观测。
     - **有效缓解状态主导偏差**。当扰动发生时，提取的视觉线索会引导调制参数放大与失败相关的视觉特征，抑制无关内容，从而驱动策略进行重新规划（如重新抓取掉落物体），而非盲目执行原动作序列。
     - **保持了预训练VLM的强语义理解能力**。由于外部VLM被冻结，避免了在机器人数据上微调导致的灾难性遗忘问题。

### 3. **评估基准创新：构建首个“虚假完成基准测试套件”**
   - **相比以往方法的改进/不同之处**：
     - 现有的机器人基准（如LIBERO、RLBench）主要评估标准场景下的任务成功率，**缺乏专门针对模型在扰动下“错误坚持原计划”这一失败模式的系统性评测**。
     - 本文在LIBERO平台上构建了一个包含**三种可控扰动类型**的基准套件：
       1. **物体掉落**：评估执行过程中发生意外时的失败检测与恢复能力。
       2. **干扰物交换**：评估在视觉相似物体存在下的实例级 grounding 能力。
       3. **场景重布局**：评估当目标物和目的地位置均改变时的空间推理与重规划能力。
   - **解决的具体问题/带来的优势**：
     - **提供了诊断VLA模型鲁棒性的专用工具**。该基准能精确地暴露模型因模态失衡而产生的“虚假完成”行为。
     - **评测更具针对性和挑战性**。它迫使模型必须依赖实时视觉证据进行进度检查和重规划，而不能简单地回放演示数据中的本体感觉轨迹。
     - **为社区设立了新的评估标准**，推动未来研究更加关注模型在动态、非理想环境下的可靠性。

### 4. **验证的全面性与有效性：在仿真和现实世界中均取得显著性能提升**
   - **相比以往方法的改进/不同之处**：
     - **广泛的实验验证**：不仅在提出的虚假完成基准上测试，还在标准的LIBERO基准、更具挑战的双臂RoboTwin 2.0基准以及真实机器人实验中进行评估。
     - **显著的性能优势**：实验表明，ReViP在**所有测试场景**中均一致性地超越了现有SOTA VLA模型（如π₀、OpenVLA、UniVLA等）。
   - **解决的具体问题/带来的优势**：
     - **证明了方法的多场景通用性**。ReViP不仅专门针对虚假完成问题有效，其带来的视觉-本体感觉再平衡机制也能**普遍提升标准任务的成功率**。
     - **验证了仿真到现实的迁移能力**。真实世界实验表明，ReViP能成功处理物体掉落、多干扰物等复杂情况，显著降低了虚假完成率。
     - **展示了“即插即用”的潜力**：补充实验表明，将ReViP的核心机制应用于另一个VLA骨干网络（π₀.₅）同样能带来性能提升，说明其设计具有**良好的通用性和可移植性**。

**总结**：ReViP的核心贡献在于从一个**新的视角（模态失衡）** 诊断了VLA模型的关键缺陷，并提出了一个**新颖的、模块化的解决方案（外部VLM观察器 + 特征调制增强器）** 来针对性解决。同时，它创建了一个**专门的评估基准**来量化这一问题，并通过**全面且强有力的实验**证明了其方法的有效性和泛化能力。这为构建更可靠、更关注实时视觉反馈的机器人操作模型提供了重要的思路和工具。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 论文实验与评估效果总结

该论文通过系统的实验设计，全面评估了所提出的 **ReViP** 框架在减少“虚假完成”和提升任务成功率方面的有效性。实验涵盖了仿真基准测试和真实世界验证。

### 一、 使用的数据集与评价指标

#### 1. 核心数据集
*   **False-Completion Benchmark Suite (虚假完成基准套件)**：**论文原创构建**，基于LIBERO平台。包含8个任务，分为三类受控扰动场景：
    *   **物体掉落**：评估模型对执行中动态干扰（如物体从夹爪掉落）的响应和恢复能力。
    *   **干扰物交换**：评估模型在视觉相似物体干扰下的实例级识别与定位能力。
    *   **场景重布局**：评估模型在目标物体和目标区域位置均发生变化时的空间推理和重新规划能力。
*   **标准仿真基准**：
    *   **LIBERO**：广泛使用的语言条件机器人操作基准。论文在四个子套件上评估：`Spatial`（空间推理）、`Object`（物体识别）、`Goal`（目标理解）和 `10`（长时程任务）。
    *   **RoboTwin 2.0**：专注于**双臂**、接触丰富的操作任务的仿真基准。论文在“困难模式”下进行评估，该模式引入了域随机化（光照、杂物、桌面高度变化等）。

#### 2. 真实世界实验平台
*   **硬件**：ROKAE 6自由度机械臂 + JODELL平行夹爪。
*   **视觉**：两个ORBBEC Femto Bolt RGB-D相机（第一人称和第三人称视角）。
*   **任务**：包括“拾取放置”（含干扰物）和“抽屉操作”（长时程序列）等任务，并引入了掉落、交换等扰动。

#### 3. 主要评价指标
*   **成功率**：任务成功完成的比率。这是所有实验中的**核心指标**。
*   **平均排名**：在多个任务或套件上，模型成功率排名的平均值（越低越好）。用于综合评估模型性能。
*   **虚假完成率**：通过对比策略的完成声明 (`d_t=1`) 与视觉目标谓词 (`G(I_t)=0`) 来间接衡量。ReViP的目标是降低此现象的发生，从而**提升真实成功率**。

### 二、 对比的基线方法

论文与一系列代表性的VLA模型进行了对比，覆盖了单臂和双臂设置：

*   **单臂操作基线**：
    *   **`π₀` 系列**：`π₀`, `π₀-Fast`。`π₀` 是ReViP选择的基础骨干网络。
    *   **其他先进VLA模型**：`OpenVLA`, `OpenVLA-OFT`, `SpatialVLA`, `CoT-VLA`, `TriVLA`, `UniVLA`。
*   **双臂操作基线**：
    *   `DP3`, `RDT`, `π₀`（适配到双臂设置）。

### 三、 关键性能提升与结论

#### 1. 在 False-Completion Benchmark 上的表现
*   **总体结果**：ReViP在8个任务上取得了**最高的平均成功率**，显著优于所有基线。
*   **关键数据**：
    *   平均成功率：**62%**。
    *   相比最强基线 `π₀-Fast` 提升 **+18%**。
    *   相比骨干模型 `π₀` 提升 **+26%**。
*   **分场景提升**：
    *   **物体掉落**：平均成功率 **65.2%**，证明其能有效检测执行失败并重新规划。
    *   **干扰物交换**：成功率显著优于 `π₀` 和 `π₀-Fast`，表明任务阶段线索有助于区分视觉相似的实例。
    *   **场景重布局**：成功率 **88%**，显示出优越的空间推理和对当前视觉配置的依赖能力。

#### 2. 在通用仿真基准上的表现
*   **LIBERO 基准**：
    *   ReViP在四个子套件上均达到**最佳或接近最佳性能**，平均成功率 **96.7%**，排名第一。
    *   在最具挑战性的长时程套件 `LIBERO-10` 上，将 `π₀` 的 **85.2%** 提升至 **92.2%**（+7%），证明了其在复杂任务中的稳定性。
*   **RoboTwin 2.0 基准**：
    *   在双臂、接触丰富的“困难模式”任务中，ReViP取得了 **14%** 的平均成功率，优于 `RDT` 和 `π₀`，表明其机制能有效扩展到更复杂的操作场景并保持鲁棒性。

#### 3. 真实世界实验表现
*   ReViP在包含扰动的真实任务中取得了 **60%** 的平均成功率，而 `π₀` 和 `π₀-Fast` 分别为 **34%** 和 **18%**。
*   定性实验显示，ReViP能够检测到物体掉落并自主执行重新抓取，而基线模型则倾向于忽略视觉失败证据，继续执行原计划导致失败。

#### 4. 消融与扩展实验
*   **插件化能力**：将ReViP的“视觉-本体感觉再平衡”机制应用到另一个先进骨干网络 `π₀.₅` 上，构建了 `ReViP₀.₅`。实验表明，该机制能带来一致的性能提升（如在物体掉落任务上提升 **+13.8%**），证明了其设计具有**通用性和可移植性**，并非特定于某个骨干网络。

### 四、 核心结论

通过以上系统的实验评估，论文得出以下核心结论：

1.  **有效解决了虚假完成问题**：ReViP通过引入**任务阶段观察器**提取实时视觉任务线索，并利用**任务阶段增强器**进行特征级调制，成功纠正了VLA模型中对本体感觉信号的过度依赖，显著降低了在扰动下的虚假完成行为。
2.  **全面提升了任务性能**：不仅在专为“虚假完成”设计的基准上表现优异，在标准的LIBERO和RoboTwin 2.0基准上也达到了最先进的性能水平，证明了该方法在提升模型**鲁棒性**的同时，不损害其**通用操作能力**。
3.  **具备仿真到真实的迁移能力**：真实世界实验验证了ReViP框架的有效性，其改进能够迁移到存在噪声、遮挡和不确定性的真实机器人操作场景中。
4.  **机制具有通用性**：该再平衡机制可以作为一种插件式模块，有效集成到不同的VLA骨干网络中，提升其性能。

**总而言之，ReViP通过重新平衡视觉与本体感觉在决策中的权重，使机器人策略更加“眼见为实”，从而在面临动态扰动时表现出更强的环境感知、错误恢复和任务完成能力。**


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2601.16667v1)
- [HTML 版本](https://arxiv.org/html/2601.16667v1)
