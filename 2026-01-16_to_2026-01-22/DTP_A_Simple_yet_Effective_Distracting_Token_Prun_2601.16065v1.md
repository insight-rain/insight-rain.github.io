# DTP: A Simple yet Effective Distracting Token Pruning Framework for Vision-Language Action Models

**相关性评分**: 8.0/10

**排名**: #5


---


## 基本信息

- **arXiv ID**: [2601.16065v1](https://arxiv.org/abs/2601.16065v1)
- **发布时间**: 2026-01-22T16:02:56Z
- **相关性评分**: 8.0/10
- **是否相关**: 是

## 作者

Chenyang Li, Jieyuan Liu, Bin Li, Bo Gao, Yilin Yuan, Yangfan He, Yuchen Li, Jingqun Tang

## 关键词

Vision-Language-Action Model, VLA for Robotics, Inference Acceleration, fine tune

## 一句话总结

该论文提出了一种名为DTP的简单有效框架，通过动态检测和修剪视觉语言动作模型中的干扰图像令牌，以提升机器人任务的成功率，而不改变原始架构或增加额外输入。

## 摘要

Vision-Language Action (VLA) models have shown remarkable progress in robotic manipulation by leveraging the powerful perception abilities of Vision-Language Models (VLMs) to understand environments and directly output actions. However, by default, VLA models may overly attend to image tokens in the task-irrelevant region, which we describe as 'distracting tokens'. This behavior can disturb the model from the generation of the desired action tokens in each step, affecting the success rate of tasks. In this paper, we introduce a simple yet effective plug-and-play Distracting Token Pruning (DTP) framework, which dynamically detects and prunes these distracting image tokens. By correcting the model's visual attention patterns, we aim to improve the task success rate, as well as exploring the performance upper boundaries of the model without altering its original architecture or adding additional inputs. Experiments on the SIMPLER Benchmark (Li et al., 2024) show that our method consistently achieving relative improvements in task success rates across different types of novel VLA models, demonstrating generalizability to transformer-based VLAs. Further analysis reveals a negative correlation between the task success rate and the amount of attentions in the task-irrelevant region for all models tested, highlighting a common phenomenon of VLA models that could guide future research. We also publish our code at: https://anonymous.4open.science/r/CBD3.

## 详细分析

## 论文摘要：DTP：一种简单有效的视觉-语言-动作模型分心令牌剪枝框架

**1. 研究背景和动机**
视觉-语言-动作模型通过结合视觉-语言模型的强大感知能力来理解环境并直接输出机器人动作，在机器人操作任务中展现出巨大潜力。然而，现有VLA模型在生成动作时，其视觉注意力常常过度集中于与任务无关的图像区域（即“分心令牌”），这干扰了正确动作令牌的生成，导致任务成功率下降。本文旨在解决这一普遍问题，探索在不改变模型原始架构或增加额外输入的情况下，通过修正视觉注意力模式来提升模型性能的上限。

**2. 核心方法和技术创新**
本文提出了**分心令牌剪枝框架**，这是一个即插即用、无需训练的方法。其核心创新在于通过三步动态识别并剪枝分心令牌：
- **重要区域构建**：基于提示词与图像令牌在选定Transformer层中的交互（注意力权重或嵌入相似度），计算相关性热图，识别出与任务意图最相关的视觉令牌区域。
- **视觉注意力模式分析**：分析模型在生成每个动作令牌时，其所有注意力层对图像令牌的加权关注热图。
- **分心令牌剪枝**：采用一种**基于交集的策略**，对于非重要区域中的图像令牌，如果其注意力值超过了重要区域内最大注意力值（经容忍度因子 `τ` 缩放），则将其判定为分心令牌并进行剪枝。

**3. 主要实验结果**
在SIMPLER和LIBERO基准测试上，DTP在多种先进的VLA模型上均取得了显著提升：
- **任务成功率提升**：在WidowX机器人任务中，SpatialVLA相对提升28.4%，Nora提升近2倍，即使最强的UniVLA基线也获得了7.7%的相对提升。
- **强泛化性**：方法在Google Robot任务和更复杂的LIBERO-10任务上同样有效，证明了其跨模型架构、任务和机器人平台的通用性。
- **揭示关键现象**：分析发现，所有测试模型的任务成功率与模型在非重要区域的注意力总量呈**显著负相关**，这揭示了VLA模型一个共同的弱点。
- **探索性能上限**：通过调节容忍度 `τ`，DTP能够探索模型在现有架构下的性能上限，找到更符合模型“偏好”的注意力模式。

**4. 研究意义和价值**
DTP框架具有重要的理论价值与实践意义：
- **实用价值**：提供了一种简单、高效、无需重新训练的即插即用方案，可直接提升现有VLA模型在机器人操作中的鲁棒性和成功率。
- **科学洞察**：首次系统性地量化并验证了“分心令牌”对VLA模型性能的负面影响，为理解模型失败机制提供了新视角。
- **指导未来研究**：所揭示的注意力泄漏问题是VLA模型的共性弱点，这为未来设计更鲁棒的具身AI模型指明了改进方向，例如开发更智能的注意力引导机制。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析

### **核心问题**
论文旨在解决**视觉-语言-动作模型在机器人操作任务中，因过度关注任务无关的视觉区域而导致任务失败**的问题。作者将模型过度关注的、与任务无关的图像标记称为“干扰标记”。这些标记会分散模型在生成动作标记时的注意力，从而降低任务成功率。

### **核心创新点**
论文提出了一个名为 **“干扰标记剪枝”** 的即插即用框架。其核心创新在于：
1.  **无需训练、架构无关的推理时优化**：DTP 是一个纯推理阶段的优化模块，无需修改模型架构、重新训练或增加额外输入。它通过分析模型内部的注意力机制动态地识别并剪枝干扰标记。
2.  **双视角交叉验证的剪枝策略**：
    *   **任务相关性视角**：通过分析提示词与图像标记在特定Transformer层中的交互（注意力或嵌入相似度），构建“重要区域”，识别与任务指令相关的图像部分。
    *   **模型注意力视角**：通过分析模型在生成每个动作标记时对图像标记的跨注意力权重，构建“视觉注意力模式”，了解模型实际关注了哪里。
    *   **基于交集的动态剪枝**：对于位于“非重要区域”的图像标记，如果其获得的模型注意力值超过了“重要区域”内最大注意力值的一定比例（由容忍度参数 `τ` 控制），则将其判定为“干扰标记”并进行剪枝。
3.  **探索性能上限的理论与实践框架**：通过系统性地调整容忍度 `τ`，DTP 能够探索在**不改变模型原有架构**的前提下，通过优化注意力模式所能达到的**任务成功率上限**。这为评估和提升VLA模型的潜力提供了一个新视角。

### **解决方案（方法概述）**
DTP 框架通过以下三个步骤动态地纠正模型的视觉注意力模式：

1.  **重要区域构建**：计算提示词标记与所有图像标记在选定Transformer层中的相关性（公式1-3），生成相关性热图。通过空间偏置（如高斯平滑）和选择Top-k高相关标记，确定与任务指令相关的“重要区域” `G`。
2.  **视觉注意力模式构建**：在模型生成每个动作标记时，收集所有层中从该动作标记到图像标记的跨注意力权重，并按各层视觉注意力比例进行加权求和（公式4），得到代表模型实际关注点的注意力热图 `A`。
3.  **干扰标记剪枝**：应用**交集策略**（公式5）。对于不在重要区域 `G` 内的图像标记（即“非重要区域”），如果其在注意力热图 `A` 中的值 `A_u[v]` 大于重要区域内最大注意力值 `a_m` 的 `τ` 倍，则判定该标记为干扰标记并予以剪除。剪枝后，模型使用净化后的视觉输入重新生成更准确的动作。

### **实际价值与意义**
1.  **即插即用的性能提升工具**：DTP 被证明能**一致地提升**多种先进VLA模型（SpatialVLA, Nora, UniVLA）在多个机器人操作基准（SIMPLER, LIBERO）上的任务成功率，提升幅度最高可达近2倍（相对提升185.5%）。它对强基线模型和弱模型均有效。
2.  **揭示了VLA模型的共性弱点**：论文通过分析发现，**任务失败与模型在“非重要区域”分配的注意力总量呈显著正相关**。这揭示了当前VLA模型普遍存在的“注意力泄漏”问题，为未来研究指明了方向。
3.  **提供了模型诊断与优化新范式**：DTP 不仅是一个提升工具，更是一种分析工具。它允许研究者量化注意力模式对任务不确定性的影响（公式6-9），并探索模型在现有架构下的理论性能极限。
4.  **促进高效可靠的具身智能**：通过减少视觉噪声，使模型更专注于任务关键区域，DTP 有助于构建更稳健、决策更精确的机器人控制系统，推动视觉-语言-动作模型在实际场景中的应用。

**总结**：这篇论文的核心贡献是提出了一个**简单、有效、通用**的框架，通过**在推理时智能地剪枝分散注意力的视觉标记**，来纠正VLA模型的注意力偏差，从而提升其机器人操作性能，并同时为理解和探索这类模型的潜力提供了新的方法论。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文针对视觉-语言-动作（VLA）模型在机器人操作任务中，其视觉注意力机制容易过度关注与任务无关的图像区域（即“干扰令牌”），从而导致任务失败率升高这一核心问题，提出了一种名为“干扰令牌剪枝”（DTP）的即插即用框架。该框架的核心方法是：首先，通过分析提示词与图像令牌的交互，动态构建任务相关的“重要区域”；其次，分析模型生成每个动作令牌时的视觉注意力分布；最后，通过一种基于交集的策略，自动识别并剪除那些位于非重要区域但获得了过高注意力的干扰令牌。实验表明，该方法无需修改模型架构或重新训练，就能有效纠正VLA模型的注意力模式，在多个基准测试和不同VLA模型上一致地提升了任务成功率，并揭示了任务成功率与模型对无关区域注意力值之间存在负相关关系，为未来构建更鲁棒的VLA模型提供了洞见。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文创新点分析

这篇论文提出的 **Distracting Token Pruning (DTP)** 框架，在视觉-语言-动作模型领域具有多项明确的创新点。以下是逐条分析：

---

### 1. **提出“干扰令牌”概念与动态检测、剪枝框架**
   - **相比以往方法的改进/不同之处**：
     - **以往方法**：多数VLA改进工作集中于**架构设计**（如引入深度信息、改进动作分词器）或**训练策略**（如世界模型、端到端训练）。部分工作（如BYOVLA、Otter）尝试在输入层面干预或增加模块来过滤特征，但通常需要修改架构或重新训练。
     - **本文方法**：首次明确将VLA模型中**对任务无关区域图像令牌的过度关注**定义为“干扰令牌”，并提出一个**即插即用、无需训练、架构无关**的推理时动态检测与剪枝框架。它不改变模型原始权重或结构，仅通过分析注意力模式来修正输入。
   - **解决的具体问题/带来的优势**：
     - **解决核心问题**：直接针对VLA模型在生成动作时**注意力分散到无关视觉区域**这一普遍现象，该现象已被证明与任务失败率正相关。
     - **核心优势**：**通用性强、部署简单**。可应用于任何基于Transformer的VLA模型，无需重新训练或架构修改，显著降低了应用门槛。

### 2. **设计“重要性区域”与“视觉注意力模式”的双视角交集剪枝策略**
   - **相比以往方法的改进/不同之处**：
     - **以往方法**：手动检查注意力模式或基于单一启发式规则（如仅依赖文本-图像相关性）进行剪枝，效率低且可能不符合模型自身偏好。
     - **本文方法**：创新性地结合两个视角：
       1.  **任务相关性视角（自顶向下）**：通过分析**提示词令牌与图像令牌的交互**（注意力或嵌入相似度），构建“重要性区域”，识别与任务指令相关的视觉令牌。
       2.  **模型行为视角（自底向上）**：通过分析**模型生成每个动作令牌时对图像令牌的跨注意力**，构建“视觉注意力模式”，揭示模型实际关注点。
       3.  **交集策略**：仅当模型在**非重要区域**的注意力值，超过了**重要区域内最大注意力值乘以容忍度τ**时，才将该令牌判定为“干扰令牌”并进行剪枝。
   - **解决的具体问题/带来的优势**：
     - **解决核心问题**：克服了手动分析的不可行性，并避免了单一视角的偏差。该策略能**自适应地识别出模型自身“误关注”的令牌**，而非强加人类先验。
     - **核心优势**：**精准且自适应**。通过双视角校准，剪枝决策更符合模型内部工作机制，从而更有效地纠正注意力，提升动作生成的准确性。

### 3. **提出并探索VLA模型的“性能上限”概念**
   - **相比以往方法的改进/不同之处**：
     - **以往方法**：通常只报告基线模型的性能，或通过架构改进追求更高分数，但缺乏对**在现有架构和权重不变前提下，模型理论上能达到的最佳性能**的系统性探索。
     - **本文方法**：将不同视觉注意力模式 `α` 下的模型性能，形式化为**在给定视觉特征下对正确动作的条件不确定性** `H(A*|Z_α)`。通过调节剪枝容忍度 `τ`，DTP可以诱导出一系列注意力模式 `α_τ`，从而**近似探索模型在不变动权重和结构下的性能上限** `P(α*)`。
   - **解决的具体问题/带来的优势**：
     - **解决核心问题**：为评估VLA模型提供了一个**新的分析维度**，帮助区分是模型**架构能力不足**，还是**注意力机制未能充分利用现有能力**。
     - **核心优势**：**具有诊断和指导意义**。如果DTP能显著提升性能至接近上限，说明原模型的注意力机制是主要瓶颈；反之，则说明模型表征能力本身存在根本限制。这为未来研究（是改进注意力机制还是提升基础模型）提供了方向。

### 4. **实证揭示“无关区域注意力”与任务失败率的强负相关关系**
   - **相比以往方法的改进/不同之处**：
     - **以往方法**：可能观察到模型注意力不集中，但缺乏**大规模、定量化的实证分析**来证明这种注意力分散是跨模型、跨任务的普遍问题，且与失败有因果关系。
     - **本文方法**：在多个基准（SIMPLER, LIBERO）、多个模型（SpatialVLA, Nora, UniVLA）上系统性地收集和分析“无关区域注意力”值。通过统计检验（Mann-Whitney U test）证明，**失败情节的无关区域注意力显著高于成功情节**，并展示了其在任务关键阶段（如抓取）的动态差异。
   - **解决的具体问题/带来的优势**：
     - **解决核心问题**：为VLA领域指出了一个**共性的、可量化的失败模式**，而不仅仅是某个特定模型的缺陷。
     - **核心优势**：**提供了坚实的经验证据和洞察**。这不仅解释了DTP为何有效，更重要的是为整个社区指明了改进VLA模型鲁棒性的一个清晰路径：**抑制对无关区域的注意力泄漏**。这比单纯追求更高的基准分数更具普适性指导价值。

---

**总结**：本文的核心创新在于从一个**新视角**（推理时注意力修正）切入，提出了一个**新方法**（双视角动态剪枝），并由此引出了**新分析**（性能上限探索）和**新发现**（无关注意力与失败的强关联）。其最大价值在于提供了一种简单、通用、有效的工具来“解锁”现有VLA模型的潜在性能，并深化了社区对VLA模型失败机理的理解。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 论文实验与评估效果分析

该论文提出的**Distracting Token Pruning (DTP)** 框架在多个标准机器人操作基准测试中进行了全面评估，证明了其有效性、通用性和实际价值。

### 一、 使用的数据集与评价指标

1.  **主要数据集**：
    *   **SIMPLER Benchmark**： 论文的核心评估基准，包含两个机器人平台的任务：
        *   **WidowX Robot Tasks**： 评估复杂的物体操作任务，如“将勺子放在毛巾上”、“堆叠积木”等。
        *   **Google Robot Tasks**： 评估拾取、移动等任务，包含“视觉匹配”和“变体聚合”两种测试模式。
    *   **LIBERO Benchmark**： 用于验证方法的泛化能力，包含LIBERO-Spatial, -Object, -Goal和更具挑战性的LIBERO-10四个子集。

2.  **评价指标**：
    *   **任务成功率**： 核心指标，直接衡量模型完成指定任务的性能。
        *   **SR**： 平均任务成功率。
        *   **Rel.**： 相对于基线模型的**相对成功率提升百分比**，用于量化改进幅度。
    *   **辅助分析指标**：
        *   **不重要区域注意力值**： 用于分析模型注意力分散与任务失败之间的相关性。
        *   **性能上界探索**： 通过调整容忍度参数 `τ`，探索模型在现有架构下的潜在性能上限。

### 二、 对比的基线方法

论文将DTP框架作为“即插即用”模块，集成到三个先进的、具有不同架构特点的**VLA模型**中，并与它们的原始版本进行对比：
1.  **SpatialVLA**： 基于Paligemma 2的3B参数模型，集成了3D位置编码。
2.  **Nora**： 基于Qwen2.5-VL-3B的模型，使用FAST分词器进行连续动作解码。
3.  **UniVLA**： 一个9B参数的世界模型VLA。

**对比的核心是：每个VLA模型（基线） vs. 同一模型 + DTP（改进版）**。这种设计直接证明了DTP的通用性和对模型原生架构的无侵入性。

### 三、 关键性能提升与结论

#### 1. 核心性能提升（定量结果）

*   **在SIMPLER Benchmark (WidowX) 上**：
    *   **SpatialVLA**： 平均成功率从 **29.2%** 提升至 **37.5%**，**相对提升28.4%**。
    *   **Nora**： 平均成功率从 **6.2%** 提升至 **11.5%**，**相对提升近一倍（~85.5%）**。
    *   **UniVLA**： 在已经很高的基线（68.7%）上，进一步提升至 **74.0%**，**相对提升7.7%**。

*   **在SIMPLER Benchmark (Google Robot) 上**：
    *   提升幅度较小但**一致**。例如，SpatialVLA和Nora在各项任务上均获得 **1-3%** 的相对提升，证明了方法在不同机器人平台上的有效性。

*   **在LIBERO Benchmark 上**：
    *   在Nora模型上测试，DTP在**所有子集**上均带来提升。
    *   尤其在最具挑战性的**LIBERO-10**上，取得了 **+6.6%** 的绝对成功率提升。

#### 2. 关键结论与发现

1.  **通用性与鲁棒性**：
    *   DTP对**强基线（如UniVLA）和弱基线（如Nora）均有效**，表明“注意力分散”是VLA模型的普遍问题，而修剪干扰令牌是一种通用的解决方案。
    *   方法在**不同机器人平台（WidowX, Google Robot）、不同任务和不同基准（SIMPLER, LIBERO）** 上均表现出一致的改进，证明了其优秀的泛化能力。

2.  **性能上界探索**：
    *   通过系统性地调整容忍度参数 `τ`，论文展示了每个模型都存在一个**最优的 `τ` 值**，能使任务成功率达到峰值（见图4）。
    *   这验证了DTP能够帮助模型**逼近其在不改变权重和架构下的性能上限**，为模型评估和潜力挖掘提供了新工具。

3.  **现象分析与归因**：
    *   **关键发现**： 失败的任务轨迹中，模型分配给“不重要区域”的注意力总值**显著高于**成功的轨迹（p < 0.001）。这为DTP的有效性提供了直接证据。
    *   **时序洞察**： 注意力分散在任务**中期（抓取和操作阶段）** 最为明显，这可能是导致操作失败的关键时刻。

4.  **消融实验验证**：
    *   论文对比了多种替代方案（见表4、5）：
        *   **随机剪枝**： 在所有区域或仅在不重要区域随机剪枝令牌，性能**显著下降甚至低于基线**。
        *   **去除高斯平滑**： 性能**低于完整版DTP**。
    *   结论： **基于注意力分析的、有针对性的干扰令牌识别与剪枝策略**是DTP成功的关键，而非简单的令牌减少。

### 总结
论文通过严谨的实验设计，在多个标准数据集上定量地证明了DTP框架能够**稳定、显著地提升多种先进VLA模型在机器人操作任务上的成功率**。其核心价值在于：
*   **即插即用**： 无需重新训练或修改模型架构。
*   **通用有效**： 适用于不同架构的Transformer-based VLA模型。
*   **机理清晰**： 通过修正模型固有的“注意力分散”问题来提升性能，并提供了深入的现象学分析。
*   **潜力挖掘**： 提供了一种探索模型性能上限的方法。

这些结果强有力地支持了DTP作为一个简单而有效的推理时优化工具，对于推动VLA模型在实际机器人应用中的鲁棒性具有重要的实际价值。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2601.16065v1)
- [HTML 版本](https://arxiv.org/html/2601.16065v1)
