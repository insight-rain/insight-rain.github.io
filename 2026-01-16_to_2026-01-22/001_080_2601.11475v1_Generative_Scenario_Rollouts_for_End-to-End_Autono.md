# Generative Scenario Rollouts for End-to-End Autonomous Driving

**相关性评分**: 8.0/10

**排名**: #1


---


## 基本信息

- **arXiv ID**: [2601.11475v1](https://arxiv.org/abs/2601.11475v1)
- **发布时间**: 2026-01-16T17:59:28Z
- **相关性评分**: 8.0/10
- **是否相关**: 是

## 作者

Rajeev Yasarla, Deepti Hegde, Shizhong Han, Hsin-Pai Cheng, Yunxiao Shi, Meysam Sadeghigooghari, Shweta Mahajan, Apratim Bhattacharyya, Litian Liu, Risheek Garrepalli, Thomas Svantesson, Fatih Porikli, Hong Cai

## 关键词

Vision-Language-Action Model, VLA for Robotics, fine tune, offline Reinforcement Learning, world model

## 一句话总结

GeRo是一个基于Vision-Language-Action模型的生成式场景推演框架，通过自回归推演和强化学习集成，提升端到端自动驾驶的规划性能和鲁棒性。

## 摘要

Vision-Language-Action (VLA) models are emerging as highly effective planning models for end-to-end autonomous driving systems. However, current works mostly rely on imitation learning from sparse trajectory annotations and under-utilize their potential as generative models. We propose Generative Scenario Rollouts (GeRo), a plug-and-play framework for VLA models that jointly performs planning and generation of language-grounded future traffic scenes through an autoregressive rollout strategy. First, a VLA model is trained to encode ego vehicle and agent dynamics into latent tokens under supervision from planning, motion, and language tasks, facilitating text-aligned generation. Next, GeRo performs language-conditioned autoregressive generation. Given multi-view images, a scenario description, and ego-action questions, it generates future latent tokens and textual responses to guide long-horizon rollouts. A rollout-consistency loss stabilizes predictions using ground truth or pseudo-labels, mitigating drift and preserving text-action alignment. This design enables GeRo to perform temporally consistent, language-grounded rollouts that support long-horizon reasoning and multi-agent planning. On Bench2Drive, GeRo improves driving score and success rate by +15.7 and +26.2, respectively. By integrating reinforcement learning with generative rollouts, GeRo achieves state-of-the-art closed-loop and open-loop performance, demonstrating strong zero-shot robustness. These results highlight the promise of generative, language-conditioned reasoning as a foundation for safer and more interpretable end-to-end autonomous driving.

## 详细分析

## 论文摘要：用于端到端自动驾驶的生成式场景推演

**论文标题**：Generative Scenario Rollouts for End-to-End Autonomous Driving

### 1. 研究背景和动机
当前，视觉-语言-动作（VLA）模型已成为端到端自动驾驶规划的有力工具。然而，现有方法主要依赖稀疏轨迹标注进行模仿学习，未能充分利用其作为生成模型的潜力，且普遍存在**语言-动作监督稀疏、生成能力未充分利用、语言-动作错位**等问题。这导致模型在复杂、长尾场景下的鲁棒性和可解释性不足。为解决这些问题，本文提出了生成式场景推演框架（GeRo）。

### 2. 核心方法和技术创新
GeRo是一个即插即用的两阶段框架，旨在实现**语言引导的、时序一致的场景生成与规划**。
- **第一阶段（预训练）**：训练VLA模型，在规划、多智能体运动预测和视觉问答（VQA）任务的联合监督下，将自车与周围交通参与者的动态编码为紧凑的**潜在令牌**，为生成建立与文本对齐的表示空间。
- **第二阶段（生成式场景推演）**：核心创新。模型以**自回归方式**进行场景推演：给定多视角图像、场景描述和关于自车动作的问题，模型预测未来的潜在令牌及文本回答，并解码为轨迹。通过**推演一致性损失**（结合真实标签或预训练模型生成的伪标签）来稳定长时程预测，防止漂移。此外，引入基于**GRPO的强化学习**进行微调，其奖励函数综合了碰撞避免、碰撞时间（TTC）和语言预测准确性，共同优化轨迹的安全性与语义对齐。

### 3. 主要实验结果
在Bench2Drive和nuScenes基准测试上进行了全面评估：
- **闭环性能显著提升**：在Bench2Drive上，基于Qwen2.5VL的GeRo将驾驶分数和成功率分别提升了**+15.7和+26.2**；基于ORION的GeRo进一步将成功率提升至**60.10%**，达到新的SOTA。
- **开环预测误差大幅降低**：在nuScenes上，GeRo (Qwen) 将平均L2轨迹误差降低了67.7%，碰撞率降低了76.7%。
- **强大的零样本泛化能力**：在未针对nuScenes训练的情况下（零样本），仍能大幅降低误差，证明了其卓越的跨数据集泛化能力。
- **多场景驾驶能力突出**：在并道、超车、紧急制动等关键驾驶技能上，GeRo相比基线模型有显著提升（平均能力提升超过140%）。

### 4. 研究意义和价值
GeRo首次将**自回归场景生成**与VLA模型的运动规划紧密结合，通过语言引导的推演实现了**时序一致、可解释的长时程推理**。其价值在于：
- **技术层面**：提供了一种统一的框架，有效缓解了语言-动作错位问题，并通过强化学习整合安全约束，提升了规划的鲁棒性和安全性。
- **应用层面**：为构建更安全、更可解释、更能应对复杂长尾场景的端到端自动驾驶系统提供了新的思路和方法论，推动了生成式AI在自动驾驶领域的实际应用。

**总之，GeRo通过生成式、语言条件化的场景推演，为端到端自动驾驶的规划模块赋予了更强的推理、泛化和解释能力。**

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析

### **论文标题**
《Generative Scenario Rollouts for End-to-End Autonomous Driving》（用于端到端自动驾驶的生成式场景推演）

### **核心问题**
论文旨在解决当前**视觉-语言-动作（VLA）模型**在端到端自动驾驶规划中存在的几个关键局限性：
1.  **语言-动作监督稀疏**：现有数据集通常只提供场景级描述，缺乏与驾驶事件时间阶段绑定的细粒度动作标注，导致模型在复杂或长尾场景（如区分超车与并线）中表现脆弱。
2.  **生成能力未充分利用**：现有方法主要依赖真实轨迹进行模仿学习，忽视了VLA模型作为**生成模型**进行自回归场景推理和探索的潜力。
3.  **描述性语言 vs. 过程性语言**：当前的语言监督通常描述“发生了什么”，而非“动作如何展开”，限制了模型捕捉规划与执行所需的过程性细节的能力。
4.  **语言-动作错位**：许多数据集的指令-动作对是在收集专家驾驶数据后生成的，导致模型往往仅从视觉线索推断而忽略语言指令，产生“红灯加速”等错误。

### **核心创新点**
论文提出了 **GeRo（Generative Scenario Rollouts）**，一个即插即用的VLA模型训练框架，其核心创新在于**将自回归场景生成与运动规划统一起来**，实现语言对齐的长期、多智能体推理。

具体创新体现在以下三个层面：

#### **1. 方法论创新：两阶段生成式场景推演框架**
- **第一阶段：预训练**
    - 目标：学习一个紧凑的、共享的**潜在令牌空间**，用于编码自车和周围交通参与者的动态。
    - 方法：通过**规划损失（L1、碰撞损失）、运动预测损失（轨迹L1、3D框L1、类别焦点损失）和视觉问答（VQA）损失**进行联合监督，将语言和行为表征绑定在一起，为后续生成奠定基础。

- **第二阶段：语言条件化场景推演**
    - **自回归生成**：模型以多视角图像、场景描述和关于自车动作的问题为条件，在潜在令牌空间中**自回归地预测未来多步的令牌**。这些令牌被解码为轨迹和语言回答，并反馈给模型以引导长期推演。
    - **推演一致性损失**：引入**KL散度损失**，将推演预测的潜在分布与预训练模型生成的（或真实数据提供的）未来令牌分布对齐，以**减轻误差累积和漂移**，确保时间一致性。
    - **强化学习反馈**：引入基于**GRPO（广义推演策略优化）** 的强化学习进行微调。设计了结合**安全性**与**语义对齐**的奖励函数：
        ```python
        Reward = - Collision_Rate - 1/Time_To_Collision - Language_Alignment_Loss
        ```
        这鼓励模型生成既安全（避免碰撞、保持安全时距）又与语言描述语义一致的行为。

#### **2. 技术集成创新：首次联合执行场景生成与多任务**
- 据作者所知，这是**首个将场景生成与运动预测、规划、视觉问答联合进行**的工作。
- 通过**交互式VQA组件**，模型能在推演过程中回答关于自车意图的场景特定问题，**增强了规划的可解释性**，并为复杂环境中的语言引导推理提供了机制。

#### **3. 性能与泛化创新**
- **即插即用**：框架可应用于不同的VLA骨干模型（论文中展示了在Qwen2.5VL和ORION上的成功应用）。
- **零样本鲁棒性**：通过生成式推演和RL训练，模型展现出强大的**零样本泛化能力**（如在nuScenes数据集上的零测试性能显著提升）。

### **解决方案总结**
论文通过一个**两阶段的、生成式的、语言条件化的自回归推演框架**来解决上述问题：
1.  **解决监督稀疏与错位**：通过联合训练（规划+运动+VQA）学习语言-动作对齐的潜在表示，并利用自回归生成探索未标注的动作序列。
2.  **释放生成潜力**：将规划重构为在潜在空间中的**多步自回归场景生成任务**，使模型能够进行长期的、多模态的推理。
3.  **增强过程性与一致性**：通过语言条件化的问题引导和**推演一致性损失**，确保生成的场景在时间上连贯且符合过程逻辑。
4.  **提升安全性与鲁棒性**：引入**基于安全与语义奖励的强化学习**，直接优化长期推演的安全性、合理性和与语言指令的一致性。

### **实际价值**
- **性能提升**：在Bench2Drive基准上，相比强大基线（如ORION），**驾驶分数提升+4.16，成功率提升+5.5%**。开环轨迹误差和碰撞率也大幅降低。
- **更安全、可解释的自动驾驶**：框架生成了**与语言推理对齐的、时间一致的场景推演**，使决策过程更透明，便于人类理解和监管。
- **为下一代端到端驾驶系统提供新范式**：证明了生成式、语言条件化推理作为实现更鲁棒、更智能的自动驾驶基础模型的巨大潜力。

**总之，GeRo的核心贡献是提出并验证了一个统一的生成式场景推演范式，它巧妙地利用语言引导自回归生成和强化学习，显著提升了端到端自动驾驶规划的长时一致性、安全性、可解释性和零样本泛化能力。**


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文针对当前端到端自动驾驶中**视觉-语言-动作（VLA）模型**存在的核心问题——即**语言与动作监督稀疏、生成能力未充分利用、以及语言-动作对齐不佳**——提出了一个名为 **GeRo（Generative Scenario Rollouts）** 的即插即用训练框架。该框架的核心创新在于**将自回归的场景生成与VLA模型相结合**，通过两阶段方法：首先预训练模型以学习将车辆动态编码为与语言对齐的潜在令牌；随后进行**语言条件下的自回归场景推演**，并引入**滚动一致性损失**和**基于GRPO的强化学习反馈**来稳定长时程预测并确保安全与语义对齐。实验表明，GeRo在Bench2Drive基准测试中显著提升了驾驶性能（驾驶分数和成功率分别提升+15.7和+26.2），并在开环和闭环评估中均达到最先进水平，证明了其通过生成式、语言引导的推理来实现更安全、可解释自动驾驶的有效性。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文创新点分析

这篇论文《Generative Scenario Rollouts for End-to-End Autonomous Driving》提出的 **GeRo** 框架，在端到端自动驾驶的视觉-语言-动作模型领域，相对于已有工作有以下明确的创新点：

---

### 1. **首次将自回归场景生成与运动预测、规划、视觉问答进行联合建模**
- **改进/不同之处**：
    - 以往工作（如ORION、Qwen2.5VL）主要依赖**模仿学习**，从稀疏的轨迹标注中学习，仅将VLA模型用于**单步规划或描述**。
    - GeRo引入了**自回归的场景推演**机制，使模型能够基于当前观测和语言描述，**连续生成未来多步的交通场景**（包括自车轨迹、他车运动、语言回答）。
- **解决的问题/优势**：
    - 解决了现有VLA模型**生成能力未被充分利用**的问题。
    - 实现了**长时域、多智能体的连贯推理**，使规划不再局限于当前帧，而是能考虑未来场景的演变，从而在复杂、动态环境中做出更鲁棒、更前瞻的决策。

### 2. **提出一种结合模仿学习与强化学习的混合训练框架，并设计了新颖的奖励函数**
- **改进/不同之处**：
    - 传统方法要么纯模仿学习（易受协变量偏移影响），要么纯强化学习（训练不稳定、样本效率低）。
    - GeRo在第二阶段（场景推演阶段）**同时使用推演一致性损失和基于GRPO的强化学习反馈**。其奖励函数**综合了安全性指标（碰撞、TTC）和语义对齐指标（语言预测准确性）**。
- **解决的问题/优势**：
    - 解决了**纯模仿学习在长尾、新颖场景下性能次优**的问题。
    - 通过强化学习奖励（如碰撞惩罚、TTC奖励）**直接优化安全性和驾驶舒适性**，这是纯数据驱动的模仿学习难以直接保证的。
    - 奖励函数中的语言对齐项确保了**生成的动作与语言描述在语义上保持一致**，提升了模型的可解释性和指令遵循能力。

### 3. **引入了交互式视觉问答作为场景推演的语言引导与对齐机制**
- **改进/不同之处**：
    - 现有数据集的“语言-动作”对通常是事后标注的，导致模型容易**忽略语言指令，仅依赖视觉线索**（即语言-动作错位）。
    - GeRo在推演的每一步，都**输入与自车动作相关的问题**，并要求模型生成文本回答。这些问答对作为**持续的语言监督**，贯穿整个推演过程。
- **解决的问题/优势**：
    - 直接解决了**语言-动作监督稀疏且错位**的核心问题。
    - 将自车意图**显式地锚定在自然语言上**，增强了模型的**可解释性**。决策过程不再是“黑箱”，而是可以通过生成的文本来理解。
    - 实现了**语言引导的推理**，使模型能够根据高层语义指令（如“小心行人”）调整其多步规划。

### 4. **设计了基于潜在令牌的推演一致性损失，以稳定长时域生成**
- **改进/不同之处**：
    - 长时域自回归生成容易产生**误差累积和漂移**。
    - GeRo提出了**推演一致性损失**，使用KL散度将推演生成的潜在令牌分布，与预训练VLA模型生成的**参考令牌分布**进行对齐。参考令牌可来自真实数据，也可来自模型自身生成的伪标签。
- **解决的问题/优势**：
    - 有效**缓解了自回归生成中的漂移问题**，保证了多步预测的**时间一致性**。
    - 使得模型在缺乏真实未来数据时，也能利用自身知识生成合理的伪标签进行监督，**提升了训练数据的利用效率和模型的泛化能力**。

### 5. **作为一个即插即用的通用框架，显著提升了不同VLA基模型的性能**
- **改进/不同之处**：
    - 大多数工作是为特定架构设计的。
    - GeRo被设计为**模块化框架**，成功应用于两个不同的VLA基模型（Qwen2.5VL和ORION），并都带来了显著提升。
- **解决的问题/优势**：
    - 证明了其创新点的**普适性和有效性**，而非局限于某个特定模型。
    - 为社区提供了一个**可复现、可扩展的强基线**，其核心思想（生成式推演、语言对齐、混合训练）可以迁移到其他VLA架构上。

---

## 总结
GeRo的核心创新在于**将VLA模型从一个被动的“描述者”或“单步规划者”，转变为一个主动的“生成式世界模拟器”**。它通过**自回归场景推演**实现长时域推理，通过**语言引导的VQA**解决语义对齐问题，并通过**混合模仿-强化学习**优化安全与性能。这些创新共同解决了当前端到端自动驾驶VLA模型在**长尾场景鲁棒性、语言-动作错位、长时域规划一致性**等方面的关键瓶颈，最终在闭环和开环指标上实现了显著的SOTA性能提升，并展现出强大的零样本泛化能力。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 论文实验与评估效果总结

### 一、 使用的数据集与评价指标

#### 1. 主要数据集
- **Bench2Drive**：基于CARLA模拟器的闭环端到端自动驾驶基准数据集。
    - 用于**训练和闭环评估**。
    - 包含1000个片段（950训练，50开环验证），涵盖多样化的交通场景。
    - 闭环评估在44个交互场景的220条路线上进行。
- **nuScenes**：真实世界多模态数据集。
    - 用于**开环轨迹预测评估**，验证模型的泛化能力。
    - 使用其规划基准（28k个样本，22k/6k 训练/验证划分）。
- **语言标注数据**：结合了**ChatB2D**（与Bench2Drive配对）和**DriveLM-nuScenes**数据集，用于生成场景描述和自车行为问答对，以支持语言监督训练。

#### 2. 评价指标
- **闭环指标 (Bench2Drive)**：
    - **驾驶得分 (Driving Score, DS)**：综合路线完成度和违规惩罚。
    - **成功率 (Success Rate, SR)**：成功完成路线的比例。
    - **效率 (Efficiency)**：评估行驶速度。
    - **舒适度 (Comfortness)**：评估行驶平滑度。
    - **多能力 (Multi-Ability)**：评估五项高级城市驾驶技能（并线、超车、紧急制动、让行、交通标志遵守）。
- **开环指标**：
    - **轨迹L2误差 (Avg. L2)**：预测轨迹与真实轨迹在2秒内（2Hz）的平均L2距离误差。
    - **碰撞率 (Collision Rate)**：预测轨迹导致碰撞的比例。

### 二、 对比的基线方法
论文将GeRo框架应用于两个不同的VLA模型骨干，并与此前最先进的方法进行了广泛对比：

1.  **基于Qwen2.5VL的对比**：
    - **Qwen2.5VL**：原始的多模态大语言模型，增加了轨迹规划和运动预测头作为基线。
    - **ORION (Qwen2.5VL)**：将ORION框架中的语言模型替换为Qwen2.5VL的版本。

2.  **基于ORION的对比**：
    - **ORION**：当前先进的、统一端到端的VLA规划框架。

3.  **其他先进的端到端规划器**：
    - **传统/非VLA模型**：`VAD`, `UniAD` (Tiny/Base), `GenAD`, `MomAD`, `DriveTransformer-Large`等。
    - **其他VLA/LLM驱动模型**：`GPT-Driver`, `EMMA`, `DriveVLM`, `Senna`等（在相关工作中提及，部分在表格中对比）。

### 三、 关键性能提升与结论

#### 1. 闭环性能 (Bench2Drive) – 核心突破
- **GeRo (Qwen2.5VL) vs. 基线 Qwen2.5VL**：
    - **驾驶得分 (DS)**：从 **63.9** 提升至 **79.6** (**+15.7**)。
    - **成功率 (SR)**：从 **31.6%** 提升至 **57.8%** (**+26.2个百分点**)。
    - 这表明，**即使在不依赖高清地图的情况下**，GeRo的生成式场景推演和RL微调能带来巨大性能飞跃。

- **GeRo (ORION) vs. 基线 ORION**：
    - **驾驶得分 (DS)**：从 **77.74** 提升至 **81.90** (**+4.16**)。
    - **成功率 (SR)**：从 **54.62%** 提升至 **60.10%** (**+5.48个百分点**)。
    - 这表明GeRo作为一个**即插即用框架**，能进一步提升已有先进VLA模型的性能。

- **多能力评估**：
    - GeRo在**并线、超车、紧急制动、让行、交通标志遵守**等所有子能力上均显著超越基线。
    - 例如，GeRo (ORION)的**平均多能力得分**达到 **66.49%**，相比ORION基线的 **54.72%** 提升了 **21.5%**。在“紧急制动”和“超车”等关键场景中提升尤为显著（分别从78.33%到87.32%，71.11%到78.24%）。

#### 2. 开环性能 (nuScenes) – 卓越的泛化能力
- **GeRo (Qwen2.5VL) vs. 基线 Qwen2.5VL**：
    - **平均L2误差**：从 **0.96** 降至 **0.31** (**降低67.7%**)。
    - **平均碰撞率**：从 **0.60** 降至 **0.14** (**降低76.7%**)。
- **GeRo (ORION) vs. 基线 ORION**：
    - **平均L2误差**：从 **0.69** 降至 **0.27** (**降低60.9%**)。
    - **平均碰撞率**：从 **0.44** 降至 **0.12** (**降低72.7%**)。
- **零样本泛化 (Zero-shot)**：
    - 仅在Bench2Drive上训练，直接在nuScenes上测试，GeRo仍能取得显著优于基线的性能。例如，GeRo (Qwen2.5VL)零样本的L2误差 (**0.45**) 仍比完全在nuScenes上训练的Qwen2.5VL基线 (**0.96**) 低 **53.1%**。
    - 这强有力地证明了**生成式场景推演带来的强大泛化和世界模型推理能力**。

#### 3. 消融实验结论
论文通过系统的消融研究（见表4）验证了GeRo各个组件的有效性：
1.  **预训练阶段**：引入场景描述和视觉问答的监督对提升规划鲁棒性至关重要。
2.  **场景推演阶段**：
    - **时序一致性损失 (`ℒ_tc`)**：即使在没有真值、仅使用VLA模型生成的伪标签的情况下，也能带来显著提升（DS +3.9, SR +8.5%）。
    - **加入真值轨迹监督**：能带来进一步的巨大提升（DS +6.6, SR +10.3%）。
3.  **强化学习微调 (GRPO)**：
    - **安全奖励（碰撞、TTC）**：显著提升驾驶安全性和成功率（DS +4.1, SR +5.3%）。
    - **语言对齐奖励 (`ℒ_VLA`)**：通过问答对将自车意图与语言对齐，能带来最终的额外增益（DS +1.1, SR +2.1%），实现了**语言-动作的一致性**。

### 四、 总结
论文给出了**非常明确且强有力的定量结果**。实验表明，GeRo框架通过：
1.  **联合生成式场景推演**，实现了**时序一致**的长期规划。
2.  **语言条件化与强化学习**，确保了**语义对齐**和**安全性**。
3.  **即插即用的设计**，能无缝提升不同VLA骨干模型的性能。

最终，GeRo在**闭环驾驶得分/成功率**和**开环轨迹精度/安全性**上均取得了**最先进的性能**，并展示了**卓越的零样本泛化能力**，证明了生成式、语言驱动的推理是构建更安全、可解释端到端自动驾驶系统的有效途径。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2601.11475v1)
- [HTML 版本](https://arxiv.org/html/2601.11475v1)
