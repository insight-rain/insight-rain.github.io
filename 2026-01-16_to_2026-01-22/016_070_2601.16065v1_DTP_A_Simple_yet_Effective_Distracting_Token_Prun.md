# DTP: A Simple yet Effective Distracting Token Pruning Framework for Vision-Language Action Models

**相关性评分**: 7.0/10

**排名**: #16


---


## 基本信息

- **arXiv ID**: [2601.16065v1](https://arxiv.org/abs/2601.16065v1)
- **发布时间**: 2026-01-22T16:02:56Z
- **相关性评分**: 7.0/10
- **是否相关**: 是

## 作者

Chenyang Li, Jieyuan Liu, Bin Li, Bo Gao, Yilin Yuan, Yangfan He, Yuchen Li, Jingqun Tang

## 关键词

Vision-Language-Action Model, VLA for Robotics, Inference Acceleration, fine tune

## 一句话总结

本文提出了一种名为DTP的简单有效框架，通过动态检测和剪枝视觉语言动作模型中的干扰图像令牌，以提升任务成功率，并探索模型性能上限，适用于基于Transformer的VLA模型。

## 摘要

Vision-Language Action (VLA) models have shown remarkable progress in robotic manipulation by leveraging the powerful perception abilities of Vision-Language Models (VLMs) to understand environments and directly output actions. However, by default, VLA models may overly attend to image tokens in the task-irrelevant region, which we describe as 'distracting tokens'. This behavior can disturb the model from the generation of the desired action tokens in each step, affecting the success rate of tasks. In this paper, we introduce a simple yet effective plug-and-play Distracting Token Pruning (DTP) framework, which dynamically detects and prunes these distracting image tokens. By correcting the model's visual attention patterns, we aim to improve the task success rate, as well as exploring the performance upper boundaries of the model without altering its original architecture or adding additional inputs. Experiments on the SIMPLER Benchmark (Li et al., 2024) show that our method consistently achieving relative improvements in task success rates across different types of novel VLA models, demonstrating generalizability to transformer-based VLAs. Further analysis reveals a negative correlation between the task success rate and the amount of attentions in the task-irrelevant region for all models tested, highlighting a common phenomenon of VLA models that could guide future research. We also publish our code at: https://anonymous.4open.science/r/CBD3.

## 详细分析

## 论文摘要：DTP：一种简单有效的视觉-语言-动作模型干扰令牌剪枝框架

**1. 研究背景和动机**
视觉-语言-动作模型在机器人操作任务中展现出巨大潜力，但其在生成动作时，注意力常被任务无关的图像区域（即“干扰令牌”）所分散，导致任务成功率下降。现有方法或需人工干预，或需修改模型架构并重新训练，缺乏一种即插即用、无需训练且能提升多种VLA模型性能的通用方案。本文旨在解决这一核心问题。

**2. 核心方法和技术创新**
本文提出了**干扰令牌剪枝框架**，这是一种在推理时动态检测并剪枝干扰令牌的即插即用方法。其核心创新在于一个**三阶段、基于交集的剪枝策略**：
- **重要区域构建**：通过分析提示词与图像令牌在选定Transformer层中的交互（注意力或嵌入相似度），识别与任务最相关的视觉令牌区域。
- **视觉注意力模式分析**：计算模型在生成每个动作令牌时，对所有视觉令牌的加权注意力热图，揭示模型的“关注点”。
- **动态剪枝**：对于位于非重要区域的视觉令牌，如果其注意力值超过了重要区域内最大注意力值乘以一个**容忍度参数τ**，则将其判定为干扰令牌并进行剪枝。该方法无需修改模型架构或额外训练。

**3. 主要实验结果**
在SIMPLER和LIBERO基准测试上，DTP在多种先进的VLA模型上均取得了显著且一致的性能提升：
- **广泛适用性**：在SpatialVLA、Nora和UniVLA等不同架构的模型上，任务成功率均获得提升（相对提升最高达185.5%）。
- **探索性能上限**：通过调节τ，DTP能够探索模型在现有架构下的性能上限，部分任务成功率接近翻倍。
- **揭示关键现象**：分析发现，任务失败与模型在非重要区域分配的注意力呈显著正相关，这为理解VLA模型的失败模式提供了新见解。消融实验验证了针对性剪枝策略的有效性。

**4. 研究意义和价值**
DTP框架具有重要的理论价值与实践意义：
- **实用价值**：提供了一种简单、通用、无需训练的后处理工具，可直接提升现有VLA模型在机器人操作任务中的鲁棒性和成功率。
- **分析价值**：通过分析“不重要注意力”，揭示了VLA模型中注意力分散这一普遍弱点，为未来构建更鲁棒的具身AI模型指明了方向。
- **方法论价值**：提出了一种通过剪枝干扰信息来逼近模型理论性能上限的新思路，为模型诊断和性能挖掘提供了新工具。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析

### **核心问题**
论文旨在解决**视觉-语言-动作模型在机器人操作任务中，因过度关注任务无关的视觉区域而导致任务成功率下降**的问题。作者将模型过度关注的这些任务无关图像标记称为“干扰标记”。

### **核心创新点**
论文提出了一个名为 **DTP** 的框架，其核心创新在于：
1.  **“即插即用”的推理时优化**：DTP 是一个无需训练、不修改模型原始架构、无需额外输入的插件式框架。它仅在模型推理时动态地分析和修正其视觉注意力模式。
2.  **基于交叉验证的动态剪枝策略**：DTP 通过两个互补的视角来识别“干扰标记”：
    *   **任务相关性视角**：通过分析提示词与图像标记的交互（注意力或嵌入相似度），构建“重要区域”。
    *   **模型注意力视角**：通过分析模型在生成每个动作标记时对图像标记的注意力分布，构建“视觉注意力模式”。
    *   **交叉剪枝**：对于位于“非重要区域”的图像标记，如果其注意力值超过了“重要区域”内最大注意力值的一定比例（由容忍度参数 `τ` 控制），则将其判定为“干扰标记”并进行剪枝。
3.  **探索性能上限**：通过系统地调整容忍度 `τ`，DTP 能够探索在给定模型架构下，通过优化注意力模式所能达到的**任务成功率理论上限**，为模型评估和潜力挖掘提供了新工具。

### **解决方案（DTP框架的三阶段流程）**
1.  **重要区域构建**：
    *   计算提示词标记与所有视觉标记之间的相关性得分（通过跨注意力权重或嵌入余弦相似度）。
    *   聚合多层、多提示词的相关性，形成**相关性热图**。
    *   通过高斯平滑和角点抑制等后处理，筛选出得分最高的 `k` 个视觉标记，构成**重要区域 `G`**。

2.  **视觉注意力模式构建**：
    *   在模型生成每个动作标记时，提取所有 Transformer 层中该动作标记对视觉标记的注意力权重。
    *   根据每层注意力中视觉部分所占的比例进行加权求和，得到该步骤的**视觉注意力模式 `A`**，它揭示了模型生成动作时的实际关注点。

3.  **干扰标记剪枝**：
    *   **关键判定规则**：对于任意位于非重要区域 (`A_u`) 的视觉标记 `v`，如果其注意力值 `A_u[v]` 满足：`A_u[v] > τ * max(A_g)`，则将其标记为干扰标记。
    *   **执行剪枝**：在生成最终动作时，屏蔽（剪枝）所有被标记为干扰的视觉标记，迫使模型将注意力重新分配到更相关的区域。

### **实际价值与技术意义**
*   **普适性提升**：在 SIMPLER 和 LIBERO 等多个基准测试中，DTP 在 SpatialVLA、Nora、UniVLA 等不同架构、不同性能水平的 VLA 模型上均能一致地提升任务成功率（相对提升最高达 **185.5%**），证明了其广泛的适用性。
*   **揭示模型共性弱点**：通过分析发现，所有测试模型在**失败的任务轨迹中，对非重要区域的注意力都显著高于成功轨迹**。这揭示了当前 VLA 模型普遍存在的“注意力泄漏”问题，为未来研究指明了方向。
*   **提供实用工具**：DTP 作为一种轻量级、无需训练的后处理工具，为现有 VLA 模型的部署和性能优化提供了一种简单有效的途径，尤其适用于无法进行模型重训练或架构修改的场景。
*   **方法论贡献**：提出了一种量化分析注意力模式与任务性能（通过条件熵理论框架）之间关系的方法，并将剪枝过程形式化为一个寻找最优注意力模式 `α*` 的近似过程，增强了工作的理论深度。

**总结**：DTP 的核心价值在于，它用一个**极其简洁**的框架（基于注意力机制的内省和交叉验证），**有效地诊断并缓解**了 VLA 模型中的一个**普遍且关键的性能瓶颈**（注意力分散），同时为理解和挖掘模型潜力提供了新的分析维度和实用工具。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文针对视觉-语言-动作模型在机器人操作任务中，其视觉注意力机制容易过度关注任务无关区域（即“干扰令牌”），从而导致任务失败的核心问题，提出了一种名为“干扰令牌剪枝”的即插即用框架。该方法通过动态分析指令与图像令牌的相关性来构建任务关键区域，并监测模型生成动作时的注意力分布，最后基于交叉比对策略，自动识别并剪除那些位于非关键区域但吸引了过高注意力的干扰令牌。实验表明，该方法无需修改模型架构或重新训练，就能有效纠正模型的注意力模式，在多个基准测试和不同VLA模型上普遍提升了任务成功率，并揭示了任务成功率与模型对无关区域注意力强度之间的负相关关系，为提升VLA模型的鲁棒性提供了新思路。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文创新点分析

这篇论文提出的 **Distracting Token Pruning (DTP)** 框架，在视觉-语言-动作模型领域具有多项明确的创新点。以下是逐条分析：

### 1. **提出“干扰令牌”概念与动态检测、剪枝框架**
   - **相比以往方法的改进/不同之处**：
     - **以往方法**：多数VLA模型的改进集中在**架构设计**（如引入深度信息、改进动作分词器）或**训练策略**（如世界模型、端到端训练）。一些工作（如BYOVLA、Otter）尝试通过修改输入图像或增加可训练模块来增强鲁棒性，但这些方法**要么需要修改输入，要么需要改变模型架构并进行重新训练**。
     - **DTP方法**：首次明确将VLA模型在任务无关区域过度关注的图像令牌定义为 **“干扰令牌”** ，并提出了一个**纯推理阶段、无需训练、即插即用**的框架来动态检测并剪枝这些令牌。它不改变模型原始权重、架构或额外输入。
   - **解决的具体问题/带来的优势**：
     - **解决问题**：直接针对VLA模型在决策时**注意力分散**到任务无关视觉区域这一根本性弱点，该弱点会导致动作生成错误和任务成功率下降。
     - **核心优势**：**通用性强、部署成本低**。由于无需重新训练或修改模型，DTP可以无缝应用到任何基于Transformer的现有VLA模型上，快速提升其性能，为模型部署提供了一种高效的后处理优化工具。

### 2. **设计“任务相关性”与“模型注意力”的双视角交集剪枝策略**
   - **相比以往方法的改进/不同之处**：
     - **以往方法**：手动分析注意力模式耗时且主观，无法规模化；简单的基于阈值的注意力修剪可能不符合模型自身的偏好。
     - **DTP方法**：创新性地融合了两个视角：
       1.  **任务重要性视角**：通过分析提示词令牌与图像令牌的交互（注意力或嵌入相似度），构建**任务相关重要区域**。这从“任务指令”出发，识别了理论上应该关注的区域。
       2.  **模型行为视角**：通过分析模型生成每个动作令牌时的跨注意力图，构建**视觉注意力模式**。这反映了模型“实际”关注的地方。
       3.  **交集策略**：仅当模型在**非重要区域**的注意力值，超过了**重要区域内最大注意力值**的某个容忍度（`τ`）时，才将该令牌判定为“干扰令牌”并进行剪枝。
   - **解决的具体问题/带来的优势**：
     - **解决问题**：解决了**如何自动化、客观地识别“有害”注意力**的问题。双视角交集确保了剪枝的令牌既是任务无关的（从任务角度看），又是模型过度关注的（从模型行为角度看），避免了误删重要信息或保留有害干扰。
     - **核心优势**：实现了**精准、自适应的干扰检测**。该策略尊重了不同VLA模型可能具有的独特注意力偏好，通过调节`τ`可以探索模型性能上界，而非强加一个统一的“理想”注意力模式。

### 3. **探索并量化VLA模型的“性能上界”**
   - **相比以往方法的改进/不同之处**：
     - **以往方法**：评估模型性能通常止步于基线结果，或通过扩大模型、增加数据来提升性能，缺乏在**固定架构和权重下**探索其理论最大潜力的系统性方法。
     - **DTP方法**：将DTP框架中的容忍度参数 `τ` 视为调节视觉注意力模式的“旋钮”。通过系统性地调整 `τ`（从激进剪枝到不剪枝），观察任务成功率的变化，从而**绘制出模型在现有能力下可能达到的性能边界曲线**。
   - **解决的具体问题/带来的优势**：
     - **解决问题**：回答了“**在不改变模型本身的情况下，通过优化其注意力机制，它到底能有多好？**”这一问题。
     - **核心优势**：
       1.  **诊断工具**：为模型评估提供了新维度，帮助研究者理解当前架构的潜力与局限。
       2.  **指导意义**：性能上界与基线之间的差距，揭示了仅通过优化注意力就能获得的“免费”性能提升空间，为未来模型架构设计（例如，如何让模型默认拥有更优的注意力模式）指明了方向。

### 4. **实证揭示“无关区域注意力”与任务失败的强相关性**
   - **相比以往方法的改进/不同之处**：
     - **以往方法**：虽然可能观察到模型注意力不集中的现象，但缺乏大规模、定量的实证研究来证明这种注意力分散与任务失败之间存在**普适的、统计显著的因果关系**。
     - **DTP方法**：论文对大量成功与失败的任务轨迹进行了分析，定量计算了“无关区域注意力”值，并使用曼-惠特尼U检验进行了统计比较。
   - **解决的具体问题/带来的优势**：
     - **解决问题**：不仅提出了解决方法（DTP），还**从原理上验证了所要解决问题的普遍性和严重性**。它证实了“注意力泄漏”是跨模型、跨任务的一个共性失败原因，而非个别案例。
     - **核心优势**：
       1.  **增强了DTP的动机说服力**：使DTP框架的提出建立在坚实的实证发现之上。
       2.  **贡献了普适性见解**：这一发现本身是对VLA研究领域的重要贡献，提示未来研究应致力于提升模型注意力的鲁棒性和聚焦能力。

### 总结
本文的核心创新在于从一个**新的角度**（推理时动态注意力优化）切入VLA模型的性能提升问题，提出了一种**简单、通用、有效**的解决方案（DTP）。它不仅是一个实用的性能提升工具，更提供了一个分析模型注意力缺陷、探索其性能极限的框架，并对VLA模型的失败机理提供了重要的实证洞察。其“即插即用”的特性使其具有很高的实际应用价值。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 论文实验与评估效果分析

该论文提出的**Distracting Token Pruning (DTP)** 框架在多个标准基准测试上进行了系统性评估，证明了其有效性、通用性和实际价值。

### 一、 使用的数据集与评价指标

1.  **主要数据集**：
    *   **SIMPLER Benchmark**： 核心评估平台，包含两个机器人仿真环境：
        *   **WidowX Robot**： 评估复杂的物体操作任务（如放置、堆叠）。
        *   **Google Robot**： 评估视觉匹配和变体聚合任务。
    *   **LIBERO Benchmark**： 用于验证方法的泛化能力，包含多个终身学习套件（LIBERO-Spatial, -Object, -Goal, -10）。

2.  **核心评价指标**：
    *   **任务成功率 (Success Rate, SR)**： 评估任务最终完成的比例，是衡量机器人操作性能的核心指标。
    *   **相对成功率 (Relative Success Rate, Rel.)**： 计算 `(DTP增强后的SR / 基线模型SR) * 100%`，用于量化性能提升的幅度。
    *   **抓取成功率 (Grasp Success)**： 在WidowX任务中，额外报告成功抓取物体的中间步骤成功率。

### 二、 对比的基线方法

论文将DTP与**三种先进的、具有不同架构的VLA模型**进行集成和对比，而非与独立的“方法”对比。这旨在证明DTP作为“即插即用”模块的通用性。基线模型包括：
1.  **SpatialVLA**： 基于Paligemma 2的3B参数模型，集成了3D位置编码。
2.  **Nora**： 基于Qwen2.5-VL-3B的模型，使用FAST分词器进行连续动作解码。
3.  **UniVLA**： 一个9B参数的世界模型VLA。

**对比方式**： 分别报告每个基线模型**原始版本**和**集成DTP后版本**的性能。此外，在消融实验中，将完整的DTP方法与几种简化变体进行对比。

### 三、 关键性能提升与结论

#### 1. 主要性能提升（定量结果）

*   **在SIMPLER Benchmark (WidowX) 上的显著提升**：
    *   **SpatialVLA**： 平均成功率从 **29.2%** 提升至 **37.5%** (**相对提升28.4%**)。
    *   **Nora**： 平均成功率从 **6.2%** 提升至 **11.5%** (**相对提升近2倍，即~185.5%**)。对于这个较弱的基线，提升尤为显著。
    *   **UniVLA**： 这个强大的基线模型成功率已高达68.7%，DTP仍能将其提升至 **74.0%** (**相对提升7.7%**)。

*   **在SIMPLER Benchmark (Google Robot) 上的稳定提升**：
    *   提升幅度较小但**一致**。例如，SpatialVLA和Nora在各项任务上均获得 **+1% 至 +3%** 的相对提升，证明了DTP在不同机器人平台和任务类型上的鲁棒性。

*   **在LIBERO Benchmark 上的泛化能力验证**：
    *   在Nora模型上测试，DTP在**所有LIBERO套件**上均带来提升。
    *   特别是在最具挑战性的**LIBERO-10**上，取得了 **+6.6%** 的绝对成功率提升，表明DTP能有效应对更复杂、多样的操作任务。

#### 2. 核心结论与发现

*   **通用性与鲁棒性**： DTP能够一致地提升**强**（如UniVLA）和**弱**（如Nora）的VLA模型性能，说明“注意力分散”是当前VLA模型的普遍弱点，而DTP提供了一种通用的解决方案。
*   **探索性能上界**： 通过调节容忍度参数 `τ`，DTP可以探索模型在**不改变其原始架构**下的性能上界。实验表明，存在一个最优的 `τ` 值能使任务成功率达到峰值，这为理解模型潜力和优化注意力模式提供了新视角。
*   **注意力模式与失败的相关性**： 分析揭示了**任务无关区域的注意力值与任务失败率呈显著正相关**（`p < 0.001`）。失败轨迹在任务关键阶段（如抓取）往往伴随着更高的“无关注意力”。这从原理上解释了DTP为何有效。
*   **优于随机或简化的策略**： 消融实验表明，**完整的DTP策略**（基于重要区域和注意力模式的交集进行针对性剪枝）显著优于**在全图随机剪枝**、**仅在无关区域随机剪枝**或**不使用高斯平滑**的简化版本，验证了其设计必要性。

### 总结
论文通过在上述数据集和评价指标上的系统实验，**定量地证明了DTP框架的有效性**。它不仅能在多个基准上稳定提升不同VLA模型的任务成功率（最高实现近2倍的相对提升），还通过理论分析和消融实验，深入揭示了其工作原理和优越性，为构建更鲁棒的视觉-语言-动作模型提供了简单而强大的工具。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2601.16065v1)
- [HTML 版本](https://arxiv.org/html/2601.16065v1)
