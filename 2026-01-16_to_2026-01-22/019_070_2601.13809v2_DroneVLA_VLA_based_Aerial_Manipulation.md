# DroneVLA: VLA based Aerial Manipulation

**相关性评分**: 7.0/10

**排名**: #19


---


## 基本信息

- **arXiv ID**: [2601.13809v2](https://arxiv.org/abs/2601.13809v2)
- **发布时间**: 2026-01-20T10:08:00Z
- **相关性评分**: 7.0/10
- **是否相关**: 是

## 作者

Fawad Mehboob, Monijesu James, Amir Habel, Jeffrin Sam, Miguel Altamirano Cabrera, Dzmitry Tsetserukou

## 关键词

Vision-Language-Action Model, VLA for Robotics

## 一句话总结

这篇论文提出了一种基于视觉-语言-动作（VLA）模型的自主无人机操控系统，能够通过自然语言命令实现物体抓取和交付，并整合了感知、规划和交互模块以提升安全性和实用性。

## 摘要

As aerial platforms evolve from passive observers to active manipulators, the challenge shifts toward designing intuitive interfaces that allow non-expert users to command these systems naturally. This work introduces a novel concept of autonomous aerial manipulation system capable of interpreting high-level natural language commands to retrieve objects and deliver them to a human user. The system is intended to integrate a MediaPipe based on Grounding DINO and a Vision-Language-Action (VLA) model with a custom-built drone equipped with a 1-DOF gripper and an Intel RealSense RGB-D camera. VLA performs semantic reasoning to interpret the intent of a user prompt and generates a prioritized task queue for grasping of relevant objects in the scene. Grounding DINO and dynamic A* planning algorithm are used to navigate and safely relocate the object. To ensure safe and natural interaction during the handover phase, the system employs a human-centric controller driven by MediaPipe. This module provides real-time human pose estimation, allowing the drone to employ visual servoing to maintain a stable, distinct position directly in front of the user, facilitating a comfortable handover. We demonstrate the system's efficacy through real-world experiments for localization and navigation, which resulted in a 0.164m, 0.070m, and 0.084m of max, mean euclidean, and root-mean squared errors, respectively, highlighting the feasibility of VLA for aerial manipulation operations.

## 详细分析

## 论文摘要：DroneVLA: 基于视觉-语言-动作模型的空中操控

**1. 研究背景和动机**
随着无人机从被动观察者演变为主动操控者，设计直观的界面以允许非专家用户自然地指挥系统成为关键挑战。现有基于大语言模型或视觉语言模型的空中操控方案，要么缺乏对无人机底层运动的直接控制权，要么存在“黑箱”幻觉带来的安全风险。本研究旨在提出一种**安全、可靠且直观**的自主空中操控系统，能够理解高级自然语言指令，实现与人类的物体取放交互。

**2. 核心方法和技术创新**
本文提出了 **DroneVLA** 系统，其核心创新在于采用了一种**分层、解耦的架构**：
- **硬件平台**：使用搭载一自由度夹爪和RGB-D相机的定制四旋翼无人机，夹爪前置设计以减弱下洗气流干扰。
- **语义理解模块**：引入一个**概念性视觉-语言-动作模型**，负责解析用户指令（如“拿起红色螺丝刀”）的语义意图，并生成优先级任务队列。该模型基于 **TinyVLA** 设计，在桌面端运行，专注于预测夹爪的“开/关”二元动作，而将运动控制解耦。
- **感知与规划流水线**：集成 **Grounding DINO** 实现开放词汇的物体检测与3D定位；采用**动态A*算法**进行全局路径规划，并将人类建模为圆柱形障碍物以确保安全距离。
- **人机交互控制器**：利用 **MediaPipe** 实时估计人体姿态和朝向，通过结合位置基和图像基的**混合视觉伺服控制**，使无人机能稳定地飞行到用户正前方的舒适交接位置。

**3. 主要实验结果**
在约6m×6m的室内环境中进行了10次端到端实验，系统成功完成了从起飞、场景勘察、物体定位与抓取，到安全导航至人类并完成交接的全流程。
- **导航精度**：实际飞行轨迹与规划路径的最大欧氏误差为0.164米，平均误差为0.070米，均方根误差为0.084米，且始终与人类保持约1米的安全距离。
- **VLA验证**：在Unity仿真中进行的10次实验验证了VLA模型能根据图像状态正确预测夹爪的“开/关”动作，证明了其决策逻辑的可行性。

**4. 研究意义和价值**
本研究首次提出了将VLA模型应用于空中操控任务的概念框架。其核心价值在于**在灵活性与安全性之间取得了平衡**：利用VLM的语义理解能力实现开放词汇的物体操控意图解析，同时通过解耦的、基于确定性控制律的视觉伺服和运动规划来保证飞行的安全性与可靠性。这为未来实现**全自由度端到端空中操控VLA模型**奠定了重要的理论与实践基础，推动了具身空中智能向更复杂、动态的室内工业应用场景发展。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析：DroneVLA

### **一、 核心问题**
论文旨在解决一个关键挑战：**如何让非专业用户能够通过自然、直观的方式（如自然语言）来指挥无人机执行复杂的空中抓取与递送任务**。具体来说，它聚焦于室内人机交互场景，需要解决以下子问题：
1.  **意图理解**：如何将用户的高级语言指令（如“拿起红色螺丝刀”）转化为机器可执行的任务。
2.  **开放词汇感知**：如何在无需针对特定物体重新训练的情况下，检测和定位场景中任意指定的物体。
3.  **安全可靠的操作**：如何在动态、近距离的人机交互环境中，确保无人机飞行稳定、抓取准确，并实现安全、自然的人手交接。
4.  **系统集成**：如何将先进的视觉-语言模型与资源受限的无人机硬件平台有效结合。

### **二、 核心创新点**
本文的核心创新在于**提出并初步验证了一个基于视觉-语言-动作模型的全新空中操控系统架构**，其创新性体现在以下几个方面：

1.  **首次提出VLA用于空中操控**：
    - 论文明确指出，这是**首次将Vision-Language-Action模型的概念应用于空中操控任务**。这代表了从被动观察向主动、语义理解式操控的范式转变。

2.  **“语义-控制”解耦的混合架构**：
    - **创新策略**：没有采用端到端的“黑箱”VLA直接输出飞行控制指令（存在安全风险），也没有采用完全基于预定义技能库的僵硬系统。
    - **具体方案**：将系统分为两层：
        - **高层语义推理（VLA模块）**：使用轻量级TinyVLA模型，**仅负责解析语言指令的意图，并输出简单的、离散的夹爪动作（开/合）**。这相当于一个“何时抓取”的决策器。
        - **底层运动控制（传统控制器）**：**导航、避障、视觉伺服和交接位姿生成**等复杂、连续的飞行控制任务，由基于MediaPipe（人体姿态估计）和Grounding DINO（物体检测）的**确定性、可验证的传统算法**完成。
    - **价值**：在利用VLA语义灵活性的同时，**确保了核心飞行控制的安全性和可靠性**，规避了模型“幻觉”直接导致危险动作的风险。

3.  **面向安全人机交互的集成化感知与控制管道**：
    - **开放词汇检测**：集成**Grounding DINO**，实现零样本（zero-shot）的物体检测与定位，使系统能处理未预先训练的物体类别。
    - **人体感知与建模**：利用**MediaPipe**实时估计人体姿态、朝向和手部位置，将人建模为带有安全边际的圆柱形障碍物。
    - **人本位的交接控制器**：基于人机交接文献，计算一个符合人体工程学的目标交接位姿（距离人前方0.6-0.8米，胸部高度），并采用**混合视觉伺服（PBVS + IBVS）** 实现精准、稳定的飞行对准。

4.  **系统化的验证方法**：
    - 在真实飞行中验证了**感知、定位、规划（基于A*的人类感知运动规划）和导航**的完整管道，展示了端到端任务的可行性。
    - 在Unity仿真中**单独验证了VLA模块的抓取决策逻辑**，为后续闭环控制奠定了基础。

### **三、 解决方案概述**
论文通过一个由四大子系统组成的集成架构来解决上述问题：

1.  **硬件平台**：定制四旋翼无人机，配备1自由度夹爪和Intel RealSense RGB-D相机。夹爪前伸以减轻下洗气流干扰。
2.  **VLA语义推理模块**：
    - **输入**：实时RGB图像流 + 用户自然语言指令。
    - **处理**：在**地面站**运行轻量级TinyVLA模型，进行视觉-语言特征融合。
    - **输出**：**二元夹爪动作指令（打开/关闭）**。当视觉判断接近目标物体时触发相应动作。
3.  **感知管道**：
    - **物体检测与定位**：`RGB图像 + 文本提示` → **Grounding DINO** → 2D边界框 → 结合深度图 → 3D世界坐标。
    - **人体感知**：`RGB图像` → **MediaPipe Pose** → 人体33个关键点3D坐标、身体朝向、手部位置。
4.  **人本位的交接控制器与规划器**：
    - **运动规划**：使用**动态A*算法**在占据栅格地图上进行全局路径规划，将人体作为动态障碍物并保持安全距离。
    - **交接控制**：根据人体朝向计算目标交接点，通过**混合视觉伺服**控制无人机飞抵并保持在该点。
    - **任务流程**：`起飞侦察` → `定位目标与人` → `规划并飞向目标` → `VLA触发抓取` → `规划并飞向人` → `视觉伺服保持交接位姿` → `完成交接`。

### **四、 实际价值与意义**
- **技术价值**：为**具身空中智能**提供了一个安全、可扩展的架构蓝图，证明了VLA与传统机器人控制相结合路径的可行性。
- **应用价值**：极大地降低了无人机操控门槛，使其能在**仓库物流（取放货）、智能家居（递送物品）、医疗辅助（传递工具）** 等需要与人类紧密协作的室内场景中发挥更大作用。
- **前瞻性**：论文将当前系统定位为“奠基性步骤”，其构建的完整数据管道为未来**收集数据、训练定制化的端到端5自由度控制VLA模型**铺平了道路，并瞄准了更复杂的工业室内操作任务。

**总结**：DroneVLA的核心创新是**首创性地为空中操控设计了一个“语义理解（VLA）与安全控制（传统算法）解耦”的混合系统**，它通过集成开放词汇感知、人体感知建模和人类感知规划，解决了使用自然语言安全、可靠地指挥无人机进行物体抓取与人手交接的关键问题。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文旨在解决非专业用户如何通过自然语言直观、安全地指挥无人机执行空中抓取与递送任务的核心问题。为此，作者提出了一个名为DroneVLA的集成系统框架，其核心创新在于将**轻量级视觉-语言-动作模型**用于语义意图理解，并与**基于Grounding DINO的开放词汇感知**、**考虑人类安全的A*路径规划**以及**基于MediaPipe的视觉伺服人机交接控制器**相结合。该方法将高层语义推理与底层确定性控制解耦，在保证安全性的同时实现了任务的灵活性。实验结果表明，该系统在真实飞行中能够成功完成端到端的物体定位、抓取和避障递送，验证了其感知与导航管线的鲁棒性，并为未来实现全闭环、高自由度的VLA空中操控奠定了概念与技术基础。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文创新点分析

这篇论文《DroneVLA: VLA based Aerial Manipulation》提出了一种基于视觉-语言-动作（VLA）模型的自主空中操控系统。相对于已有工作，其明确的创新点如下：

### 1. **首次提出并验证了VLA模型在空中操控任务中的应用概念**
   - **相比以往方法的改进/不同之处**：
     - 以往的研究主要将大型语言模型（LLMs）或视觉语言模型（VLMs）用于高级任务规划或离散技能选择（如AERMANI-VLM），或者使用端到端VLA模型进行无人机导航（如RaceVLA），但尚未有工作将VLA模型专门用于**空中物体抓取与操控**这一具体领域。
     - 本文提出的VLA模型架构（受TinyVLA启发）被设计用于解释自然语言指令并直接生成**抓取器的二进制动作**（开/合），首次将VLA的“感知-推理-动作”闭环应用于空中机械臂的控制回路中。
   - **解决的具体问题/带来的优势**：
     - 解决了非专家用户如何**直观、自然**地指挥空中机器人进行复杂操作（如“拾取红色螺丝刀”）的问题。用户无需学习专业控制指令或界面。
     - 为资源受限的嵌入式平台（如无人机）实现轻量级、可解释的多模态智能控制提供了概念验证和可行路径。

### 2. **采用“语义推理与底层控制解耦”的混合系统架构**
   - **相比以往方法的改进/不同之处**：
     - **与端到端VLA方法（如RaceVLA）对比**：RaceVLA等模型是“黑箱”，直接将原始图像映射到4D控制指令。本文系统则将VLA的职责**限定为高级语义意图理解和生成二进制抓取指令**，而无人机的**空间定位、导航、稳定和视觉伺服**则由独立的、基于经典算法的模块（如动态A*规划、MediaPipe驱动的控制器）处理。
     - **与纯VLM任务规划方法（如AERMANI-VLM）对比**：后者依赖结构化提示和预定义技能库，可能缺乏执行动态任务所需的灵活性和实时调整能力。本文系统在保留VLM语义灵活性的同时，通过紧密的**闭环视觉伺服**来处理抓取和交接过程中的连续微调。
   - **解决的具体问题/带来的优势**：
     - **显著提升了系统的安全性和可靠性**：将关键的运动控制交给可验证、确定性的经典控制算法，避免了端到端VLA模型可能因“幻觉”而产生危险控制指令的风险，这在涉及人机交互的安全关键场景中至关重要。
     - **实现了性能与安全的平衡**：既利用了VLA/VLM在开放词汇理解和意图解析方面的强大能力，又通过稳健的底层控制保证了无人机在复杂动态环境（如近地飞行、靠近物体和人）中的稳定性和安全性。

### 3. **集成开放词汇检测与以人为本的交接控制器，实现全流程自主人机交互**
   - **相比以往方法的改进/不同之处**：
     - **感知层面**：集成了**Grounding DINO**这一开放词汇目标检测器，使系统能够零样本检测和定位语言指令中描述的任意物体，无需针对新物体进行模型重新训练。这超越了传统需要预定义类别的检测系统。
     - **交互层面**：设计了一个由**MediaPipe姿态估计**驱动的人本控制器。它不仅定位人，还实时估计人体朝向、姿态，并据此计算出一个符合人机交互（HRI）文献的最佳交接位姿（距离、高度、朝向）。
     - **规划层面**：运动规划器（动态A*）将人类建模为带有安全裕度的圆柱形障碍物，确保整个任务路径（从家到物体，再到人）始终保持安全距离。
   - **解决的具体问题/带来的优势**：
     - **解决了通用性与实用性的矛盾**：开放词汇检测使系统能处理未曾见过的物体，极大地扩展了应用场景。以人为本的控制器确保了交接过程的**安全、自然和舒适**，提升了用户体验和系统接受度。
     - **实现了从“感知物体”到“安全送达给人”的端到端自主流程**，将物体检索、抓取、导航和人性化交接无缝衔接，形成了一个完整的解决方案。

### 4. **针对空中操控的硬件与系统集成设计考量**
   - **相比以往方法的改进/不同之处**：
     - 论文明确指出并设计了**抓取器在无人机上的安装位置**，使其远离机身中心以减轻**下洗气流**对抓取稳定性和目标物体的干扰。同时，讨论了抓取器距离与无人机重心之间影响飞行稳定性的**权衡**。
     - 采用了**分布式计算架构**：将计算密集的VLA模块和部分感知任务放在地面站运行，而将低延迟的控制回路保留在机载计算单元（OrangePi）上。这不同于试图将所有智能体嵌入机载资源的做法。
   - **解决的具体问题/带来的优势**：
     - **直接解决了空中抓取的一个关键物理挑战**——旋翼下洗流。通过机械设计优化，提高了抓取成功率和飞行稳定性。
     - **在有限机载资源下实现了复杂功能**：通过计算卸载，可以在无人机上使用更复杂、性能更好的模型（如VLA），而不受机载算力和功耗的严格限制，为系统功能升级留出空间。

### 总结
本文的核心创新在于**开创性地将VLA模型引入空中操控领域**，并设计了一套**安全、可靠、以人为本的混合智能系统架构**。它没有盲目追求完全的端到端学习，而是巧妙地结合了**数据驱动的语义理解（VLA）** 和**模型驱动的经典控制（视觉伺服、运动规划）** 的优势，在提升系统智能化和自然交互能力的同时，严格保障了人机共存环境下的操作安全性。这项工作为未来实现更自主、更智能的空中协作机器人奠定了重要的概念和技术基础。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 论文实验与评估效果分析

根据论文内容，该研究（DroneVLA）在实验评估中**主要实现了概念验证和系统集成测试**，但**未提供与基线方法的定量对比结果**。其实验效果、使用的“数据集”和评价指标如下：

### 一、 实验效果与实现目标
论文通过一系列真实世界飞行实验，成功演示了一个端到端的自主空中抓取与递送系统。核心效果包括：
1.  **完整的任务闭环**：系统能够理解高级自然语言指令（如“拿起红色螺丝刀”），在杂乱场景中定位目标物体，规划安全路径进行抓取，并最终通过视觉伺服安全地将物体递送给人类用户。
2.  **高成功率与安全性**：在 `N=10` 次随机物体布置的试验中，**所有实验均成功完成**。无人机在递送阶段能始终保持与人类约 **1米** 的安全距离，实现了安全、自然的交接。
3.  **精准的感知与定位**：集成的感知流水线（Grounding DINO + MediaPipe + RGB-D相机）能够实时、准确地识别、分类并定位场景中的任意物体和人类。
4.  **VLA抓取逻辑验证**：虽然VLA模块未接入真实飞行控制回路，但在Unity仿真中进行了严格验证。在10次仿真实验中，模型能根据视觉状态正确预测夹爪的 **“开/关”** 二元动作，证明了其视觉到动作映射逻辑的可行性。

### 二、 使用的“数据集”与评价指标
论文**没有使用公开的标准数据集**，其评估基于在受控实验室环境中采集的实时数据。

- **“数据集”来源**：在一个约 `6m x 6m` 的室内实验室中，使用布置了15-20个日常物体（杯子、工具、植物等）的桌子，以及一位人类参与者，构建了动态测试场景。所有传感器数据（RGB-D图像、Vicon动捕地面真值）通过ROS2记录。
- **主要评价指标**：
    1.  **任务成功率**：端到端任务（搜索、抓取、导航、递送）的完成比例（10/10）。
    2.  **轨迹跟踪误差**：衡量无人机实际飞行轨迹与规划路径的偏差。
        - **最大欧几里得误差**：0.164 m
        - **平均欧几里得误差**：0.070 m
        - **均方根误差 (RMSE)**：0.084 m
    3.  **安全性指标**：通过路径规划中的人类圆柱体障碍物模型和安全边际，确保无人机在递送时与人类保持预设的安全距离（约1米）。

### 三、 与基线方法的对比及性能结论
**论文未进行正式的、定量的基线方法对比**。原因在于本研究的主要贡献是**提出并集成一个新颖的VLA空中操控系统概念**，属于探索性、概念验证性质的工作。

然而，作者在讨论部分（第3.2节）从**方法论层面**与相关研究进行了定性对比，阐明了其技术定位和优势：

1.  **与端到端VLA方法（如RaceVLA）对比**：
    - **对比基线**：RaceVLA等模型将原始视觉输入直接映射到连续控制命令。
    - **DroneVLA的定位与结论**：DroneVLA采用 **“解耦”架构**。VLA仅负责高级语义理解（判断“何时”抓取），而具体的导航和稳定控制则由确定性的视觉伺服和运动规划器（“如何”执行）负责。这**避免了端到端“黑箱”模型可能因幻觉而产生危险控制指令的安全风险**，提高了系统的可解释性和安全性。

2.  **与基于技能库的VLM方法（如AERMANI-VLM）对比**：
    - **对比基线**：AERMANI-VLM使用结构化提示和预定义技能库进行高层推理。
    - **DroneVLA的定位与结论**：DroneVLA**在灵活性与可靠性之间取得平衡**。它利用VLMs（如Grounding DINO）的开放词汇检测能力获得语义灵活性，同时通过紧密的闭环视觉伺服来处理抓取所需的连续、动态微调，克服了纯离散技能执行可能存在的僵化问题。

### 总结
该论文的实验评估**核心在于系统集成与可行性验证**，而非追求在标准基准测试上的性能超越。它成功地证明了：
- 一个融合了**开放词汇感知、VLA语义推理、人类感知运动规划和视觉伺服**的完整空中操控系统是可行的。
- 所提出的**解耦架构**（语义VLA + 确定性控制器）在确保任务成功和安全交互方面是有效的。
- 为未来收集真实世界数据以训练**全自由度（5-DOF）端到端VLA模型**奠定了坚实的基础框架和数据流水线。

**局限性**：VLA模块尚未在真实飞行中进行闭环控制测试，其作用目前仅限于验证抓取决策逻辑。论文的定量结果主要集中在系统整体的定位和轨迹跟踪精度上。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2601.13809v2)
- [HTML 版本](https://arxiv.org/html/2601.13809v2)
