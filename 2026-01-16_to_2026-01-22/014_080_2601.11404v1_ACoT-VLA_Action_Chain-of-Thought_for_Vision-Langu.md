# ACoT-VLA: Action Chain-of-Thought for Vision-Language-Action Models

**相关性评分**: 8.0/10

**排名**: #14


---


## 基本信息

- **arXiv ID**: [2601.11404v1](https://arxiv.org/abs/2601.11404v1)
- **发布时间**: 2026-01-16T16:17:06Z
- **相关性评分**: 8.0/10
- **是否相关**: 是

## 作者

Linqing Zhong, Yi Liu, Yifei Wei, Ziyu Xiong, Maoqing Yao, Si Liu, Guanghui Ren

## 关键词

Vision-Language-Action Model, VLA for Robotics, fine tune

## 一句话总结

这篇论文提出了一种名为ACoT-VLA的新架构，通过动作链式思考范式，在动作空间中进行直接推理，以提升视觉-语言-动作模型在机器人操作任务中的性能。

## 摘要

Vision-Language-Action (VLA) models have emerged as essential generalist robot policies for diverse manipulation tasks, conventionally relying on directly translating multimodal inputs into actions via Vision-Language Model (VLM) embeddings. Recent advancements have introduced explicit intermediary reasoning, such as sub-task prediction (language) or goal image synthesis (vision), to guide action generation. However, these intermediate reasoning are often indirect and inherently limited in their capacity to convey the full, granular information required for precise action execution. Instead, we posit that the most effective form of reasoning is one that deliberates directly in the action space. We introduce Action Chain-of-Thought (ACoT), a paradigm where the reasoning process itself is formulated as a structured sequence of coarse action intents that guide the final policy. In this paper, we propose ACoT-VLA, a novel architecture that materializes the ACoT paradigm. Specifically, we introduce two complementary components: an Explicit Action Reasoner (EAR) and Implicit Action Reasoner (IAR). The former proposes coarse reference trajectories as explicit action-level reasoning steps, while the latter extracts latent action priors from internal representations of multimodal input, co-forming an ACoT that conditions the downstream action head to enable grounded policy learning. Extensive experiments in real-world and simulation environments demonstrate the superiority of our proposed method, which achieves 98.5%, 84.1%, and 47.4% on LIBERO, LIBERO-Plus and VLABench, respectively.

## 详细分析

## 论文摘要：ACoT-VLA: Action Chain-of-Thought for Vision-Language-Action Models

**1. 研究背景和动机**
当前，视觉-语言-动作（VLA）模型已成为机器人通用策略的主流范式，通常依赖预训练的视觉-语言模型（VLM）直接将多模态输入映射为动作。然而，现有方法（如语言子任务预测或视觉目标图像合成）的中间推理过程是间接的，难以传递精确动作执行所需的全部、细粒度信息。这导致了**语义-运动鸿沟**：高层、抽象的输入与低层、可执行的电机指令之间存在根本性脱节。为解决此问题，本文提出了一种范式转变：将推理过程直接置于**动作空间**中进行。

**2. 核心方法和技术创新**
本文提出了**动作思维链（Action Chain-of-Thought, ACoT）** 这一新范式，并构建了 **ACoT-VLA** 框架来实现它。其核心创新在于引入了两个互补的组件：
- **显式动作推理器（Explicit Action Reasoner, EAR）**：一个轻量级Transformer，根据多模态观察合成粗粒度的参考动作轨迹，提供**显式的、可执行的动作空间引导**。
- **隐式动作推理器（Implicit Action Reasoner, IAR）**：通过可学习查询与VLM内部表征进行交叉注意力建模，提取**隐式的动作先验**（如视觉中的交互意图、语言中的动作语义）。

这两个模块生成的显式和隐式引导信息，通过一个**动作引导预测（Action-Guided Prediction, AGP）头**进行融合，共同为下游的动作生成头（基于扩散模型）提供条件，从而实现更接地气的策略学习。

**3. 主要实验结果**
在广泛的仿真和真实世界实验中，ACoT-VLA均取得了最先进的性能：
- **LIBERO基准测试**：平均成功率高达 **98.5%**，尤其在需要长时程推理的LIBERO-Long任务上优势显著。
- **LIBERO-Plus基准测试**：在包含多种扰动（如相机视角、机器人初始状态、传感器噪声）的鲁棒性测试中，平均成功率达 **84.1%**，远超其他方法。
- **VLABench基准测试**：在意图得分（IS）和进度得分（PS）上分别达到 **63.5%** 和 **47.4%**，展现了强大的泛化能力。
- **真实世界部署**：在AgiBot G1和AgileX机器人平台上执行“擦污渍”、“倒水”、“开放集抓取”等任务，成功率显著优于基线模型（如 `π0.5`）。

**4. 研究意义和价值**
本研究首次将机器人策略的“思维”过程定义为**结构化的、显式的动作意图链**，而非抽象的语言或视觉子目标。这一根本性转变**直接弥合了语义理解与运动控制之间的鸿沟**，为策略学习提供了更丰富、更直接的信息通道。ACoT-VLA框架不仅显著提升了任务成功率和鲁棒性，也为开发更具可解释性、更接地气的通用机器人智能体开辟了新的研究方向。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析：ACoT-VLA

### **核心问题**
现有**视觉-语言-动作（VLA）模型**存在一个根本性缺陷：**语义-运动鸿沟**。模型通常在**视觉或语言空间**进行中间推理（如预测子任务或合成目标图像），但这些抽象、间接的表示无法为**精确、低级的动作执行**提供充分、细粒度的指导。这导致模型在将高层次语义理解转化为可执行的低层次运动指令时，信息传递效率低下且不精确。

### **核心创新点**
论文提出了一个全新的范式：**动作思维链**。

1.  **范式创新**：首次将机器人的“思考”过程定义为**在动作空间中直接进行结构化推理**，而非在抽象的语言或视觉空间。这相当于让模型“用动作的语言来思考”。
2.  **架构创新**：提出了 **ACoT-VLA 框架**，通过两个互补的组件来具体实现动作思维链：
    *   **显式动作推理器**：一个轻量级Transformer，根据多模态观察**合成粗粒度的参考动作轨迹**，提供**显式的、可执行的**动作空间指导。
    *   **隐式动作推理器**：通过可学习查询与VLM内部表征进行交叉注意力建模，**提取潜在的动作先验**（如视觉中的交互意图、语言中的动作语义），提供**隐式的行为启发**。
3.  **整合机制**：设计了一个**动作引导预测头**，通过双路交叉注意力机制，将显式和隐式两种动作指导协同融合，共同引导最终动作序列的生成。

### **解决方案**
1.  **思路转变**：将中间推理的“输出”从语言/图像**转变为动作序列本身**。这为下游动作预测头提供了**同质化、运动学上连贯**的直接指导。
2.  **双路指导生成**：
    *   **显式路径**：`EAR` 接收带噪声的动作序列，通过自注意力（建模时序依赖）和与VLM的交叉注意力（注入多模态上下文），去噪生成一个参考轨迹。
    *   **隐式路径**：`IAR` 对VLM的键值缓存进行下采样和压缩，利用可学习查询提取其中蕴含的、与动作相关的潜在分布信息。
3.  **引导式动作预测**：最终的动作预测头将待预测的噪声动作作为查询，分别与 `EAR` 生成的显式轨迹嵌入和 `IAR` 提取的隐式特征进行交叉注意力，融合两种指导信息，再通过自注意力融合块统一，最终去噪得到精确的动作序列。
4.  **训练策略**：采用**流匹配**目标函数，并引入**教师强制稳定**技巧（训练时使用真实轨迹生成显式指导，推理时切换为自条件模式），确保训练稳定高效。

### **实际价值与效果**
*   **性能卓越**：在多个主流仿真基准测试（LIBERO, LIBERO-Plus, VLABench）上均达到**最先进水平**，平均成功率显著提升（如LIBERO达到98.5%）。
*   **泛化与鲁棒性强**：在包含多种扰动（视角、光照、噪声等）的LIBERO-Plus基准上表现尤为突出，证明了动作空间指导能有效提升模型在分布外场景下的**鲁棒性**。
*   **解决长时程任务**：在需要严格误差控制的长时程任务上优势明显，因为动作级推理能提供更结构化、细粒度的指导，**减少误差累积**。
*   **现实世界有效**：在真实机器人（AgiBot G1, AgileX）上部署，在“擦拭污渍”、“倒水”、“开放集抓取”等任务中成功率和适应性均优于基线模型。
*   **计算效率可接受**：虽然引入了额外模块，但增加的参数量和推理延迟相对较小（从91ms增至112ms），与带来的性能提升相比是值得的。

**总结**：ACoT-VLA 通过开创性的“动作思维链”范式，**直接弥合了感知与行动之间的鸿沟**。它让机器人策略的推理过程**运动学化、接地气**，从而实现了更精确、更鲁棒、泛化能力更强的通用机器人策略学习。这项工作为下一代具身智能体的研究开辟了新的方向。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文针对现有视觉-语言-动作（VLA）模型在将高层语义/视觉输入映射到精确、低层动作执行时存在的“语义-运动学鸿沟”这一核心问题，提出了**动作思维链**这一新范式。其核心方法是设计了一个名为ACoT-VLA的框架，该框架通过**显式动作推理器**生成粗粒度参考动作轨迹，以及**隐式动作推理器**从多模态表征中提取潜在动作先验，共同构成直接作用于动作空间的“思维链”，为最终的动作预测头提供同质、精细的指导。实验结果表明，该方法在多个仿真和真实世界机器人操作基准测试中均取得了最先进的性能，显著提升了策略的成功率、长时程任务的鲁棒性以及对分布外扰动的泛化能力，验证了在动作空间进行直接推理的有效性。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文创新点分析

这篇论文《ACoT-VLA: Action Chain-of-Thought for Vision-Language-Action Models》的核心创新在于提出了一种全新的机器人策略推理范式，并构建了相应的架构来实现它。其创新点具体如下：

### 1. **概念创新：提出“动作思维链”范式**
   - **相比以往方法的改进/不同之处**：
     - **以往方法**：现有的VLA模型通常采用两种中间推理形式：
       1. **语言思维链**：使用大语言模型生成子任务描述（如“先靠近，再抓取”）作为中间步骤。
       2. **视觉思维链**：利用世界模型合成未来的目标图像作为视觉引导。
     - **本文方法**：首创性地提出**动作思维链**。该范式将推理过程本身定义为**在动作空间中进行**，即生成一系列**粗粒度的动作意图序列**作为中间推理步骤。
   - **解决的具体问题/带来的优势**：
     - **解决“语义-运动学鸿沟”**：语言和视觉是丰富但抽象的语义表示，而机器人执行需要精确、低级的运动指令。以往基于语言或视觉的中间推理提供的引导是**间接且次优的**。ACoT直接在动作空间推理，提供了**运动学上连贯、同质的引导**，从根本上弥合了高层意图与底层控制之间的差距。
     - **提升长时程任务鲁棒性**：论文在LIBERO-Long任务上的显著提升（如对比`π_0.5`）表明，直接的动作级引导能提供更精细、结构化的信息，有效减少了长序列任务中的误差累积。

### 2. **架构创新：设计显式与隐式动作推理器**
   - **相比以往方法的改进/不同之处**：
     - **以往方法**：模型通常依赖单一的、从VLM嵌入到动作的直接映射，或仅利用一种形式的中间表示（纯语言或纯视觉）。
     - **本文方法**：设计了两个互补的组件来具体实现ACoT范式：
       1. **显式动作推理器**：一个轻量级Transformer，根据多模态观察**合成粗粒度的参考动作轨迹**。这提供了**明确、可执行的动作空间引导**。
       2. **隐式动作推理器**：通过可学习查询与VLM内部表征进行交叉注意力，**提取潜在的动作先验**。这捕获了隐藏在语言（如“伸手”）和视觉上下文中的**行为分布和交互意图**。
   - **解决的具体问题/带来的优势**：
     - **提供全面且互补的引导**：EAR提供了**直接的、基于运动模式的引导**，而IAR提供了**基于语义和上下文的隐式行为倾向**。两者结合，为策略学习提供了比单一形式更丰富、更接地气的动作相关信息。
     - **高效利用VLM知识**：IAR通过下采样和交叉注意力，**有选择地**从VLM的键值缓存中提取与动作相关的信息，避免了原始高维特征中的噪声，提高了信息提取的效率和针对性。

### 3. **训练与推理机制创新：动作引导预测与教师强制稳定**
   - **相比以往方法的改进/不同之处**：
     - **动作引导预测头**：最终的策略头（AGP）不是直接处理噪声动作嵌入，而是将其作为**查询**，通过**双交叉注意力**机制同时与EAR的显式引导和IAR的隐式引导进行交互，融合后再进行去噪预测。
     - **教师强制稳定训练**：在训练时，为了避免EAR初期不稳定的输出干扰策略头的学习，**使用真实动作轨迹来计算显式引导**。在推理时则切换为**完全自条件模式**，由EAR自主生成参考动作。
   - **解决的具体问题/带来的优势**：
     - **实现信息深度融合**：双注意力机制确保最终的动作预测能**协同利用**显式的运动轨迹和隐式的行为语义，做出更准确的决策。
     - **保证训练稳定性**：教师强制技巧**解耦了**EAR模块和策略头模块的训练难度，使得整个框架能够稳定、高效地收敛，避免了早期不良预测导致的训练崩溃。

### 4. **实证性能的显著优势**
   - **相比以往方法的改进/不同之处**：
     - 在多个主流仿真基准（LIBERO, LIBERO-Plus, VLABench）和真实世界实验中，ACoT-VLA均取得了**最先进的性能**。
     - 特别是在**鲁棒性测试**（LIBERO-Plus）中，在相机视角变化、机器人初始状态扰动、传感器噪声等挑战性条件下，表现远超基于语言或视觉引导的方法。
   - **解决的具体问题/带来的优势**：
     - **验证了范式的有效性**：卓越的实证结果强有力地证明了“在动作空间中思考”这一范式的优越性。它不仅能提高标准任务的成功率，更能显著增强策略在**分布外泛化和面对现实扰动时的鲁棒性**。
     - **提供了可复现的强基线**：论文提供了详细的实现、训练配置和消融实验，为后续在动作空间进行推理的研究树立了一个坚实的标杆。

**总结**：本文最根本的创新在于**思维范式的转变**——从在抽象的“感知空间”（语言/视觉）中思考，转向在具体的“执行空间”（动作）中思考。并通过精巧的**架构设计**（EAR+IAR）和**训练策略**实现了这一范式，最终在性能上取得了突破性进展，为解决机器人学中长期存在的“感知-动作异质性”问题提供了新的、有效的思路。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 论文实验与评估效果总结

该论文通过广泛的仿真和真实世界实验，全面验证了所提出的 **ACoT-VLA** 框架的有效性、泛化能力和实际应用价值。

### 一、 使用的数据集与评价指标

#### 1. 仿真基准数据集
- **LIBERO**： 广泛使用的通用机器人策略评估基准，包含4个子任务套件（Spatial, Object, Goal, Long），共40个任务，每个任务提供50条演示。用于评估空间感知、物体操作、目标完成和长时程推理能力。
    - **评价指标**： **平均成功率 (Success Rate, SR)**。每个任务进行50次独立试验，计算成功比例。
- **LIBERO-Plus**： 基于LIBERO构建的鲁棒性导向基准，引入了7个维度的受控分布偏移（如相机视角、机器人初始状态、语言指令变化、光照、背景、传感器噪声、物体布局），共10,030个评估片段。
    - **评价指标**： **平均成功率 (SR)**。在包含多种扰动的整个评估集上计算。
- **VLABench**： 大规模评估套件，基于ManiSkill3构建，包含5个评估轨道（In-distribution, Category, Commonsense, Instruction, Texture），评估标准性能、类别泛化、常识推理、指令理解和外观变化鲁棒性。
    - **评价指标**： **意图得分 (Intention Score, IS)** 和 **进度得分 (Progress Score, PS)**。

#### 2. 真实世界实验
- **自定义数据集**： 在AgiBot G1和AgileX机器人平台上收集了三个任务的数据：
    1.  **Wipe Stain**： 接触式精细操作。
    2.  **Pour Water**： 长时程、多阶段的物体操控。
    3.  **Open-set Pick**： 开放集指令跟随，评估跨平台适应性。
- **评价指标**： **平均成功率 (SR)**。在预定义的、可重复的初始条件下进行多次试验，由经验丰富的操作员判定成功与否。

### 二、 对比的基线方法

论文与当前最先进的多种VLA模型进行了全面对比，根据其使用的中间推理引导类型分为三类：

1.  **视觉引导 (Visual Guidance) 方法**：
    - `CoT-VLA`, `WorldVLA`, `DreamVLA`, `UniVLA`, `F1`, `GE-Act` 等。这些方法通过预测子目标图像或利用世界模型进行视觉推理来引导动作生成。

2.  **语言引导 (Linguistic Guidance) 方法**：
    - `TraceVLA`, `OpenVLA`, `UniAct`, `SpatialVLA`, `ThinkAct`, `π0-FAST`, `FPC-VLA`, `SmolVLA`, `GR00T-N1`, `π0`, `DD-VLA`, `MemoryVLA`, `π0.5`, `OpenVLA-OFT` 等。这些方法利用大语言模型生成子任务或动作描述等语言形式的中间推理。

3.  **无显式推理或传统方法**：
    - `Diffusion Policy` (基于扩散模型的策略)，`Octo` (开源通用策略)。作为性能基准。

**注**： 论文选择 `π0.5` 作为主要的直接基线，因为ACoT-VLA是在其架构基础上构建的。

### 三、 关键性能提升与结论

#### 1. 仿真实验结果（核心结论）

| 基准测试 | ACoT-VLA 成功率 | 最佳基线方法及成功率 | **关键性能提升** | 结论与分析 |
| :--- | :--- | :--- | :--- | :--- |
| **LIBERO** (平均) | **98.5%** | `OpenVLA-OFT` (97.1%) | **+1.4%** (绝对提升) | **在标准基准上达到新的SOTA**。在四个子套件上均排名第一，尤其在要求严格错误控制的 **LIBERO-Long** 套件上提升显著（96.0% vs 基线92.4%），证明了**动作级推理能有效缓解长时程任务中的误差累积**。 |
| **LIBERO-Plus** (平均) | **84.1%** | `OpenVLA-OFT+` (79.6%) | **+4.5%** (绝对提升) | **在鲁棒性测试中表现卓越**。在7种扰动维度上综合表现最佳，特别是在**相机视角偏移**(+11.6%)、**机器人初始状态扰动**(+16.3%)和**传感器噪声**(+12.5%)等挑战性扰动下，优势明显。证明了**动作空间引导能提供更直接、更鲁棒的泛化信号**，减少对特定视觉或语言表示的依赖。 |
| **VLABench** (平均IS/PS) | **63.5% / 47.4%** | `π0.5` (60.2% / 43.1%) | **+3.3% / +4.3%** (绝对提升) | **在多样化任务和分布偏移下表现更优**。在**未见纹理(Unseen-texture)** 轨道上提升最大（IS: +12.6%, PS: +7.2%），进一步验证了其对视觉外观变化的强鲁棒性。 |

#### 2. 真实世界实验结果
- 在三个真实机器人操作任务上，ACoT-VLA的平均成功率为 **66.7%**，显著优于 `π0.5` (61.0%) 和 `π0` (33.8%)。
- 在 **Open-set Pick** 任务中，该方法在 **AgiBot G1** 和 **AgileX** 两种不同构型的机器人平台上均表现良好，证明了其**跨平台适应性**。

#### 3. 消融实验结论
- **模块有效性**： 在LIBERO上，单独添加**显式动作推理器(EAR)** 将平均成功率从96.9%提升至98.3%；单独添加**隐式动作推理器(IAR)** 提升至98.1%；两者结合达到最佳的98.5%。证明了两种引导方式的**互补性**。
- **技术选择**： 在IAR中，对VLM的键值缓存进行**降采样**后交互的策略效果最好，表明原始VLM特征中存在对动作预测的噪声信息，需要设计合适的对齐机制。
- **效率权衡**： 增加EAR和IAR模块仅带来约23%的推理延迟增长（从91ms到112ms），但换来了显著的性能提升，被认为是**有利的权衡**。

### 总结
论文通过在三大量化仿真基准和真实机器人实验上的系统评估，有力地证明了 **ACoT（动作思维链）范式** 的优越性。其核心结论是：**将中间推理过程从抽象的语言/视觉空间转移到具体的动作空间，能为策略学习提供更直接、更丰富、更鲁棒的引导信息，从而在任务成功率、长时程鲁棒性以及对各种分布偏移的泛化能力上，全面超越现有的基于语言或视觉CoT的VLA模型。**


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2601.11404v1)
- [HTML 版本](https://arxiv.org/html/2601.11404v1)
