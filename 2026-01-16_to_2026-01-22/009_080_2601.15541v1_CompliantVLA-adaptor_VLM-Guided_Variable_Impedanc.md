# CompliantVLA-adaptor: VLM-Guided Variable Impedance Action for Safe Contact-Rich Manipulation

**相关性评分**: 8.0/10

**排名**: #9


---


## 基本信息

- **arXiv ID**: [2601.15541v1](https://arxiv.org/abs/2601.15541v1)
- **发布时间**: 2026-01-21T23:52:40Z
- **相关性评分**: 8.0/10
- **是否相关**: 是

## 作者

Heng Zhang, Wei-Hsing Huang, Qiyi Tong, Gokhan Solak, Puze Liu, Sheng Liu, Jan Peters, Arash Ajoudani

## 关键词

Vision-Language-Action Model, VLA for Robotics, fine tune, safe reinforcement learning

## 一句话总结

该论文提出了一种增强VLA模型的适配器，通过VLM引导的可变阻抗控制来提升接触密集型机器人操作任务的安全性和有效性。

## 摘要

We propose a CompliantVLA-adaptor that augments the state-of-the-art Vision-Language-Action (VLA) models with vision-language model (VLM)-informed context-aware variable impedance control (VIC) to improve the safety and effectiveness of contact-rich robotic manipulation tasks. Existing VLA systems (e.g., RDT, Pi0, OpenVLA-oft) typically output position, but lack force-aware adaptation, leading to unsafe or failed interactions in physical tasks involving contact, compliance, or uncertainty. In the proposed CompliantVLA-adaptor, a VLM interprets task context from images and natural language to adapt the stiffness and damping parameters of a VIC controller. These parameters are further regulated using real-time force/torque feedback to ensure interaction forces remain within safe thresholds. We demonstrate that our method outperforms the VLA baselines on a suite of complex contact-rich tasks, both in simulation and on real hardware, with improved success rates and reduced force violations. The overall success rate across all tasks increases from 9.86\% to 17.29\%, presenting a promising path towards safe contact-rich manipulation using VLAs. We release our code, prompts, and force-torque-impedance-scenario context datasets at https://sites.google.com/view/compliantvla.

## 详细分析

## 论文摘要：CompliantVLA-adaptor: VLM-Guided Variable Impedance Action for Safe Contact-Rich Manipulation

### 1. 研究背景和动机
当前，视觉-语言-动作模型在机器人操作任务中展现出强大的语义理解和泛化能力。然而，这些模型通常仅输出位置或轨迹指令，缺乏对物理交互力的感知与适应能力。在执行涉及接触、顺应性或环境不确定性的任务时，这种“刚性”控制模式极易导致交互力过大，引发任务失败或安全问题，限制了VLA模型在真实接触密集型任务中的安全部署。

### 2. 核心方法和技术创新
本文提出了 **CompliantVLA-adaptor**，一个即插即用的适配器模块，旨在为现有VLA模型赋予顺应性控制能力。其核心创新在于：
- **VLM引导的变阻抗控制**：利用视觉语言模型分析图像、语言指令和实时力/力矩反馈，生成**上下文感知的刚度与阻尼参数**，将高层语义理解转化为底层控制参数。
- **混合控制架构**：构建了一个三层时序架构，无缝集成VLA的动作生成、VLM的阻抗参数推理（~1 Hz）以及基于力反馈实时调节的变阻抗控制器（1000 Hz）。
- **双模态接触相位识别**：结合VLM的视觉语义推理与力传感器反馈，鲁棒地识别任务执行阶段，并据此采用分层的阻抗调节策略。

### 3. 主要实验结果
在仿真和真实机器人实验中，该方法在8个接触密集型任务上进行了验证：
- **成功率提升**：在30N的接触力安全阈值约束下，**整体任务平均成功率从9.86%提升至17.29%**。在涉及机械约束的任务上提升尤为显著。
- **安全性改善**：相较于基线VLA模型常因力超限导致“灾难性失败”，本方法实现了“优雅降级”，失败多源于轻微错位而非不安全力。
- **真实世界验证**：在实物推箱任务中，适配器有效调节了刚度并控制了接触力，证明了其作为安全层的潜力，尽管当前VLA模型的零样本泛化能力限制了更多任务的完成。

### 4. 研究意义和价值
本工作为VLA模型安全应用于物理交互任务提供了一条切实可行的路径。其价值在于：
- **桥梁作用**：弥合了VLA模型的高层语义推理能力与实现安全物理交互所需的底层顺应性控制之间的鸿沟。
- **实用性与泛化性**：以轻量级、模块化的适配器形式，无需重新训练VLA模型，即可为其增加关键的安全层，促进了现有模型的实用化部署。
- **方向启示**：展示了利用大模型（VLM）的上下文理解能力来实时指导传统控制参数（阻抗）的新范式，为构建更安全、更智能的机器人系统提供了新思路。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析

### **一、 论文旨在解决的核心问题**
当前最先进的**视觉-语言-动作模型**在涉及物理接触的复杂操作任务中存在**安全性缺陷**。具体表现为：
- **缺乏力感知与顺应性控制**：现有VLA模型（如RDT、Pi0、OpenVLA-oft）通常输出**位置或轨迹指令**，将机器人视为刚性位置跟踪系统。
- **导致不安全交互**：在执行插入、关门、推压等**接触密集型任务**时，模型无法根据接触力动态调整行为，容易产生过大的交互力，可能导致任务失败、物体损坏或机器人自身受损。
- **语义理解与物理执行脱节**：VLA模型虽具备高层次的任务语义理解能力，但无法将这种理解转化为执行层面所需的**物理顺应性**。

### **二、 核心创新点**
论文提出了 **“CompliantVLA-adaptor”** ，这是一个**即插即用**的适配器模块，其创新性体现在**方法论融合**上：

1. **VLM引导的、上下文感知的变阻抗控制**：
    - **创新融合**：首次将**视觉语言模型**的语义推理能力，与经典的**变阻抗控制**的物理顺应性相结合。
    - **核心机制**：利用VLM（如GPT-4o-mini）分析**视觉观察**、**语言指令**和**实时力反馈**，动态生成适合当前任务阶段和场景的阻抗参数（刚度 `K` 和阻尼 `D`）。

2. **混合架构与分层安全系统**：
    - **三层控制时序**：
        - **VLM阻抗生成层** (~1 Hz)：进行语义推理，生成上下文感知的阻抗参数。
        - **VLA动作生成层** (~3 Hz)：输出期望的末端执行器位移。
        - **底层VIC控制器** (1000 Hz)：以自适应阻抗跟踪期望位姿，确保安全接触。
    - **双重安全调节**：
        - **前馈调节**：VLM根据识别的任务阶段（自由运动、接近、接触、撤回）生成基础阻抗参数。
        - **反馈调节**：通过实时力/力矩传感器反馈，引入缩放因子 `α_force`，在接触力接近安全阈值时主动降低刚度。

3. **零样本泛化与无需重新训练**：
    - 该适配器**无需对基础VLA模型进行任何微调或重新训练**，保留了VLA模型原有的强大泛化能力。
    - 利用**预训练VLM的常识**来理解任务场景（如“物体是否易碎”），实现对新任务和对象的**零样本**阻抗适配。

### **三、 解决方案的运作流程**
1. **输入与感知**：系统接收RGB图像（全局和腕部视角）、自然语言任务指令以及来自腕部力传感器的实时`力/力矩`数据。
2. **接触阶段识别**：VLM综合视觉和力反馈，判断当前处于 **“自由运动、接近、接触、撤回”** 中的哪个阶段。
3. **阻抗参数生成**：VLM根据阶段识别结果、任务语义和当前力反馈，生成各向异性的刚度矩阵 `K` 和阻尼矩阵 `D`。例如，在“接触”阶段会建议较低的刚度以提高顺应性。
4. **安全执行**：生成的阻抗参数输入到变阻抗控制器中，该控制器接收VLA模型计算出的期望位移，最终产生安全的关节力矩指令，驱动机器人执行任务。整个过程确保接触力不超过预设的安全阈值（如30N）。

### **四、 实际价值与效果**
- **提升安全性**：将失败模式从 **“灾难性的力超限和物体翻倒”** 转变为 **“轻微的错位或滑移”** ，实现了“优雅降级”。
- **提高任务成功率**：在模拟的8个接触密集型任务中，将**平均成功率从9.86%提升至17.29%**，在涉及机械约束（如抽屉、旋钮）的任务上提升尤为显著。
- **提供轻量级安全层**：为现有VLA模型提供了一个可复用的、模块化的安全增强方案，推动了VLA在真实物理世界中更安全地部署。

**总结**：本文的核心创新在于**创造性地使用VLM作为“阻抗教练”**，桥接了VLA的高层语义智能与低层物理交互安全之间的鸿沟，通过**上下文感知的变阻抗控制**，使机器人具备了类似人类的“手感”，从而安全、有效地完成复杂的接触密集型操作任务。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文旨在解决当前视觉-语言-动作（VLA）模型在执行接触丰富的机器人操作任务时，因缺乏力感知和顺应性控制而导致的**安全性差和任务失败率高**的核心问题。为此，论文提出了一个名为 **CompliantVLA-adaptor** 的即插即用适配器框架，其核心方法是利用**视觉语言模型（VLM）** 来解析任务场景（图像和语言指令），生成上下文感知的**可变阻抗控制（VIC）** 参数（刚度和阻尼），并结合实时力/力矩反馈对这些参数进行动态调节，从而在VLA生成的高层动作之上增加一层安全的顺应性控制层。实验结果表明，该方法在模拟和真实硬件的一系列复杂接触任务中，相比基线VLA模型，显著**提高了任务成功率（平均从9.86%提升至17.29%）并大幅减少了力超限违规**，将灾难性失败转变为温和的退化，为实现安全的VLA操控提供了一条有效路径。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文创新点分析

这篇论文提出的 **CompliantVLA-adaptor** 在多个层面实现了明确的创新，旨在解决现有视觉-语言-动作（VLA）模型在接触密集型操作任务中的核心缺陷。以下是其核心创新点及其与以往方法的对比和优势：

### 1. **首创VLM引导的、上下文感知的变阻抗控制适配器**
   - **改进/不同之处**：
     - **以往方法**：现有的VLA模型（如RDT, Pi0, OpenVLA）通常仅输出位置或轨迹指令，缺乏对交互力的感知和适应能力。同时，传统的变阻抗控制（VIC）方法需要手动调参、任务特定的调度或大量专家演示，无法根据语义上下文自动调整。
     - **本文方法**：提出一个“即插即用”的适配器模块，**利用视觉语言模型（VLM）** 来解析图像和自然语言指令，生成与任务上下文（如物体脆弱性、任务阶段）相适应的刚度和阻尼参数。
   - **解决的问题/优势**：
     - **解决了** VLA模型在物理交互中“语义理解”与“力感知控制”之间的脱节问题。
     - **带来了** **零样本泛化能力**：无需为每个新任务进行专门的VIC训练或调参，即可根据高级语义理解自动生成合适的阻抗参数，使机器人能安全处理未见过的接触场景。

### 2. **融合多模态信息的混合接触阶段识别与阻抗生成**
   - **改进/不同之处**：
     - **以往方法**：接触阶段识别要么依赖纯视觉（易受遮挡干扰），要么仅依赖力传感器（缺乏语义信息）。VIC参数生成方法要么是预定义的，要么依赖语言模型但未在复杂接触任务中验证。
     - **本文方法**：设计了一个**混合系统**：
       1. **VLM进行语义阶段识别**：结合视觉、语言指令和力反馈，将任务执行划分为“自由运动、接近、接触、撤回”四个阶段。
       2. **各向异性阻抗参数生成**：VLM根据当前阶段、运动方向和力测量值，生成**各向异性**的阻抗参数（例如，沿运动方向刚度低以利插入，垂直方向刚度高以保持对齐）。
   - **解决的问题/优势**：
     - **解决了** 单一传感器模态在复杂接触场景中识别不鲁棒、以及阻抗参数生成“一刀切”的问题。
     - **带来了** **更精细、更符合物理直觉的合规行为**。机器人能根据任务的实际物理约束动态调整不同方向的柔顺性，显著提升了在插入、关门等需要对齐和力控的任务中的成功率和安全性。

### 3. **实时力反馈与VLM语义调参相结合的双层安全机制**
   - **改进/不同之处**：
     - **以往方法**：一些工作考虑了力/力矩预测，但**没有形成闭环的力反馈控制**。学习型VIC方法可能依赖力反馈，但缺乏利用语义信息进行高层调节的能力。
     - **本文方法**：提出了一个**双层调节策略**：
       1. **VLM语义层**：基于上下文生成基础阻抗参数 `K_VLM, D_VLM`。
       2. **实时力反馈层**：引入一个力缩放因子 `α_force`，当实测力超过安全阈值时，动态降低刚度 (`K_final = K_VLM * α_force`)，阻尼随之调整以保证临界阻尼。
   - **解决的问题/优势**：
     - **解决了** VLM可能因知识局限或视觉误判而生成不安全参数的风险，以及单纯力反馈反应可能过于保守或振荡的问题。
     - **带来了** **兼具前瞻性（语义）和反应性（力觉）的安全保障**。即使VLM判断需要高刚度进行精密定位，一旦实际接触力过大，系统会立即变得柔顺，防止损坏物体或机器人，实现了“优雅降级”而非“灾难性失败”。

### 4. **模块化、即插即用的系统架构设计**
   - **改进/不同之处**：
     - **以往方法**：提升VLA的力感知能力通常需要重新设计或从头训练整个模型，成本高昂。VIC与高层策略的集成往往是紧耦合的。
     - **本文方法**：CompliantVLA-adaptor被设计为一个**独立的、模块化的适配层**，可以接入任何现有的、输出位置指令的VLA模型（论文中验证了Pi0, RDT, OpenVLA-oft），将其“原始动作”转换为合规动作。
   - **解决的问题/优势**：
     - **解决了** 为获得力控能力而需废弃或大幅修改现有高性能VLA模型的问题。
     - **带来了** **部署的便捷性和可扩展性**。为现有VLA系统提供了一个轻量级的“安全外挂”，在不牺牲其强大泛化能力的前提下，快速赋予其安全物理交互的能力，是迈向实际部署的实用一步。

### 总结
本文的核心创新在于**创造性地将大模型（VLM）的语义推理能力与传统机器人控制（VIC）的物理安全性相结合**，通过一个精巧的适配器架构，弥合了高层智能与底层力控之间的鸿沟。其创新不是单一算法的突破，而是一个**系统级的解决方案**，针对“让具备强大认知能力的VLA模型安全地接触物理世界”这一关键难题，提供了有效且可实施的路径。实验结果中，在考虑力阈值后，整体任务成功率从 **9.86% 提升至 17.29%**，并且失败模式从“力超限导致的任务终止”转变为“轻微的错位或滑动”，充分验证了其在提升安全性方面的根本性优势。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 实验与评估效果分析

### 1. 实验设置与数据集
- **仿真实验**：使用了来自 **LIBERO** 和 **ManiSkill** 基准测试的 **8个代表性接触密集型任务**（如精密插入、形状分类、抽屉开关、受限环境物体放置等）。
- **真实世界实验**：在 **Franka Emika Panda 7-DoF 机械臂** 上部署，使用双摄像头（全局+腕部）进行视觉感知，执行了6个真实任务（如推箱子、抓取放置、关抽屉等）。
- **评价指标**：
    - **主要指标**：在 **接触力阈值（30N）约束下** 的 **任务成功率**。
    - **安全指标**：**接触力违规次数**（超过30N阈值即视为违规，连续3次违规则任务终止）。
    - **辅助分析**：阻抗参数（刚度、阻尼）的适应性调整、失败模式分析。

### 2. 对比的基线方法
论文与三种先进的 **视觉-语言-动作（VLA）基础模型** 进行了对比，这些模型均采用位置/轨迹控制，缺乏力感知：
- **Pi0**：基于流匹配（flow matching）的动作生成模型。
- **RDT-1B**：最大的基于扩散的机器人操作基础模型。
- **OpenVLA-oft**：OpenVLA的优化微调变体。

### 3. 关键性能提升与结论

#### 仿真实验结果（核心定量结果）
- **整体成功率提升**：在8个接触密集型任务上，**平均成功率从基线模型的 9.86% 提升至 17.29%**，相对提升显著。
- **任务层面提升**：
    - 在 **7/8 的任务** 中，CompliantVLA-adaptor 均取得了比对应基线模型 **更高或相当的成功率**。
    - 对于涉及 **机械约束** 的任务（如操作抽屉、旋钮），提升最为显著，因为这些场景特别受益于自适应柔顺控制。
    - 基线模型在考虑力阈值后表现极不稳定，部分任务成功率为 **0%**；而适配器显著减少了因力过大导致的任务失败。
- **失败模式转变**：
    - **基线模型**：失败多为 **灾难性的**，表现为接触力阈值违规、物体被撞倒。
    - **CompliantVLA-adaptor**：失败表现为 **优雅降级**，主要是轻微的未对准或滑动，而非不安全的过大接触力。这证明了其 **根本性地提升了交互安全性**。

#### 真实世界实验结果
- **成功案例**：在“持续向前推红盒子”任务中成功演示，并展示了适配器如何根据接触力实时调节刚度参数，将接触力维持在安全范围内。
- **主要挑战与结论**：
    - 由于 **现实差距** 和当前VLA模型 **零样本泛化能力不足**，大多数真实任务（如精确抓取放置）未能成功完成。
    - 然而，适配器在已执行的任务中 ** consistently 减少了不安全接触力**，证明了其作为 **安全模块的潜力**。
    - 论文指出，未来需要针对真实世界对VLA模型进行微调，尤其是力敏感和精密操作任务。

### 4. 总结
论文通过系统的仿真与初步的真实实验证明：
1.  **有效性**：CompliantVLA-adaptor 能有效利用VLM的语义理解和实时力反馈，生成上下文感知的阻抗参数，显著提升VLA模型在接触密集型任务中的 **成功率和安全性**。
2.  **通用性**：该适配器作为一个 **即插即用模块**，能兼容多种不同的SOTA VLA模型（Pi0, RDT-1B, OpenVLA-oft），并带来一致性的性能提升。
3.  **价值**：**弥合了高层语义理解与底层柔顺控制之间的鸿沟**，为将强大的VLA模型安全部署到需要物理交互的真实场景中，提供了一条切实可行的技术路径。

**局限性**：当前性能的绝对成功率（17.29%）仍较低，这反映了接触密集型任务本身的高难度，以及完全依赖VLM进行高频阻抗参数生成的延迟与次优性问题。这指明了未来需要与轻量化、机器人专用模型结合的方向。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2601.15541v1)
- [HTML 版本](https://arxiv.org/html/2601.15541v1)
