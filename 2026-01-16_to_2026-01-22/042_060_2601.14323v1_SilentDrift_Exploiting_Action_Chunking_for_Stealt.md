# SilentDrift: Exploiting Action Chunking for Stealthy Backdoor Attacks on Vision-Language-Action Models

**相关性评分**: 6.0/10

**排名**: #42


---


## 基本信息

- **arXiv ID**: [2601.14323v1](https://arxiv.org/abs/2601.14323v1)
- **发布时间**: 2026-01-20T01:24:17Z
- **相关性评分**: 6.0/10
- **是否相关**: 是

## 作者

Bingxin Xu, Yuzhang Shang, Binghui Wang, Emilio Ferrara

## 关键词

Vision-Language-Action Model, VLA for Robotics

## 一句话总结

这篇论文提出了一种针对视觉-语言-动作模型的隐蔽后门攻击方法，利用动作分块和增量姿态表示的安全漏洞，在机器人应用中实现高攻击成功率。

## 摘要

Vision-Language-Action (VLA) models are increasingly deployed in safety-critical robotic applications, yet their security vulnerabilities remain underexplored. We identify a fundamental security flaw in modern VLA systems: the combination of action chunking and delta pose representations creates an intra-chunk visual open-loop. This mechanism forces the robot to execute K-step action sequences, allowing per-step perturbations to accumulate through integration. We propose SILENTDRIFT, a stealthy black-box backdoor attack exploiting this vulnerability. Our method employs the Smootherstep function to construct perturbations with guaranteed C2 continuity, ensuring zero velocity and acceleration at trajectory boundaries to satisfy strict kinematic consistency constraints. Furthermore, our keyframe attack strategy selectively poisons only the critical approach phase, maximizing impact while minimizing trigger exposure. The resulting poisoned trajectories are visually indistinguishable from successful demonstrations. Evaluated on the LIBERO, SILENTDRIFT achieves a 93.2% Attack Success Rate with a poisoning rate under 2%, while maintaining a 95.3% Clean Task Success Rate.

## 详细分析

## 论文摘要：《SilentDrift：利用动作分块对视觉-语言-动作模型进行隐蔽后门攻击》

### 1. 研究背景和动机
随着视觉-语言-动作模型在医疗、制造等安全关键机器人应用中的部署日益增多，其安全性问题却未得到充分探索。现有后门攻击通常引发**突然的恶意行为**（如错误抓取或释放），这些行为会产生运动学不连续性和分布异常，容易被轨迹验证过滤器或人工质检发现，实用性受限。本文发现，现代VLA架构中普遍采用的**动作分块**与**增量位姿表示**相结合，会形成一个**块内视觉开环**的安全漏洞，使得微小扰动能在执行过程中不断累积，最终导致任务失败。

### 2. 核心方法和技术创新
本文提出了 **SilentDrift**，一种利用上述漏洞的隐蔽黑盒后门攻击框架，其核心创新点包括：
- **利用块内开环漏洞**：攻击利用VLA模型在预测并执行一个K步动作块时缺乏视觉反馈校正的特性，使注入的微小扰动在块内积分累积，形成显著偏移。
- **Smootherstep平滑扰动**：采用**五次多项式Smootherstep函数**构造扰动，保证其在轨迹边界处具有**零速度和零加速度**，满足严格的**C²连续性**运动学约束，从而规避基于动力学的异常检测。
- **关键帧攻击策略**：仅在机器人接近目标的**关键操作阶段**注入毒化数据，最大化攻击影响的同时，最小化触发器的暴露时间和数据污染比例，提升隐蔽性。

### 3. 主要实验结果
在LIBERO基准测试上对VLA-Adapter和π₀两种模型进行评估：
- **高攻击成功率**：在仅**2%** 的低毒化率下，攻击成功率高达**93.2%**。
- **保持清洁任务性能**：清洁任务成功率保持在**95.3%**，与基线模型性能相当，表明攻击具有高度隐蔽性。
- **视觉不可区分性**：生成的毒化轨迹在视觉上与成功演示无法区分，呈现自然的“接近失误”失败，能有效规避人工审查。
- **消融实验验证**：验证了动作分块大小与攻击成功率正相关，以及Smootherstep函数在保持攻击效力的同时实现了运动学隐蔽性。

### 4. 研究意义和价值
本研究首次系统揭示了VLA模型中由**动作分块设计**引入的**根本性安全漏洞**。**SilentDrift** 攻击框架证明了，即使不改变模型权重、仅通过极少量精心构造的毒化数据，也能植入高度隐蔽且致命的后门。这项工作具有重要的警示意义，它迫使社区重新审视VLA架构的安全假设，并为开发针对性的防御机制（如**关键状态自适应验证**）提供了明确方向，对推动安全、可靠的具身智能系统发展具有关键价值。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析：SilentDrift

### **一、 论文旨在解决的核心问题**
论文指出，当前部署在安全关键机器人应用中的**视觉-语言-动作模型**存在一个被忽视的安全漏洞。现有的后门攻击方法（如BadVLA、GoBA）会产生**运动学不连续**（如突然松爪、急转弯）和**分布异常**，这些异常很容易被标准的轨迹验证过滤器或人工质检发现，因此在严格的部署环境中**实用性有限**。论文的核心目标是设计一种**隐蔽的、难以被检测的**后门攻击，能够在不破坏模型正常功能的前提下，可靠地导致任务失败。

### **二、 核心技术创新点**
论文的创新点是一个紧密关联的三层体系，环环相扣：

1.  **发现并形式化了一个根本性的架构漏洞**：
    - **问题根源**：现代VLA模型普遍采用 **“动作分块”** （一次预测未来K步动作）和 **“增量位姿表示”** （动作表示为相对变化量）的组合设计。
    - **关键洞察**：这种设计在分块执行期间创造了一个 **“块内视觉开环”** 。机器人盲目地执行预测好的K步动作序列，期间缺乏基于视觉反馈的中间修正。
    - **攻击面**：这使得微小的**每步扰动可以在整个分块内通过积分不断累积**。例如，每步仅1毫米的漂移，在一个K=50的分块内可累积成5厘米的偏差，足以导致操作失败。

2.  **提出了满足运动学一致性的隐蔽扰动生成方法**：
    - **挑战**：简单的恒定偏移扰动会在攻击起始点产生速度/加速度的突变（无限加加速度），极易被动力学异常检测器发现。
    - **解决方案**：采用 **Smootherstep函数**（一个五次多项式）来调制扰动。
        - **数学保证**：该函数保证了 **`C²`连续性**，即在轨迹边界处速度、加速度均为零。
        - **效果**：生成的扰动轨迹在位置、速度、加速度层面都平滑自然，与人类演示或正常轨迹在动力学特征上**无法区分**，从而完美规避基于动力学的检测。

3.  **设计了关键帧攻击策略以最大化隐蔽性和效果**：
    - **选择性投毒**：在数据投毒阶段，**仅污染关键的操作阶段**（如抓取前的接近阶段），而非整个轨迹。这极大减少了投毒数据比例（仅需2%），避免了训练数据分布的明显偏移。
    - **上下文感知触发**：在攻击执行阶段，触发器（如一个红色圆形贴片）的激活与机器人的物理状态（如末端执行器接近目标物体的距离）**同步**。
        - **优势1（隐蔽性）**：触发器仅在关键时刻短暂出现，最小化视觉足迹。
        - **优势2（不可逆性）**：在“无法回头”的关键点注入漂移，迫使机器人执行一个被污染的、开环的动作分块，当视觉反馈再次介入时，偏差已无法挽回。

### **三、 解决方案的总体框架**
**SilentDrift** 是一个**黑盒、模型无关**的攻击框架，其工作流程如下：
1.  **利用漏洞**：瞄准VLA模型的“动作分块”和“增量位姿”设计。
2.  **生成隐蔽扰动**：使用Smootherstep函数构造满足`C²`连续性的平滑漂移，确保运动学一致性。
3.  **实施精准攻击**：通过关键帧策略，仅在机器人执行精细操作的关键时刻注入扰动。
4.  **实现攻击目标**：微小的每步扰动在开环执行的分块内积分，累积成足以导致任务失败的显著偏差，而整个过程在视觉和动力学层面都看起来完全正常。

### **四、 实际价值与影响**
- **安全警示**：论文揭示了VLA模型在追求效率（动作分块减少推理频率）和光滑性（增量位姿）时，无意中引入的**系统性安全风险**。这对AI驱动的机器人系统的安全部署敲响了警钟。
- **攻击范式转变**：将后门攻击的关注点从**触发器的隐蔽性**，提升到了**攻击行为本身的运动学隐蔽性**。这代表了一类更高级、更难以防御的攻击。
- **促进防御研究**：论文在最后提出了初步的防御思路（**临界状态自适应验证**），即根据任务关键性动态调整开环执行窗口，为后续的防御机制设计指明了方向。这体现了其研究的建设性。
- **高威胁性验证**：在LIBERO基准测试上，仅以**2%的投毒率**，对`π₀`和VLA-Adapter等主流模型实现了**超过93%的攻击成功率**，同时保持了**超过95%的干净任务成功率**，证明了该攻击方法的高效性和极强的隐蔽性。

**总结**：`SilentDrift`的核心创新在于**首次系统性地挖掘并利用了VLA模型“动作分块”架构的内在安全缺陷**，并创造性地将**计算机图形学中的平滑插值函数**与**机器人运动规划中的运动学约束**相结合，设计出一种在行为层面极具隐蔽性的后门攻击，对确保具身智能系统的安全具有重要的理论和实践意义。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文针对**视觉-语言-动作（VLA）模型在安全关键机器人应用中的安全漏洞**，提出了一个名为**SilentDrift**的隐蔽后门攻击框架。其核心问题是：现代VLA模型普遍采用的**动作分块（Action Chunking）**和**增量位姿（Delta Pose）**表示相结合，会在执行一个动作块期间形成一个**块内视觉开环**，使得微小的扰动能在整个动作块内累积，最终导致任务失败。

为解决此问题，论文提出了一个**黑盒攻击方法**，其核心创新在于两点：1）利用**Smootherstep函数**构造具有**C²连续性**的扰动，确保在轨迹边界处速度和加速度为零，从而生成运动学上一致、难以被动力学检测器发现的平滑轨迹偏差；2）采用**关键帧攻击策略**，仅在机器人接近目标的关键阶段注入扰动，最大化攻击影响的同时最小化触发器的暴露时间，提升了攻击的隐蔽性。

最终，在LIBERO基准测试中，该方法仅以**2%的数据投毒率**，在保持模型**95.3%干净任务成功率**的同时，实现了**93.2%的攻击成功率**，证明了该攻击方法的高效性和隐蔽性，揭示了VLA模型架构中存在的根本性安全缺陷。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文《SilentDrift》的创新点分析

这篇论文针对视觉-语言-动作模型的隐蔽后门攻击，提出了一个名为**SilentDrift**的新颖攻击框架。其核心创新点在于**首次系统性地利用了VLA模型架构中“动作分块”与“增量位姿表示”结合所产生的安全漏洞**，并设计了一套高度隐蔽的攻击方法。以下是其相对于已有工作的明确创新点：

---

### 1. **攻击目标创新：首次针对“动作分块”架构的固有漏洞**
- **相比以往方法**：现有的VLA后门攻击（如BadVLA, GoBA, TabVLA）将VLA模型视为一个整体，攻击其输出的单步动作，导致**行为突变**（如突然松爪、错误转向）。这些攻击忽略了VLA模型**预测并执行一个动作序列（分块）** 的时序结构。
- **改进/不同之处**：本文首次指出并利用了现代VLA模型（如π₀, VLA-Adapter）普遍采用的**动作分块**机制。该机制使机器人在执行一个K步的动作块期间，处于**块内视觉开环**状态，即缺乏实时视觉反馈来纠正动作误差。
- **解决的问题/优势**：这一发现揭示了VLA模型一个**根本性的安全缺陷**。攻击者可以利用这个开环窗口，注入微小的、每步的扰动，让这些扰动在动作块的执行过程中**累积**，最终导致任务失败。这为攻击提供了一个全新的、更底层的攻击面。

### 2. **攻击方法创新：利用Smootherstep函数保证运动学一致性**
- **相比以往方法**：以往的攻击注入的扰动（δₜ）通常是突变的（例如常数偏移），这会在攻击起始点产生**速度、加速度的不连续**（即“急动”），从而容易被基于动力学的异常检测器或人工审查发现。
- **改进/不同之处**：SilentDrift采用计算机图形学中的**Smootherstep函数**（一个五次多项式）来构造扰动。该函数能保证生成的扰动轨迹具有 **`C²`连续性**，即在攻击开始和结束的时刻，扰动的**速度和加速度都为零**。
- **解决的问题/优势**：
    1. **规避动力学检测**：生成的被污染轨迹在速度、加速度、急动度上都是平滑且有界的，与人类演示或正常策略产生的轨迹在运动学特性上**无法区分**，从而能绕过标准的轨迹验证过滤器。
    2. **视觉隐蔽性**：机器人执行被污染轨迹时，其运动看起来自然流畅，像一个“接近成功但最终失败”的演示，而非明显的异常行为，极大提升了攻击的隐蔽性。

### 3. **攻击策略创新：关键帧选择性毒化策略**
- **相比以往方法**：传统后门攻击可能在整个轨迹或随机时间点注入毒化数据，这会**改变训练数据的整体分布**，容易被统计审计方法检测到，且触发条件可能不精准。
- **改进/不同之处**：SilentDrift提出**关键帧攻击策略**。它仅在任务执行的关键阶段（例如，机械臂接近目标物体的“最后逼近阶段”）激活攻击并注入毒化数据。
- **解决的问题/优势**：
    1. **最大化攻击效率**：在“不可逆点”注入漂移，此时机器人已无法有效纠正错误，确保任务必然失败。
    2. **最小化暴露风险**：
        - **训练时**：仅毒化极少量的关键帧（论文中下毒率<2%），极大降低了数据分布的变化，使被攻击模型与干净模型的训练损失曲线几乎无法区分（见图4）。
        - **部署时**：触发信号（视觉触发器）仅在关键时刻短暂出现，最小化了其视觉足迹，难以被实时检测系统发现。

### 4. **理论贡献与形式化分析**
- **相比以往方法**：以往工作多为经验性攻击，缺乏对VLA模型时序漏洞的严格理论分析。
- **改进/不同之处**：论文对“动作分块+增量位姿”导致的**漂移累积**进行了严格的形式化证明（公式5），明确指出累积误差是各步扰动之和（`𝐄_accum = Σδ_i`），且误差随分块大小K线性增长。同时，严格证明了Smootherstep函数的`C²`连续性边界条件。
- **解决的问题/优势**：这为攻击的有效性提供了坚实的**理论基础**，不仅解释了为何微小扰动（如每步1mm）能通过累积（K=50时达5cm）导致任务失败，也使得攻击参数（如扰动幅度、攻击窗口）可以精确控制。

### 5. **攻击范式的综合性优势**
- **模型无关的黑盒攻击**：SilentDrift仅需向训练数据集中注入毒化数据，**无需访问模型架构、权重或梯度**（白盒信息），攻击成本低，适用性广。
- **高攻击成功率与高隐蔽性并存**：在LIBERO基准测试中，仅用2%的下毒率，就在两个主流VLA模型（VLA-Adapter和π₀）上实现了**超过93%的攻击成功率**，同时保持了**超过95%的干净任务成功率**。这实现了后门攻击的两个核心且往往矛盾的目标：**高效触发恶意行为**与**不影响正常功能**。

---

**总结**：SilentDrift的核心创新在于从一个**全新的架构漏洞视角**（动作分块开环）出发，设计了一套**理论严谨、高度隐蔽、实施成本低**的后门攻击方法。它不再与现有的基于运动学异常或数据分布异常的检测机制“硬碰硬”，而是通过**模仿自然运动的数学特性**和**精准的时机选择**来绕过它们，这为VLA模型的安全性研究敲响了警钟，并指明了未来防御机制需要关注的新方向（如动态调整开环窗口的适应性验证）。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 论文实验与评估效果分析

### 一、 实验设置
#### 1. **数据集**
- **LIBERO基准测试**：一个用于终身机器人学习的综合仿真环境。包含四个任务套件：
    - **LIBERO-Spatial**（空间任务）
    - **LIBERO-Object**（物体任务）
    - **LIBERO-Goal**（目标任务）
    - **LIBERO-10**（长期任务）
- 每个套件包含10个任务，总计40个任务。实验使用了所有干净轨迹数据，并过滤了无操作帧。

#### 2. **评估模型**
论文在两种代表性的VLA架构上实施了攻击：
- **VLA-Adapter** (Wang et al., 2025)：一个参数高效的VLA模型（0.5B参数），通过高效微调实现SOTA性能。
- **π₀ (pi-0)** (Black et al., 2024)：一个基于流匹配的VLA基础模型，专为实时控制设计。
- **共同点**：两者都采用**动作分块（Action Chunking）** 来生成平滑轨迹。

#### 3. **攻击配置**
- **攻击类型**：**黑盒、模型无关**的攻击框架。仅需注入中毒数据的访问权限，无需模型架构、权重或训练梯度。
- **中毒比例**：极低的**2%**（每个任务仅注入一个中毒片段），模拟低资源隐蔽攻击。
- **触发机制**：视觉触发器（红色圆形贴片，半径5像素，透明度1.0）和物理扰动（Smootherstep漂移，幅度0.3米）仅在机器人末端执行器接近目标物体（距离 < 0.15米）时注入。
- **训练**：在6块NVIDIA RTX A6000 GPU上微调，最多15,000步，遵循原始训练方案。

#### 4. **评价指标**
1.  **干净任务成功率 (CTSR, Clean Task Success Rate)**：衡量模型在**良性（无触发）** 任务上的性能。用于评估后门是否影响模型的正常功能。
2.  **攻击成功率 (ASR, Attack Success Rate)**：量化**攻击有效性**。计算公式为：
    `ASR = (CTSR - SR_trigger) / CTSR`
    其中 `SR_trigger` 是模型在**触发（中毒）** 任务上的成功率。ASR越高，表示攻击越成功（即触发后性能下降越明显）。

### 二、 主要定量结果
论文在表1中给出了核心实验结果。**SilentDrift在保持高CTSR的同时，实现了极高的ASR**。

| 模型 | 指标 | Spatial(%) | Object(%) | Goal(%) | Long(%) | **Average(%)** |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **VLA-Adapter** | **Baseline SR** | 99.8 | 98.4 | 96.2 | 91.8 | **96.6** |
| | **CTSR** | **99.8** | **97.4** | **95.2** | **88.8** | **95.3** |
| | **ASR** | **95.6** | **97.1** | **88.7** | **91.4** | **93.2** |
| **π₀ (pi-0)** | **Baseline SR** | 96.2 | 97.8 | 94.6 | 84.2 | **93.2** |
| | **CTSR** | **95.8** | **97.0** | **93.2** | **83.6** | **92.4** |
| | **ASR** | **95.4** | **96.9** | **88.2** | **90.1** | **92.7** |

**关键结论：**
- **高攻击成功率**：在VLA-Adapter上平均ASR达到**93.2%**，在π₀上达到**92.7%**，证明攻击非常有效。
- **高隐蔽性**：CTSR（VLA-Adapter: 95.3%, π₀: 92.4%）与干净模型的基线成功率（96.6%, 93.2%）非常接近，表明后门**几乎没有损害模型的正常功能**，满足了隐蔽攻击的核心要求。
- **跨任务泛化性**：攻击在所有四个任务套件上都有效，尽管复杂任务（如Goal）的ASR略低，作者认为这是由于轨迹多样性和恢复机会更多所致。

### 三、 与基线方法的对比
论文明确指出，**没有将SilentDrift与现有的VLA后门攻击进行直接的定量比较**。原因如下：

1.  **攻击范式根本不同**：现有攻击（如BadVLA, GoBA, TabVLA）将VLA输出视为整体预测，**忽略了动作分块的时间结构**。它们通常导致**运动学异常**（如突然的夹爪释放、错误的目标转向），这些异常容易被基于动力学的检测器或人工质检发现（见图1 Top）。
2.  **SilentDrift的创新点**：本文是**首个利用动作分块漏洞**的工作。它通过**运动学一致性**实现隐蔽性，而非依赖触发器的隐蔽性。因此，与产生“明显失败”的现有攻击进行ASR对比意义不大，因为后者在现实部署中很可能已被过滤掉。
3.  **对比的实质**：论文的对比主要体现在**定性分析**和**攻击原理**上，强调了SilentDrift在**视觉不可区分性**和**运动学平滑性**方面的优势（见图1 Bottom, 图5）。

### 四、 消融研究与关键结论
论文通过系统的消融实验（图6）验证了其设计选择，并得出以下关键结论：

1.  **动作分块大小（K）是漏洞关键**（图6a）：
    - ASR随分块大小`K`增加而显著提升（从`K=1`到`K=4`跃升明显）。
    - **结论**：验证了理论分析——更大的开环窗口会放大恶意漂移的累积。`‖E_accum‖ ≈ K ⋅ ‖δ̄‖`。

2.  **关键帧攻击策略的有效性**（图6b）：
    - 仅在最终接近阶段（触发距离~0.15m）激活攻击，其ASR与更早或全程触发相当。
    - **结论**：在精细操作阶段诱导漂移足以导致任务失败，无需全程触发，**最大化隐蔽性**。

3.  **扰动函数的选择**（图6d）：
    - **Smootherstep**（保证C²连续性）的攻击性能与**Constant Offset**（常数偏移）和**Smoothstep**（C¹连续）相当。
    - **结论**：VLA的漏洞主要由**累积漂移的幅度**驱动，而非其起始的突兀性。因此，**实现运动学隐蔽性不会削弱攻击效力**。

4.  **中毒比例**（图6c）：
    - 默认的极低中毒比例（每个任务1个中毒片段）已达到最优ASR。
    - **结论**：进一步增加中毒样本收益甚微，而减少比例会导致ASR显著下降，表明需要最低限度的曝光来建立触发器-行为的关联。

### 五、 定性效果与隐蔽性验证
- **视觉不可区分性**（图5）：中毒轨迹与干净轨迹在视频帧序列中**肉眼无法区分**。3D轨迹图显示，中毒路径仅在最终接近阶段才平滑地偏离。
- **训练过程隐蔽性**（图4）：后门模型与干净模型的**训练损失曲线几乎完全重合**，证明攻击在训练阶段不会产生可感知的异常。
- **运动学剖面隐蔽性**（图3）：Smootherstep调制产生的扰动具有**C²连续性**，在轨迹边界处速度和加速度为零，与自然的人类演示特征匹配，可逃避基于动力学的异常检测。

### 总结
**SilentDrift在实验中最终实现的效果是：**
在仅需**2%** 极低数据中毒率、**黑盒**访问的条件下，对两种主流VLA模型成功植入了高度隐蔽的后门。该后门在**不损害模型正常任务性能（CTSR > 95%）** 的前提下，能**在触发时以超过93%的成功率导致任务失败**。其成功根植于对VLA架构中“动作分块”与“位姿差表示”组合所产生的**帧内视觉开环漏洞**的首次系统性利用，并通过**Smootherstep函数**和**关键帧攻击策略**确保了攻击在运动学和视觉上的双重隐蔽性。论文未与现有VLA后门攻击进行直接数值对比，因为其攻击范式（利用时间结构、追求运动学隐蔽）与前者（导致突兀行为）有本质区别。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2601.14323v1)
- [HTML 版本](https://arxiv.org/html/2601.14323v1)
