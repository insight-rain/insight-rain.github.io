# Being-H0.5: Scaling Human-Centric Robot Learning for Cross-Embodiment Generalization

**相关性评分**: 8.0/10

**排名**: #9


---


## 基本信息

- **arXiv ID**: [2601.12993v1](https://arxiv.org/abs/2601.12993v1)
- **发布时间**: 2026-01-19T12:20:38Z
- **相关性评分**: 8.0/10
- **是否相关**: 是

## 作者

Hao Luo, Ye Wang, Wanpeng Zhang, Sipeng Zheng, Ziheng Xi, Chaoyi Xu, Haiweng Xu, Haoqi Yuan, Chi Zhang, Yiqing Wang, Yicheng Feng, Zongqing Lu

## 关键词

Vision-Language-Action Model, VLA for Robotics, fine tune, world model

## 一句话总结

Being-H0.5是一个基于人类交互数据的基础视觉-语言-动作模型，通过统一动作空间和混合流框架实现跨具身泛化，在机器人平台上表现出色。

## 摘要

We introduce Being-H0.5, a foundational Vision-Language-Action (VLA) model designed for robust cross-embodiment generalization across diverse robotic platforms. While existing VLAs often struggle with morphological heterogeneity and data scarcity, we propose a human-centric learning paradigm that treats human interaction traces as a universal "mother tongue" for physical interaction. To support this, we present UniHand-2.0, the largest embodied pre-training recipe to date, comprising over 35,000 hours of multimodal data across 30 distinct robotic embodiments. Our approach introduces a Unified Action Space that maps heterogeneous robot controls into semantically aligned slots, enabling low-resource robots to bootstrap skills from human data and high-resource platforms. Built upon this human-centric foundation, we design a unified sequential modeling and multi-task pre-training paradigm to bridge human demonstrations and robotic execution. Architecturally, Being-H0.5 utilizes a Mixture-of-Transformers design featuring a novel Mixture-of-Flow (MoF) framework to decouple shared motor primitives from specialized embodiment-specific experts. Finally, to make cross-embodiment policies stable in the real world, we introduce Manifold-Preserving Gating for robustness under sensory shift and Universal Async Chunking to universalize chunked control across embodiments with different latency and control profiles. We empirically demonstrate that Being-H0.5 achieves state-of-the-art results on simulated benchmarks, such as LIBERO (98.9%) and RoboCasa (53.9%), while also exhibiting strong cross-embodiment capabilities on five robotic platforms.

## 详细分析

## 论文摘要：Being-H0.5：面向跨具身泛化的人本机器人学习

### 1. 研究背景和动机
当前，视觉-语言-动作模型在机器人领域展现出巨大潜力，但其发展面临两大核心瓶颈：**数据稀缺**与**具身异构性**。不同机器人平台（如机械臂、灵巧手、人形机器人）在形态、控制接口和动力学上差异巨大，导致现有模型往往成为针对单一硬件的“专家”，难以实现跨平台的知识迁移与泛化。这严重阻碍了通用机器人智能的规模化发展。

### 2. 核心方法和技术创新
本文提出**Being-H0.5**，一个旨在实现**跨具身泛化**的基础VLA模型。其核心创新在于：
- **人本学习范式**：将人类手部交互轨迹视为物理交互的“母语”，作为通用先验知识。为此，构建了迄今为止最大的具身预训练数据集**UniHand-2.0**（超过35,000小时，涵盖30种机器人具身）。
- **统一动作空间**：将异构的机器人控制信号和人类手部运动映射到一个语义对齐的统一向量空间中，作为跨具身的“通用语法”。
- **统一序列建模**：将所有异构数据（视觉、文本、状态、动作）序列化为单一的多模态令牌流，在一个框架内实现**感知、描述与行动**的统一训练。
- **模型架构创新**：
    - **流混合**：将动作专家模块解耦为共享的基础层和针对特定具身/任务的路由专家层，提升容量与效率。
    - **流形保持门控**：通过评估上下文可靠性，在感知模糊时回退到鲁棒先验，提升部署稳定性。
    - **通用异步分块**：使单一模型能适应不同机器人的控制延迟和频率，实现实时跨具身控制。

### 3. 主要实验结果
- **仿真基准测试**：在LIBERO和RoboCasa基准上取得领先性能（LIBERO平均成功率98.9%，RoboCasa 53.9%），仅使用低分辨率RGB输入。
- **真实机器人部署**：将**单一**的Being-H0.5检查点成功部署到五种形态迥异的机器人平台（如PND Adam-U、Unitree G1等），在空间操作、长时程、双手协调等多样化任务上表现出色。
- **关键发现**：模型展现出**具身级零样本迁移**能力，即在目标机器人上**完全没有训练数据**的任务-具身组合上，也能取得非零的成功率，这为跨具身泛化指明了新的方向。

### 4. 研究意义和价值
Being-H0.5标志着机器人学习向**规模化、人本化、通用化**迈出了关键一步。其贡献在于：
- **实践价值**：证明了利用大规模人类数据作为物理常识先验，并结合统一建模框架，可以训练出能直接控制多种异构机器人的单一通用模型，极大降低了为每种新机器人平台开发专用策略的成本。
- **理论意义**：提出的“统一动作空间”和“人本学习”范式，为解决具身异构性这一根本挑战提供了新的思路，即通过寻找物理交互的“通用语义”来实现知识迁移。
- **社区贡献**：开源了模型、训练流程和部署基础设施，为后续研究提供了重要的数据集（UniHand-2.0）和可复现的基准，推动了开放、协作的机器人智能发展。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析：Being-H0.5

### **一、 核心要解决的问题**
论文旨在解决**机器人通用智能（General-Purpose Robotics）** 中的一个根本性挑战：**跨形态泛化（Cross-Embodiment Generalization）**。具体表现为：
1.  **形态异构性**：不同机器人平台（如机械臂、灵巧手、人形机器人）在运动学、自由度、控制接口上差异巨大，导致为一个平台训练的模型无法直接用于另一个。
2.  **数据稀缺性**：针对特定机器人的高质量演示数据获取成本极高，规模有限，远不及自然语言处理（NLP）领域的数据量级。
3.  **“物理鸿沟”**：现有视觉-语言-动作模型通常是针对单一形态的“单语者”，缺乏对不同硬件“物理语言”的通用理解，导致知识无法跨平台迁移。

### **二、 核心创新点**
论文提出了一套完整的、以**人为中心（Human-Centric）** 的解决方案，其创新是一个系统性工程，涵盖数据、模型架构、训练方法和部署基础设施。

#### **1. 数据层面的创新：UniHand-2.0 数据集**
- **规模与多样性**：构建了迄今为止最大的具身智能预训练数据集，包含 **35,000+ 小时**的多模态数据（16K小时人类视频、14K小时机器人数据、5K小时视觉-文本数据），覆盖**30种不同的机器人形态**。
- **核心理念**：将**人类手部运动**视为物理交互的“母语”和通用模板。人类视频提供了丰富、低成本、高语义密度的交互先验，作为连接不同机器人形态的桥梁。
- **数据收集系统**：开发了 **UniCraftor** 系统，用于高质量、多模态（RGB-D、精确外参、硬件同步事件）的人类演示数据采集，解决了现有开源数据在几何信息和时间精度上的不足。

#### **2. 模型与算法层面的创新**
- **统一状态-动作空间**：
    - **核心思想**：将异构的人类手部运动（MANO参数）和机器人控制信号，映射到一个**语义对齐的、固定维度的统一向量空间**中。
    - **作用**：充当机器人控制的“通用语法”，将功能意图（如“抓取”）与具体的机械实现解耦，使模型能学习跨形态共享的物理交互逻辑。

- **混合流专家**：
    - **架构**：在混合专家Transformer框架下，为动作生成模块设计了 **Mixture-of-Flow**。
    - **机制**：底层为**共享基础专家**，学习跨形态的通用运动基元（如接近、抓握）；上层为**路由专用专家**，根据具体任务和形态动态激活，实现高效的专业化。
    - **优势**：在保持模型总参数庞大的同时，每次推理仅激活部分参数，兼顾了能力与部署效率。

- **统一序列建模与多任务预训练**：
    - **方法**：将所有异构数据（视觉、文本、状态、动作）序列化为统一的token流，在一个框架内进行**感知、描述和行动**的联合训练。
    - **混合监督**：结合**连续流匹配**（用于高保真动作生成）和**掩码运动token预测**（用于学习鲁棒的行为先验），使模型既能精确控制，又具备稳定的运动抽象能力。

#### **3. 部署与后训练创新**
- **形态特异性适配**：在统一动作空间的基础上，仅对目标机器人激活的“动作槽”对应的适配器参数进行微调，实现高效 specialization，避免知识遗忘。
- **流形保持门控**：
    - **问题**：在感知分布偏移时，基于有噪声的上下文特征生成动作会导致不稳定。
    - **方案**：计算观测特征与可靠动作先验之间的差异，生成一个门控信号。当差异大时，抑制特征依赖的修正，回退到学习到的稳健先验偏移，保证动作生成的稳定性。
- **通用异步分块**：
    - **问题**：不同机器人控制频率和推理延迟不同，导致实时控制中的时空不匹配。
    - **方案**：在训练中模拟不同形态的延迟，将动作块分为“已提交前缀”和“待预测后缀”，只对后缀计算损失。配合**双线程环形缓冲区**的部署架构，实现跨形态的平滑实时控制。

### **三、 解决方案的路径总结**
论文的解决路径可以概括为：**“用人类数据定义通用语义，用统一空间对齐异构形态，用混合架构扩展能力，用稳健机制保障落地”**。

1.  **数据奠基**：通过超大规模、多形态的 **UniHand-2.0** 数据集，尤其是人类视频，为模型注入丰富的物理交互常识和先验。
2.  **表示统一**：通过 **统一状态-动作空间**，为所有形态建立一个共同的、物理可解释的“交流语言”，打破形态壁垒。
3.  **模型学习**：采用 **统一序列建模** 和 **MoF架构**，在一个框架内高效学习从感知、推理到执行的完整链条，并具备处理复杂形态的能力。
4.  **稳健部署**：通过 **MPG** 和 **UAC** 等后训练与部署技术，解决现实世界中的感知不确定性、延迟差异等问题，使单一模型检查点能**稳定部署在多个真实机器人**上。

### **四、 实际价值与验证**
- **性能领先**：在仿真基准测试（LIBERO: **98.9%**, RoboCasa: **53.9%**）上达到SOTA，且仅使用低分辨率RGB输入。
- **跨形态泛化实证**：**单个** Being-H0.5 检查点成功控制了 **5个** 物理结构迥异的真实机器人（如PND Adam-U人形机器人、Franka+Inspire灵巧手、Unitree G1等），完成了空间排列、长时程、双手协调等复杂任务。
- **涌现的零样本迁移**：观察到了**形态级零样本迁移**的迹象——在目标机器人上**完全没有训练数据**的任务-形态对上，模型仍能表现出非零的成功率和任务一致的行为结构。这为通过增加数据多样性来实现更强大的涌现智能指明了方向。
- **开源与可复现**：论文承诺开源模型权重、训练流水线和部署基础设施，对推动社区发展具有重要意义。

**结论**：Being-H0.5 不仅仅是一个新的VLA模型，它代表了一种**以人类为中心、以统一表示为纽带、以稳健部署为目标的机器人学习新范式**。它系统性地解决了从数据稀缺、形态异构到现实部署的一系列关键挑战，为实现真正通用的、可跨平台部署的机器人智能迈出了坚实的一步。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文旨在解决机器人视觉-语言-动作（VLA）模型在**跨形态（cross-embodiment）泛化**方面的核心挑战，即单一模型难以适应不同机械结构（如灵巧手、平行夹爪、人形机器人）的机器人平台。为此，论文提出了一个**以人为中心（human-centric）** 的学习范式，其核心方法包括：1）构建超大规模多模态数据集**UniHand-2.0**（超过3.5万小时），将人类手部运动作为物理交互的“母语”与机器人数据统一；2）设计**统一动作空间**，将异构的机器人控制信号映射到语义对齐的槽位；3）采用**混合流（Mixture-of-Flow）** 架构及**流形保持门控（MPG）**、**通用异步分块（UAC）** 等创新技术，以提升模型的容量、鲁棒性和实时部署能力。最终，模型**Being-H0.5**在多个仿真基准（如LIBERO达到98.9%）和五个真实机器人平台上实现了最先进的性能，并首次在真实机器人上观察到了**跨形态的零样本任务迁移**能力，证明了其强大的泛化性和实用性。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文《Being-H0.5》的核心创新点分析

这篇论文在机器人学习领域，特别是在跨具身（Cross-Embodiment）通用化方面，提出了一系列系统性的创新。其核心思想是**以人类交互数据为“母语”，构建一个统一的、可扩展的视觉-语言-动作（VLA）基础模型**。以下是其相对于已有工作的明确创新点：

### 1. **数据层面：超大规模、以人为中心的预训练配方 UniHand-2.0**
   - **改进/不同之处**：
     - **规模与多样性**：构建了迄今为止最大的具身预训练数据集，总计超过 **35,000小时**（16000小时人类数据，14000小时机器人数据，5000小时视觉-文本数据），涵盖**30种不同的机器人具身**。这远超Open X-Embodiment、AgiBot World等现有数据集。
     - **以人为核心**：将大规模的人类手部运动视频（通过MANO模型参数化）作为主要的预训练材料，并将其视为所有末端执行器的“通用模板”。这突破了以往VLA模型主要依赖稀缺、昂贵的机器人遥操作数据的瓶颈。
   - **解决的问题/带来的优势**：
     - **解决数据稀缺与多样性不足**：为模型提供了海量的、覆盖真实世界复杂场景的交互先验知识。
     - **提供物理常识**：人类数据蕴含了跨所有机器人平台都通用的交互逻辑、因果关系和接触物理，为模型提供了强大的、可迁移的“行为先验”，使其能快速适应新硬件。

### 2. **方法层面：统一的动作空间与序列建模**
   - **改进/不同之处**：
     - **统一动作空间**：提出一个**物理可解释的统一状态-动作空间**，将人类手部轨迹和异构机器人控制信号映射到语义对齐的“槽位”中。这不同于以往工作（如GR00T-N1）为每个机器人平台使用独立的动作头或简单的零填充。
     - **统一序列建模**：将所有异构监督（人类演示、机器人轨迹、视觉-文本数据）序列化为一个单一的多模态令牌流，在一个框架内通过**统一的序列建模**进行优化。模型在同一个序列中学习“感知、描述、行动”。
   - **解决的问题/带来的优势**：
     - **解决具身异构性带来的表征冲突**：统一空间充当了不同硬件的“通用语法”，将功能意图与机械关节解耦，使模型能学习底层的交互物理，而非平台特定的命令。
     - **实现高效、可扩展的预训练**：避免了维护多个独立数据管道和损失函数的复杂性，使跨模态知识转移成为可能，为模型赋予了强大的跨具身泛化能力。

### 3. **架构层面：混合流专家与鲁棒性增强模块**
   - **改进/不同之处**：
     - **混合流**：在混合Transformer架构中，为动作专家引入了**混合流**设计。它将动作模块解耦为**共享的基础专家**（编码通用运动基元）和**路由的专项专家**（处理特定具身/任务动态）。这不同于传统容量固定的动作头。
     - **流形保持门控**：在推理时，通过计算观测特征与参考动作嵌入之间的切片Wasserstein距离，生成一个**可靠性门控**。当感知上下文不可靠时，该门控会抑制特征依赖的修正，回退到一个稳健的学习先验偏移。
     - **通用异步分块**：将训练时实时分块控制技术扩展至**跨具身**场景。模型学习适应不同机器人的控制频率和延迟分布，确保单个检查点能在异构平台上实现流畅的实时控制。
   - **解决的问题/带来的优势**：
     - **解决模型容量瓶颈与负迁移**：MoF通过稀疏激活专家，在不线性增加计算开销的前提下，大幅提升了模型对复杂具身和任务的建模能力，减少了跨平台干扰。
     - **提升部署鲁棒性**：MPG解决了在感知分布偏移（如光照变化、遮挡）下，基于流的动作生成容易产生抖动和不稳定轨迹的问题。UAC解决了真实机器人部署中，推理延迟与执行不同步导致的控制不连续问题。

### 4. **系统层面：便携可扩展的数据收集系统与实时部署框架**
   - **改进/不同之处**：
     - **UniCraftor系统**：开发了一个模块化、即插即用的数据收集系统，集成了**原生深度感知**、**基于AprilTag的高精度外参标定**和**硬件同步的交互事件记录**。这解决了现有开源人类数据集（如Ego4D）缺乏深度、外参不准、标注时间粒度粗糙的问题。
     - **双线程实时部署架构**：设计了生产者-消费者模式的双线程环形缓冲区架构，将推理线程与控制线程解耦，并集成了MPG和UAC协议。
   - **解决的问题/带来的优势**：
     - **解决高质量人类数据获取难的问题**：UniCraftor能以较低成本收集带有精确几何和时序信息的高保真人类演示数据，为预训练提供了更干净的信号。
     - **实现低延迟、稳健的跨平台实时控制**：该部署框架使单个Being-H0.5检查点能够稳定运行在从10Hz桌面机械臂到50Hz人形机器人的各种硬件上，是实验室模型走向实际应用的关键桥梁。

### 5. **实证发现：涌现的跨具身零样本迁移能力**
   - **改进/不同之处**：
     - 论文报告了一个**意外的实证发现**：经过跨具身联合后训练的单一通用检查点，在**从未见过该机器人数据的任务-具身对上**，表现出了**非零的成功率**。例如，仅在FR3机器人上训练过的“开抽屉”任务，Adam-U人形机器人也能执行出类似意图的行为。
   - **解决的问题/带来的优势**：
     - **揭示了VLA模型的新潜力**：这表明，在统一动作空间和多样化数据下训练的模型，能够学习到可组合的、与具体形态解耦的**任务抽象**，而不仅仅是模仿特定的运动轨迹。这为通向更通用、更具涌现性的机器人智能指明了一个可行的扩展方向。

**总结**：Being-H0.5的创新是一个从**数据**（UniHand-2.0）、**方法**（统一空间/序列建模）、**架构**（MoF/MPG/UAC）到**系统**（UniCraftor/部署框架）的完整体系。其核心贡献在于，通过“人类即通用具身”的范式，系统性地解决了机器人学习中数据稀缺、具身异构、仿真到现实差距以及部署鲁棒性等核心挑战，并首次在实证中展示了跨具身零样本迁移的曙光，推动了通用机器人基础模型向实用化迈进。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 实验与评估效果总结

论文通过广泛的仿真与真实机器人实验，全面评估了 **Being-H0.5** 模型的性能，证明了其在**跨具身泛化**、**任务成功率**和**实时部署**方面的卓越能力。

### 一、 使用的数据集与评价指标

#### 1. 主要数据集
- **UniHand-2.0**： 论文自建的**超大规模预训练数据集**，是评估的基石。包含：
    - **35,000+小时**多模态数据（16K小时人类演示，14K小时机器人数据，5K小时视觉-文本理解数据）。
    - 涵盖**30种不同的机器人具身**（从桌面机械臂到腿式人形机器人）。
- **仿真基准**：
    - **LIBERO**： 用于评估知识迁移和终身学习能力的基准，包含空间、物体、目标和长时序四类任务。
    - **RoboCasa**： 用于评估家庭场景下长时序、多样化任务的基准，包含拾放、开关门/抽屉等24个任务。
- **真实机器人任务集**： 在**5个异构机器人平台**（PND Adam-U, Unitree G1, FR3+Inspire Hand, BeingBeyond D1, LeRobot SO-101）上设计了**10个任务**，覆盖空间推理、长时序、双手操作和泛化能力四大类别。

#### 2. 核心评价指标
- **任务成功率**： 在仿真和真实实验中，基于**预定义的客观成功标准**，计算成功完成任务的试验比例。这是最主要的性能指标。
- **跨具身零样本迁移成功率**： 评估单一检查点在**从未见过**的“任务-机器人”配对上的表现，是衡量泛化能力的关键。
- **平均手腕位移相似度**： 在人类运动预测消融实验中，用于衡量预测动作与真实动作在意图上的一致性。

### 二、 对比的基线方法

论文与当前最先进的VLA模型和专用策略进行了全面对比：

1.  **主流VLA模型**：
    - **π₀ / π₀.5系列**： 当前性能领先的扩散型VLA基线。
    - **GR00T-N1**： 面向人形机器人的强大基础模型。
    - **OpenVLA / SpatialVLA / CoT-VLA / X-VLA / EO1** 等： 在LIBERO等基准上报告了SOTA结果的各种VLA变体。
    - **InternVLA-M1 / F1**： 近期提出的高性能VLA模型。

2.  **3D或多模态方法**（在RoboCasa上）：
    - **3DA, DP3, GWM**： 依赖3D点云或显式3D表示的方法。

3.  **论文内部的消融基线**：
    - **Being-H0.5-specialist**： 在特定机器人或基准上微调的专家模型，作为性能上限。
    - **Being-H0.5-generalist**： **单一检查点**同时在所有机器人或基准上训练和部署的通用模型，是核心创新。
    - **Being-H0.5-scratch**： 不使用UniHand-2.0预训练的模型，用于验证大规模预训练的价值。
    - **去除关键组件（MPG/UAC）的版本**： 用于验证**流形保持门控**和**通用异步分块**技术的有效性。

### 三、 关键性能结果与结论

#### 1. 仿真基准：达到新的SOTA水平
- **LIBERO**：
    - **Being-H0.5-specialist** 取得了 **98.9%** 的平均成功率，在**LIBERO-Long**（复杂多步推理）上达到 **97.4%**，显著优于所有对比方法。
    - **Being-H0.5-generalist**（单一检查点）在联合训练LIBERO+RoboCasa后，仍保持 **97.6%** 的高成功率，证明了强大的跨任务吸收能力。
- **RoboCasa**：
    - **Being-H0.5-specialist** 以 **53.9%** 的总平均成功率刷新SOTA。
    - **Being-H0.5-generalist** 同样取得 **53.3%** 的优异性能。
    - **关键提升**：在**拾放（Pick & Place）** 任务上达到 **36-40%** 的成功率，远超 **π₀.5 (21.5%)** 等基线，甚至优于许多使用3D输入的方法，凸显了其从大规模人类数据中提炼出的**可迁移空间先验**的有效性。

#### 2. 真实机器人实验：单一模型控制异构机器人舰队
- **通用模型接近专家性能**： Being-H0.5-generalist在空间、长时序、双手任务上的成功率仅略低于为每个机器人单独训练的specialist版本，在部分场景下甚至更优，表明**联合训练增强了共享子技能的鲁棒性**。
- **显著超越基线**： 在长时序和双手任务上，Being-H0.5大幅领先 **π₀.5**。这归因于其**统一动作空间**和**显式的跨具身设计**，避免了基线模型因具身特定接口导致的负迁移。
- **涌现的零样本跨具身迁移**： 论文报告了一个**重要发现**：经过跨具身联合后训练的单一Being-H0.5-generalist检查点，在**完全没有目标机器人演示数据**的任务上（例如，让Adam-U执行仅在G1或FR3上演示过的任务），取得了**非零的成功率**。这为通过增加数据多样性来实现**组合式泛化**指明了方向。

#### 3. 消融实验：验证核心创新价值
- **大规模预训练至关重要**： 移除UniHand-2.0预训练（scratch版本）后，generalist性能大幅下降，证明人类中心数据提供的**广泛操作先验**是稳定异构具身混合优化的关键，而非简单的“更多数据”。
- **MPG与UAC提升实时鲁棒性**： 在真实机器人上，移除**流形保持门控**和**通用异步分块**会导致长时序和双手任务成功率显著下降，尤其是在存在感知分布偏移和执行延迟不匹配时。
- **混合运动表征有效**： 消融实验表明，引入**掩码运动令牌预测**目标有助于模型在嘈杂的大规模人类视频数据中捕获更稳定、意图对齐的行为先验。

### 结论
论文通过系统性的实验证明，**Being-H0.5** 不仅在LIBERO和RoboCasa等主流仿真基准上达到了最先进的性能，更重要的是，其**单一通用检查点**能够在实际部署中流畅地控制**五个形态各异的真实机器人**，完成复杂的空间、长时序和双手协调任务，并首次展示了**跨具身零样本任务迁移**的潜力。这些结果强有力地支持了其**“以人类为中心的学习”** 和 **“统一动作空间”** 两大核心范式的有效性，为构建真正通用、可扩展的机器人基础模型迈出了关键一步。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2601.12993v1)
- [HTML 版本](https://arxiv.org/html/2601.12993v1)
