# TRIM: Hybrid Inference via Targeted Stepwise Routing in Multi-Step Reasoning Tasks

**相关性评分**: 7.0/10

**排名**: #18


---


## 基本信息

- **arXiv ID**: [2601.10245v1](https://arxiv.org/abs/2601.10245v1)
- **发布时间**: 2026-01-15T10:06:06Z
- **相关性评分**: 7.0/10
- **是否相关**: 是

## 作者

Vansh Kapoor, Aman Gupta, Hao Chen, Anurag Beniwal, Jing Huang, Aviral Kumar

## 关键词

Inference Efficiency, Lightweight Architecture, Inference Acceleration

## 一句话总结

TRIM通过目标性逐步路由在推理任务中提升效率，将关键步骤分配给大模型，常规步骤由小模型处理，显著降低成本。

## 摘要

Multi-step reasoning tasks like mathematical problem solving are vulnerable to cascading failures, where a single incorrect step leads to complete solution breakdown. Current LLM routing methods assign entire queries to one model, treating all reasoning steps as equal. We propose TRIM (Targeted routing in multi-step reasoning tasks), which routes only critical steps$\unicode{x2013}$those likely to derail the solution$\unicode{x2013}$to larger models while letting smaller models handle routine continuations. Our key insight is that targeted step-level interventions can fundamentally transform inference efficiency by confining expensive calls to precisely those steps where stronger models prevent cascading errors. TRIM operates at the step-level: it uses process reward models to identify erroneous steps and makes routing decisions based on step-level uncertainty and budget constraints. We develop several routing strategies within TRIM, ranging from a simple threshold-based policy to more expressive policies that reason about long-horizon accuracy-cost trade-offs and uncertainty in step-level correctness estimates. On MATH-500, even the simplest thresholding strategy surpasses prior routing methods with 5x higher cost efficiency, while more advanced policies match the strong, expensive model's performance using 80% fewer expensive model tokens. On harder benchmarks such as AIME, TRIM achieves up to 6x higher cost efficiency. All methods generalize effectively across math reasoning tasks, demonstrating that step-level difficulty represents fundamental characteristics of reasoning.

## 详细分析

## 论文摘要：TRIM：多步推理任务中基于目标逐步路由的混合推理

### 1. 研究背景和动机
随着大语言模型（LLM）生态的多样化，模型性能与推理成本之间的权衡日益凸显。在多步推理任务（如数学解题）中，单个错误步骤可能导致整个解决方案崩溃（级联错误）。现有的路由方法通常在查询级别将整个问题分配给一个模型，无法区分推理步骤中关键决策点与常规延续之间的差异，导致计算资源分配效率低下。**TRIM** 旨在解决这一核心矛盾：如何仅在可能破坏解决方案的关键步骤上调用昂贵的大模型，而让廉价的小模型处理常规步骤，从而在保证质量的同时大幅提升推理效率。

### 2. 核心方法和技术创新
TRIM 的核心创新在于**步骤级别的目标路由**。其框架在生成解决方案时，每一步都进行评估和路由决策：
- **步骤级评估**：利用过程奖励模型（PRM）为每个中间步骤生成正确性分数，作为路由依据。
- **路由策略**：设计了多种路由策略，从简单的**基于阈值的策略（TRIM-Thr）**，到考虑长时程精度-成本权衡的**强化学习策略（TRIM-Agg/Seq）**，再到能显式处理PRM评分噪声和不确定性的**部分可观测马尔可夫决策过程策略（TRIM-POMDP）**。
- **关键设计**：当决定“重新生成”时，仅由大模型重写当前步骤，之后控制权交回小模型，而非大模型接管剩余所有步骤。这种**精准干预**能有效纠正错误路径，同时最大限度减少大模型令牌的使用。

### 3. 主要实验结果
在多个数学推理基准测试上，TRIM 展现出卓越的效率和性能：
- **效率提升**：在 MATH-500 上，最简单的阈值策略（TRIM-Thr）比现有查询级路由方法成本效率高 **5倍**。更高级的策略（TRIM-Agg/POMDP）仅使用 **20%** 的大模型令牌即可达到与昂贵大模型（Claude 3.7 Sonnet）相当的性能。
- **泛化能力**：在更具挑战性的 AIME 基准上，TRIM 实现了高达 **6.33倍** 的成本效率提升。更重要的是，在 AIME 上训练的路由策略能有效泛化到 OlympiadBench 等其他数学数据集，证明了步骤级难度模式是跨数据集的**可迁移特性**，而非数据集特定伪影。
- **鲁棒性**：TRIM-POMDP 在 PRM 评分噪声较大的低预算场景下表现优异，而 TRIM-Agg 在高预算场景下通过 RL 学习能隐式处理噪声，两者均展现出对不完美评估信号的鲁棒性。

### 4. 研究意义和价值
TRIM 的研究具有重要的理论意义和实际价值：
- **理论贡献**：系统性地证明了在多步推理中，**少量精准的步骤级干预**能从根本上改变推理效率，为混合模型推理提供了新的理论视角。
- **实践价值**：提供了一套实用框架，能够实例化从简单到复杂的多种路由策略。该方法显著降低了使用高性能大模型的**经济门槛**，为实现高质量、低成本的LLM服务部署提供了可行路径。
- **前瞻方向**：工作表明步骤级难度是推理的**基本特征**，并为未来实现更细粒度的（如令牌级）路由以追求极致效率指明了方向。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文分析：TRIM（多步推理任务中的目标性逐步路由）

### **核心问题**
当前大语言模型（LLM）部署面临一个根本性困境：**性能与成本的权衡**。大型模型能力强但推理成本高昂，小型模型成本低但性能（尤其在复杂任务上）较差。现有的**查询级路由**方法将整个问题分配给单一模型，假设所有推理步骤难度相同，这在多步推理任务（如数学解题）中效率低下，因为：
- 错误具有**级联效应**：早期一个错误步骤可能导致整个解答失败。
- 并非所有步骤都同等关键：只有少数**关键步骤**（容易导致解答偏离的步骤）真正需要大模型的干预。

### **核心创新点**
论文提出了 **TRIM（Targeted Stepwise Routing）框架**，其根本性创新在于将路由的**粒度从“查询级”细化到“步骤级”**。

1.  **核心思想**：**仅将关键步骤**路由到昂贵的大模型，而让廉价的小模型处理常规的延续步骤。通过将昂贵的计算资源**精准地限制**在能防止级联错误发生的步骤上，从根本上改变了推理效率。
2.  **方法论创新**：设计了**一系列逐步路由策略**，形成一个从简单到复杂的策略谱系：
    - **TRIM-Thr（阈值策略）**：基于过程奖励模型（PRM）对当前步骤的评分，低于阈值则用大模型重生成。简单有效，作为强基线。
    - **TRIM-Seq/TRIM-Agg（RL训练策略）**：使用强化学习训练路由策略。不仅考虑当前步骤，还考虑**历史步骤的正确性序列（Seq）或聚合特征（Agg，如历史最低分）**，以进行**长视野的精度-成本权衡**决策。
    - **TRIM-POMDP（基于部分可观测马尔可夫决策过程的策略）**：将PRM评分视为对隐藏的真实正确性状态的**噪声观测**，显式地对这种不确定性进行建模。通过求解POMDP来获得最优路由策略，特别擅长在**低预算/稀疏奖励**场景下进行规划。

### **解决方案与工作机制**
1.  **步骤级生成与决策**：
    - 解答被分解为一系列步骤（以双换行符分隔）。
    - 在每个步骤 `t`，小模型 `M_w` 先生成一个候选步骤 `y_t^w`。
    - **路由器** 根据当前部分解答轨迹 `y_{1:t-1}` 和 `y_t^w` 进行评估。
    - 路由器做出二元决策：**继续（accept）** 使用 `y_t^w`，或**重生成（regenerate）** 该步骤（即用大模型 `M_s` 基于 `y_{1:t-1}` 重新生成 `y_t^s` 替换）。
    - 决策后，将接受的步骤追加到解答中，并继续下一个步骤。

2.  **关键技术组件**：
    - **过程奖励模型（PRM）**：用于提供步骤级的正确性估计分数（`r_t`），是路由决策的核心信号。
    - **成本模型**：核心成本定义为**大模型生成的令牌数**，因为解码令牌的成本是顺序且无法并行化的，而预填充（prefill）成本可通过并行策略摊销。

3.  **实现效率**：
    - 论文指出，通过采用**投机解码（Speculative Decoding）** 类似的系统级优化（如大模型对小模型的生成进行分块预填充以保持KV缓存同步），TRIM可以**避免频繁切换模型带来的上下文重编码开销**，甚至可能比单独运行大模型更快（见附录A的延迟分析）。

### **实际价值与效果**
1.  **卓越的成本效率**：
    - 在MATH-500上，即使最简单的 **TRIM-Thr** 也比之前的查询级路由方法成本效率高 **5倍**。
    - 更高级的策略（**TRIM-Agg, TRIM-POMDP**）仅使用 **20%** 的大模型令牌，就能达到与昂贵大模型相当的性能。
    - 在更难的AIME基准上，成本效率提升最高达 **6.33倍**。

2.  **强大的泛化能力**：
    - 在AIME上训练的路由策略，可以直接在OlympiadBench和Minerva Math等同类难度基准上取得优秀效果（例如，Δ_IBC 从2.5 泛化到 2.57 和 3.12）。
    - 这表明TRIM捕捉到的是**多步推理中步骤级难度的本质特征**，而非数据集特定的表面特征。相比之下，查询级路由器容易过拟合到数据集风格，泛化性差。

3.  **对PRM噪声的鲁棒性**：
    - **TRIM-POMDP** 通过显式建模观测噪声，在PRM评分不可靠时（如在极难任务上）表现尤为稳健。
    - **TRIM-Agg** 通过RL训练也能隐式学习对PRM噪声的鲁棒性。

4.  **灵活性与实用性**：
    - 提供了从简单（易部署）到复杂（高性能）的一系列策略选择。
    - POMDP策略可以**快速为不同的成本预算（λ）重新计算策略**，无需重新训练。
    - 框架不局限于数学推理，任何能提供步骤级正确性估计的领域（如使用模型自评分的科学问答）均可应用。

### **总结**
**TRIM的核心创新在于通过“步骤级路由”这一范式转变，实现了对大模型计算资源的“外科手术式”精准投放。** 它解决了多步推理中资源分配不均的痛点，将成本从“为整个问题付费”转变为“只为关键纠错付费”，在保证高性能的同时，实现了数量级级别的成本效率提升，并为实际部署提供了灵活、鲁棒且可泛化的解决方案。这项工作为下一代高效LLM推理系统的设计指明了重要方向。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文针对多步推理任务（如数学解题）中传统查询级路由方法效率低下的问题，提出了一种名为TRIM的**步级路由框架**。其核心思想是：推理过程中的错误往往集中在少数关键步骤，只需在这些步骤上调用昂贵的大模型进行干预，即可有效防止错误级联，而让廉价的小模型处理常规步骤。论文设计了从简单的基于阈值的策略到考虑长期权衡的强化学习策略和部分可观测马尔可夫决策过程（POMDP）策略等多种路由方法。实验表明，该方法在MATH-500和AIME等数学推理基准测试上取得了显著效果，例如，最简单的阈值策略就能实现比现有方法高5倍的成本效率，而更高级的策略仅使用20%的大模型令牌就能达到与大模型相当的性能，并且展现出良好的跨数据集泛化能力。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## TRIM论文的创新点分析

这篇论文针对多步推理任务中的大语言模型（LLM）混合推理问题，提出了**TRIM（Targeted Stepwise Routing）**框架。其核心创新在于**从查询级路由转向步骤级路由**，并围绕这一核心设计了一系列方法与策略。以下是其相对于已有工作的明确创新点：

---

### 1. **核心范式创新：从查询级路由到步骤级路由**
- **改进/不同之处**：
    - **以往方法**（如RouteLLM、AutoMix、Smoothie）采用**查询级路由**：将整个问题（查询）分配给一个模型（大模型或小模型）负责生成**全部**答案。
    - **TRIM** 采用**步骤级路由**：将多步推理分解为单个步骤，在**每个步骤生成时**动态决定是接受小模型的输出，还是将该步骤**重新生成**（escalate）给大模型。
- **解决的问题/带来的优势**：
    - **解决效率低下问题**：传统方法假设整个查询的难度均匀，导致要么过度使用大模型（成本高），要么小模型在关键步骤出错导致整个答案失败。TRIM识别并仅干预**关键步骤**（易出错、会导致后续推理崩溃的步骤），将昂贵的大模型调用限制在真正必要的地方。
    - **实现成本-性能的帕累托改进**：实验表明，即使最简单的阈值策略（TRIM-Thr）也能比现有方法实现**5倍**的成本效率提升，而更高级的策略仅用大模型**20%**的token就能达到接近大模型单独使用的性能。

### 2. **利用过程奖励模型进行实时步骤评估与决策**
- **改进/不同之处**：
    - **以往方法**：过程奖励模型主要用于事后验证、候选排序或探索 shaping（例如，在波束搜索中筛选解决方案）。
    - **TRIM**：将PRM**深度集成到生成过程中**，作为**路由决策的核心信号**。在每一步，PRM实时评估当前已生成轨迹（包括新步骤）的质量，输出步骤级正确性分数，供路由器判断是否需要升级到大模型。
- **解决的问题/带来的优势**：
    - **实现细粒度、自适应的干预**：能够实时检测推理轨迹是否“偏离正轨”，并在错误刚发生时进行精准纠正，防止错误累积（cascading failures）。
    - **提供了可操作的步骤难度表征**：PRM分数作为步骤难度的代理，使得路由器能够基于数据而非启发式规则进行决策。

### 3. **设计了一系列从简单到复杂的步骤级路由策略**
论文没有局限于单一策略，而是提出了一个策略谱系，以适应不同约束和需求：

#### **3.1 TRIM-Thr：基于阈值的近视策略**
- **改进/不同之处**：虽结构简单，但**应用层面新颖**。它将类似推测解码中的“接受/拒绝”机制，**适配并系统化应用于成本约束下的路由问题**，通过调整阈值来直接控制成本-性能权衡曲线。
- **优势**：实现简单、计算开销极低，且已能大幅超越复杂的查询级路由方法，为实际部署提供了一个强基线。

#### **3.2 TRIM-Seq/TRIM-Agg：基于强化学习的非近视策略**
- **改进/不同之处**：
    - **超越近视决策**：TRIM-Thr仅根据当前步骤的PRM分数决策。RL策略（TRIM-Seq和TRIM-Agg）则考虑**整个推理轨迹的历史信息**（如历史分数序列或聚合统计量如最小分数），进行**长视野规划**。
    - **优化目标**：RL策略显式优化一个包含最终任务奖励和大模型token成本的综合目标函数，从而学习在长期收益和即时成本间取得平衡的策略。
- **解决的问题/带来的优势**：
    - **解决“何时干预性价比最高”的问题**：例如，即使当前步骤分数低，但如果历史轨迹已严重错误（不可恢复），则不值得花费成本升级。RL策略能学会此类高级决策。
    - **TRIM-Agg** 使用聚合特征（当前分数、历史最小分数、步骤长度、步骤索引），在几乎不损失性能的前提下大幅提升训练速度，更具实用性。

#### **3.3 TRIM-POMDP：基于部分可观测马尔可夫决策过程的策略**
- **改进/不同之处**：
    - **显式建模PRM的不确定性和噪声**：这是最根本的改进。TRIM-POMDP不将PRM分数视为真实状态，而是将其视为对**潜在真实正确性状态**（如“轨迹至今正确”、“最近一步错误但可恢复”、“已不可恢复”）的**噪声观测**。
    - **学习观测函数**：通过在有步骤级标注的数据集上训练，学习PRM分数在给定真实状态下的分布，从而量化其不确定性。
- **解决的问题/带来的优势**：
    - **解决PRM不完美带来的决策风险**：在PRM校准差或噪声大的场景下（如在更难的AIME数据集上），POMDP方法通过维护一个对真实状态的**置信度**来进行决策，表现出更强的**鲁棒性**。
    - **策略可快速重计算**：POMDP的紧凑表述允许使用标准求解器（如SARSOP）为不同的成本预算（λ）快速重新计算最优策略，无需重新训练RL模型，**灵活性高**。
    - **在低预算 regime 表现卓越**：实验显示，在严格成本限制下，TRIM-POMDP优于RL策略，因为后者在稀疏奖励环境下难以训练，而POMDP规划不受此影响。

### 4. **证明了步骤级难度模式的跨数据集泛化性**
- **改进/不同之处**：
    - **以往查询级路由器**：容易过拟合到特定数据集的表面特征（如问题表述风格、长度），导致在分布外数据集上泛化性能急剧下降（论文中BERT路由器的Δ_IBC从AIME的0.44降至OlympiadBench的-0.04）。
    - **TRIM**：其决策基于**推理过程中动态产生的步骤级正确性信号**，这反映了多步推理中**固有的、可转移的失败模式**（如特定类型的数学变换易出错）。
- **解决的问题/带来的优势**：
    - **提升实用性与部署便利性**：在一个数据集（如AIME）上训练的TRIM-Agg路由器，无需微调即可在相似难度的其他数学推理数据集（如OlympiadBench、Minerva Math）上保持高性能。这降低了获取大量标注数据的需求，表明TRIM捕捉到了**任务本质的结构**。

### 5. **系统与成本模型的务实设计**
- **改进/不同之处**：
    - **成本定义**：论文将成本明确定义为**大模型生成的解码token数量**，并论证预填充成本可通过并行化技术（类似推测解码）摊销，而解码token成本是不可避免的序列成本。这抓住了推理效率的**主要瓶颈**。
    - **动作设计**：`regenerate`动作仅让大模型**重新生成当前步骤**，之后控制权立即交还小模型。这与“一旦升级，大模型接管剩余所有步骤”的直觉设计不同。
- **解决的问题/带来的优势**：
    - **聚焦核心优化目标**：使效率提升的度量清晰且可操作。
    - **实证支持的动作设计**：通过消融实验证明，仅纠正关键步骤后交还控制权，比大模型完全接管**成本效率高得多**。这验证了多步推理中“**少数关键步骤决定全局成败**”的洞察，干预需要精准而非泛滥。

---

## 总结
TRIM的核心创新在于**将混合推理的粒度从“查询”细化到“步骤”**，并围绕这一思想构建了一套完整的技术体系。它通过**PRM实时评估、多策略路由决策、显式不确定性建模**，解决了传统方法在**多步推理任务上资源分配粗糙、效率低下、泛化性差**的核心问题。最终在多个数学推理基准上实现了**数量级级别的成本效率提升**，同时保持了强大的性能，为LLM的高效实际部署提供了有前景的新范式。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 论文实验与评估效果总结

### 一、 核心实验效果
TRIM 在**多步数学推理任务**中，通过**步骤级路由**，实现了**显著的成本效率提升**，同时保持或接近强模型（昂贵模型）的性能。其核心效果是：**仅使用少量昂贵模型生成的令牌（Token），即可恢复强模型与弱模型之间的大部分性能差距**。

### 二、 使用的数据集
论文在多个具有挑战性的数学推理基准上进行了评估：
1.  **MATH-500** (Hendrycks et al., 2021): 从MATH数据集中选取的500个测试问题。
2.  **AIME** (Di Zhang, 2025): 美国数学邀请赛题目，难度更高。
3.  **OlympiadBench** (He et al., 2024): 奥林匹克级别的双语多模态科学问题。
4.  **Minerva Math**: 另一个数学推理数据集（用于交叉数据集泛化测试）。
5.  **GPQA-DIAMOND** (附录F): 用于验证TRIM在**非数学领域**（生物、物理、化学）的泛化能力。

### 三、 评价指标
论文采用了多种指标来全面衡量**性能-成本权衡**：
1.  **性能恢复率 (PGR)**: 衡量路由策略恢复强模型(`M_s`)与弱模型(`M_w`)之间性能差距的比例。
    ```math
    \mathrm{PGR}(\pi) = \frac{r(\pi) - r(M_w)}{r(M_s) - r(M_w)}
    ```
2.  **成本-性能阈值 (CPT)**: 达到特定PGR目标（如50%， 80%， 95%）所需的**最小成本**。成本定义为**昂贵模型(`M_s`)生成的令牌数**。论文同时报告了绝对令牌数(`C¯`)和相对于始终使用`M_s`的归一化比例(`c`)。
3.  **单位成本增量收益 (ΔIBC)**: 衡量相对于基线（始终使用`M_s`）的**相对成本效率提升**。正值表示比单独使用强模型更高效。
    ```math
    \Delta_{\text{IBC}}(\pi) = \frac{\text{IBC}(\pi) - \text{IBC}_{\text{Base}}}{\text{IBC}_{\text{Base}}}
    ```
4.  **预算准确率**: 在固定昂贵模型令牌预算（如10%， 20%）下的任务准确率。

### 四、 对比的基线方法
论文与多种先进的**查询级路由**方法进行了对比：
1.  **RouteLLM** (Ong et al., 2024) 系列:
    - **BERT**: 基于BERT编码器的分类器。
    - **矩阵分解 (MF)**。
    - **滑动窗口排序 (SW Ranking)**。
2.  **Smoothie** (Guha et al., 2024): 无监督、基于嵌入的隐变量高斯模型。
3.  **AutoMix** (Aggarwal et al., 2023): 基于POMDP的自验证路由。
    - **AutoMix-PRM**: 论文改进版，用PRM分数替代原版的自验证信号，性能更强。

### 五、 关键性能结果与结论
#### 1. **成本效率大幅提升**
- **在MATH-500上**:
    - **最简单的TRIM-Thr策略**就比最好的查询级基线（AutoMix-PRM）成本效率高 **4.75倍** (`ΔIBC`: 4.75 vs 0.95)。
    - **TRIM-Agg 和 TRIM-POMDP** 仅使用 **~20%** 的昂贵模型令牌，即可达到强模型(`M_s`) **95%** 的性能恢复率 (`PGR=95%`)。这相当于用 **80%** 的令牌节省实现了近乎顶级的性能。
- **在更难的AIME上**:
    - TRIM-POMDP实现了高达 **6.33倍** 的成本效率 (`ΔIBC=6.33`)，TRIM-Agg也达到 **2.50倍**。

#### 2. **性能-成本曲线全面领先**
- 如图6所示，所有TRIM变体（Thr, Agg, POMDP）的**性能-成本曲线**都显著优于所有查询级路由基线，更接近理论上的“理想查询级路由Oracle”前沿。
- **TRIM-POMDP** 在**低预算（高λ）**  regime表现尤其出色，因其能进行长远规划并处理PRM估计的不确定性。
- **TRIM-Agg** 在**高预算（低λ）** regime表现最佳，RL训练在此环境下更有效。

#### 3. **卓越的跨数据集泛化能力**
- 在AIME上训练的TRIM-Agg策略，**直接迁移**到OlympiadBench和Minerva Math上，仍能保持极高的成本效率 (`ΔIBC` 分别为2.57和3.12)。
- 相比之下，查询级路由方法（如BERT、SW Ranking）**泛化性很差**，在跨数据集测试时`ΔIBC`大幅下降甚至为负。这表明TRIM捕捉到的是**多步推理中步骤难度的本质特征**，而非数据集特定表象。

#### 4. **对PRM噪声的鲁棒性**
- **TRIM-POMDP** 通过显式建模PRM分数作为潜在正确状态的**噪声观测**，对PRM的误校准和噪声具有**内在鲁棒性**。
- **TRIM-Agg** 通过RL训练也能**隐式学习**处理PRM噪声，在噪声PRM下性能衰减远小于简单的TRIM-Thr（见表8）。

#### 5. **实际延迟与吞吐量优势**
- 附录A的延迟分析表明，借助推测解码等系统优化，**TRIM的端到端推理速度可以比单独运行强模型更快**（最高达2.75倍加速），因为其大幅减少了昂贵模型的顺序解码令牌数。

#### 6. **超越数学领域的泛化**
- 在GPQA-DIAMOND（科学QA）上，使用模型自评分为步骤正确性信号，TRIM-Thr仍能有效工作，在仅使用62%昂贵令牌的情况下达到`PGR=95%`，证明了其**框架的通用性**。

### 总结
**TRIM通过步骤级的路由决策，实现了多模型推理范式的根本性效率突破。** 其实验结果表明：
- **效果显著**：以极低的额外成本（少量昂贵模型令牌）拦截关键错误步骤，防止错误级联，从而用“四两拨千斤”的方式大幅提升解决方案成功率。
- **全面领先**：在多个指标和数据集上，均大幅优于现有的查询级路由SOTA方法。
- **实用性强**：策略简单有效（如Thr），高级策略（Agg, POMDP）性能接近理论极限，且具备良好的泛化性和鲁棒性，为实际部署提供了高效、灵活的解决方案。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2601.10245v1)
- [HTML 版本](https://arxiv.org/html/2601.10245v1)
