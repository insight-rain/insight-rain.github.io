# Efficient On-Board Processing of Oblique UAV Video for Rapid Flood Extent Mapping

**相关性评分**: 6.0/10

**排名**: #25


---


## 基本信息

- **arXiv ID**: [2601.11290v1](https://arxiv.org/abs/2601.11290v1)
- **发布时间**: 2026-01-16T13:41:56Z
- **相关性评分**: 6.0/10
- **是否相关**: 是

## 作者

Vishisht Sharma, Sam Leroux, Lisa Landuyt, Nick Witvrouwen, Pieter Simoens

## 关键词

Inference Efficiency, Inference Acceleration, Edge Deployment

## 一句话总结

该论文提出了一种名为Temporal Token Reuse的自适应推理框架，通过利用空中视频的时空冗余性，在嵌入式设备上加速视频分割，以提高边缘部署的推理效率。

## 摘要

Effective disaster response relies on rapid disaster response, where oblique aerial video is the primary modality for initial scouting due to its ability to maximize spatial coverage and situational awareness in limited flight time. However, the on-board processing of high-resolution oblique streams is severely bottlenecked by the strict Size, Weight, and Power (SWaP) constraints of Unmanned Aerial Vehicles (UAVs). The computational density required to process these wide-field-of-view streams precludes low-latency inference on standard edge hardware. To address this, we propose Temporal Token Reuse (TTR), an adaptive inference framework capable of accelerating video segmentation on embedded devices. TTR exploits the intrinsic spatiotemporal redundancy of aerial video by formulating image patches as tokens; it utilizes a lightweight similarity metric to dynamically identify static regions and propagate their precomputed deep features, thereby bypassing redundant backbone computations. We validate the framework on standard benchmarks and a newly curated Oblique Floodwater Dataset designed for hydrological monitoring. Experimental results on edge-grade hardware demonstrate that TTR achieves a 30% reduction in inference latency with negligible degradation in segmentation accuracy (< 0.5% mIoU). These findings confirm that TTR effectively shifts the operational Pareto frontier, enabling high-fidelity, real-time oblique video understanding for time-critical remote sensing missions

## 详细分析

## 论文摘要：面向快速洪水范围测绘的无人机倾斜视频高效机载处理

### 1. 研究背景和动机
无人机在灾害响应等任务中广泛应用，其拍摄的**倾斜视频**能最大化空间覆盖和态势感知。然而，无人机严格的**尺寸、重量和功耗（SWaP）** 限制严重制约了高分辨率视频流的实时机载处理。现有深度学习模型逐帧暴力计算，未能有效利用视频中固有的**时空冗余**（如大面积的静态天空、水体），导致在边缘设备上延迟高、能耗大，无法满足灾情快速测绘等时效性任务的需求。

### 2. 核心方法和技术创新
本文提出了**时序令牌重用（Temporal Token Reuse, TTR）** 框架，一种用于嵌入式设备的自适应视频分割加速方法。其核心创新在于：
- **动态识别与重用**：将图像划分为块（令牌），使用轻量级的**余弦相似度度量**动态比较连续帧间的对应图像块。若相似度超过阈值，则判定该区域为静态，直接重用上一帧计算好的深层特征，**绕过冗余的主干网络计算**。
- **高效上下文保持**：通过改进的 **BlockSkip 模块**，在稀疏处理时从缓存或当前计算中为动态块填充邻域特征，确保卷积操作能获得正确上下文，避免拼接伪影。
- **CNN 基础与实用导向**：基于 **SegBlocks** 等高效的卷积神经网络（CNN）架构构建，而非计算复杂度高的 Transformer，确保了在功耗受限硬件上的实际部署可行性。

### 3. 主要实验结果
在多个数据集和硬件平台（NVIDIA GTX 1080 Ti 和 Jetson Orin Nano）上验证了 TTR 的有效性：
- **显著加速**：在自建的 **Floodwater 数据集**（针对洪水监测的倾斜视频）上，TTR 将 EfficientNet-B4 的推理速度提升了约 **67%**（从 30 FPS 到 50 FPS），在边缘设备上实现了从非实时（15 FPS）到实时（25 FPS）的关键跨越。
- **精度损失极小**：上述加速仅导致平均交并比（mIoU）下降 **<0.5%**，在 FloodNet 等标准灾害评估数据集上甚至能保持精度不变。
- **强泛化性**：在 UAVid（城市空中场景）和 A2D2（自动驾驶，高动态场景）数据集上的实验表明，TTR 能适应不同冗余度的场景，均带来显著速度提升。

### 4. 研究意义和价值
本研究通过 TTR 框架，成功地将**自适应计算**理念应用于无人机视频实时分析，**移动了精度与效率的帕累托前沿**。其价值在于：
- **实际应用突破**：使得高精度分割模型能够在资源严格受限的无人机平台上实现**实时、高保真**推理，直接服务于洪水快速制图、搜救等关键任务。
- **方法论贡献**：提供了一种轻量、鲁棒且无需复杂运动估计的时空冗余利用新范式，弥补了传统帧级跳过或光流方法在精细度和效率上的不足。
- **资源开放**：发布了新的 **Floodwater 数据集**和代码，促进了该领域的研究。

**总之，TTR 为在智能边缘设备上部署强大的实时感知系统提供了切实可行的解决方案，推动了高效计算机视觉在应急遥感等关键任务中的实际应用。**

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析

### **核心问题**
论文旨在解决**无人机（UAV）在机载实时处理高分辨率倾斜视频时面临的严峻计算瓶颈**。具体矛盾在于：
- **需求侧**：灾害响应（如洪水测绘）需要无人机快速侦察，提供大范围空间覆盖和实时态势感知，这依赖于高分辨率倾斜视频流。
- **限制侧**：无人机受严格的**尺寸、重量和功率（SWaP）** 约束，其机载边缘硬件（如Jetson）的计算能力有限，难以对高分辨率视频流进行低延迟的语义分割推理。

问题的根源是现有深度学习模型（如CNN、Transformer）的**“暴力”处理方式**：将每一帧都视为独立输入，对所有像素/区域进行完整计算，而忽略了视频中**巨大的时空冗余**（例如，天空、静止水体、建筑在连续数百帧中几乎不变）。这种冗余计算导致功耗高、延迟大，缩短了任务时间，无法满足关键任务的实时性要求。

### **核心创新点**
论文提出了 **“时序令牌重用”（Temporal Token Reuse, TTR）** 框架，这是一种**自适应的视频推理框架**，专门用于在嵌入式设备上加速视频语义分割。其创新性体现在：

1.  **思想创新：从“均匀计算”到“自适应计算”**
    - 摒弃了对每一帧所有区域进行均匀处理的范式，转而根据**场景的时空动态性**智能分配计算资源。
    - 核心原则：**只为发生变化的区域（动态区域）重新计算深度特征，对静态区域则重用之前计算好的特征**。

2.  **方法创新：轻量级时序冗余检测与特征缓存**
    - **将图像块视为令牌（Token）**：基于SegBlocks框架，将输入图像划分为块（Patch）。
    - **轻量级相似性度量**：使用计算成本极低的**余弦相似度**，比较当前帧与上一帧对应图像块（原始RGB）的相似性。
        ```python
        # 核心判断逻辑
        if cosine_similarity(patch_t, patch_{t-1}) > threshold τ:
            标记为 REDUNDANT (冗余/静态) -> 重用特征
        else:
            标记为 ACTIVE (活跃/动态) -> 重新计算特征
        ```
    - **深度特征缓存与重用**：为每一网络层维护一个**特征缓存**。对于标记为“冗余”的块，直接从缓存中提取上一帧对应位置的特征，**完全绕过CNN主干网络**在该块上的计算。
    - **BlockSkip模块**：为了解决稀疏处理（部分块被跳过）导致的上下文丢失和边界伪影问题，TTR引入了BlockSkip模块。它在处理“活跃”块时，从其邻居（包括“活跃”和“冗余”块）复制或提取特征来构建局部感受野，确保标准卷积层能正常运作，保持分割质量。

### **解决方案的流程**
1.  **输入**：视频流序列。
2.  **分块与相似性检测**：对每一帧分块，并与上一帧缓存中的对应块进行余弦相似度比较。
3.  **生成稀疏掩码**：根据阈值τ，为每个块生成“活跃”或“冗余”标签。
4.  **自适应前向传播**：
    - “活跃”块：送入CNN主干网络进行计算，生成新特征，并**更新特征缓存**。
    - “冗余”块：**跳过CNN计算**，直接从上一帧的特征缓存中读取特征。
    - 通过BlockSkip模块整合新旧特征，保持空间连贯性。
5.  **输出**：组装完整的特征图，生成当前帧的语义分割掩码。
6.  **循环**：当前帧的特征缓存成为下一帧的“上一帧缓存”。

### **实际价值与效果**
- **性能提升**：在边缘级硬件（NVIDIA Jetson Orin Nano）上，TTR将**推理速度提升了约30%**（例如，EfficientNet-B4从15 FPS提升至25 FPS），而分割精度损失极小（**mIoU下降 <0.5%**）。
- **推动实际应用**：使得原本在边缘设备上无法实时运行的高精度模型（如EfficientNet-B4）进入了可用的实时窗口（>20 FPS），**使无人机能够进行高保真、低延迟的实时洪水范围测绘**，直接支持灾害应急响应。
- **提供新基准**：论文发布了一个新的**倾斜视角洪水数据集（Floodwater Dataset）**，使用SAM2生成伪标签，填补了该领域高质量视频标注数据的空白。
- **通用性与鲁棒性**：方法不仅在洪水数据集上有效，在城市场景（UAVid）和自动驾驶场景（A2D2）中也表现出稳定的加速效果，证明了其**对不同程度时空冗余的自适应能力**。

**总结**：TTR框架的核心创新在于，通过一种**轻量、优雅的机制**，将**空间自适应计算**的思想成功**扩展到了时间维度**，巧妙地利用了视频数据中最丰富的冗余源——**时间静态性**，从而在严格受限的边缘计算平台上，实现了精度与效率的帕累托前沿的实质性推进。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文旨在解决无人机（UAV）在**尺寸、重量和功耗（SWaP）严格受限**的边缘设备上，实时处理高分辨率倾斜视频进行语义分割（如洪水范围测绘）时面临的**计算瓶颈**。核心矛盾在于视频数据存在巨大的时空冗余，而现有深度神经网络却对每一帧进行“一刀切”的暴力计算，导致效率低下、延迟高。

为此，论文提出了 **Temporal Token Reuse (TTR)** 框架。该方法将图像划分为块（token），利用轻量级的**余弦相似度度量**动态识别连续帧之间未发生变化的静态区域。对于这些冗余区域，TTR直接**重用上一帧已计算的深层特征**，从而绕过主干网络的重复杂计算；仅对发生变化的动态区域执行完整的网络前向传播。该方法基于CNN架构（如EfficientNet）并集成了SegBlocks的块处理机制，以确保空间上下文完整性。

实验结果表明，在边缘级硬件（如Jetson Orin Nano）上，TTR能在**几乎不损失分割精度（mIoU下降<0.5%）** 的前提下，将推理速度提升**最高约30%**（例如从15 FPS提升至25 FPS），显著推动了精度与效率的帕累托前沿，使得高精度模型在资源受限的无人机平台上实现实时视频理解成为可能。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文创新点分析

这篇论文《Efficient On-Board Processing of Oblique UAV Video for Rapid Flood Extent Mapping》的核心创新在于提出了 **Temporal Token Reuse (TTR)** 框架，旨在解决无人机（UAV）上实时处理高分辨率倾斜视频所面临的严格计算资源（SWaP）限制问题。以下是其相对于已有工作的明确创新点：

---

### 1. **提出“时域令牌重用”框架，将空间自适应计算扩展至时域**
   - **相比以往方法的改进/不同之处**：
     - **以往方法（空间动态计算）**：如SBNet、SegBlocks、动态ViT等，主要关注**单帧图像内部**的空间稀疏性，通过选择性处理图像块或动态调整网络深度来节省计算。它们为每一帧**重新评估**所有区域的计算需求。
     - **以往方法（时域方法）**：如基于关键帧的方法或光流特征传播，通常在**整帧级别**进行操作。关键帧方法可能错过瞬态事件，而光流计算本身开销大且易受纹理缺失、遮挡等影响。
     - **本文TTR**：将图像分割为**块（令牌）**，并引入一个**轻量级的时域相似性度量**（余弦相似度）。它在**块级别**动态识别哪些区域在连续帧间是静态的，并**重用**这些静态块在上一帧中已计算的深度特征，从而完全跳过对这些区域的主干网络计算。
   - **解决的具体问题/带来的优势**：
     - **解决了问题**：传统方法无法有效利用视频中**巨大的时域冗余**（无人机视频中大部分背景区域长时间静止）。整帧处理或粗糙的时域方法要么计算浪费，要么可能丢失细节或引入误差。
     - **核心优势**：
       1. **细粒度自适应**：计算节省发生在**块级别**，允许系统在**同一帧内**同时高效处理静态背景和精细追踪动态目标（如洪水前沿、车辆）。
       2. **低开销决策**：使用简单的余弦相似度比较原始像素块，避免了计算昂贵的光流估计或复杂的策略网络。
       3. **保持高精度**：通过**BlockSkip模块**（改进自SegBlocks的BlockCopy）确保重用块与重新计算块边界处的上下文连贯性，避免了拼接伪影，使mIoU下降极小（<0.5%）。

### 2. **设计了一种专为时域重用优化的“块跳过”机制**
   - **相比以往方法的改进/不同之处**：
     - **SegBlocks的BlockCopy**：主要为处理**空间**上不同分辨率的块而设计，通过复制或上采样邻居块特征来为当前处理块构建完整的感受野。
     - **本文的BlockSkip**：在BlockCopy基础上进行了**关键修改**，以支持**时域特征重用**。当为当前活动块构建填充区域时，如果邻居块被标记为“冗余”，则**直接从上一帧的对应层特征缓存中**获取该邻居块的特征，而不是从当前帧的计算图中获取。
   - **解决的具体问题/带来的优势**：
     - **解决了问题**：在稀疏处理（部分块跳过）的CNN中，卷积操作在块边界需要邻居的上下文信息。如果邻居块未被计算，其信息缺失会导致特征不连续和分割质量下降。
     - **核心优势**：**无缝融合了新旧特征**。它允许标准卷积层在由“新计算特征”和“缓存重用特征”混合组成的稀疏特征图上正常操作，从而**保持了分割掩码的空间一致性和高保真度**，这是实现高精度下高加速比的关键。

### 3. **构建并开源了一个面向洪水监测的倾斜视频数据集**
   - **相比以往方法的改进/不同之处**：
     - **现有数据集局限**：论文指出，现有UAV数据集（如FloodNet）多为**正射（nadir）图像**或缺乏密集的逐帧视频标注。而实际无人机侦察多采用**倾斜视角**以获得更好的空间覆盖和态势感知。标注高分辨率视频成本极高。
     - **本文的Floodwater数据集**：收集了30段比利时弗兰德斯地区洪水场景的**真实倾斜视角UAV视频**（720p至4K），并利用**Segment Anything Model 2 (SAM2)** 在半监督框架下生成密集的像素级伪标签（主要是水/非水二分类）。
   - **解决的具体问题/带来的优势**：
     - **解决了问题**：填补了用于开发和评估**实时、倾斜视角UAV视频分割算法**的公开基准数据集的空白。
     - **核心优势**：
       1. **领域针对性**：数据特性（高分辨率、倾斜视角、大静态区域）与TTR旨在解决的计算挑战高度吻合，使评估更贴近实际应用。
       2. **促进相关研究**：公开该数据集有助于推动无人机应急响应领域，特别是洪水快速制图的研究。

### 4. **在CNN主干网上实现时域自适应，做出务实的设计选择**
   - **相比以往方法的改进/不同之处**：
     - **主流趋势**：当前许多高效计算和自适应方法的研究围绕**Vision Transformer**展开，利用其令牌化特性进行动态令牌选择、合并等。
     - **本文的选择**：作者**明确选择基于CNN**（如ResNet, EfficientNet）构建TTR，而非Transformer。
   - **解决的具体问题/带来的优势**：
     - **解决了问题**：Transformer的自注意力机制具有二次复杂度，对于机载设备实时处理高分辨率视频**计算负担过重**。尽管其令牌化思想与TTR的“块”概念契合，但底层架构不切实际。
     - **核心优势**：**务实性与可行性**。CNN拥有更成熟的轻量化设计（如深度可分离卷积）和丰富的边缘部署优化经验。通过结合SegBlocks，CNN也能获得类似Transformer的**块级处理能力**。这一选择确保了TTR框架能够在**真实的、资源受限的UAV硬件**（如Jetson Orin Nano）上实现部署，体现了从研究到实际应用的桥梁作用。

### 5. **通过动态计算负载验证了与场景运动的高度自适应关联**
   - **相比以往方法的改进/不同之处**：
     - **常见评估**：多数高效方法仅报告平均FPS或FLOPs节省。
     - **本文的深入分析**：论文绘制了**模型计算负载（FLOPs）与帧间光流幅度**的随时间变化曲线，并计算了高皮尔逊相关系数（>0.8）。
   - **解决的具体问题/带来的优势**：
     - **解决了问题**：定量证明了TTR的加速不是固定的，而是**智能动态的**。
     - **核心优势**：**强有力地证实了机制有效性**。这表明TTR的轻量级相似性度量是场景动态变化的有效代理，能够使计算资源分配与场景实际运动紧密同步。在静态阶段（如无人机悬停）最大化节省，在动态阶段（如快速转弯、目标出现）自动增加计算以保持精度，从而在系统层面实现**能效最大化**，延长无人机任务时间。

---

**总结**：本文的核心创新**TTR框架**，其本质是提出了一种**轻量级、细粒度、基于块的时域特征缓存与重用机制**。它巧妙地将空间自适应计算的思想延伸至时间维度，并针对无人机边缘计算的实际约束（CNN主干、低开销决策、上下文保持）进行了精心设计。相较于以往或侧重空间、或侧重时域但较为粗糙的方法，TTR在**精度保持、计算效率、实用部署性**之间取得了更优的平衡，为解决无人机视频实时分析这一关键难题提供了新颖且有效的解决方案。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 论文实验与评估效果分析

该论文通过详尽的实验，系统性地评估了所提出的**Temporal Token Reuse (TTR)** 框架在多个数据集和硬件平台上的性能。实验结果表明，TTR在保持高分割精度的同时，显著提升了推理速度，验证了其在资源受限的边缘设备（如无人机）上进行实时视频语义分割的有效性。

### 一、 使用的数据集
论文使用了四个数据集，覆盖了从目标应用到通用场景的评估：
1.  **Floodwater Dataset (新构建)**：论文贡献的新数据集。包含30段比利时洪水区域的**高分辨率（720p至4K）倾斜视角无人机视频**，用于模拟真实的洪水侦察场景。该数据集具有显著的时空冗余性，是TTR框架的主要目标应用场景。
2.  **FloodNet Dataset**：标准的灾后损害评估基准数据集（图像集）。用于验证TTR方法在识别“淹没建筑”、“淹没道路”等关键灾害特征时的**语义鲁棒性**，确保效率提升不以牺牲关键任务精度为代价。
3.  **UAVid Dataset**：无人机城市场景语义分割视频数据集。包含8个类别（建筑、道路、植被、车辆等），场景复杂，用于测试TTR在**密集、动态的城市场景**中的泛化能力。
4.  **A2D2 Dataset**：车载自动驾驶数据集。作为**压力测试**，其持续的相机运动和低冗余度环境用于检验TTR在高度动态场景下的适应性和极限性能。

### 二、 评价指标
论文采用了两类核心评价指标：
*   **分割精度**：
    *   **平均交并比 (mIoU)**：主要精度指标，衡量模型在每个类别上预测区域与真实区域重叠度的平均值。
    *   **像素精度 (Pixel Accuracy)**：辅助精度指标，计算所有像素中被正确分类的比例。
*   **计算效率**：
    *   **帧率 (FPS)**：核心效率指标，衡量在特定硬件上每秒能处理的帧数。这是实现实时处理的关键。
    *   **计算负载分析**：通过分析FLOPs（浮点运算数）与场景动态性（以光流幅值为代理）的相关性，来验证TTR的自适应行为。

### 三、 对比的基线方法
论文设定了两个层次的对比：
1.  **不同架构的先进模型对比**：将集成TTR后的最终模型与当前先进的模型进行对比，以定位其性能。
    *   **SegFormer-B0**：代表先进的轻量级**Transformer**模型。
    *   **BiSeNetV2** 和 **MobileNetV3**：代表为**实时边缘计算**精心设计的轻量级CNN模型。
2.  **TTR集成效果对比**：为了直接证明TTR的贡献，论文将其集成到两个经典CNN主干网络上，并与它们的原始版本（密集处理）进行对比。
    *   **EfficientNet-B4**：高效且精度较高的CNN架构。
    *   **ResNet-50**：广泛使用的经典CNN架构。

### 四、 关键性能提升与结论
实验在**NVIDIA GTX 1080 Ti（桌面级）** 和 **NVIDIA Jetson Orin Nano（边缘设备）** 两个硬件平台上进行，主要结论如下：

#### 1. 在目标应用（洪水监测）上效果显著
*   **Floodwater Dataset**:
    *   **EfficientNet-B4 + TTR** 在Jetson Orin Nano上实现了 **1.67倍加速**（从15 FPS提升至25 FPS），同时mIoU仅下降 **0.4%**（从78.0%降至77.6%）。
    *   这使得一个高精度模型从非实时（<30 FPS）进入了可部署的实时窗口。
*   **FloodNet Dataset**:
    *   TTR在保持**零精度损失**（mIoU均为62.1%）的前提下，仍能提供轻微的加速。这证明了TTR不会损害对关键灾害特征的识别能力。

#### 2. 在通用基准上表现出强大的泛化能力
*   **UAVid Dataset**:
    *   EfficientNet-B4 + TTR在1080 Ti上获得 **1.69倍加速**（32 FPS → 54 FPS），mIoU仅降0.3%。证明了其在复杂城市场景中有效区分静态与动态区域的能力。
*   **A2D2 Dataset (高压测试)**:
    *   即使在高度动态的车载场景下，EfficientNet-B4 + TTR仍实现了 **1.68倍加速**（25 FPS → 42 FPS），mIoU仅降0.3%。这证实了TTR能自适应地利用任何存在的冗余，而非仅适用于静态背景。

#### 3. 核心结论与价值
*   **效率-精度权衡的优化**：如图7所示，TTR将ResNet-50和EfficientNet-B4等较重模型的性能点推向了**帕累托前沿的右上方**（更高FPS，精度损失极小），使其帧率可与轻量级模型竞争，但精度更高。
*   **实现自适应计算**：如图8所示，TTR的计算负载（FLOPs）与场景动态性（光流）呈现**高度正相关（r > 0.8）**。这表明TTR能根据场景变化动态调整计算量：在静态场景（如无人机悬停）中大幅节省算力，在动态场景中则投入更多计算资源以保持精度。
*   **实际价值**：该框架使得在严格受**尺寸、重量和功耗（SWaP）** 限制的无人机平台上，部署高精度、高帧率的实时语义分割模型成为可能，这对于洪水应急测绘、搜救等时效性极强的任务具有重大意义。

**总结**：论文通过全面的实验证明，TTR框架能够在多种真实场景和硬件平台上，平均带来约 **30%的延迟降低（对应~1.6倍的FPS提升）**，而分割精度损失可忽略不计（**<0.5% mIoU**），成功地将自适应计算理念应用于无人机视频的实时处理中。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2601.11290v1)
- [HTML 版本](https://arxiv.org/html/2601.11290v1)
