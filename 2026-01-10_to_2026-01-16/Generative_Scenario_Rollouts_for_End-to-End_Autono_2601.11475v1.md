# Generative Scenario Rollouts for End-to-End Autonomous Driving

**相关性评分**: 8.0/10

**排名**: #1


---


## 基本信息

- **arXiv ID**: [2601.11475v1](https://arxiv.org/abs/2601.11475v1)
- **发布时间**: 2026-01-16T17:59:28Z
- **相关性评分**: 8.0/10
- **是否相关**: 是

## 作者

Rajeev Yasarla, Deepti Hegde, Shizhong Han, Hsin-Pai Cheng, Yunxiao Shi, Meysam Sadeghigooghari, Shweta Mahajan, Apratim Bhattacharyya, Litian Liu, Risheek Garrepalli, Thomas Svantesson, Fatih Porikli, Hong Cai

## 关键词

Vision-Language-Action Model, VLA for Robotics, Inference Efficiency, Lightweight Architecture, Inference Acceleration, Edge Deployment

## 一句话总结

这篇论文提出了一种名为GeRo的生成式场景推演框架，用于端到端自动驾驶，通过语言条件自回归生成实现高效的VLA模型推理和规划。

## 摘要

Vision-Language-Action (VLA) models are emerging as highly effective planning models for end-to-end autonomous driving systems. However, current works mostly rely on imitation learning from sparse trajectory annotations and under-utilize their potential as generative models. We propose Generative Scenario Rollouts (GeRo), a plug-and-play framework for VLA models that jointly performs planning and generation of language-grounded future traffic scenes through an autoregressive rollout strategy. First, a VLA model is trained to encode ego vehicle and agent dynamics into latent tokens under supervision from planning, motion, and language tasks, facilitating text-aligned generation. Next, GeRo performs language-conditioned autoregressive generation. Given multi-view images, a scenario description, and ego-action questions, it generates future latent tokens and textual responses to guide long-horizon rollouts. A rollout-consistency loss stabilizes predictions using ground truth or pseudo-labels, mitigating drift and preserving text-action alignment. This design enables GeRo to perform temporally consistent, language-grounded rollouts that support long-horizon reasoning and multi-agent planning. On Bench2Drive, GeRo improves driving score and success rate by +15.7 and +26.2, respectively. By integrating reinforcement learning with generative rollouts, GeRo achieves state-of-the-art closed-loop and open-loop performance, demonstrating strong zero-shot robustness. These results highlight the promise of generative, language-conditioned reasoning as a foundation for safer and more interpretable end-to-end autonomous driving.

## 详细分析

## 论文摘要：用于端到端自动驾驶的生成式场景推演

**论文标题**：Generative Scenario Rollouts for End-to-End Autonomous Driving

### 1. 研究背景和动机
当前，视觉-语言-动作（VLA）模型已成为端到端自动驾驶规划的有力工具。然而，现有方法主要依赖稀疏轨迹标注的模仿学习，未能充分利用其作为生成模型的潜力，且普遍存在**语言-动作监督稀疏、生成能力未充分利用、语言-动作错位**等问题。这导致模型在复杂、长尾场景下的鲁棒性和可解释性不足。为解决这些问题，本文提出了生成式场景推演框架（GeRo）。

### 2. 核心方法和技术创新
GeRo是一个即插即用的VLA模型训练框架，其核心创新在于**将自回归场景生成与规划任务统一**。主要方法分为两个阶段：
- **预训练阶段**：训练VLA模型将自车与交通参与者的动态编码为紧凑的潜在令牌，并通过规划、运动预测和视觉问答（VQA）任务的联合监督，实现文本与行为表征的对齐。
- **生成式场景推演阶段**：模型以语言（场景描述和自车动作问题）为条件，在潜在令牌空间中进行**自回归推演**，预测未来的令牌序列，进而解码为轨迹和语言回答。该阶段通过**推演一致性损失**（利用真实数据或伪标签）和**基于GRPO的强化学习**（融合碰撞避免、碰撞时间TTC和语言对齐等奖励）进行优化，确保了长时域推演的时序一致性与安全性。

### 3. 主要实验结果
在Bench2Drive和nuScenes基准测试上，GeRo取得了显著的性能提升：
- **闭环性能**：在Bench2Drive上，基于Qwen2.5VL的GeRo将驾驶分数和成功率分别提升了**+15.7**和**+26.2%**；基于ORION的GeRo进一步将成功率提升至**60.1%**，达到新的SOTA。
- **开环性能**：在nuScenes上，GeRo显著降低了轨迹L2误差（例如，GeRo (Qwen) 从0.96降至0.31）和碰撞率，并展现出强大的**零样本泛化能力**。
- **多能力评估**：在并道、超车、紧急制动等复杂驾驶技能上，GeRo相比基线模型有大幅提升，证明了其场景级推理的有效性。

### 4. 研究意义和价值
GeRo首次将**自回归生成式场景推演**与VLA规划模型相结合，通过语言锚定的时序推理，显著提升了端到端自动驾驶系统在复杂、动态环境中的**规划鲁棒性、安全性和可解释性**。该框架为构建更安全、更智能的自动驾驶系统提供了一种新的范式，强调了生成式、语言条件推理在实现可信赖自主决策中的核心价值。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析：Generative Scenario Rollouts for End-to-End Autonomous Driving

### **一、 论文旨在解决的核心问题**
当前基于**视觉-语言-动作（VLA）** 模型的端到端自动驾驶系统存在几个关键瓶颈：
1.  **语言-动作监督稀疏且错位**：现有数据集多为场景级描述，缺乏与驾驶动作时序绑定的细粒度语言标注，导致模型在复杂或长尾场景（如区分超车与并线）中表现脆弱。
2.  **生成能力未被充分利用**：现有VLA模型主要依赖模仿学习，仅使用真实轨迹进行规划，**忽视了其作为生成模型进行场景级推理和探索的潜力**。
3.  **语言描述与动作过程脱节**：现有语言监督多为“描述性”（发生了什么），而非“过程性”（如何发生），限制了模型对规划与执行所需过程性细节的理解。
4.  **语言-动作不一致**：指令与动作对通常在数据收集后生成，导致模型可能仅依赖视觉线索而忽略语言指令，产生“红灯加速”等错误。

### **二、 核心创新点：GeRo框架**
论文提出了 **Generative Scenario Rollouts (GeRo)**，一个即插即用的VLA模型训练框架。其核心创新在于**将自回归场景生成与运动规划统一**，实现语言引导的长时程、多智能体推理。

**主要创新体现在以下三个层面：**

1.  **创新的框架设计**：
    - **两阶段训练流程**：
        - **阶段一（预训练）**：训练VLA模型将自车和周围智能体的动态编码到**共享的潜在令牌空间**中。通过联合监督规划、运动预测和视觉问答任务，实现语言与行为表征的对齐。
        - **阶段二（场景推演）**：在潜在令牌空间中进行**语言条件下的自回归生成**。给定场景描述和自车动作问题，模型预测未来的潜在令牌和文本响应，以引导长时程推演。
    - **自回归场景推演机制**：模型能像生成文本一样，一步步“想象”并生成未来多帧的交通场景（包括自车轨迹、他车轨迹和语言描述），实现真正的**生成式规划**。

2.  **新颖的监督与优化方法**：
    - **推演一致性损失**：使用KL散度对齐推演预测的潜在分布与预训练模型的潜在分布，或使用真实轨迹进行模仿学习监督，以**缓解自回归生成中的误差累积和漂移问题**。
    - **集成强化学习（RL）的反馈**：引入基于GRPO的强化学习进行微调。设计了**新颖的奖励函数**，联合优化轨迹准确性和语言语义对齐：
        ```python
        # 奖励函数示例（概念）
        Reward = -碰撞惩罚 - (1/碰撞时间) - 语言预测损失
        ```
        这确保了生成的行为既安全（避撞、长TTC）又与语言意图一致。

3.  **增强的可解释性与交互性**：
    - **交互式视觉问答组件**：在推演过程中，模型能回答关于自车意图的场景特定问题（如“现在应该减速吗？”）。这**将自车意图用自然语言锚定**，极大增强了规划决策的可解释性，并提供了语言引导推理的机制。

### **三、 解决方案的运作原理**
1.  **输入**：多视角图像、场景描述、关于自车动作的问题。
2.  **编码**：视觉和文本编码器将输入投影到共享嵌入空间，LLM核心将其处理为紧凑的自车/智能体潜在令牌。
3.  **生成式推演**：
    - 模型以当前令牌、场景描述和问题为条件，**自回归地预测下一时间步的令牌**。
    - 这些令牌被解码为轨迹（规划头、运动预测头）和语言答案（LLM头）。
    - 预测的令牌被**反馈回模型**，结合更新后的问题，继续生成更未来的令牌，实现多步推演。
4.  **训练与优化**：通过**推演一致性损失**确保时序一致性，通过**GRPO强化学习损失**利用安全与语义奖励优化整体策略。

### **四、 实际价值与效果**
- **性能显著提升**：在Bench2Drive基准测试上，相较于基线模型（如Qwen2.5VL），**驾驶分数提升+15.7，成功率提升+26.2**。在nuScenes开环评估中，轨迹误差降低超过60%。
- **解决长尾场景**：通过生成式推演和语言引导，模型在**并线、超车、紧急制动**等复杂场景中的能力得到大幅提升（见表2）。
- **零样本泛化能力强**：在未见过的数据集（nuScenes）上评估仍保持优异性能，证明了其强大的泛化能力。
- **为更安全、可解释的自动驾驶奠定基础**：通过将生成式推理、语言对齐和强化学习结合，GeRo展示了如何构建一个不仅能“执行”还能“解释”和“想象”未来可能性的自动驾驶系统。

**总结**：GeRo的核心突破在于将VLA模型从一个被动的“轨迹预测器”转变为一个主动的“场景模拟器”，通过**生成式、语言锚定的自回归推演**，实现了更鲁棒、更可解释的端到端规划，有效解决了现有方法在语言-动作对齐和长时程推理方面的根本缺陷。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文针对当前端到端自动驾驶中视觉-语言-动作（VLA）模型存在的**语言-动作监督稀疏、生成能力未充分利用、语言-动作错位**等核心问题，提出了**GeRo（Generative Scenario Rollouts）**框架。该框架是一个即插即用的两阶段方法：首先通过预训练将车辆动态编码为与语言对齐的潜在令牌；然后，核心创新在于引入**语言条件化的自回归场景推演**，使模型能够基于场景描述和问题，在潜在空间中进行多步、一致的未来场景生成和规划，并结合**基于GRPO的强化学习**（融合碰撞、安全距离、语言对齐等奖励）来优化推演质量。实验表明，GeRo在Bench2Drive基准上显著提升了驾驶评分（+15.7）和成功率（+26.2），并在开环和闭环评估中均达到最先进水平，证明了其通过生成式、语言引导的推演实现更鲁棒、可解释自动驾驶的有效性。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文创新点分析

这篇论文《Generative Scenario Rollouts for End-to-End Autonomous Driving》提出的 **GeRo** 框架，在端到端自动驾驶的视觉-语言-动作模型领域，相对于已有工作有以下明确的创新点：

---

### 1. **首次将自回归场景推演与VLA模型规划统一**
- **改进/不同之处**： 现有VLA模型（如ORION、Qwen2.5VL）主要依赖模仿学习，根据稀疏的轨迹标注进行单步规划，**未充分利用其作为生成模型的潜力**进行多步、连贯的场景推理。GeRo则设计了一个“即插即用”的自回归推演框架，使VLA模型能够**联合执行规划并生成基于语言描述的未来多步交通场景**。
- **解决的问题/优势**： 解决了现有方法在**长时程规划**和**多智能体交互推理**上的不足。通过自回归地生成未来潜在token（代表自车和周围车辆的状态），模型能够进行更一致、更远见的决策，从而显著提升了在复杂、动态场景下的规划鲁棒性。

### 2. **提出结合模仿学习与强化学习的混合训练框架**
- **改进/不同之处**：
    - **模仿学习部分**： 除了使用真实轨迹监督，还引入了**基于模型的伪标签监督**。当真实标签不可用时，使用预训练VLA模型生成的潜在token作为参考目标，通过KL散度损失 (`ℒ_tc`) 来保证推演过程中的**时间一致性**，缓解了自回归生成中常见的误差累积和漂移问题。
    - **强化学习部分**： 引入了基于GRPO的强化学习微调阶段，并设计了一套新颖的奖励函数。
- **解决的问题/优势**：
    - **时间一致性损失**： 解决了长时程推演中预测结果逐渐偏离真实世界动态的问题，确保了多步预测的连贯性。
    - **GRPO与奖励函数**： 单纯模仿学习难以处理分布外数据和长尾场景。通过集成**碰撞避免**、**碰撞时间**和**语言对齐精度**等奖励，联合优化了轨迹的物理安全性和语义正确性。这使模型能探索更优策略，显著提升了在**紧急制动、让行**等安全关键场景以及**零样本泛化**中的性能。

### 3. **设计了交互式视觉问答组件以增强可解释性与语言对齐**
- **改进/不同之处**： 现有数据集的语言标注多为**描述性**（发生了什么），缺乏**过程性**（动作如何展开）。GeRo在场景推演过程中，持续引入关于自车意图的**问题-答案对**作为语言条件，并要求模型生成相应的文本回答。
- **解决的问题/优势**：
    - **解决语言-动作错位**： 传统方法中，语言指令常与视觉线索脱节（如“红灯停”却执行加速）。GeRo通过将自车动作显式地锚定在自然语言推理中，强制模型进行**语言 grounding**，确保了决策的语义可解释性。
    - **增强可解释性**： 为每个规划决策提供了伴随的文本推理（如图4所示），使自动驾驶系统的决策过程对人类而言更透明、更可信。

### 4. **作为即插即用框架，在多个先进基线上实现显著提升**
- **改进/不同之处**： GeRo不是一个全新的独立模型，而是一个**训练框架**，可以套用在不同的现有VLA模型（如Qwen2.5VL和ORION）之上。
- **解决的问题/优势**：
    - **普适性与有效性**： 证明了其创新方法的通用性。在Bench2Drive基准上，GeRo (Qwen) 相比基线将驾驶分数和成功率分别提升了+15.7和+26.2；GeRo (ORION) 在已经很强的ORION基线上仍能分别提升+4.16和+5.5%。
    - **综合性能领先**： 实验表明，该框架在**闭环驾驶**（驾驶分数、成功率、多能力评估）、**开环轨迹预测**（L2误差）以及**零样本跨数据集泛化**（nuScenes）上均达到了最先进水平，特别是在**超车、并道、紧急制动**等高级驾驶技能上优势明显。

---

## 总结
GeRo的核心创新在于**将VLA模型从“单步模仿者”转变为“多步生成式推理者”**。它通过**自回归场景推演**、**时间一致性约束**、**安全与语义对齐的强化学习**以及**交互式语言 grounding** 这四大支柱，系统性地解决了当前端到端自动驾驶在长时程规划、安全性、鲁棒性和可解释性方面的关键瓶颈。其作为即插即用框架的设计，也使得这些进步能够便捷地赋能于现有的先进模型。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 论文实验与评估效果总结

### 一、 使用的数据集与评价指标

#### 1. 数据集
- **主要训练与评估数据集**：**Bench2Drive**。这是一个基于CARLA模拟器的闭环端到端自动驾驶基准数据集。
    - 包含1000个片段（950个用于训练，50个用于开环验证）。
    - 每个片段约150米，涵盖多样化的交通场景。
    - 用于**闭环评估**（220条路线，44个交互场景）和**开环规划**。
- **开环规划补充数据集**：**nuScenes** 规划基准。
    - 包含28,000个样本（22k训练 / 6k验证）。
    - 用于评估轨迹预测的泛化能力。
- **语言数据来源**：
    - **ChatB2D** 数据集（与Bench2Drive结合）。
    - **DriveLM-nuScenes** 数据集。
    - 论文还生成了额外的场景描述和自车动作问答对，用于训练生成式场景推演。

#### 2. 评价指标
- **闭环评估指标（Bench2Drive）**：
    - **驾驶得分**：综合路线完成度和违规惩罚。
    - **成功率**：成功完成路线的比例。
    - **效率**：评估行驶速度。
    - **舒适度**：评估行驶平滑度。
    - **多能力**：评估五项高级城市驾驶技能（并线、超车、紧急制动、让行、交通标志遵守）。
- **开环评估指标**：
    - **轨迹L2误差**：预测轨迹与真实轨迹之间的平均L2距离（在1秒、2秒、3秒及平均时间点上）。
    - **碰撞率**：预测轨迹导致碰撞的比例。

### 二、 对比的基线方法
论文将GeRo框架应用于两个不同的VLA模型骨干，并与此前最先进的方法进行了全面对比。

#### 1. 主要对比模型
- **基于模仿学习的端到端规划器**：
    - **TCP-traj**、**ThinkTwice**、**DriveAdapter**、**AD-MLP**。
    - **UniAD**（Tiny和Base版本）。
    - **VAD**、**GenAD**、**MomAD**、**DriveTransformer-Large**。
- **基于视觉-语言-动作的模型**：
    - **Qwen2.5VL**：一个通用的多模态大语言模型，被适配用于运动规划。
    - **ORION**：一个统一的端到端VLA框架，将VLM推理与轨迹预测对齐。
    - **ORION (Qwen2.5VL)**：将ORION的原始语言模型替换为Qwen2.5VL的变体。

#### 2. GeRo的两种实现
- **GeRo (Qwen)**：在Qwen2.5VL-3B模型上应用GeRo框架。**不依赖高清地图**，仅使用导航指令和边界框、运动预测作为辅助监督。
- **GeRo (ORION)**：在ORION模型上应用GeRo框架。**利用了高清地图和更丰富的辅助信息**。

### 三、 关键性能提升与结论

#### 1. 闭环性能（Bench2Drive）
- **整体驾驶性能大幅提升**：
    - **GeRo (Qwen)** 相比基线 **Qwen2.5VL**：
        - **驾驶得分**：从 **63.9** 提升至 **79.6** (**+15.7**)。
        - **成功率**：从 **31.6%** 提升至 **57.8%** (**+26.2个百分点**)。
    - **GeRo (ORION)** 相比基线 **ORION**：
        - **驾驶得分**：从 **77.74** 提升至 **81.90** (**+4.16**)。
        - **成功率**：从 **54.62%** 提升至 **60.10%** (**+5.48个百分点**)。
    - **结论**：GeRo框架显著提升了两种骨干模型的闭环驾驶性能，即使在不依赖地图的Qwen骨架上也能达到接近或超过依赖地图的SOTA模型的水平。

- **多能力评估表现卓越**：
    - **GeRo (Qwen)** 相比基线 **Qwen2.5VL**，平均多能力得分从 **25.60%** 提升至 **61.98%** (**提升超过140%**)。
    - **GeRo (ORION)** 相比基线 **ORION**，平均多能力得分从 **54.72%** 提升至 **66.49%** (**+21.5%**)。
    - 在**超车**、**紧急制动**等关键技能上提升尤为显著（例如，GeRo (ORION)在超车上达到78.24%，紧急制动达到87.32%）。
    - **结论**：生成式场景推演和语言对齐极大地增强了模型在复杂、长尾场景下的推理和决策能力。

#### 2. 开环性能（nuScenes & Bench2Drive）
- **轨迹预测精度显著提高**：
    - 在nuScenes上，**GeRo (Qwen)** 相比基线 **Qwen2.5VL**：
        - **平均L2误差**：从 **0.96** 降至 **0.31** (**降低67.7%**)。
        - **平均碰撞率**：从 **0.60** 降至 **0.14** (**降低76.7%**)。
    - **GeRo (ORION)** 相比基线 **ORION**：
        - **平均L2误差**：从 **0.69** 降至 **0.27** (**降低60.9%**)。
        - **平均碰撞率**：从 **0.44** 降至 **0.12** (**降低72.7%**)。
- **强大的零样本泛化能力**：
    - 在**零样本**设置下（仅在Bench2Drive上训练，在nuScenes上测试），GeRo模型依然表现出色。
    - 例如，GeRo (Qwen) 零样本的L2误差为0.45，碰撞率为0.25，相比其基线的零样本性能仍有大幅提升。
    - **结论**：GeRo的生成式、语言接地的推演机制赋予了模型优秀的跨数据集泛化能力，这对于应对现实世界中的未知场景至关重要。

#### 3. 消融实验结论
论文通过系统的消融研究（见表4）验证了GeRo各个组件的有效性：
1.  **预训练阶段**的语言接地（场景描述、VQA）对提升规划鲁棒性有积极作用。
2.  **场景推演阶段**的时序一致性损失（`ℒ_tc`）和真实轨迹监督（`ℒ_plan`, `ℒ_mot`）是性能提升的关键，即使在没有真实标签、仅使用模型预测作为伪标签的情况下，`ℒ_tc`也能带来显著增益。
3.  **GRPO强化学习**的引入带来了进一步的性能飞跃，**碰撞避免**和**时间碰撞**奖励直接提升了安全性，而**语言对齐奖励**（`ℒ_VLA`）则确保了文本意图与动作执行的一致性，最终实现了最佳性能。

### 四、 总结
论文给出了**非常明确且强有力的定量结果**。通过在**Bench2Drive**和**nuScenes**上的大量实验，GeRo框架被证明能够：
- **显著提升**现有VLA模型（Qwen2.5VL和ORION）在**闭环驾驶**（驾驶得分、成功率、多能力）和**开环轨迹预测**（L2误差、碰撞率）上的性能。
- 实现**卓越的零样本泛化能力**，表明其生成式、语言接地的推理机制具有强大的适应性和鲁棒性。
- 通过**消融实验**清晰地论证了其**两阶段训练框架**、**时序一致性约束**以及**结合安全与语义的RL奖励**各自不可或缺的价值。

这些结果共同支撑了论文的核心论点：**生成式、语言接地的场景推演是构建更安全、更可解释、更强大的端到端自动驾驶系统的有效途径。**


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2601.11475v1)
- [HTML 版本](https://arxiv.org/html/2601.11475v1)
