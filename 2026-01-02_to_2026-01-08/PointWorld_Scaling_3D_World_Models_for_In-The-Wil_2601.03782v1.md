# PointWorld: Scaling 3D World Models for In-The-Wild Robotic Manipulation

**相关性评分**: 8.0/10

**排名**: #15


---


## 基本信息

- **arXiv ID**: [2601.03782v1](https://arxiv.org/abs/2601.03782v1)
- **发布时间**: 2026-01-07T10:29:12Z
- **相关性评分**: 8.0/10
- **是否相关**: 是

## 作者

Wenlong Huang, Yu-Wei Chao, Arsalan Mousavian, Ming-Yu Liu, Dieter Fox, Kaichun Mo, Li Fei-Fei

## 关键词

Vision-Language-Action Model, VLA for Robotics, Inference Efficiency, Lightweight Architecture, Inference Acceleration, Edge Deployment

## 一句话总结

PointWorld是一个预训练的3D世界模型，通过将状态和动作统一表示为3D点流，实现高效推理（0.1秒）和模型预测控制，适用于野外机器人操作，但未明确涉及语言组件。

## 摘要

Humans anticipate, from a glance and a contemplated action of their bodies, how the 3D world will respond, a capability that is equally vital for robotic manipulation. We introduce PointWorld, a large pre-trained 3D world model that unifies state and action in a shared 3D space as 3D point flows: given one or few RGB-D images and a sequence of low-level robot action commands, PointWorld forecasts per-pixel displacements in 3D that respond to the given actions. By representing actions as 3D point flows instead of embodiment-specific action spaces (e.g., joint positions), this formulation directly conditions on physical geometries of robots while seamlessly integrating learning across embodiments. To train our 3D world model, we curate a large-scale dataset spanning real and simulated robotic manipulation in open-world environments, enabled by recent advances in 3D vision and simulated environments, totaling about 2M trajectories and 500 hours across a single-arm Franka and a bimanual humanoid. Through rigorous, large-scale empirical studies of backbones, action representations, learning objectives, partial observability, data mixtures, domain transfers, and scaling, we distill design principles for large-scale 3D world modeling. With a real-time (0.1s) inference speed, PointWorld can be efficiently integrated in the model-predictive control (MPC) framework for manipulation. We demonstrate that a single pre-trained checkpoint enables a real-world Franka robot to perform rigid-body pushing, deformable and articulated object manipulation, and tool use, without requiring any demonstrations or post-training and all from a single image captured in-the-wild. Project website at https://point-world.github.io/.

## 详细分析

## 论文摘要：PointWorld: 为野外机器人操作扩展3D世界模型

### 1. 研究背景和动机
人类能够通过一瞥和对自身动作的思考，预测3D世界将如何响应，这种能力对于机器人操作同样至关重要。然而，现有的世界模型在从野外视觉观察和机器人动作进行物理一致预测方面仍存在差距。**PointWorld** 旨在弥合这一差距，其核心理念是**统一表示**：将状态和动作在共享的3D物理空间中表示为3D点流，从而构建一个能够从单张或多张RGB-D图像以及低级机器人动作命令预测全场景3D点位移的大规模预训练3D世界模型。

### 2. 核心方法和技术创新
- **统一的状态-动作表示**：将场景状态表示为来自RGB-D图像的部分观测3D点云，将机器人动作表示为基于其已知几何（URDF）和运动学通过前向运动学生成的密集3D点轨迹（“机器人点流”）。这种**与具体机器人形态无关**的表示，使得模型能够从异构的机器人平台数据中统一学习。
- **大规模高质量数据集**：利用3D视觉（深度估计、相机位姿估计、点跟踪）的最新进展，构建了一个包含约200万条轨迹、500小时数据的大规模3D交互数据集，涵盖真实（DROID）和仿真（BEHAVIOR-1K）环境中的单臂、双臂及全身操作。
- **可扩展的模型架构与训练**：采用先进的点云骨干网络（PointTransformerV3），并引入了**运动加权损失**和**异方差不确定性正则化**，以应对真实数据噪声和场景中大部分点静止的挑战。模型以“分块”形式进行多步预测，实现了高效（0.1秒）的单次前向推理。
- **基于模型的规划集成**：将预训练的PointWorld无缝集成到模型预测控制（MPC）框架中，通过采样（如MPPI）和优化，仅根据单张野外RGB-D图像和指定的点级目标，即可为零样本机器人操作生成动作序列。

### 3. 主要实验结果
- **模型缩放有效性**：系统的消融实验表明，现代点云骨干、预训练的2D特征（DINOv3）、改进的目标函数以及增大模型规模（至10亿参数）均能显著提升预测精度，并遵循对数线性缩放规律。
- **强大的泛化能力**：单一预训练模型在**零样本**条件下，能够泛化到未见过的真实场景，其性能与在该场景数据上从头训练的专家模型相当。经过少量微调（仅需1/20的原训练步数），性能可超越专家模型。
- **野外机器人操作成功**：在真实Franka机器人上，**同一个预训练模型**无需任何演示或额外训练，仅凭单张野外捕获的RGB-D图像，即可成功完成**刚性物体推动、可变形物体操纵、关节物体操作以及工具使用**等多种复杂任务，验证了其捕获可迁移交互物理规律的能力。

### 4. 研究意义和价值
PointWorld代表了迈向通用空间智能机器人的重要一步。其贡献在于：
- **方法论上**：提出了一种通过统一3D点流表示来扩展3D世界模型的清晰路径，并提炼了关键的设计原则。
- **资源上**：开源了大规模、高质量的3D交互数据集和预训练模型，为社区提供了宝贵资源。
- **实践上**：证明了单一、大规模预训练的3D动力学模型能够直接赋能真实机器人在开放世界中进行多样、复杂的操作，为实现**无需任务特定数据或微调**的通用机器人操作提供了新的可能性。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析：PointWorld

### **一、 论文拟解决的核心问题**
当前机器人操作领域的世界模型存在以下**关键瓶颈**：
1.  **表征割裂**：状态（环境）和动作（机器人）通常使用不同的、特定于具体机器人的表示方式（如关节角度、末端位姿），这阻碍了跨不同机器人平台（单臂、双臂、人形）的统一学习和知识迁移。
2.  **泛化能力弱**：现有模型（无论是基于物理的仿真器还是学习型动力学模型）往往需要针对特定场景、物体或任务进行定制化建模或微调，难以直接应用于开放、非结构化的“野外”环境。
3.  **物理一致性与效率的权衡**：大规模视频生成模型能产生逼真预测但缺乏明确的动作条件输入和物理一致性；而专注于物理的模型则计算成本高，且存在“仿真到现实”的差距。

**核心目标**：构建一个**大规模、预训练的3D世界模型**，能够仅根据单张或多张野外捕获的RGB-D图像和低层机器人动作指令，准确、高效地预测整个3D场景的物理演化，从而支持多样化的机器人操作任务。

### **二、 核心技术创新点**

#### **1. 统一的3D点流表示法**
这是论文最根本的**范式创新**。
- **状态表示**：将环境状态表示为从RGB-D图像反投影得到的**3D点云**。每个点具有位置和（来自冻结的DINOv3编码器的）外观特征。
- **动作表示**：将机器人动作也表示为**3D点流**。利用已知的机器人URDF模型和关节指令序列，通过前向运动学生成机器人表面（特别是夹爪）上一系列点在时间上的运动轨迹。
- **统一与优势**：将状态和动作统一在同一个3D几何空间中，形成了 **“交互几何”** 。这种表示法：
    - **与具体机器人无关**：任何机器人的动作都可以转化为其自身几何表面的点流，实现了跨机器人平台的学习。
    - **强调物理交互**：直接关注几何接触和运动，而非外观渲染，更接近物理仿真的本质。
    - **训练稳定**：使用简单的L2或Huber损失回归3D位移，无需复杂的匹配或排列不变性处理。

#### **2. 大规模高质量数据集的构建**
为了训练这样一个通用模型，论文投入巨大精力**构建并开源了一个前所未有的3D交互数据集**。
- **数据源**：整合了真实世界数据集DROID和仿真数据集BEHAVIOR-1K，总计约**200万条轨迹，500小时**的数据。
- **关键技术突破**：针对真实世界数据，开发了一套**先进的3D标注流水线**，结合了：
    - **FoundationStereo**：用于高精度度量深度估计。
    - **VGGT与优化**：用于精确的相机外参标定。
    - **CoTracker3**：用于稠密的2D点跟踪，再提升至3D。
- **结果**：获得了比原始数据集质量高得多的、带有精确3D点流对应关系的真实世界交互数据，为模型提供了可靠的监督信号。

#### **3. 可扩展的3D世界模型架构与训练方法**
论文通过系统的实验，提炼出一套**可扩展的3D世界建模“配方”**。
- **高效骨干网络**：采用**PointTransformerV3** 作为点云处理骨干。实验证明，相比传统的图神经网络动力学模型，PTv3在参数量大幅增长（可达957倍）的同时，保持了合理的内存和计算开销，实现了更好的性能。
- **针对性的训练目标**：
    - **运动加权损失**：由于场景中大部分点是静止的，使用基于真实运动的软权重来聚焦于正在移动的点，解决信号稀疏问题。
    - **异方差不确定性正则化**：模型同时预测每个点的位移和不确定性（对数方差）。该损失函数能自动降低对噪声大、不可靠标注点的权重，提高了在真实噪声数据上的鲁棒性。
    - **分块预测**：模型一次性预测未来一个时间块（如10步，1秒）内所有点的运动，而非单步自回归。这提高了时间一致性，并**将推理速度提升至0.1秒**，满足实时控制需求。
- **利用预训练视觉先验**：为场景点云注入来自**冻结的DINOv3模型**的多层特征，为模型提供了强大的物体属性和语义先验，显著提升了预测精度。

#### **4. “一个模型，多种任务”的零样本部署能力**
这是技术创新的**最终体现和实际价值**。
- **单一预训练检查点**：使用上述方法在混合数据集上预训练一个模型（如10亿参数）。
- **零样本野外操作**：将该模型与**基于采样的模型预测控制** 框架（如MPPI）集成。给定一张野外RGB-D图像和用户定义的任务点目标（如通过GUI指定要移动的物体部分），MPPI利用PointWorld快速评估大量候选动作序列的后果，并选择最优轨迹。
- **演示结果**：**无需任何演示数据、无需任何针对新场景或任务的微调**，该单一模型成功让真实Franka机器人完成了**刚性物体推动、可变形物体（围巾、枕头）操作、铰接物体（微波炉、抽屉）操控以及工具使用（用掸子、扫帚清扫）** 等多样化任务。

### **三、 解决方案总结**
**PointWorld的解决路径可以概括为：用一个统一的3D几何语言（点流）来描述世界和机器人的互动，利用现代3D视觉技术获取大规模、高质量的“物理交互教科书”（数据集），再通过精心设计的、可扩展的深度学习架构来学习这本教科书中的规律，最终形成一个能够直接理解物理世界并规划动作的通用大脑。**

其**实际价值**在于：向构建具有“空间智能”、能够快速适应未知开放环境的通用机器人迈出了关键一步。它降低了机器人获得复杂操作技能的数据和调试成本，提供了一种通过预测模型进行零样本规划的新范式。开源的数据集、模型和代码将进一步推动整个领域的发展。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文旨在解决机器人操作中**在开放、非结构化环境下进行精确物理交互预测**的核心难题。为此，作者提出了 **PointWorld**，一个基于**三维点流**统一表示状态与动作的大规模预训练世界模型。该方法将场景（来自RGB-D图像）和机器人动作（通过正向运动学生成）都表示为三维空间中的点轨迹，并直接预测给定动作序列下整个场景的三维点位移。通过构建一个包含真实与仿真数据的大规模高质量三维交互数据集，并系统研究了模型架构、训练目标等关键设计原则，论文表明，**单个预训练的PointWorld模型能够零样本（无需演示或微调）集成到模型预测控制框架中，使真实机器人仅凭单张野外捕获的图像，即可成功完成刚体推动、可变形物体与关节物体操作以及工具使用等多种复杂任务**，展现了强大的泛化与实用能力。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## PointWorld 论文的创新点分析

这篇论文《PointWorld: Scaling 3D World Models for In-The-Wild Robotic Manipulation》在3D世界建模和机器人操作领域提出了多项明确的创新。以下是其核心创新点的逐条分析：

### 1. **统一的状态与动作表示：3D点流**
   - **改进/不同之处**：传统方法通常将**状态**（如像素、体素、网格）和**动作**（如关节角度、末端位姿）表示为不同的模态。PointWorld 创新性地将**两者统一为3D点流**：状态是场景的3D点云，动作是机器人自身几何（通过正向运动学生成）的3D点轨迹。
   - **解决的问题/优势**：
     - **具身无关性**：不同机器人（如单臂Franka、双足人形）的动作都可以表示为点流，使模型能够**无缝集成跨不同具身的数据进行学习**。
     - **强调几何与接触**：直接对3D几何进行建模，而非外观（如RGB像素），更专注于**物理交互和接触动力学**，这对于精确操作至关重要。
     - **简化学习**：在共享的3D空间中回归点位移，使用稳定的L2/Huber损失，避免了复杂的目标函数或匹配问题。

### 2. **大规模、高质量的3D交互数据集构建**
   - **改进/不同之处**：现有机器人数据集（如DROID）缺乏精确的3D标注（深度、相机外参、点轨迹）。本文**构建了一个定制化流水线**，结合了前沿的3D视觉技术（FoundationStereo深度估计、VGGT相机位姿估计、CoTracker3点跟踪）来从原始RGB-D视频中提取高精度的3D点流。
   - **解决的问题/优势**：
     - **解决了监督信号的质量问题**：为3D世界模型训练提供了**密集、精确的像素级3D位移真值**，这是学习精细接触动力学的基础。
     - **规模与多样性**：构建了包含约200万轨迹、500小时的数据集，涵盖真实（DROID）和仿真（BEHAVIOR-1K）环境中的单臂、双手及全身操作，是**目前最大的3D动力学建模数据集之一**。
     - **促进泛化**：高质量、多样化的数据是模型能够在未知“野外”环境中零样本泛化的关键前提。

### 3. **可扩展的3D世界模型训练“配方”**
   - **改进/不同之处**：论文通过系统的消融实验，提炼并验证了一套用于**大规模3D世界模型训练的有效设计原则**，而不仅仅是提出一个模型。
   - **核心设计原则及解决的问题**：
     - **骨干网络**：采用 **PointTransformerV3**，相比传统的图神经网络动力学模型，它在**部分可观测性下具有更强的长程建模能力**，且**参数量可扩展至10亿级**，同时保持较高的推理效率（~0.1秒）。
     - **训练目标**：引入了**运动加权损失**（聚焦于移动的点）和**异方差不确定性正则化**（应对真实数据噪声），**稳定了在噪声、稀疏信号数据上的训练**。
     - **预训练特征**：为场景点云注入**冻结的DINOv3视觉特征**，提供了强大的**物体先验和语义信息**，弥补了3D表征的不足，显著提升了预测精度。
     - **分块预测**：采用**多步（10步）分块预测**，而非单步自回归。这**提高了时间一致性，减少了累积误差，并摊销了计算成本**，实现了一次前向传播预测整个轨迹，非常适合与MPC集成。

### 4. **“单一预训练模型”实现零样本野外操作**
   - **改进/不同之处**：以往的工作通常需要针对特定任务、场景或机器人进行微调或提供演示。PointWorld 展示了**一个在混合数据上预训练的单一模型**，在部署时**无需任何演示、微调或任务特定训练**，仅凭单张野外RGB-D图像，就能通过模型预测控制完成多样任务。
   - **解决的问题/优势**：
     - **强大的泛化能力**：该模型能够零样本处理**刚性物体推动、可变形物体操作、关节物体操控以及工具使用**等多种任务，证明了其学到的物理交互动力学具有广泛的迁移性。
     - **简化部署流程**：极大地降低了机器人适应新任务、新环境所需的成本和数据需求，向“通用”机器人操作迈进一步。
     - **统一规划接口**：模型预测的3D点流自然地与基于采样的模型预测控制（如MPPI）集成，通过定义在点空间中的成本函数（如移动特定点到目标位置）即可进行规划。

### 5. **对3D世界模型缩放规律的实证研究**
   - **改进/不同之处**：论文系统地研究了**模型规模（参数量）和数据规模**对3D世界模型性能的影响，并观察到了**类似大语言模型的对数线性缩放规律**。
   - **解决的问题/优势**：
     - **为未来研究提供指导**：明确了在3D世界建模领域，**持续扩大模型和数据集是提升性能的有效途径**。
     - **验证了架构的可扩展性**：PointTransformerV3骨干网能够有效利用增加的参数量，性能随规模增长而稳定提升。

### 总结
PointWorld 的核心创新在于**通过一个统一、具身无关的3D点流表示，结合一个大规模高质量数据集和一套经过验证的可扩展训练方法，构建了一个能够零样本泛化到复杂野外操作任务的预训练3D世界模型**。它不仅在表示学习和模型架构上有所突破，更重要的是通过严谨的工程和实验，为如何构建和利用大规模3D物理世界模型提供了宝贵的路线图和实践经验。其**实际价值**在于显著提升了机器人对未知环境的物理理解和操作能力，降低了部署门槛，是迈向具有空间智能的通用机器人的重要一步。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 论文实验与评估效果总结

论文《PointWorld: Scaling 3D World Models for In-The-Wild Robotic Manipulation》通过一系列大规模、严谨的实验，系统地评估了所提出的**PointWorld 3D世界模型**的性能、泛化能力和实际应用效果。其核心目标是验证一个**单一预训练模型**能否在真实世界的机器人操作任务中实现零样本（zero-shot）泛化。

### 一、 使用的数据集
为了训练和评估模型，论文构建并使用了两个大规模数据集：

1.  **DROID (真实世界数据集)**:
    *   **来源**: 大规模野外机器人操作数据集。
    *   **处理**: 作者投入大量精力构建了一个**定制化的3D标注流程**，利用先进的**FoundationStereo**（深度估计）、**VGGT**（相机位姿估计）和**CoTracker3**（点跟踪）技术，从原始的RGB-D视频中提取高质量的**3D点流**作为真值。最终恢复了约**200小时**的交互数据。
    *   **特点**: 包含单臂Franka机器人在多样化、非结构化环境中的操作，涉及刚性、可变形、铰接物体和工具使用。

2.  **BEHAVIOR-1K (仿真数据集)**:
    *   **来源**: 在逼真家庭环境中的双足人形机器人（Galexea R1 Pro）操作仿真数据集。
    *   **处理**: 利用仿真器的特权信息（如物体刚体轨迹、接触信息）直接生成精确的3D点流。通过基于接触和物体运动的过滤，保留了约**1100小时**的交互数据。
    *   **特点**: 包含双臂、全身和移动操作，场景和任务高度多样化。

**最终训练集**：合并上述两个数据集，总计约 **200万条轨迹（500小时）**，构成了用于训练大规模3D世界模型的最大数据集之一。

### 二、 核心评价指标
论文采用了一个**密集、细粒度**的评估指标，以暴露模型预测的细微差别：

*   **主要指标**: **移动点的 ℓ₂ 误差**。
    *   **计算方式**: 在预测时间步上，计算模型预测的3D场景点位移与真值位移之间的平均欧氏距离。
    *   **聚焦移动点**: 由于交互中大部分场景点是静止的，标准ℓ₂损失信号稀疏。因此，评估时**仅关注那些根据真值判断发生了移动的点**，这使得指标对模型捕捉动态交互的能力高度敏感。
    *   **解读**: 尽管绝对误差值（通常在厘米级）看起来不大，但论文指出，微小的数值差异（如几毫米）往往对应着** rollout 保真度**的显著提升，这比任务成功率更能揭示模型的内在质量。

*   **辅助指标**: 静态点的 ℓ₂ 误差（用于验证模型不会对背景产生过度预测）。

*   **对于真实世界数据（DROID）**，还采用了**专家置信度过滤**：用一个仅在测试集上训练的“专家”模型来识别并过滤掉真值中不可靠的轨迹点（约20%），确保评估基于高质量的监督信号。

### 三、 基线方法对比与性能分析
论文的评估是多层次、系统性的，并非与某个单一的“SOTA”模型比较，而是通过**消融实验和组件分析**来验证每个设计决策的有效性，并最终在真实机器人上展示零样本规划能力。

#### 1. 架构与组件消融（核心贡献验证）
论文将PointWorld与一系列基线进行对比，以验证其设计选择：

*   **骨干网络（Backbone）**:
    *   **基线**: Graph-Based Neural Dynamics (GBND， 常用于动力学建模)、PointNet、PointNet++、SparseConvNet、Transformer。
    *   **结果**: **PointTransformerV3 (PTv3)** 在准确性、内存效率和推理速度上取得了最佳平衡。PTv3-1B模型参数量是GBND的**957倍**，但推理延迟仅**~0.12秒**，移动点预测误差 (**0.0312 m**) 显著低于GBND (**0.0390 m**)。这表明现代点云骨干网络更适合大规模3D世界建模。

*   **动作表示（Action Representation）**:
    *   **对比方案**: 低维动作（关节角度、末端执行器位姿）、稀疏/密集的全身点流、**仅夹爪点流**（PointWorld采用）。
    *   **结果**: **仅夹爪点流**在真实（DROID）和仿真（B1K）数据上都取得了最佳或接近最佳的性能。它既能有效编码接触几何，又避免了过多静态机器人点对稀疏学习信号的干扰，并支持跨异构机器人（单臂 vs. 双臂）的**正向迁移**。

*   **训练目标与策略**:
    *   **移动加权 & 不确定性正则化 & Huber损失**: 与朴素ℓ₂损失相比，这些技术共同作用，**稳定了训练并提升了在噪声真实数据上的准确性**。不确定性头还能自发地捕捉物体物理属性（如布料边缘）导致的动作条件不确定性。
    *   **分块预测 vs. 自回归预测**: 在训练和推理中均使用**分块预测**（一次前向传播预测多步）相比自回归滚动，**显著减少了误差累积（漂移）**，同时计算效率更高（单次前向 vs. 多次前向）。

*   **预训练特征与缩放定律**:
    *   **DINOv3特征**: 为场景点注入冻结的DINOv3图像特征，带来了**显著的性能提升**，提供了关键的物体先验知识。
    *   **模型与数据缩放**: 增大模型参数量（50M → 1B）或增加训练数据量，均能带来近似**对数线性**的误差下降（见图9），符合大模型的缩放定律。

#### 2. 泛化与迁移实验
论文在多个维度测试了模型的泛化能力（见表2）：

*   **域内泛化**: 在DROID和B1K各自的测试集上表现良好，表明模型没有过拟合。
*   **跨域零样本泛化**:
    *   **仿真 → 真实 (B→D)**: 性能较差（误差0.0558 m），说明纯仿真训练难以直接应对真实世界的复杂性和噪声。
    *   **真实 → 仿真 (D→B)**: 表现尚可（误差0.1460 m），但仍有差距。
*   **跨域微调**: 使用**仅5%** 的原训练步数进行微调，能迅速将跨域性能提升到接近域内模型的水平，证明了预训练模型的高效可迁移性。
*   **真实世界场景零样本泛化**:
    *   将在“实验室A”数据上预训练的模型，直接应用到从未见过的“实验室B”场景。
    *   **结果**: PointWorld (D+B预训练) 达到了 **0.0300 m** 的移动点误差，与专门在“实验室B”数据上从头训练的“专家”模型 (**0.0293 m**) **性能相当**。这证明了其强大的**野外泛化能力**。
    *   若对预训练模型进行少量微调，其性能可**超越**从头训练的专家模型。

#### 3. 真实机器人操作实验（最终效果展示）
这是论文最引人注目的部分，旨在验证 **“一个预训练模型 + 单张野外RGB-D图像 + MPC规划”** 的可行性。

*   **设置**: 使用真实的Franka机器人（夹爪几何在训练中**未见过**），仅提供单视角RGB-D输入。通过MPPI采样规划器，基于PointWorld预测的动力学，优化末端执行器轨迹以实现任务。
*   **任务**: 涵盖了四大类操作：**刚性物体推动**（纸巾盒、书）、**可变形物体操作**（折叠围巾、放置枕头）、**铰接物体操作**（打开微波炉、关闭抽屉）、**工具使用**（用鸡毛掸子、扫帚清扫）。
*   **结果**:
    *   在**零样本**（无任务演示、无微调）条件下，PointWorld成功完成了所有类型的任务。
    *   报告了**任务成功率**（见图8），例如：刚性推动（~90%）、可变形操作（~80%）、铰接操作（~70%）、工具使用（~60%）。这些成功率证明了预训练模型所捕获的物理交互知识（接触推理、材料属性推断、物体-物体交互）是**可迁移且实用的**。
    *   关键结论：**单个预训练检查点**能够使真实机器人执行多样化的操作行为，仅需一张野外捕获的图像，无需任何额外演示或训练。

### 四、 主要性能提升与结论
1.  **技术性能提升**: 通过系统性的架构、目标函数和表示学习改进，PointWorld在3D点流预测精度上相比传统GBND等基线有**显著提升**，同时保持了实时（0.1秒级）推理速度。
2.  **泛化能力突破**: 模型展示了出色的**跨场景、跨配置的零样本泛化能力**，特别是在从未见过的真实环境中，其


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2601.03782v1)
- [HTML 版本](https://arxiv.org/html/2601.03782v1)
