# TAP-ViTs: Task-Adaptive Pruning for On-Device Deployment of Vision Transformers

**相关性评分**: 7.0/10

**排名**: #33


---


## 基本信息

- **arXiv ID**: [2601.02437v1](https://arxiv.org/abs/2601.02437v1)
- **发布时间**: 2026-01-05T09:00:08Z
- **相关性评分**: 7.0/10
- **是否相关**: 是

## 作者

Zhibo Wang, Zuoyuan Zhang, Xiaoyi Pang, Qile Zhang, Xuanyi Hao, Shuguo Zhuo, Peng Sun

## 关键词

Vision Transformers, On-Device Deployment, Pruning, Task-Adaptive, Lightweight Architecture, Edge Deployment, Inference Efficiency

## 一句话总结

TAP-ViTs 提出了一种任务自适应剪枝框架，用于在保护隐私的前提下，为资源受限的边缘设备生成轻量化的 Vision Transformer 模型，以提高推理效率。

## 摘要

Vision Transformers (ViTs) have demonstrated strong performance across a wide range of vision tasks, yet their substantial computational and memory demands hinder efficient deployment on resource-constrained mobile and edge devices. Pruning has emerged as a promising direction for reducing ViT complexity. However, existing approaches either (i) produce a single pruned model shared across all devices, ignoring device heterogeneity, or (ii) rely on fine-tuning with device-local data, which is often infeasible due to limited on-device resources and strict privacy constraints. As a result, current methods fall short of enabling task-customized ViT pruning in privacy-preserving mobile computing settings. This paper introduces TAP-ViTs, a novel task-adaptive pruning framework that generates device-specific pruned ViT models without requiring access to any raw local data. Specifically, to infer device-level task characteristics under privacy constraints, we propose a Gaussian Mixture Model (GMM)-based metric dataset construction mechanism. Each device fits a lightweight GMM to approximate its private data distribution and uploads only the GMM parameters. Using these parameters, the cloud selects distribution-consistent samples from public data to construct a task-representative metric dataset for each device. Based on this proxy dataset, we further develop a dual-granularity importance evaluation-based pruning strategy that jointly measures composite neuron importance and adaptive layer importance, enabling fine-grained, task-aware pruning tailored to each device's computational budget. Extensive experiments across multiple ViT backbones and datasets demonstrate that TAP-ViTs consistently outperforms state-of-the-art pruning methods under comparable compression ratios.

## 详细分析

## 论文摘要：TAP-ViTs：面向设备端部署的视觉Transformer任务自适应剪枝

### 1. 研究背景和动机
视觉Transformer（ViT）在多种视觉任务中表现出色，但其巨大的计算和内存需求阻碍了其在资源受限的移动和边缘设备上的高效部署。剪枝是降低ViT复杂度的有效方法。然而，现有方法要么生成一个适用于所有设备的通用剪枝模型，忽略了设备的异构性；要么依赖设备本地数据进行微调，这在资源有限和隐私约束严格的场景下往往不可行。因此，当前方法难以在保护隐私的移动计算环境中实现**任务定制化**的ViT剪枝。

### 2. 核心方法和技术创新
本文提出了 **TAP-ViTs**，一个新颖的任务自适应剪枝框架，旨在**无需访问任何原始本地数据**即可为每个设备生成定制化的剪枝模型。其技术创新主要包括：
- **基于高斯混合模型（GMM）的度量数据集构建**：每个设备在本地拟合一个轻量级GMM来近似其私有数据分布，并仅将GMM参数上传至云端。云端利用这些参数，从公共数据中选择分布一致的样本来为每个设备构建一个**任务代表性**的度量数据集。
- **双粒度重要性评估剪枝策略**：基于上述代理数据集，提出一种联合评估**复合神经元重要性**和**自适应层重要性**的策略。前者综合了神经元的活跃度、冗余度和任务相关性；后者通过计算剪枝前后模型输出的KL散度来衡量每层对任务的重要性，从而为不同层分配差异化的剪枝预算。

### 3. 主要实验结果
在多个ViT骨干网络（如DeiT、T2T-ViT、Swin）和数据集（TinyImageNet、CIFAR-100）上的广泛实验表明：
- **性能优越**：在保留70%参数的相同压缩比下，TAP-ViTs持续优于最先进的剪枝方法。
- **超越原模型**：在多个案例中，剪枝后的模型甚至**超越了原始未剪枝模型**的准确率，表明其有效剔除了冗余并保留了任务关键参数。
- **泛化性强**：框架在不同ViT变体上均表现稳健。
- **实用性强**：设备端的GMM拟合开销极小（约1分钟内完成），验证了其在真实边缘设备上部署的可行性。

### 4. 研究意义和价值
TAP-ViTs为解决**隐私保护**与**设备异构性**背景下的高效模型部署难题提供了创新方案。其核心价值在于：
- **隐私性**：通过仅交换GMM参数，避免了原始敏感数据的上传，满足了严格的隐私约束。
- **自适应性**：生成的剪枝模型能够精准匹配每个设备的特定任务需求和数据分布。
- **高效性**：整个流程计算开销低，适合资源受限的边缘环境。
- **社会意义**：该技术有助于在低资源设备上实现高质量AI，促进更普惠、包容的边缘智能发展。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析：TAP-ViTs

### **一、 论文旨在解决的核心问题**
论文瞄准了**Vision Transformers (ViTs) 在资源受限的边缘/移动设备上高效、个性化部署的难题**，并特别强调了**隐私保护**的约束。具体而言，它指出了现有ViT剪枝方法的两个主要局限：

1.  **缺乏任务/设备自适应性**：现有方法通常使用固定的公开数据集和统一的剪枝策略，生成一个“通用”的压缩模型，忽略了不同设备上**本地数据分布（Non-IID）和任务需求**的异构性。
2.  **隐私与资源的矛盾**：让设备使用本地数据对剪枝后的模型进行微调，虽然能提升任务性能，但面临两大障碍：
    *   **隐私泄露风险**：设备不愿上传原始数据。
    *   **资源限制**：边缘设备计算能力有限，难以承担训练/微调的开销。

因此，论文的核心目标是：**在无法访问设备原始私有数据的前提下，为每个异构设备生成定制化的、高性能的剪枝后ViT模型。**

### **二、 核心创新点**
论文提出了 **TAP-ViTs** 框架，其创新性主要体现在以下两个紧密耦合的组成部分：

#### **1. 基于高斯混合模型（GMM）的隐私保护度量数据集构建**
*   **创新思路**：为了在不接触原始数据的情况下感知设备任务特性，提出用轻量级的**统计模型**来近似本地数据分布。
*   **具体方法**：
    *   **设备端**：每个设备使用一个预训练的特征提取器，将其私有数据 `D_i` 映射到特征空间，然后拟合一个**高斯混合模型（GMM）** 来近似该特征分布。设备仅需将轻量的GMM参数 `{π_k, μ_k, Σ_k}` 上传至云端，**不泄露任何原始数据**。
    *   **云端**：利用接收到的GMM参数，在庞大的公开数据集 `D_c` 中计算每个样本在该GMM下的似然值。选择似然值最高（即与设备数据分布最一致）的样本子集，为每个设备构建一个**定制化的度量数据集 `D_i^c`**。
*   **价值**：成功地在隐私约束下，为每个设备创建了一个能**代理其任务特性**的数据集，为后续自适应剪枝提供了关键依据。

#### **2. 基于双粒度重要性评估的任务自适应剪枝策略**
*   **创新思路**：摒弃了传统的、单一标准的均匀剪枝，提出一种**细粒度、任务感知**的剪枝机制，包含两个层面的评估：
    *   **复合神经元重要性评估**：
        *   不是仅依赖权重幅值等单一指标，而是综合评估神经元的三个维度：
            *   **活跃度**：神经元对输入的平均响应强度。
            *   **冗余度**：神经元与同层其他神经元输出的互信息（负相关，冗余度高则重要性低）。
            *   **相关性**：神经元输出与模型最终预测之间的统计相关性（使用希尔伯特-施密特范数衡量）。
        *   通过加权求和（`I_j = αA_j + βR_j + γT_j`）得到综合重要性分数，能更全面、准确地识别对特定任务关键的神经元。
    *   **自适应层重要性评估**：
        *   不是对所有层采用统一的剪枝比例，而是评估每一层对模型预测的贡献度。
        *   **方法**：临时“禁用”某一层，计算原始模型输出与禁用后模型输出之间的KL散度。散度越大，说明该层越重要。
        *   根据计算出的层重要性分数，**按比例分配各层的剪枝预算**。重要层少剪，次要层多剪。
*   **价值**：实现了**精细化、任务驱动的模型压缩**，能够在给定的全局压缩比例下，最大程度地保留对特定设备任务至关重要的模型容量，从而在压缩后甚至可能获得比原模型更优的性能（通过消除冗余）。

### **三、 解决方案总结**
TAP-ViTs 的整体解决方案是一个**云端-设备协同的框架**：

1.  **隐私感知的任务表征（设备端）**：设备用GMM压缩其数据分布信息并上传。
2.  **代理数据集构建（云端）**：云端利用GMM从公开数据中筛选匹配样本，为每个设备生成定制化的度量数据集。
3.  **任务自适应剪枝（云端）**：基于该度量数据集，执行“复合神经元评估”和“自适应层评估”，生成设备专属的剪枝掩码，对原始ViT进行剪枝。
4.  **轻量微调与部署（云端->设备）**：对剪枝后的模型用度量数据集进行少量迭代的微调，然后将最终的轻量、定制化模型部署到对应设备。

### **四、 实际价值与意义**
*   **技术价值**：为ViT的落地部署提供了一种**兼顾性能、效率、隐私和个性化**的实用化压缩方案。实验表明，在仅保留70%参数时，其定制化模型性能**优于**原模型及现有SOTA剪枝方法。
*   **应用价值**：使得在智能手机、IoT设备等资源受限且数据隐私敏感的场景中，部署高性能、个性化的ViT模型成为可能，推动了边缘AI的发展。
*   **方法论贡献**：提出的 **“GMM代理分布”** 和 **“多维度重要性评估”** 思路，对解决更广泛的隐私保护下的自适应模型优化问题具有启发意义。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文旨在解决在资源受限且注重隐私的边缘设备上部署视觉Transformer（ViT）时，如何实现**任务自适应的模型剪枝**这一核心难题。现有方法要么生成单一通用模型，忽略了设备间的任务异构性；要么依赖本地数据进行微调，这在资源有限和隐私约束下往往不可行。

为此，论文提出了 **TAP-ViTs** 框架，其核心创新在于两点：首先，设计了一种**基于高斯混合模型（GMM）的代理数据集构建方法**，设备仅上传拟合本地数据分布的轻量级GMM参数，云端据此从公共数据中筛选出分布一致的样本来为每个设备构建任务代表性的度量数据集，从而在保护隐私的前提下感知任务特性。其次，提出了一种**双粒度重要性评估剪枝策略**，该策略结合了评估神经元活跃度、冗余度和任务相关性的复合神经元重要性，以及评估层对模型预测分布影响的自适应层重要性，从而实现了细粒度、任务感知的剪枝。

实验结果表明，TAP-ViTs在多种ViT架构和数据集上均优于现有剪枝方法，在仅保留70%参数的情况下，其准确率不仅能与原始未剪枝模型持平，甚至在多个场景下实现了**超越**，验证了该框架在隐私保护前提下进行高效、任务自适应模型压缩的有效性和可部署性。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## TAP-ViTs 论文创新点分析

这篇论文针对在资源受限的边缘设备上部署视觉Transformer（ViT）时面临的**任务异构性**和**数据隐私**两大核心挑战，提出了一套完整的解决方案。其创新点明确且具有层次性，具体如下：

### 1. **隐私保护的任务感知度量数据集构建机制**
   - **改进/不同之处**： 以往方法（如MD-ViT、UP-ViT）使用一个**固定的、公开的度量数据集**来指导所有设备的剪枝，忽略了设备间数据分布的差异。TAP-ViTs则提出为**每个设备定制专属的度量数据集**。其核心是让设备端使用**高斯混合模型（GMM）** 拟合本地数据的特征分布，并仅将轻量级的GMM参数（而非原始数据）上传至云端。云端利用这些参数，从公共数据集中筛选出与设备数据分布最匹配的样本来构建该设备的代理数据集。
   - **解决的问题与优势**：
     - **解决了隐私泄露问题**： 设备无需上传任何原始数据，满足了严格的隐私约束（如医疗、家庭监控场景）。
     - **解决了任务异构性问题**： 为每个设备构建的代理数据集能更准确地反映其特定的下游任务（数据分布），为后续的剪枝提供了**任务感知**的指导依据，打破了“一刀切”的剪枝模式。
     - **计算开销低**： 设备端仅需进行轻量的GMM拟合（论文实验显示在边缘设备上可在约1分钟内完成），避免了联邦学习等方案中沉重的本地训练负担。

### 2. **双粒度重要性评估的剪枝策略**
   - **改进/不同之处**： 现有剪枝方法通常采用**单一的、粗粒度的重要性评估标准**（如权重幅度、梯度），并在所有层应用**均匀的剪枝比例**。TAP-ViTs提出了一个**双粒度**评估框架：
     1.  **复合神经元重要性评估**： 综合衡量神经元的**活跃度**（对输入的响应）、**冗余度**（与同层其他神经元的互信息）和**任务相关性**（与模型最终输出的统计关联）。最终重要性是这三者的加权和。
     2.  **自适应层重要性评估**： 通过计算剪掉某层前后模型输出分布的KL散度，来量化该层对**当前任务**的整体贡献，从而动态分配各层的剪枝预算。
   - **解决的问题与优势**：
     - **解决了重要性评估片面性问题**： 复合评估从多个维度更全面、准确地识别出对特定任务真正关键的神经元，避免了仅依赖单一指标（如幅度）可能误删重要但数值小的神经元。
     - **解决了层间敏感性差异问题**： 自适应层预算分配允许对任务关键层保留更多参数，对冗余层进行更激进的剪枝。这基于论文的实证发现：不同任务下，ViT各层的重要性排名存在显著差异。
     - **实现了细粒度、任务自适应的剪枝**： 结合上述两点，该策略能根据每个设备的代理数据集，精细地裁剪模型，在满足整体压缩率的同时，最大化保留任务性能。

### 3. **“无原始数据访问”的端到端任务自适应剪枝框架**
   - **改进/不同之处**： 这是前述两个核心创新的系统级整合。以往实现任务自适应有两种主流路径：(i) **在云端使用设备数据微调**——违反隐私；(ii) **基于联邦学习的协同剪枝/训练**——需要设备端进行大量计算，不适用于资源极端受限的设备。TAP-ViTs创造性地提出了一条新路径：**仅通过交换模型参数（GMM参数）来传递任务信息**，在云端完成所有重计算量的剪枝工作。
   - **解决的问题与优势**：
     - **解决了隐私与效率的权衡难题**： 在严格保护数据隐私的前提下，实现了为异构设备定制剪枝模型的目标，且设备侧开销极低。
     - **提升了部署可行性**： 生成的剪枝模型可以直接部署，设备无需再进行任何训练或微调。框架符合典型的“云-边”协同计算范式，实用性强。
     - **取得了卓越的性能**： 实验表明，在仅保留70%参数的情况下，TAP-ViTs定制的模型在设备本地任务上的准确率不仅大幅优于现有SOTA剪枝方法，甚至在多个案例中**超过了原始未剪枝的完整模型**。这证明了其能有效剔除冗余并保留/增强任务关键结构。

### 总结
TAP-ViTs的核心创新在于**方法论层面**的突破：它通过 **“GMM代理 + 双粒度评估”** 这一组合，首次系统性地解决了在**隐私约束**下为**异构任务**进行**高效ViT剪枝**的难题。其价值在于为边缘AI部署提供了一个**切实可行、性能优异且隐私安全**的模型压缩新范式。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 论文实验与评估效果总结

论文通过一系列详实的实验，全面评估了所提出的 **TAP-ViTs** 框架在任务自适应剪枝方面的有效性、鲁棒性和实际部署可行性。

### 1. 实验设置概览

- **模型架构**:
    - 标准ViT: **DeiT-Base** (86M参数), **DeiT-Small** (22M参数)
    - ViT变体: **T2T-ViT**, **Swin Transformer**
- **数据集**:
    - **TinyImageNet**: 包含200个类别的图像分类数据集。
    - **CIFAR-100**: 包含100个类别的图像分类数据集。
    - **任务模拟**: 将完整测试集按语义标签划分为10个不相交的子集，每个子集代表一个“设备”的特定任务分布，模拟真实场景中的异构性和非独立同分布数据。
- **评价指标**:
    - **主要指标**: **Top-1准确率** 和 **Top-5准确率**。
    - **聚合方式**: 由于每个设备测试子集不同，最终报告的是**设备特定准确率的加权平均值**，权重为各设备测试样本数。
    - **其他分析指标**: 神经元重要性排名相关性（Kendall‘s τ）、层重要性KL散度、GMM拟合时间（评估部署开销）。
- **基线方法**:
    - **MD-ViT**: 基于依赖关系引导高斯过程搜索的多维剪枝方法。
    - **UP-ViT**: 统一的ViT结构化剪枝框架。
    - **DC-ViT**: 针对数据受限场景的细粒度结构修改方法。
- **对比设置**:
    - **公平对比**: 所有方法（包括TAP-ViTs）剪枝至保留**70%** 的原始参数，并使用**少量数据**（TinyImageNet的1/10或CIFAR-100的1/5）进行**50个epoch**的轻量级微调。
    - **宽松对比**: 为基线方法提供**完整训练集**和**200个epoch**的微调（在结果表中标记为`*`），作为其性能上限的参考。

### 2. 关键性能结果与结论

#### **2.1 与基线方法的对比（核心结论）**
在公平的轻量微调设置下，TAP-ViTs**显著且一致地超越了所有基线方法**。

**以DeiT-Base在70%参数保留率下的结果为例**:
| 数据集 | TAP-ViTs (Ours) | 最佳基线 (MD-ViT*) | **提升幅度** | 原始模型 (100%) |
| :--- | :--- | :--- | :--- | :--- |
| **TinyImageNet** | **88.24%** | 84.98% | **+3.26%** | 85.38% |
| **CIFAR-100** | **92.72%** | 87.52% | **+5.20%** | 90.02% |

- **核心发现1: 超越原始模型**: TAP-ViTs剪枝后的模型（仅70%参数）在多个情况下**性能超过了未剪枝的原始模型**。这表明该方法不仅能压缩模型，还能通过移除冗余、保留任务关键参数来提升模型效率。
- **核心发现2: 数据与计算高效**: 即使在基线方法获得更优条件（更多数据、更长微调）的宽松设置下，TAP-ViTs的性能依然**与之相当或更优**。这证明了其**GMM代理数据集构建**和**双粒度重要性评估**策略的高效性，能够在极有限的资源下实现精准的任务自适应。

#### **2.2 在不同ViT架构上的泛化性**
TAP-ViTs在T2T-ViT和Swin Transformer上也表现出色：
- **T2T-ViT (70%参数)**: 在CIFAR-100上准确率从85.88%**提升至88.69%**。
- **Swin Transformer (70%参数)**: 在CIFAR-100上准确率从88.64%**提升至91.91%**。
- **结论**: 该方法对不同ViT设计范式（如Token聚合、分层窗口）均有效，展现了良好的**架构鲁棒性**。

#### **2.3 不同剪枝强度下的性能**
随着参数保留率从90%降至60%，模型性能平缓下降。
- **关键观察**: 即使在**60%** 的激进剪枝率下，DeiT-Base在CIFAR-100上的准确率（~92%）仍**高于原始模型**（90.02%）。这证明了框架在**宽泛的压缩比范围内都能保持高性能**，适用于不同资源约束的设备。

#### **2.4 消融实验验证核心组件**
移除任一核心组件均导致性能显著下降：
- **移除GMM数据集构建**: 性能下降最剧烈（如DeiT-S在CIFAR-100上从90.32%跌至76.39%）。这证明了**在隐私约束下感知任务特性的必要性**，代理数据集是任务自适应剪枝的基石。
- **移除高效剪枝策略**: 性能也有明显下降（如DeiT-S在TinyImageNet上从81.50%跌至79.49%）。这验证了**双粒度重要性评估**对于精准识别并保留关键参数的有效性。

#### **2.5 实际部署可行性分析**
- **设备端开销**: 在NVIDIA Jetson Orin Nano上测量**GMM拟合时间**。即使处理1000个本地样本，耗时也**仅在1分钟左右**，且时间随样本数线性增长。
- **结论**: 该框架唯一的设备端计算开销**极低**，完全适合资源受限的边缘设备，满足了**实际部署的可行性**要求。

### 3. 总结
论文通过系统、严谨的实验设计，定量证明了TAP-ViTs框架的以下优势：
1.  **高性能**: 在同等压缩比下，准确率显著超越SOTA剪枝方法，甚至能超越原始模型。
2.  **强适应性**: 无需原始本地数据，仅通过轻量级GMM参数即可为异构设备生成定制化剪枝模型。
3.  **高泛化性**: 在多种主流ViT架构和数据集上均表现稳定。
4.  **高实用性**: 设备端开销极小，满足隐私保护和资源约束的双重要求，具备真实的边缘部署价值。

这些实验结果共同支撑了论文的核心主张：TAP-ViTs为**隐私保护、任务自适应的ViT边缘部署**提供了一个高效、可行的解决方案。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2601.02437v1)
- [HTML 版本](https://arxiv.org/html/2601.02437v1)
