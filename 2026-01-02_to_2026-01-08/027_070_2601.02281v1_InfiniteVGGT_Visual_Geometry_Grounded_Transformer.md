# InfiniteVGGT: Visual Geometry Grounded Transformer for Endless Streams

**相关性评分**: 7.0/10

**排名**: #27


---


## 基本信息

- **arXiv ID**: [2601.02281v1](https://arxiv.org/abs/2601.02281v1)
- **发布时间**: 2026-01-05T17:11:00Z
- **相关性评分**: 7.0/10
- **是否相关**: 是

## 作者

Shuai Yuan, Yantai Yang, Xiaotian Yang, Xupeng Zhang, Zhonghao Zhao, Lingming Zhang, Zhipeng Zhang

## 关键词

Inference Efficiency, Lightweight Architecture, Edge Deployment

## 一句话总结

InfiniteVGGT是一种用于无限流式3D视觉几何理解的因果Transformer模型，通过滚动内存和剪枝策略提升推理效率，适用于实时系统。

## 摘要

The grand vision of enabling persistent, large-scale 3D visual geometry understanding is shackled by the irreconcilable demands of scalability and long-term stability. While offline models like VGGT achieve inspiring geometry capability, their batch-based nature renders them irrelevant for live systems. Streaming architectures, though the intended solution for live operation, have proven inadequate. Existing methods either fail to support truly infinite-horizon inputs or suffer from catastrophic drift over long sequences. We shatter this long-standing dilemma with InfiniteVGGT, a causal visual geometry transformer that operationalizes the concept of a rolling memory through a bounded yet adaptive and perpetually expressive KV cache. Capitalizing on this, we devise a training-free, attention-agnostic pruning strategy that intelligently discards obsolete information, effectively ``rolling'' the memory forward with each new frame. Fully compatible with FlashAttention, InfiniteVGGT finally alleviates the compromise, enabling infinite-horizon streaming while outperforming existing streaming methods in long-term stability. The ultimate test for such a system is its performance over a truly infinite horizon, a capability that has been impossible to rigorously validate due to the lack of extremely long-term, continuous benchmarks. To address this critical gap, we introduce the Long3D benchmark, which, for the first time, enables a rigorous evaluation of continuous 3D geometry estimation on sequences about 10,000 frames. This provides the definitive evaluation platform for future research in long-term 3D geometry understanding. Code is available at: https://github.com/AutoLab-SAI-SJTU/InfiniteVGGT

## 详细分析

## 论文摘要：InfiniteVGGT: Visual Geometry Grounded Transformer for Endless Streams

**1. 研究背景和动机**
在线、大规模、持久的3D视觉几何理解是增强现实和具身智能等应用的核心需求，但面临着**可扩展性与长期稳定性**之间的根本矛盾。现有方法存在两难困境：基于Transformer的流式方法（如StreamVGGT）因KV缓存线性增长导致内存爆炸；而基于RNN的压缩方法（如CUT3R）则因信息丢失导致长期漂移。本文旨在设计一个能处理**无限长视频流**、且内存有界的在线3D重建系统。

**2. 核心方法和技术创新**
本文提出了 **InfiniteVGGT**，一种基于“滚动内存”范式的因果视觉几何Transformer。其核心创新在于一种**免训练、与注意力机制解耦的KV缓存修剪策略**，具体包括：
- **冗余度量**：摒弃传统依赖注意力权重的做法，提出使用**键向量的余弦相似度**作为信息冗余的代理指标。这允许在昂贵的注意力计算前高效识别并丢弃冗余token，且完全兼容FlashAttention。
- **滚动内存机制**：设计了一个分层、动态的内存管理系统。**第一帧的KV缓存作为不可变的锚点**被完整保留，以维持全局几何一致性。后续帧的token则根据其键向量的多样性分数进行筛选保留。
- **自适应层间预算分配**：观察到不同网络层的信息多样性不同，因此采用**基于层间多样性得分的软最大化分配**，将固定的总token预算智能地分配到各层，优化内存使用效率。

此外，为填补长时评估基准的空白，本文引入了 **Long3D 基准数据集**，包含长达约10,000帧的连续序列，为长时3D几何理解提供了首个 rigorous 评估平台。

**3. 主要实验结果**
在多个数据集和任务上的实验表明，InfiniteVGGT在长序列处理上具有显著优势：
- **3D重建**：在7-Scenes、NRGBD及自建的Long3D数据集上，InfiniteVGGT在准确率（Acc.）、完整性（Comp.）和法向一致性（NC）等指标上均**优于或媲美当前最佳的流式方法（如TTT3R、CUT3R）**，同时有效抑制了长期漂移。
- **视频深度估计**：在Bonn数据集的长序列上，取得了更低的绝对相对误差（Abs Rel）和更高的精度（δ<1.25）。
- **关键优势**：成功解决了基线模型（StreamVGGT）在长序列上的内存溢出（OOM）问题，实现了**真正意义上的无限长序列处理能力**，且推理速度更快、峰值内存消耗更低。

**4. 研究意义和价值**
- **理论价值**：提出了一种新颖的“滚动内存”范式，通过**键空间多样性分析**这一优雅的视角，巧妙地解决了流式Transformer中内存增长与信息保留的根本矛盾，为后续研究提供了新思路。
- **实用价值**：所提出的方法是**免训练的**，可直接应用于现有流式架构，并完全兼容硬件优化内核（如FlashAttention），具备极高的部署可行性。这为需要实时、持久3D感知的机器人、AR/VR等在线应用扫清了关键障碍。
- **社区贡献**：发布的Long3D基准填补了领域内缺乏超长连续序列评估标准的空白，为未来长时3D理解研究提供了至关重要的评估基础。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析

### **一、 研究问题**
论文旨在解决**在线、长序列3D几何理解**中的一个根本性矛盾：
- **离线模型**（如VGGT）：几何精度高，但需要处理所有数据，内存和计算开销随序列长度线性增长，无法用于实时流式系统。
- **现有流式模型**：虽为在线设计，但存在两大缺陷：
    1.  **显式历史累积**（如StreamVGGT）：KV缓存无限增长，导致内存和计算不可持续。
    2.  **隐式状态压缩**（如CUT3R/TTT3R）：将历史压缩为固定大小的RNN状态，牺牲了长期上下文信息，导致**灾难性漂移**和**长期依赖丢失**。

**核心问题**：能否在**资源有限**的在线系统中，**选择性地保留关键历史信息**，以实现长期稳定的3D重建？

### **二、 核心创新点**

#### **1. 方法论创新：“滚动记忆”范式**
提出 **`InfiniteVGGT`**，一种基于Transformer的因果视觉几何模型，其核心是引入一个**有界、自适应、持续表达**的KV缓存，即“滚动记忆”。
- **目标**：避免缓存无限增长，同时防止信息过度压缩导致的漂移。
- **关键洞察**：在连续的相机轨迹中，相邻帧之间存在**巨大的令牌级冗余**。直接利用注意力分数进行剪枝会与FlashAttention等优化内核冲突。

#### **2. 技术核心：基于键多样性的训练无关剪枝策略**
为了解决上述冲突，论文提出了一个**无需训练、与注意力机制解耦**的智能缓存剪枝方法：
- **冗余度量**：放弃使用需要显式计算注意力矩阵的方法，转而使用**键向量的余弦相似度**作为令牌信息重要性的代理。
    - **原理**：计算缓存中所有归一化键向量的均值，然后计算每个键与该均值的**负余弦相似度**作为“多样性分数”。
    - **逻辑**：与均值差异越大的键，所含信息越独特、越有价值，应予以保留。
- **分层自适应预算分配**：并非在所有层平均分配缓存预算。
    - **观察**：模型不同层的信息多样性不同（浅层空间推理差异大，深层语义趋同）。
    - **方法**：根据每层计算出的平均多样性分数，通过Softmax分配不同的令牌保留预算，实现**层间非均匀的优化存储**。
- **锚定令牌机制**：将**第一帧**的完整KV缓存设为不可变的锚定集。因为VGGT系列模型以第一帧为全局坐标系参考，修剪它会破坏整个重建的几何一致性。

#### **3. 评估体系创新：Long3D基准**
为解决领域内缺乏超长连续序列评估标准的问题，论文引入了 **`Long3D`** 基准数据集。
- **内容**：包含5个挑战性场景（室内/室外），每个序列长达2,000至10,000帧。
- **价值**：首次为**无限视野、连续3D几何估计**的性能提供了严格的评估平台。

### **三、 解决方案总结**
论文通过一个**三层递进**的方案解决了“无限流式3D理解”的难题：

1.  **根本策略**：将无限的KV缓存转换为**有界的滚动记忆**。
2.  **实现手段**：提出**基于键余弦相似度的多样性感知剪枝算法**。该算法：
    - **高效**：无需计算昂贵的注意力权重，与FlashAttention完全兼容。
    - **智能**：能识别并丢弃冗余令牌，保留信息丰富的关键上下文。
    - **自适应**：通过层间预算分配，尊重了Transformer不同层的信息特性。
3.  **系统集成**：将上述剪枝策略与**锚定帧保护机制**结合，集成到StreamVGGT框架中，形成了完整的`InfiniteVGGT`系统。

### **四、 实际价值与效果**
- **性能**：在7-Scenes、NRGBD等数据集的长序列（300-500帧）测试中，达到了SOTA。在全新的Long3D基准（上万帧）上，显著降低了长期漂移，优于其他流式方法。
- **效率**：保持了流式处理的低延迟特性，峰值GPU内存消耗显著低于基线方法。
- **贡献**：不仅提出了一个新模型，更贡献了一个**解决长序列Transformer缓存爆炸的通用性思路**（基于键空间的多样性剪枝），以及一个**推动领域发展的评估基准**。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文旨在解决在线、无限长视频流中进行3D几何理解时，**可扩展性与长期稳定性之间的根本矛盾**。现有流式方法要么因KV缓存无限增长导致内存爆炸，要么因过度压缩历史状态而引发灾难性漂移。为此，论文提出了 **InfiniteVGGT**，其核心创新在于一种基于**滚动记忆**的因果视觉几何Transformer。该方法通过一种**免训练、与注意力机制解耦的剪枝策略**，利用**键向量的余弦相似度**作为冗余度代理，动态且分层地丢弃KV缓存中的过时信息，从而在严格限定内存的前提下实现“无限”序列处理。最终，该方法在多个长序列基准测试中取得了**最先进的性能**，首次实现了对真正长时、连续输入的鲁棒重建，并为此发布了首个超长序列（约10,000帧）评估基准**Long3D**。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文创新点分析

这篇论文《InfiniteVGGT: Visual Geometry Grounded Transformer for Endless Streams》针对**在线、无限长序列的3D几何理解**这一核心挑战，提出了系统性的创新。其创新点可归纳为以下三个方面：

---

### 1. **核心架构创新：基于“滚动内存”的在线3D几何Transformer**

- **改进/不同之处**：
    - **以往方法**：在线3D重建方法面临两难困境。
        1.  **显式历史累积方法**（如StreamVGGT）：保留所有历史帧的Key-Value缓存，导致内存和计算开销线性增长（`O(t)`），无法处理长序列。
        2.  **隐式状态压缩方法**（如CUT3R, TTT3R）：将历史信息压缩到一个固定大小的RNN隐状态中，虽然内存有界，但会丢失大量信息，导致**长期漂移**和**灾难性遗忘**。
    - **本文方法**：提出 **“滚动内存”** 范式。它维护一个**有界但自适应、持续表达**的KV缓存。通过一种**免训练、与注意力机制无关的剪枝策略**，智能地丢弃过时/冗余信息，随着新帧的加入“滚动”更新内存。

- **解决的具体问题/带来的优势**：
    - **解决了“内存无限增长”与“信息长期保持”之间的矛盾**。首次实现了在**严格有界的内存和计算资源**下，处理**无限长**图像序列。
    - **避免了灾难性遗忘**：通过选择性保留关键历史token，而非粗暴压缩，有效维持了长期的时间一致性，减少了重建漂移。
    - **保持了在线性**：能够以流式方式逐帧处理，满足机器人、AR等实时应用的需求。

---

### 2. **关键技术创新：基于Key多样性的免训练缓存剪枝策略**

- **改进/不同之处**：
    - **直觉方法（被证明不可行）**：基于注意力权重来判断token重要性。但这需要显式地计算完整的 `O(N^2)` 注意力矩阵，与为了高效处理长序列而必须使用的**FlashAttention等优化内核**（其核心优势正是避免物化注意力矩阵）相冲突。
    - **本文方法**：提出使用**Key向量的余弦相似度**作为token冗余度的代理指标。
        1.  **计算Key空间的均值向量**。
        2.  计算每个Key与该均值的**负余弦相似度**作为“多样性分数”。分数越高，表示该Key越独特、信息量越大。
        3.  根据多样性分数进行**Top-K选择**，保留最独特的token。

- **解决的具体问题/带来的优势**：
    - **解决了“高效内核”与“智能剪枝”之间的根本矛盾**。该策略完全**不依赖注意力权重**，可以在昂贵的注意力计算**之前**就完成缓存剪枝。
    - **实现了与FlashAttention的完全兼容**，在获得极致计算效率的同时，实现了智能的内存管理。
    - **方法简单、高效、可解释**：计算开销低，且多样性分数直接反映了特征空间中的信息分布。

---

### 3. **系统优化与评估创新：分层自适应预算分配与Long3D基准**

**创新点A：分层自适应的缓存预算分配机制**

- **改进/不同之处**：
    - **朴素方法**：为所有Transformer层分配统一的KV缓存token预算。
    - **本文方法**：观察到不同层的信息多样性分布不均（浅层空间细节多样，深层语义特征收敛），因此提出**分层软分配预算**。
        1.  计算每一层所有token多样性分数的平均值。
        2.  通过softmax函数，根据各层的平均多样性分数按比例分配总预算。多样性高的层获得更多预算。

- **解决的具体问题/带来的优势**：
    - **优化了有限缓存资源的利用效率**。将“好钢用在刀刃上”，在信息丰富的层保留更多上下文，提升了整体重建精度。
    - **是一种数据驱动的、自适应的优化**，比固定分配策略更灵活有效。

**创新点B：引入Long3D超长序列评测基准**

- **改进/不同之处**：
    - **以往基准的局限**：现有3D重建数据集（如7-Scenes）要么序列很短（≤1000帧），要么是由不连续的视频片段组成，**无法评估模型在真正连续、超长流式输入下的长期稳定性**。
    - **本文贡献**：提出了 **Long3D** 基准，包含5个场景，每个场景提供**2000到近10000帧**的连续RGB图像流和全局真值点云。

- **解决的具体问题/带来的优势**：
    - **填补了研究领域的空白**：首次为“无限长序列3D几何理解”提供了 rigorous 的评估平台。
    - **推动了研究方向**：使得衡量模型的长期漂移、记忆能力和稳定性成为可能，为未来研究设立了明确的评估标准。
    - **验证了本工作的价值**：在Long3D上的实验表明，InfiniteVGGT在超长序列上显著优于现有方法，尤其是在控制误差累积方面。

---

### **总结**
本文的创新是一个**系统性工程**：从**核心架构范式**（滚动内存）的提出，到**关键算法**（基于Key多样性的剪枝）的设计，再到**系统级优化**（分层预算分配）和**评估体系**（Long3D基准）的构建，层层递进，共同解决了在线、无限长3D重建中“内存-精度-效率”的三角难题，为该领域迈向实用化、持久化的场景理解奠定了重要基础。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 论文实验与评估效果分析

论文通过一系列实验，全面评估了 **InfiniteVGGT** 在长序列、在线3D几何理解任务上的性能。其核心目标是验证模型在**无限长视频流**中，能否在保持内存有界的同时，实现稳定、高精度的重建。

### 一、 使用的数据集
论文使用了三类数据集进行评估，覆盖了不同长度和场景：

1.  **经典短/中序列数据集**（用于与现有方法对标）：
    *   **7-Scenes**：室内场景数据集，论文从中抽取了最长的连续序列（300-500帧，stride=2）进行评估。
    *   **NRGBD**：包含RGB-D数据的室内场景数据集，同样抽取长连续序列（300-500帧）进行测试。
    *   **Bonn**：用于视频深度估计的数据集，选取了其中200-500帧的连续序列。

2.  **作者提出的新基准数据集**：
    *   **Long3D**：为了解决**缺乏超长连续序列基准**的关键空白而提出。包含5个极具挑战性的室内外场景序列，长度从约2,000帧到近10,000帧，使用专业3D空间扫描仪采集，提供了全局真值点云。这是论文的核心贡献之一，也是评估“无限流”能力的**决定性平台**。

### 二、 使用的评价指标
根据任务不同，采用了以下指标：

1.  **3D重建质量**（主要任务）：
    *   **Accuracy (Acc.)**：预测点云到真值点云的平均距离。**越低越好**。
    *   **Completion (Comp.)**：真值点云到预测点云的平均距离。**越低越好**。
    *   **Chamfer Distance (CD)**：Accuracy和Completion的平均值。**越低越好**。
    *   **Normal Consistency (NC)**：预测点云与真值点云之间法向量的一致性。**越高越好**。

2.  **视频深度估计**：
    *   **Absolute Relative Error (Abs Rel)**：绝对相对误差。**越低越好**。
    *   **δ < 1.25**：深度预测值在真值1.25倍以内的像素比例。**越高越好**。

3.  **系统效率**（消融实验）：
    *   **每帧推理时间 (Time)**：**越低越好**。
    *   **峰值GPU内存占用 (Peak Memory)**：**越低越好**。

### 三、 对比的基线方法
论文与以下几类代表性方法进行了全面对比：

1.  **离线方法 (Offline)**：
    *   **VGGT**：性能强大的离线SOTA模型，作为性能上限参考。但在长序列上会**内存溢出(OOM)**，无法运行。

2.  **在线流式方法 (Online Streaming)**：
    *   **StreamVGGT**：基于因果注意力且KV缓存无限增长的在线方法。在长序列上同样会因内存爆炸而**OOM**。
    *   **CUT3R**：采用RNN隐状态压缩历史的在线方法，内存有界但信息损失大。
    *   **TTT3R**：在CUT3R基础上引入测试时训练，以提升长度泛化能力。
    *   **Point3R**：使用显式指针记忆的早期方法，内存同样会无限增长，在长序列上**不适用**（论文引用指出其内存问题）。

### 四、 关键性能提升与结论

#### 1. 在经典数据集（7-Scenes, NRGBD）上的表现
*   **核心结论**：InfiniteVGGT在**所有可运行的在线方法中取得了最佳或极具竞争力的重建精度**，并且随着序列长度增加（300->500帧），性能下降最小，展现了优异的**长期稳定性**。
*   **关键数据**（以500帧输入为例）：
    *   **7-Scenes上**：在Accuracy (0.043 vs. TTT3R的0.062)、Completion (0.025 vs. TTT3R的0.029) 和 NC (0.561 vs. TTT3R的0.552) 上均优于最强的基线TTT3R。
    *   **NRGBD上**：优势更为明显，Accuracy (0.080) 显著优于CUT3R (0.326) 和TTT3R (0.165)，NC (0.643) 也最高。这证明了其**更强的泛化能力和对复杂场景的鲁棒性**。
*   **重要对比**：离线VGGT和在线StreamVGGT在300帧以上均**OOM**，而InfiniteVGGT成功运行，首次实现了对长序列的在线高精度处理。

#### 2. 在Long3D超长基准上的表现
*   **核心结论**：InfiniteVGGT在**长达近万帧的连续流**上，依然能保持可靠的性能，并**显著抑制了长时漂移**，验证了其“无限流”处理能力。
*   **关键数据**：
    *   在5个场景（2000-9500帧）上，InfiniteVGGT在**绝大多数场景的Accuracy和Chamfer Distance上取得最佳**。
    *   例如，在9545帧的“Academic Building”场景中，其CD (3.470) 远低于CUT3R (4.638) 和TTT3R (6.951)。
*   **指出不足**：论文坦诚，在Completion指标的均值上，该方法有时不如基线。作者将此列为未来需要优化的关键方向。

#### 3. 在视频深度估计（Bonn）上的表现
*   **核心结论**：InfiniteVGGT在长视频深度估计任务上同样领先，证明了其滚动记忆机制对提升**帧间深度一致性**的有效性。
*   **关键数据**：在500帧输入下，Abs Rel (0.069) 和 δ<1.25 (0.960) 均优于所有基线（CUT3R: 0.084/0.939; TTT3R: 0.076/0.953）。

#### 4. 消融实验验证核心设计
*   **令牌选择策略**：**基于键向量余弦相似度**的方法，在保持与FlashAttention兼容的前提下，比基于注意力权重的传统方法**重建更准确（CD更低）、推理更快（耗时减少~120ms/帧）、内存占用更少**。
*   **层间自适应预算分配**：动态分配各层KV缓存预算的策略，比均匀分配能带来**更好的重建精度（Acc.）和法向一致性（NC）**。
*   **锚定帧机制**：完整保留第一帧的所有令牌作为不可变锚点，对**维持全局几何一致性至关重要**，移除该机制会导致性能显著下降。
*   **预算大小**：初始每头预算 `B(l,h)` 存在一个饱和点（文中约为25000），超过后性能提升 negligible，在效率与精度间取得了平衡。

### 总结
论文通过系统的实验表明，**InfiniteVGGT成功解决了在线3D几何理解中“内存无限增长”与“长时信息漂移”的两难困境**。它在多个数据集上超越了所有内存有界的在线基线方法，在首次提出的超长序列基准Long3D上证明了其处理“无限流”的独特能力，并通过消融实验坚实论证了其核心设计（基于余弦相似度的滚动记忆、层间自适应预算、锚定帧）的有效性和必要性。其**训练免费、与FlashAttention完全兼容**的特性，使其具备了强大的实用价值。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2601.02281v1)
- [HTML 版本](https://arxiv.org/html/2601.02281v1)
