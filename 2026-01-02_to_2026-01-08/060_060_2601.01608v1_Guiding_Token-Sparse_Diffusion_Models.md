# Guiding Token-Sparse Diffusion Models

**相关性评分**: 6.0/10

**排名**: #60


---


## 基本信息

- **arXiv ID**: [2601.01608v1](https://arxiv.org/abs/2601.01608v1)
- **发布时间**: 2026-01-04T17:18:27Z
- **相关性评分**: 6.0/10
- **是否相关**: 是

## 作者

Felix Krause, Stefan Andreas Baumann, Johannes Schusterbauer, Olga Grebenkova, Ming Gui, Vincent Tao Hu, Björn Ommer

## 关键词

Inference Efficiency, Lightweight Architecture, Inference Acceleration, Edge Deployment

## 一句话总结

该论文提出Sparse Guidance方法，通过利用token级稀疏性改进稀疏训练扩散模型的推理性能，在减少计算量的同时提升输出质量，与推理效率和轻量化架构相关。

## 摘要

Diffusion models deliver high quality in image synthesis but remain expensive during training and inference. Recent works have leveraged the inherent redundancy in visual content to make training more affordable by training only on a subset of visual information. While these methods were successful in providing cheaper and more effective training, sparsely trained diffusion models struggle in inference. This is due to their lacking response to Classifier-free Guidance (CFG) leading to underwhelming performance during inference. To overcome this, we propose Sparse Guidance (SG). Instead of using conditional dropout as a signal to guide diffusion models, SG uses token-level sparsity. As a result, SG preserves the high-variance of the conditional prediction better, achieving good quality and high variance outputs. Leveraging token-level sparsity at inference, SG improves fidelity at lower compute, achieving 1.58 FID on the commonly used ImageNet-256 benchmark with 25% fewer FLOPs, and yields up to 58% FLOP savings at matched baseline quality. To demonstrate the effectiveness of Sparse Guidance, we train a 2.5B text-to-image diffusion model using training time sparsity and leverage SG during inference. SG achieves improvements in composition and human preference score while increasing throughput at the same time.

## 详细分析

## 论文摘要：《引导令牌稀疏扩散模型》

### 1. 研究背景和动机
扩散模型在图像合成中表现出色，但其训练和推理的计算成本高昂。近年来，研究者利用视觉数据固有的冗余性，通过**令牌稀疏训练**（如掩码或路由）来降低训练成本。然而，这些稀疏训练的模型在推理时，与主流的**无分类器引导**（CFG）方法兼容性差，导致生成质量下降、性能不稳定，限制了其实际应用。本文旨在解决这一瓶颈，使稀疏训练的扩散模型在推理时既能保持高效，又能获得高质量的生成结果。

### 2. 核心方法和技术创新
本文提出了**稀疏引导**（Sparse Guidance, SG）方法。其核心创新在于：
- **将训练时稀疏性转化为推理时引导信号**：SG不再使用CFG中的条件/无条件预测组合，而是利用**令牌级稀疏率**（γ）作为控制模型容量的“旋钮”。
- **构建容量差进行引导**：在推理时，使用两个不同的稀疏率（`γ_strong` < `γ_weak`）对同一条件输入进行两次前向传播，分别得到高容量（强）和低容量（弱）的预测。通过线性组合这两个预测，利用它们之间的“容量差”来引导生成过程，朝向更高质量、更高保真度的输出。
- **无需微调，兼容性强**：SG是一种无需额外微调的后处理调度机制，可直接应用于已有的稀疏训练模型。它还能与CFG等其他引导方法自然结合，提供更精细的控制。

### 3. 主要实验结果
- **在ImageNet-256基准测试上**：SG在稀疏训练的模型上实现了**FID 1.58**的优异性能，同时比密集基线模型减少**25%** 的FLOPs。在匹配基线质量的情况下，最高可节省**58%** 的计算量。
- **与现有引导方法对比**：SG在FID和计算效率上均显著优于CFG、AutoGuidance等方法。
- **扩展到大规模文本到图像模型**：在一个2.5B参数的稀疏训练扩散Transformer上应用SG，在人类偏好评分（HPSv3）和组合性基准（GenEval）上均优于CFG，同时**提高了推理吞吐量**。

### 4. 研究意义和价值
- **实用价值**：SG成功解决了稀疏训练扩散模型推理性能不佳的关键难题，使其兼具**训练高效**和**推理高质量**的双重优势，为实际部署铺平了道路，有望大幅降低扩散模型的总体计算成本和碳排放。
- **技术贡献**：提出了一种新颖的、基于容量差的引导范式，丰富了扩散模型的控制方法。它证明了**利用训练-测试间的差异（容量差）本身可以成为强大的引导信号**，这一思路具有启发性。
- **社区影响**：该工作鼓励社区更广泛地采用令牌稀疏训练方法，推动高效、高性能生成模型的发展。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析

### **研究背景与核心问题**
这篇论文旨在解决一个关键矛盾：**基于Token稀疏训练的扩散模型在训练时效率高，但在推理时性能不佳**。具体来说：
- **训练效率**：利用视觉数据的冗余性，通过**Token稀疏化**（如掩码或路由）训练扩散模型，显著降低了计算成本。
- **推理困境**：稀疏训练的模型对**无分类器引导（CFG）** 响应不佳，导致生成质量下降、输出多样性降低，限制了其实用性。

### **核心创新点：稀疏引导（Sparse Guidance, SG）**
论文提出了 **“稀疏引导”** 方法，这是一种**无需微调、后处理的推理时调度机制**。其核心思想是：
- **将训练时的稀疏性转化为推理时的引导信号**：通过为两个条件预测分支设置不同的Token稀疏率（`γ_strong` 和 `γ_weak`），人为制造一个**容量差**。
- **利用容量差进行引导**：用高稀疏率（低容量、预测较“弱”）分支的输出来引导低稀疏率（高容量、预测较“强”）分支，从而提升生成质量和多样性。
- **公式化表示**：
  ```math
  D_θ^SG(c, γ_strong, γ_weak, ω) = ω * D_θ^strong(c) + (1 - ω) * D_θ^weak(c)
  ```
  其中 `γ_strong < γ_weak`，`ω` 是引导尺度。

### **解决方案的三大优势**
1.  **无需微调**：直接应用于稀疏训练的模型，无需昂贵的“稠密微调”阶段即可恢复强大的引导效果。
2.  **提升质量与效率**：
    - **质量**：在ImageNet-256上达到 **FID 1.58**，优于许多稠密基线模型。
    - **效率**：推理时处理的Token更少，计算量（FLOPs）最高可减少 **58%**，吞吐量提升。
3.  **保持输出多样性**：与CFG（倾向于坍缩输出多样性）不同，SG能更好地保留条件预测的高方差，生成更具创造性的图像。

### **技术实现与验证**
1.  **方法兼容性**：SG可应用于不同的稀疏训练方法（如**掩码Masking**和**路由Routing**），并能与CFG等其他引导方法结合使用。
2.  **超参数简单**：主要引入稀疏率（`γ`）作为控制参数，易于调节质量和计算成本的权衡。
3.  **规模化验证**：
    - 在**ImageNet-256**上系统验证，SG在FID、sFID、召回率等指标上全面超越CFG及其他引导方法。
    - 训练了一个**25亿参数**的文本到图像稀疏扩散模型（TR-DiT-2.5B），应用SG后在**人类偏好评分（HPSv3）** 和**组合理解（GenEval）** 上均获得提升，同时提高了推理速度。

### **实际价值与影响**
- **为稀疏训练正名**：解决了稀疏训练模型推理性能差的痛点，使其真正具备了实用价值。
- **降低AI成本与能耗**：通过稀疏训练和稀疏引导，大幅降低了扩散模型训练和推理的计算开销，对降低经济成本和环境足迹（CO₂排放）有重要意义。
- **提供新的控制维度**：`γ` 提供了一个连续的控制旋钮，可以精细调节模型的“容量”和引导强度，为可控生成提供了新工具。

**总结**：该论文的核心创新在于**创造性地将训练时的“缺陷”（稀疏性）转化为推理时的“资产”（引导信号）**，提出了一种高效、高质量的引导机制，打通了稀疏扩散模型从训练到应用的全链路，具有显著的技术先进性和实际应用价值。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文旨在解决**稀疏训练的扩散模型在推理时与无分类器引导（CFG）兼容性差、导致生成质量下降**的核心问题。为此，作者提出了**稀疏引导（Sparse Guidance, SG）** 方法，其核心思想是在推理时，通过为同一个条件模型施加两个不同的令牌稀疏率（`γ_strong` 和 `γ_weak`），人为制造一个“能力差距”，并利用这个差距作为引导信号来提升生成质量，而非依赖传统的条件与无条件预测组合。该方法最终取得了显著效果：在ImageNet-256基准上，SG以**更少的计算量（减少25% FLOPs）达到了1.58的FID**，性能超越密集基线；同时，在一个25亿参数的文生图大模型中，SG在提升人类偏好评分和组合能力的同时，还**显著提高了推理吞吐量**，证明了稀疏训练模型在高效推理上的巨大潜力。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文《Guiding Token-Sparse Diffusion Models》的创新点分析

这篇论文的核心贡献是提出了 **Sparse Guidance (SG)** 方法，旨在解决稀疏训练扩散模型在推理时与无分类器引导不兼容的关键问题。以下是其相对于已有工作的明确创新点：

### 1. **提出“稀疏引导”作为一种全新的引导机制**
   - **相比以往方法的改进/不同之处**：
     - **传统方法**：无分类器引导使用**条件预测**和**无条件预测**的组合（`v_θ(c)` 和 `v_θ(∅)`），这需要计算两个完整的前向传播，使推理计算量翻倍。
     - **SG方法**：使用**两个不同稀疏率（`γ_strong` 和 `γ_weak`）的条件预测**来创建引导信号。两者都基于条件输入，但通过控制处理的令牌数量（即模型容量）产生差异。
   - **解决的具体问题/带来的优势**：
     - **解决了稀疏训练模型对CFG响应弱的问题**：稀疏训练模型（如MaskDiT、TREAD）在推理时使用CFG会导致图像质量下降或不稳定。SG通过利用模型自身的“容量差”作为引导信号，恢复了有效的引导。
     - **降低了推理计算成本**：由于两个分支都应用了令牌稀疏（即只处理部分令牌），整体FLOPs显著减少。论文实现了**最高58%的FLOPs节省**（在同等质量下），或**以25%更少的FLOPs达到更低的FID（1.58）**。
     - **无需微调**：与之前需要额外“密集微调”阶段来恢复CFG性能的方法不同，SG是一种即插即用的后处理调度机制，无需对预训练的稀疏模型进行任何微调。

### 2. **将训练时稀疏性转化为推理时的可控引导“旋钮”**
   - **相比以往方法的改进/不同之处**：
     - **传统观点**：令牌稀疏（掩码或路由）主要被视为一种**训练加速技术**，在推理时要么完全不用，要么会导致质量下降。
     - **SG的视角**：将稀疏率 `γ` 重新定义为**控制模型预测分布“锐度”的连续超参数**。较低的 `γ`（处理更多令牌）产生高容量、高方差的“强”预测；较高的 `γ`（处理更少令牌）产生低容量、低方差的“弱”预测。两者的差异（容量差）成为了引导力的来源。
   - **解决的具体问题/带来的优势**：
     - **提供了精细的质量-吞吐量权衡**：通过调整 `γ_strong`、`γ_weak` 和引导尺度 `ω`，用户可以在图像保真度（FID）和计算效率（FLOPs/吞吐量）之间进行平滑、可预测的权衡。
     - **利用了而非避免“训练-测试差距”**：传统方法试图通过微调来弥合稀疏训练与密集推理之间的差距。SG则主动利用这个差距（即模型在不同稀疏率下的行为差异）作为引导资源，变废为宝。

### 3. **与现有引导方法的兼容性与复合增益**
   - **相比以往方法的改进/不同之处**：
     - **SG的通用性**：SG公式不依赖于特定的条件形式，因此可以自然地与CFG等其他引导方法结合，形成 **CFG+SG**（将弱分支替换为无条件预测）。
     - **特别是与AutoGuidance的复合**：AutoGuidance (AG) 使用训练不足的辅助模型作为弱分支，但其效果严重依赖精确的检查点选择。SG通过稀疏率调整，可以**拓宽AG可用检查点的范围**，并补偿辅助模型的欠训练状态，从而获得更好的FID与计算效率的平衡。
   - **解决的具体问题/带来的优势**：
     - **增强了现有引导方法的灵活性和鲁棒性**：SG为像AG这样对超参数敏感的方法提供了额外的调节维度（`γ`），使其更容易达到良好性能。
     - **实现了性能叠加**：实验表明，SG与CFG或AG结合时，能取得比单独使用任一方法更优的结果（更低的FID，更高的吞吐量）。

### 4. **在大规模文本到图像生成上的验证与优势体现**
   - **相比以往方法的改进/不同之处**：
     - **先前工作局限**：关于稀疏训练和推理加速的研究大多在类别条件ImageNet等相对较小的数据集和模型上进行验证。
     - **本文的扩展**：论文训练了一个**2.5B参数**的基于令牌路由的文本到图像扩散Transformer，并在此规模上验证了SG的有效性。
   - **解决的具体问题/带来的优势**：
     - **证明了方法的可扩展性**：SG在超大规模模型和更复杂的文本到图像任务上依然有效，解决了该领域落地的一个关键障碍。
     - **获得了更优的人类偏好和构图分数**：在HPSv3和GenEval基准测试中，SG在几乎所有类别上都超越了标准CFG，表明其能生成**更符合提示、视觉上更吸引人、且多样性更高**的图像。SG保留了条件预测的高方差，避免了CFG常导致的“方差坍缩”和样本过于同质化的问题。
     - **同步提升质量与吞吐量**：在2.5B模型上，SG在将人类偏好分数提升7%（相比CFG）的同时，还将推理吞吐量从0.32 img/s提升至0.49 img/s（在H200 GPU上）。

### 总结
本文的核心创新 **Sparse Guidance (SG)** 从根本上改变了稀疏扩散模型的使用范式：它不再将推理时的稀疏性视为缺陷，而是将其转化为一种可控的引导资源。这种方法**一举三得**：
1.  **解决了**稀疏模型与CFG不兼容的核心痛点。
2.  **降低了**高价值扩散模型推理的巨额计算成本。
3.  **提升了**生成样本的视觉质量和多样性。

因此，SG为广泛采用计算高效的稀疏训练扩散模型铺平了道路，具有显著的实用价值和经济价值。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 论文实验与评估效果总结

该论文通过系统的实验验证了**稀疏引导（Sparse Guidance, SG）** 方法的有效性，在多个数据集和模型规模上实现了**质量提升与计算效率的显著改进**。

### 一、 主要数据集与评价指标

#### 1. 数据集
- **ImageNet-256**： 用于类条件图像生成评估的核心数据集。
- **文本到图像（T2I）生成任务**：
    - **COYO-700M子集（100M样本）**： 用于训练2.5B大模型。
    - **合成数据**： 来自JourneyDB和FLUX-6M，用于提升训练数据质量。
    - **评估基准**： 使用GenEval和HPSv3的提示词集进行生成和评估。

#### 2. 评价指标
- **图像质量与保真度**：
    - **FID (Fréchet Inception Distance)**： 核心指标，值越低越好。
    - **sFID (Spatial FID)**： 评估空间特征匹配。
    - **IS (Inception Score)**： 评估生成图像的多样性和清晰度。
    - **Precision & Recall**： 分别衡量生成质量与覆盖数据分布的能力。
- **文本-图像对齐与人类偏好**：
    - **HPSv3 (Human Preference Score v3)**： 基于人类偏好的综合评分。
    - **GenEval**： 评估组合性文本-图像对齐（如物体计数、颜色、位置关系等）。
- **计算效率**：
    - **GFLOPS**： 衡量单次推理的计算量。
    - **推理吞吐量 (images/s)**： 在特定硬件（如H200 GPU）上的生成速度。

### 二、 对比的基线方法

论文与多种先进的基线方法进行了全面对比：

1.  **标准引导方法**：
    - **Classifier-free Guidance (CFG)**： 当前主流引导方法。
    - **AutoGuidance (AG)**： 使用欠训练辅助模型进行引导。
    - **Independent Condition Guidance (ICG)**： 通过扰动时间步嵌入进行引导。

2.  **先进的稀疏训练扩散模型**：
    - **MaskDiT**： 基于掩码（Masking）的稀疏训练方法。
    - **TREAD (Token Routing)**： 基于路由（Routing）的稀疏训练方法。
    - **MDT, FasterDiT, SD-DiT** 等。

3.  **最先进的密集（非稀疏）扩散模型**：
    - **DiT-XL/2, SiT-XL/2**： 标准扩散Transformer基线。
    - **SiT-XL/2 + REPA**： 结合了重参数化技术的先进模型。

4.  **大规模文本到图像模型**（在HPSv3榜单上对比）：
    - **Flux-dev, Playground v2.5, CogView4, PixArt-Σ, Gemini 2.0 Flash** 等业界领先模型。

### 三、 关键性能提升与结论

#### 1. 在ImageNet-256上的核心成果
- **质量突破**： 在SiT-XL/2 + Routing模型上，应用 `SG_FID` 配置取得了 **FID 1.58** 的SOTA结果，显著优于原始CFG的2.57以及许多先进密集模型（见表3）。
- **效率提升**：
    - **`SG_FLOPS` 配置**： 在取得比无引导基线更好质量（FID 2.14 vs 4.89）的同时，**计算量反而降低了16.75 GFLOPS**。
    - **`SG_FID` 配置**： 在达到SOTA质量（FID 1.58）时，相比密集模型CFG所需的228.84 GFLOPS，仅需173.16 GFLOPS，实现了 **~24% 的计算量节省**。
    - **匹配质量下的极致节省**： 在达到与密集SiT基线相当质量时，SG可实现高达 **58% 的FLOPs节省**。
- **无需微调**： SG无需对稀疏训练的模型进行额外的密集微调（Dense Finetuning），而这是先前方法（如MaskDiT）恢复CFG效果所必需的。SG直接超越了经过密集微调后再使用CFG的效果（见图5）。

#### 2. 在大规模文本到图像（2.5B参数）上的验证
- **人类偏好提升**： 在HPSv3评估中，SG将 `TR-DiT-2.5B` 模型的得分从CFG的 **9.21 提升至 9.87**，排名超越Gemini 2.0 Flash、PixArt-Σ和CogView4等模型（见表4）。
- **组合性对齐改进**： 在GenEval基准测试中，SG在所有子类别（单物体、多物体、计数、颜色等）上均取得一致提升，总体分数从CFG的0.61提升至 **0.62**（见表5）。
- **保持高方差**： 与CFG可能导致样本多样性下降（方差坍塌）不同，SG能更好地保留条件预测中的高方差和创造性，生成更具多样性的图像（见图9）。
- **吞吐量增加**： 在H200 GPU上，应用SG后推理吞吐量从 **0.32 images/s 提升至 0.49 images/s**，增速超过50%。

#### 3. 方法特性与鲁棒性
- **广泛的适用性**： SG在两种主要的稀疏训练范式（**掩码Masking**和**路由Routing**）上均有效，证明了其通用性（见表1，图8）。
- **精细可控的权衡**： 通过调节强分支稀疏率 `γ_strong`、弱分支稀疏率 `γ_weak` 和引导强度 `ω`，SG提供了对 **“图像质量-计算成本”** 权衡的平滑、可预测的控制（见图6）。
- **与其他引导方法兼容**： SG可以自然地与CFG、AutoGuidance等方法结合（形成CFG+SG），进一步发挥协同效应，并放宽了AutoGuidance对辅助模型训练阶段的严苛要求（见图7）。

### 结论
论文通过详实的实验证明，**稀疏引导（SG）** 成功解决了稀疏训练扩散模型在推理时对CFG响应不佳的核心瓶颈。它不仅**恢复了引导增益**，还额外带来了**计算效率的大幅提升**和**输出方差的更好保持**。该工作使得高性能、低成本的稀疏训练扩散模型具备了实际部署的可行性，为降低大模型训练与推理的能耗和成本提供了强有力的技术路径。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2601.01608v1)
- [HTML 版本](https://arxiv.org/html/2601.01608v1)
