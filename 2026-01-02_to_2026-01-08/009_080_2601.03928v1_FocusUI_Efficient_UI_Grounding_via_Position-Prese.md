# FocusUI: Efficient UI Grounding via Position-Preserving Visual Token Selection

**相关性评分**: 8.0/10

**排名**: #9


---


## 基本信息

- **arXiv ID**: [2601.03928v1](https://arxiv.org/abs/2601.03928v1)
- **发布时间**: 2026-01-07T13:48:12Z
- **相关性评分**: 8.0/10
- **是否相关**: 是

## 作者

Mingyu Ouyang, Kevin Qinghong Lin, Mike Zheng Shou, Hwee Tou Ng

## 关键词

Vision-Language-Action Model, VLA for Robotics, Inference Efficiency, Lightweight Architecture, Inference Acceleration, Edge Deployment

## 一句话总结

FocusUI 是一种高效的 UI 定位框架，通过位置保持的视觉令牌选择减少计算开销，提升推理效率，适用于边缘部署。

## 摘要

Vision-Language Models (VLMs) have shown remarkable performance in User Interface (UI) grounding tasks, driven by their ability to process increasingly high-resolution screenshots. However, screenshots are tokenized into thousands of visual tokens (e.g., about 4700 for 2K resolution), incurring significant computational overhead and diluting attention. In contrast, humans typically focus on regions of interest when interacting with UI. In this work, we pioneer the task of efficient UI grounding. Guided by practical analysis of the task's characteristics and challenges, we propose FocusUI, an efficient UI grounding framework that selects patches most relevant to the instruction while preserving positional continuity for precise grounding. FocusUI addresses two key challenges: (1) Eliminating redundant tokens in visual encoding. We construct patch-level supervision by fusing an instruction-conditioned score with a rule-based UI-graph score that down-weights large homogeneous regions to select distinct and instruction-relevant visual tokens. (2) Preserving positional continuity during visual token selection. We find that general visual token pruning methods suffer from severe accuracy degradation on UI grounding tasks due to broken positional information. We introduce a novel PosPad strategy, which compresses each contiguous sequence of dropped visual tokens into a single special marker placed at the sequence's last index to preserve positional continuity. Comprehensive experiments on four grounding benchmarks demonstrate that FocusUI surpasses GUI-specific baselines. On the ScreenSpot-Pro benchmark, FocusUI-7B achieves a performance improvement of 3.7% over GUI-Actor-7B. Even with only 30% visual token retention, FocusUI-7B drops by only 3.2% while achieving up to 1.44x faster inference and 17% lower peak GPU memory.

## 详细分析

## FocusUI 论文详细摘要

### 1. 研究背景和动机
用户界面（UI）视觉定位任务要求模型根据自然语言指令，在高分辨率屏幕截图中定位目标区域。尽管视觉语言模型（VLMs）在此类任务上表现出色，但高分辨率截图会被切分成数千个视觉令牌（例如，2K分辨率下约4700个），导致巨大的计算开销和注意力稀释。与人类交互时聚焦于感兴趣区域的行为不同，现有方法处理所有视觉令牌，效率低下。此外，研究发现，UI定位任务对视觉令牌的**位置信息极为敏感**，通用的视觉令牌剪枝方法会破坏位置连续性，导致定位精度严重下降。因此，本文**首次提出并系统研究了高效UI定位任务**，旨在减少冗余视觉令牌的同时，保持高精度定位能力。

### 2. 核心方法和技术创新
本文提出了 **FocusUI** 框架，其核心创新在于**指令引导的视觉令牌选择**与**位置连续性保持**。
- **指令到区块显著性评分**：设计了一种轻量级的**查询引导显著性评分器**。其训练监督信号融合了两种互补信息：1) **指令条件化的边界框重叠分数**，用于突出与指令目标相关的区域；2) **基于规则的UI图先验分数**，通过并查集算法识别大面积的同质区域（如空白背景）并降低其权重，从而抑制冗余背景。
- **位置保持序列变换（PosPad）**：为解决直接丢弃令牌导致的位置信息断裂问题，提出了 **PosPad** 策略。该策略将每个被丢弃的**连续视觉令牌序列**压缩为一个特殊的可学习标记符（`<pos_pad>`），并将其放置在该序列的**最后一个索引位置**，从而保留了原始序列的顺序和空间位置信息，使模型能够维持准确的空间理解。

### 3. 主要实验结果
在ScreenSpot-V2、ScreenSpot-Pro、OS-World-G和UI-Vision四个UI定位基准测试上进行了全面评估：
- **性能领先**：即使仅保留30%的视觉令牌，**FocusUI-7B** 在ScreenSpot-Pro基准上的性能仍超越最强的GUI专用基线模型（GUI-Actor-7B）3.7%，展现了卓越的精度-效率权衡。
- **效率显著提升**：当视觉令牌保留率降至30%时，推理速度最高可提升 **1.44倍**，峰值GPU内存降低约 **17%**，而性能下降仅为3.2%。
- **方法有效性验证**：与Fast-V、HiPrune等通用视觉令牌剪枝方法相比，FocusUI在低保留率下性能下降远小于它们，证明了其针对UI任务设计的必要性。消融实验也证实了UI图先验和PosPad策略的关键作用。

### 4. 研究意义和价值
- **学术价值**：本文开创了“高效UI定位”这一新研究方向，深入分析了任务特性（极高的视觉令牌占比、对位置信息的敏感性），并提出了针对性的解决方案。所提出的PosPad策略为解决多模态序列中位置信息保持问题提供了新思路。
- **实用价值**：FocusUI框架可以无缝集成到现有的VLMs（如Qwen2.5-VL、Qwen3-VL）中，在不显著牺牲精度的前提下，大幅降低了UI智能体在实际部署中的计算成本和内存需求，为开发高效、实用的GUI自动化助手和智能体奠定了技术基础。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析：FocusUI

### **一、 研究问题**
论文旨在解决**用户界面视觉定位任务中的效率瓶颈**。具体问题如下：
1.  **计算开销巨大**：高分辨率UI截图被分割成数千个视觉令牌（例如2K分辨率约4700个），占用了序列长度的绝大部分（≥85.4%），导致推理速度慢、GPU内存占用高。
2.  **通用令牌剪枝方法失效**：为自然图像设计的视觉令牌剪枝方法，在UI定位这种**对位置信息极其敏感**的任务上会导致严重的精度下降。直接丢弃令牌会破坏序列的**位置连续性**，使模型无法进行精确定位。

### **二、 核心创新点**
论文提出了 **FocusUI** 框架，其创新性主要体现在以下三个紧密关联的方面：

1.  **任务定义创新**：**首次系统性地提出并定义了“高效UI视觉定位”这一任务**，并深入分析了其两大核心挑战（视觉令牌冗余与位置敏感性），为后续方法设计奠定了基础。

2.  **指令到区块的显著性选择机制**：
    - **问题**：需要智能地选择与指令相关的视觉区块，而不是随机或简单地剪枝。
    - **解决方案**：设计了一种**融合的、密集的监督信号**来训练一个轻量级的“查询引导显著性打分器”。
        - **边界框重叠分数**：基于真实标注框，为每个图像区块计算与目标区域的重叠比例。
        - **UI图先验分数**：通过并查集算法，将视觉相似的相邻区块合并为连通组件。**大面积的同质区域（如空白背景）会被赋予较低的权重**，从而抑制无关背景，突出独特的UI组件。
        - **融合监督**：将上述两种分数加权融合，生成最终的“指令到区块”显著性图，用于训练打分器。

3.  **位置保持的序列变换策略**：
    - **问题**：简单地丢弃低显著性令牌会破坏令牌序列在原始2D空间中的位置连续性，严重影响模型的空间理解能力。
    - **解决方案**：提出 **`PosPad`** 策略。
        - 对于**每个连续的被丢弃令牌序列**，不直接全部删除。
        - 将该序列**压缩为一个特殊的可学习标记**，并**放置在该连续序列的最后一个索引位置**。
        - **效果**：极大地减少了序列长度，同时**保留了被丢弃区域末尾的位置信息**，维持了模型对空间布局的理解。这是解决UI定位中位置敏感性问题的关键。

### **三、 解决方案架构**
**FocusUI** 的整体工作流程如下：
1.  **输入**：高分辨率UI截图 + 自然语言指令。
2.  **显著性预测**：轻量级“查询引导显著性打分器”接收视觉编码器的区块特征和指令的文本嵌入，预测每个视觉区块的显著性分数。
3.  **令牌选择**：根据预设的保留比例，选择分数最高的K个区块。
4.  **位置保持压缩**：对未被选中的区块应用 **`PosPad`** 策略，将连续的丢弃序列压缩为特殊标记，生成一个**既紧凑又保持位置连续性的新视觉令牌序列**。
5.  **定位输出**：将处理后的视觉序列与文本指令一起输入语言模型解码器，采用与GUI-Actor类似的坐标无关定位机制，输出目标位置。

### **四、 实际价值与技术贡献**
- **效率显著提升**：在仅保留30%视觉令牌的情况下，**FocusUI-7B** 实现了 **1.44倍** 的推理加速和 **17%** 的峰值GPU内存降低，而精度下降仅为3.2%。
- **精度保持甚至超越**：在四个UI定位基准测试上，**FocusUI** 在相同模型规模下超越了之前的SOTA方法（如GUI-Actor）。例如，在ScreenSpot-Pro上，**FocusUI-7B** 比 **GUI-Actor-7B** 性能提升 **3.7%**。
- **通用性与实用性**：框架可无缝集成到不同的VLM骨干网络中（如Qwen2.5-VL、Qwen3-VL），并兼容FlashAttention等优化技术，易于部署。
- **为GUI智能体铺路**：通过大幅降低单次定位的计算成本，使得构建能够进行**快速、多轮次交互**的实用化GUI智能体成为可能。

**总结**：FocusUI 的核心创新在于**精准地定义了高效UI定位的独特挑战**，并提出了一个**联合优化选择与位置保持**的优雅解决方案。它不仅在效率上取得突破，更通过创新的 `PosPad` 机制解决了通用剪枝方法在空间敏感任务上的失效问题，实现了精度与效率的卓越权衡。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文旨在解决**用户界面（UI）视觉定位任务中，因处理高分辨率截图导致视觉令牌数量过多、计算开销巨大的效率问题**。为此，论文提出了 **FocusUI** 框架，其核心创新在于：1）通过融合指令条件化边界框重叠信号与基于规则的UI图先验，构建**指令到图像块的密集监督**，以训练一个轻量级的查询引导显著性评分器，从而筛选出与指令最相关的视觉令牌；2）设计了 **PosPad** 策略，在丢弃不相关视觉令牌时，将每个连续的丢弃令牌序列压缩为一个置于序列末尾的特殊标记，以**保留关键的位置连续性信息**，避免通用令牌剪枝方法在精确空间定位任务上的性能崩溃。实验表明，FocusUI在多个UI定位基准测试中，**仅保留30%的视觉令牌时，性能下降极小（如7B模型仅下降3.2%），同时实现了高达1.44倍的推理加速和17%的峰值GPU内存降低**，在效率与精度之间取得了卓越的平衡。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## FocusUI 论文创新点分析

这篇论文针对用户界面（UI）视觉定位任务中计算效率低下的问题，提出了一种名为 **FocusUI** 的高效框架。其核心创新点在于**指令引导的视觉令牌选择**和**位置连续性保持**，以解决高分辨率UI截图带来的计算冗余和通用令牌剪枝方法在精确定位任务上的性能崩溃问题。

以下是论文相对于已有工作的明确创新点及其分析：

### 1. **开创“高效UI定位”这一新任务方向**
   - **改进/不同之处**：以往工作主要关注提升UI定位的**准确性**，而计算**效率**（如推理速度、内存占用）未被系统性地探索和优化。本文首次将“在保持高精度的同时显著减少视觉令牌数量”定义为一个独立的研究任务。
   - **解决的问题/优势**：明确了UI定位任务中存在的独特挑战（极高的视觉令牌占比、对位置信息敏感），为后续研究提供了清晰的问题定义和评估基准，推动了该领域向实用化、轻量化发展。

### 2. **提出融合监督的“指令到图像块”显著性评分机制**
   - **改进/不同之处**：不同于通用视觉令牌剪枝方法（如基于CLIP相似度或注意力熵），本文设计了一种**密集的、任务特定的监督信号**来训练轻量级的显著性评分器。该信号融合了：
     - **指令条件化的边界框重叠得分**：直接关联图像块与指令描述的真实目标区域。
     - **基于规则的UI图先验得分**：通过并查集算法识别大面积的同质区域（如空白背景、纯色面板）并降低其权重。
   - **解决的问题/优势**：
     - **精准筛选**：能够更准确地识别出与指令**相关**且视觉上**独特**的UI元素（如按钮、文本），同时抑制无关的、重复的背景区域。
     - **解决UI结构特性**：专门针对UI截图“大块同质区域夹杂小部件”的组成特点进行优化，这是通用自然图像剪枝方法未考虑的。

### 3. **提出创新的“位置保持填充”策略**
   - **改进/不同之处**：通用视觉令牌剪枝方法直接丢弃不重要的令牌，这破坏了令牌序列在原始图像中的**空间位置连续性**，导致模型的空间理解混乱。本文提出 **`PosPad`**：
     - 将**每个连续的被丢弃令牌序列**压缩为一个特殊的可学习标记 `<pos_pad>`。
     - 将该标记**放置在该连续序列的最后一个索引位置**，从而“锚定”并保留了该区域在原始序列中的位置信息。
   - **解决的问题/优势**：
     - **保持位置连续性**：解决了因直接丢弃令牌导致的“位置跳跃”问题，这对于依赖多模态旋转位置编码（M-RoPE）来理解 `(高度, 宽度)` 坐标的精确UI定位任务至关重要。
     - **稳定性能**：即使在激进地保留仅30%令牌的情况下，也能将性能下降控制在很低水平（如FocusUI-7B仅下降3.2%），而通用剪枝方法会导致性能崩溃（下降超过50%）。

### 4. **实现与先进VLM骨架的无缝集成及卓越的效率-精度权衡**
   - **改进/不同之处**：将上述创新（显著性评分器 + `PosPad`）模块化地集成到现有的先进视觉语言模型（如Qwen2.5-VL、Qwen3-VL）中，无需改动下游语言模型解码器的架构。系统性地评估了不同令牌保留比例下的性能与效率。
   - **解决的问题/优势**：
     - **即插即用**：方法具有通用性，可适配不同规模的VLM骨架。
     - **显著提升效率**：实验表明，在保留30%视觉令牌时，能实现：
       - **高达1.44倍的推理加速**。
       - **降低约17%的峰值GPU内存**。
       - 在四个UI定位基准测试上，性能仍超越或媲美消耗全部令牌的基线模型和专用UI模型（如GUI-Actor）。

### 总结
**FocusUI** 的核心创新在于**任务感知的设计**：它并非简单套用通用的视觉压缩技术，而是深刻分析了UI定位任务在**输入特性**（高分辨率、结构化、冗余度高）和**模型依赖**（对绝对/相对位置高度敏感）上的独特性，从而提出了针对性的解决方案。其创新点环环相扣：**融合监督**解决了“剪什么”的问题，**`PosPad`策略**解决了“怎么剪而不乱”的问题，最终共同实现了**在大幅提升计算效率的同时，几乎不损失定位精度**的突破性成果，为部署高效、实用的GUI智能体奠定了关键技术基础。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 实验与评估效果总结

### 一、 使用的数据集
论文在四个主流的UI视觉定位基准数据集上进行了全面评估：

| 数据集 | 样本数 | 平均分辨率 | 主要平台 | 特点 |
| :--- | :--- | :--- | :--- | :--- |
| **ScreenSpot-V2** | 1,272 | 1725×1657 | 混合（Web、桌面、移动） | 通用UI定位基准 |
| **ScreenSpot-Pro** | 1,581 | 3267×1727 | 桌面 | **高分辨率、专业应用**，是评估效率和精度的关键测试集 |
| **OS-World-G** | 564 | 1696×955 | 桌面 | 任务类型多样（文本匹配、元素识别、布局理解等） |
| **UI-Vision** | 5,790 | 1851×1034 | 桌面 | 大规模，评估元素、布局和动作预测 |

### 二、 评价指标
- **主要指标**：各数据集的**平均定位准确率（Avg）**。
- **效率指标**：
    - **推理速度**（加速比，×）
    - **峰值GPU内存占用**（降低百分比，%）
    - **视觉令牌保留率（Retention Ratio, r）**：保留的视觉令牌占原始总数的百分比。

### 三、 对比的基线方法
论文与当前最先进的UI专用模型和通用视觉语言模型（VLM）进行了广泛对比：

1.  **UI专用模型**：
    - **GUI-Actor** (3B, 7B)：当前SOTA的坐标无关UI定位模型。
    - **UI-TARS** (7B, 72B, 1.5-7B)
    - **Jedi** (3B, 7B)
    - **UGround-V1-7B**, **Aguvis-7B**, **Tong-UI-7B**, **OS-Atlas-7B**, **ShowUI-2B**, **Operator**

2.  **通用VLM骨干网络**：
    - **Qwen2.5-VL** (3B, 7B, 32B)
    - **Qwen3-VL** (2B)

3.  **通用视觉令牌剪枝方法**（用于证明FocusUI方法的优越性）：
    - **Fast-V** (ECCV‘24)
    - **HiPrune** (arXiv’25)
    - **Vision-Zip** (CVPR‘25)

### 四、 关键性能与结论

#### 1. **定位精度：达到或超越SOTA**
- **在ScreenSpot-Pro上**：`FocusUI-7B` (r=100%) 取得了 **48.3%** 的平均准确率，**超越了所有同规模基线**，比最强的`GUI-Actor-7B` (44.6%) **高出3.7个百分点**。
- **在高效设定下表现稳健**：即使仅保留 **30%** 的视觉令牌 (r=30%)，`FocusUI-7B` 的性能仅下降 **3.2个百分点** (至45.1%)，仍显著优于许多使用全部令牌的基线模型（如Qwen2.5-VL-7B的27.6%）。
- **在其他基准上一致领先**：在ScreenSpot-V2、OS-World-G和UI-Vision上，`FocusUI`在不同模型规模（3B, 7B）和保留率下，均达到或接近最优性能。

#### 2. **效率：显著提升推理速度并降低内存**
- **推理加速**：在ScreenSpot-Pro上，当`FocusUI-7B`的保留率从100%降至30%时，实现了 **1.44倍的推理加速**。
- **内存降低**：相同条件下，峰值GPU内存降低了 **约17%**。
- **优异的精度-效率权衡**：`FocusUI`在显著减少计算开销的同时，保持了极高的定位精度，这是通用剪枝方法无法做到的。

#### 3. **核心创新验证：超越通用剪枝方法**
- **关键对比实验**（表5）：在30%令牌保留率下，通用剪枝方法（如Fast-V, HiPrune）会导致性能**急剧下降**（例如，在Jedi-3B上，ScreenSpot-Pro准确率从36.1%暴跌至14.1%）。
- **FocusUI的优势**：`FocusUI-3B`在30%保留率下，性能仅从43.8%微降至40.6%，**下降幅度远小于通用方法**，证明了其**位置保持（PosPad）** 和**指令相关选择**策略的有效性。

#### 4. **消融实验结论**
- **PosPad策略至关重要**：与直接丢弃（Direct Drop）或全填充（Full Padding）相比，`PosPad`在保持序列连续性的同时实现了最佳的性能与效率平衡。
- **融合监督信号有效**：结合**边界框重叠分数**和**UI图先验**的`Instruction-to-Patch`监督，优于单独使用任一信号。
- **平滑的性能-保留率曲线**：性能随保留率降低而平缓下降，证明了方法的鲁棒性，即使在10%的极端保留率下仍能保持一定性能（36.6%）。

### 总结
**FocusUI成功实现了高效UI定位的核心目标**：在**四个权威基准**上，它**不仅超越了现有UI专用SOTA模型的精度**，更重要的是，通过创新的指令相关视觉令牌选择和`PosPad`策略，在**大幅减少计算量（最高1.44倍加速，17%内存降低）的同时，将性能损失控制在极低水平（30%令牌下仅损失约3%）**。这解决了高分辨率UI处理中计算开销过大的痛点，为实际部署提供了高效的解决方案。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2601.03928v1)
- [HTML 版本](https://arxiv.org/html/2601.03928v1)
