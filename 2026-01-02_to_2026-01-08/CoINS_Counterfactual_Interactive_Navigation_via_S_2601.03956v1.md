# CoINS: Counterfactual Interactive Navigation via Skill-Aware VLM

**相关性评分**: 8.0/10

**排名**: #16


---


## 基本信息

- **arXiv ID**: [2601.03956v1](https://arxiv.org/abs/2601.03956v1)
- **发布时间**: 2026-01-07T14:10:46Z
- **相关性评分**: 8.0/10
- **是否相关**: 是

## 作者

Kangjie Zhou, Zhejia Wen, Zhiyong Zhuo, Zike Yan, Pengying Wu, Ieng Hou U, Shuaiyang Li, Han Gao, Kang Ding, Wenhan Cao, Wei Pan, Chang Liu

## 关键词

Vision-Language-Action Model, VLA for Robotics, Inference Efficiency, Lightweight Architecture, Inference Acceleration, Edge Deployment

## 一句话总结

CoINS提出了一种基于技能感知视觉语言模型的层次化框架，通过反事实推理和强化学习技能库，提升机器人在交互式导航中的规划和执行能力，与VLA模型、推理效率和边缘部署等关键词相关。

## 摘要

Recent Vision-Language Models (VLMs) have demonstrated significant potential in robotic planning. However, they typically function as semantic reasoners, lacking an intrinsic understanding of the specific robot's physical capabilities. This limitation is particularly critical in interactive navigation, where robots must actively modify cluttered environments to create traversable paths. Existing VLM-based navigators are predominantly confined to passive obstacle avoidance, failing to reason about when and how to interact with objects to clear blocked paths. To bridge this gap, we propose Counterfactual Interactive Navigation via Skill-aware VLM (CoINS), a hierarchical framework that integrates skill-aware reasoning and robust low-level execution. Specifically, we fine-tune a VLM, named InterNav-VLM, which incorporates skill affordance and concrete constraint parameters into the input context and grounds them into a metric-scale environmental representation. By internalizing the logic of counterfactual reasoning through fine-tuning on the proposed InterNav dataset, the model learns to implicitly evaluate the causal effects of object removal on navigation connectivity, thereby determining interaction necessity and target selection. To execute the generated high-level plans, we develop a comprehensive skill library through reinforcement learning, specifically introducing traversability-oriented strategies to manipulate diverse objects for path clearance. A systematic benchmark in Isaac Sim is proposed to evaluate both the reasoning and execution aspects of interactive navigation. Extensive simulations and real-world experiments demonstrate that CoINS significantly outperforms representative baselines, achieving a 17\% higher overall success rate and over 80\% improvement in complex long-horizon scenarios compared to the best-performing baseline

## 详细分析

## 论文《CoINS：基于技能感知VLM的反事实交互式导航》详细摘要

### 1. 研究背景和动机
在杂乱、非结构化的真实环境中（如家庭、仓库），机器人导航常常面临路径被障碍物完全阻塞的挑战。传统的导航方法只能被动避障，而现有的基于视觉-语言模型（VLM）的导航器也缺乏主动与环境交互以开辟路径的能力。其核心瓶颈在于，现有VLM通常作为语义推理器，**缺乏对特定机器人物理能力的理解**，也无法推理“何时”以及“与哪个物体”进行交互。这限制了机器人在复杂场景中的自主性和成功率。

### 2. 核心方法和技术创新
本文提出了 **CoINS**，一个用于未知杂乱环境中交互式导航的分层框架。其核心技术创新包括：
- **技能感知的VLM（InterNav-VLM）**：通过对Qwen3-VL进行微调，将**技能语义功能（如“攀爬”）和具体物理约束参数（如最大跨越高度）** 显式注入模型输入和推理上下文。这使得模型能进行物理上可行的、针对具体机器人本体的推理。
- **反事实推理机制**：通过在新构建的InterNav数据集上进行微调，模型内化了**反事实推理逻辑**，能够隐式评估移除某个物体对导航连通性的因果影响，从而智能决定交互的必要性和目标选择。
- **面向通行性的操作技能库**：通过强化学习（RL）构建了一个全面的技能库，特别引入了**“面向通行性的操作”范式**。该策略的目标是清除路径而非精确摆放物体，提高了在阻塞路径清理过程中的导航效率。
- **InterNav数据集与基准测试**：在Isaac Sim中构建了包含多样化室内场景和物理真实交互资产的大规模数据集与系统性基准，填补了该领域的数据空白。

### 3. 主要实验结果
在仿真和真实世界实验中，CoINS均表现出显著优势：
- **推理精度**：InterNav-VLM在测试集上的推理准确率达到78.35%，显著优于GPT-4o（48.64%）、Gemini-2.5-Pro（58.34%）和基础模型Qwen3-VL（33.56%）。
- **导航性能**：在提出的交互导航基准测试中，CoINS实现了**75%的平均成功率**，比最佳基线（IN-Sight，64%）高出17%。在复杂的长视野跨房间场景中，成功率提升超过80%。
- **泛化能力**：方法成功迁移到轮式机器人平台，并能在真实世界中处理**纸箱、桶、办公椅、门**等多种物体，展示了强大的跨物体类别和跨机器人本体的泛化能力。
- **消融实验**：验证了领域微调和面向通行性操作策略均为提升性能的关键组件。

### 4. 研究意义和价值
本研究的意义在于：
- **理论价值**：首次将**反事实因果推理**和**参数化技能感知**深度集成到VLM中，为具身智能的物理推理提供了新思路。提出的分层框架（高层语义推理 + 底层鲁棒执行）为复杂任务与动作规划问题提供了有效解决方案。
- **实际应用价值**：使机器人能够在没有全局地图的未知杂乱环境中，**主动修改环境以到达目标**，极大地扩展了机器人在家庭服务、灾难救援、仓储物流等实际场景中的适用性和自主能力。开源的InterNav数据集和基准也为后续研究提供了重要平台。
- **技术推动**：所提出的“面向通行性的操作”范式改变了移动操作的任务定义，更贴近实际导航需求，为学习型移动操作策略的设计提供了新方向。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析：CoINS

### **一、 论文旨在解决的核心问题**
当前基于视觉-语言模型（VLM）的机器人导航系统存在两个关键缺陷：
1.  **缺乏技能感知**：现有VLM主要作为语义推理器，不理解具体机器人的**物理能力边界**（如最大攀爬高度、抓取范围）。这导致其规划出的动作可能物理上不可行（例如，让机器人跨越过高的障碍）。
2.  **缺乏交互推理**：在杂乱环境中，当路径被障碍物阻塞时，现有方法仅限于被动避障，**无法主动判断“何时”以及“与哪个物体”进行交互**来开辟可行路径。它们缺乏对“移除物体能否连通路径”这一因果关系的推理能力。

简言之，论文要解决的是 **“让机器人具备身体意识，并能主动改造环境以实现导航”** 的问题，即**交互式导航**。

### **二、 核心创新点**
论文提出了一个名为 **CoINS** 的分层框架，其创新性体现在以下三个紧密关联的方面：

#### **1. 技能感知的VLM（InterNav-VLM）**
- **创新机制**：将机器人的**技能语义（如“攀爬”）和具体物理约束参数（如最大高度0.25m）** 作为输入上下文，显式注入VLM。
- **技术实现**：
    - **技能感知的环境表征**：通过单目RGB图像重建度量尺度的3D场景，并生成**技能条件化的可通行性地图**。该地图不仅考虑几何障碍，还融合了机器人的能力（例如，低于攀爬高度的物体被视为可通行）。
    - **反事实推理学习**：通过在新构建的InterNav数据集上进行微调，让VLM**内化反事实推理逻辑**。模型学会隐式评估“如果移除某个物体，导航连通性会如何变化”，从而判断交互的必要性并选择最优目标物体。
    - **自省式验证**：在生成答案时，强制模型进行“思维链”推理，先检查技能可行性，再阐述交互的因果理由，有效过滤幻觉。

#### **2. 面向通行的操作范式**
- **创新理念**：与传统“将物体推到精确位置”的操纵任务不同，本文提出 **“以通行为导向的操纵”**。
- **技术实现**：通过强化学习（RL）训练一个策略库，其**奖励函数是机器人本体的**（奖励机器人到达目标），而非物体的。策略学习用机械臂将障碍物“推到一边”，只要创造出能让机器人通过的间隙即可，不追求物体的精确定位。这大大提升了导航效率和泛化性。

#### **3. 系统性基准与数据集**
- **创新贡献**：构建了 **InterNav数据集与评测基准**（基于Isaac Sim），填补了现有导航数据集的空白。该数据集专注于**必须通过交互才能导航**的场景，包含丰富的、具有真实物理属性的可交互资产（箱子、桶、椅子、门），为训练和评估交互式导航算法提供了标准平台。

### **三、 解决方案的整体框架（How）**
CoINS采用**分层架构**，将高层语义推理与底层鲁棒执行相结合：

1.  **高层规划层（InterNav-VLM）**：
    - **输入**：机器人第一视角RGB图像、导航目标、机器人技能集与能力参数。
    - **处理**：VLM进行技能感知和反事实推理。
    - **输出**：高层决策——选择技能（如“导航”、“推箱子”、“开门”）及目标物体。

2.  **底层执行层（RL技能库）**：
    - **输入**：高层决策（技能类型、目标物体信息）。
    - **处理**：调用对应的RL策略（导航、面向通行的操纵、开门）。
    - **输出**：发送具体的关节控制指令给机器人身体。
    - **关键设计**：采用分层控制，底层是一个训练好的全身控制器，确保移动和操纵的稳定性；高层是各个技能的具体策略。

3.  **协同工作流程**：
    ```mermaid
    graph LR
    A[RGB图像 + 目标 + 技能参数] --> B(InterNav-VLM)
    B -- 技能选择 & 目标物体 --> C(RL技能库)
    C -- 关节控制指令 --> D[机器人执行]
    D -- 新的观测 --> A
    ```
    整个过程**无需全局地图**，仅依赖机载传感器。

### **四、 实际价值与效果**
- **性能提升**：在仿真基准测试中，CoINS整体成功率比最佳基线高**17%**，在复杂的多房间长视野任务中提升超过**80%**。
- **泛化能力**：
    - **跨物体类别**：能处理箱子、桶、椅子、门等多种物体。
    - **跨机器人本体**：通过修改输入的技能参数，可适配不同能力的机器人（如仅能导航的轮式机器人和具备操纵能力的腿式机器人）。
- **现实可行性**：论文成功将仿真中训练的模型和策略迁移到真实世界的Unitree Go2四足机器人上，完成了在杂乱教室和需要开门的跨房间场景中的导航任务，验证了框架的**sim-to-real**能力。

**总结**：CoINS的核心突破在于**让VLM“懂得”机器人的身体，并学会“思考”改变环境带来的后果**，从而实现了从“被动避障”到“主动造路”的范式转变。其提出的技能感知、反事实推理和面向通行的操纵，为具身智能在复杂动态环境中的自主作业提供了重要的技术思路。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文旨在解决机器人**交互式导航**中的核心挑战：在杂乱、部分可观测的未知环境中，机器人不仅需要避障，更需要主动判断并执行物理交互（如推开门、移开障碍物）以开辟可行路径。现有基于视觉语言模型（VLM）的导航方法缺乏对机器人具体物理能力的理解（技能感知），也缺乏判断何时、与哪个物体交互的因果推理能力。

为此，论文提出了 **CoINS** 分层框架。其核心创新在于：1）**InterNav-VLM**：通过微调，将机器人的技能参数（如可攀爬高度）和反事实推理逻辑（“移除该物体会否让目标可达？”）注入VLM，使其具备技能感知和交互决策能力；2）**基于强化学习的技能库**：特别是“面向可通行性的操作”策略，专注于高效清除路径而非精确摆放物体；3）**InterNav数据集与基准**：为训练和评估提供大规模仿真环境。

实验表明，CoINS在复杂长视野任务中的成功率比最佳基线高出80%以上，整体成功率提升17%，并在多样物体类别和不同机器人形态（轮式、腿式）上展现出强大的泛化能力，成功实现了从仿真到真实世界的部署。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文创新点分析

本文提出的 **CoINS** 框架在交互式导航领域做出了多项明确且重要的创新，旨在解决现有方法在**技能感知**、**交互推理**和**执行泛化**方面的核心缺陷。以下是其核心创新点及其与以往工作的对比和优势分析：

### 1. **技能感知的视觉语言模型**
- **改进/不同之处**： 现有VLM导航方法（如LM-Nav, ViNT）主要作为**语义推理器**，缺乏对机器人**具体物理能力**的理解。它们通常只理解“什么物体可以交互”，而不理解“机器人能否以特定方式交互该物体”。CoINS通过**显式地将参数化技能描述**（如最大跨越高度、可操作物体类别、操作范围）注入到VLM的输入上下文和系统提示中，使模型具备**技能感知**能力。
- **解决的具体问题/优势**： 解决了VLM规划中常见的**物理不可行决策**问题。例如，传统VLM可能计划让机器人跨越一个过高的箱子或抓取一个超出臂展的瓶子。通过技能感知，InterNav-VLM能够进行**物理接地**的推理，确保生成的计划（如“跨越”或“推开”）对于当前机器人的具体形态和能力是可行的，从而避免了无效或危险的指令。

### 2. **基于反事实推理的交互决策**
- **改进/不同之处**： 现有VLM导航器和大多数交互导航方法（如IN-Sight）缺乏对交互**必要性**和**目标选择**的因果推理能力。它们通常采用启发式规则或简单的几何分析。CoINS通过在海量交互导航数据集（InterNav Dataset）上对VLM进行微调，使其**内化了反事实推理逻辑**。模型学习隐式评估“如果移除某个物体，导航连通性将如何改变”。
- **解决的具体问题/优势**： 解决了“**何时交互**”和“**与何物交互**”这两个核心决策难题。这使得机器人能够智能地判断：是应该绕行、直接跨越，还是必须主动移开障碍物。它避免了不必要的交互（节省时间和能量），也能在复杂阻塞场景中精准选择那个移除后能最大程度改善路径（甚至使不可达变为可达）的关键物体，从而显著提升长视野任务的完成率和效率。

### 3. **面向通行性的操作策略**
- **改进/不同之处**： 传统的学习型操作策略（如IN-ArmPush）或经典NAMO方法，其目标通常是**将物体精确重放到指定位置**。CoINS提出了一种**面向通行性的操作范式**。其强化学习策略的奖励函数是**以机器人为中心**的，核心目标是让**机器人自身到达目标点**，操作只是清除路径的手段。
- **解决的具体问题/优势**： 解决了交互导航中**目标不一致**和**操作效率低下**的问题。传统方法为移开障碍物设定一个精确的终点，这过程可能缓慢且过度。而CoINS的策略只要求将物体推开足够距离以创造可通过的间隙即可，大大提高了导航的整体效率。同时，这种范式更符合交互导航的根本目的——通行而非精确重排。

### 4. **层次化框架与大规模仿真基准**
- **改进/不同之处**：
    - **框架**： 将**高层语义推理（VLM）** 与**底层鲁棒执行（RL技能库）** 无缝集成在一个层次化框架中。这与端到端VLA模型或解耦的规划-执行框架都不同。
    - **基准**： 构建了**InterNav数据集和基准测试**。与现有静态导航数据集不同，该数据集专注于必须通过交互才能通行的场景，包含丰富的、具有物理属性的可交互资产和多样化的场景布局。
- **解决的具体问题/优势**：
    - **框架优势**： 结合了VLM强大的常识和语义理解能力，以及RL策略在具体技能执行上的鲁棒性和适应性，实现了“**聪明的大脑**”加“**灵巧的身体**”。
    - **基准优势**： 填补了该领域缺乏大规模、标准化评估平台的空白。为训练和公平比较不同交互导航算法提供了基础，其高保真物理和渲染也有助于**缩小仿真到现实的差距**。

### 5. **技能感知的环境接地方法**
- **改进/不同之处**： 并非让VLM直接“想象”技能，而是设计了一个**技能感知的环境接地流水线**。它利用度量级三维场景重建（融合VGGT和Map-Anything），生成**融合了机器人能力**的通行性地图（例如，根据机器人跨越高度过滤地形）和**可操作物体实例图**（结合语义检测和机器人工作空间判断）。
- **解决的具体问题/优势**： 将抽象的技能描述**落地到具体的、度量化的环境表征**中。这使得高层推理基于的是与机器人能力匹配的环境理解，而非原始的、与能力无关的视觉或语义信息。它**主动过滤**掉了物理上不可行的技能选项，为VLM的决策提供了可靠的空间几何和可达性依据。

---

**总结**： CoINS的核心创新在于**将机器人的具身能力深度融入交互导航的感知、决策和执行全链路**。它通过**技能感知VLM**和**反事实推理**解决了高层决策的合理性与可行性问题，通过**面向通行性的RL策略**解决了底层执行效率与泛化问题，并通过**层次化集成**和**新基准**为领域发展提供了系统性解决方案。这些创新共同使其在复杂、长视野的交互导航任务中取得了显著优于现有方法的性能（整体成功率提升17%，复杂场景提升超80%）。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 实验与评估效果总结

### 一、 数据集与评价指标

#### 1. 数据集
- **InterNav 数据集**： 论文在 Isaac Sim 仿真器中构建的全新交互式导航数据集。该数据集基于 Matterport3D 的室内场景布局，并程序化地填充了多种可交互的物体资产（如纸箱、桶、椅子、门等），以模拟杂乱的真实世界环境。数据集包含训练集（90%）和测试集（10%），用于训练和评估 VLM 的推理能力。
- **仿真基准测试场景**： 包含 15 个多样化场景，分为三个复杂度递增的类别：
    - **小房间**： 5 个场景。
    - **大房间**： 5 个场景。
    - **房间到房间**： 5 个场景，涉及开门等长视野任务。
- **真实世界实验**： 在两个实际环境中进行验证：
    - **杂乱教室**： 充满桌椅和纸箱的狭窄环境。
    - **走廊到房间**： 需要开门才能进入目标房间的场景。

#### 2. 评价指标
论文使用以下三个核心指标来评估导航性能：
- **成功率**： 在时间限制内，机器人成功到达目标位置（距离小于阈值）的试验百分比。
- **路径长度**： 机器人从起点到终点所行驶的总距离。
- **到目标距离**： 试验结束时，机器人与目标位置之间的最终距离（用于衡量失败案例的接近程度）。

### 二、 对比的基线方法

论文将提出的 **CoINS** 框架与以下三个代表性的基线方法进行了全面对比：

1.  **Art-planner**： 一种基于采样的四足机器人导航方法，将所有物体视为静态障碍物，**不具备交互能力**。
2.  **IN-Sight**： 一种基于可通行性估计的交互导航方法，结合了全局和局部规划器。它使用机器人本体直接推挤障碍物，**不使用机械臂进行精细操作**。
3.  **IN-ArmPush**： 一种基于搜索的“可移动障碍物间导航”方法，集成了用于机械臂操作的强化学习策略。论文将其适配到未知环境（用局部地图替代其依赖的全局地图）。该方法采用**先精确重定位物体、再导航**的两阶段策略。

### 三、 关键性能提升与结论

#### 1. 仿真实验结果（核心性能对比）
在提出的交互式导航基准测试上，CoINS 取得了显著优于所有基线方法的综合性能。

**主要定量结果（平均值）**：
- **整体成功率**： CoINS 达到 **75%**，比表现最好的基线（IN-Sight，64%）高出 **11个百分点**。在论文摘要中提到的“17%更高整体成功率”可能指特定场景或相对于某个基线的相对提升。
- **路径长度**： CoINS 为 10.32 米，与 IN-Sight (10.26 米) 相当，但显著优于 IN-ArmPush (12.46 米)，说明其交互策略更高效。
- **到目标距离**： CoINS 为 1.19 米，远低于 IN-ArmPush (2.80 米) 和 Art-planner (5.23 米)，表明即使在失败案例中，CoINS 也能更接近目标。

**分场景性能亮点**：
- **在最具挑战性的“房间到房间”场景**（涉及长视野、多交互、开门）： CoINS 的成功率达到 **58%**，显著优于 IN-Sight (32%) 和 IN-ArmPush (26%)。论文指出，在复杂长视野场景中，CoINS 相比最佳基线有 **超过80%的改进**（推测是成功率相对提升比例）。
- **安全性**： IN-Sight 虽然在某些场景成功率较高，但其依赖机器人本体碰撞的交互方式在实际部署中存在损坏机器人的高风险。CoINS 使用机械臂进行针对性操作，安全性更高。

#### 2. VLM 推理能力评估
- **准确性**： 在专门的 VQA 测试集上，微调后的 **InterNav-VLM** 达到了 **78.35%** 的推理准确率，显著高于原始 Qwen3-VL-8B-Instruct (33.56%)、GPT-4o (48.64%) 和 Gemini-2.5-Pro (58.34%)。
- **技能感知能力**： InterNav-VLM 能根据输入的机器人技能参数（如最大跨越高度）做出符合物理约束的决策。例如，对于腿式机器人，它能正确判断何时应跨越矮障碍物，何时需要推开高障碍物。
- **反事实推理**： 模型学会了隐式评估移除物体对导航连通性的因果影响，从而能正确选择“何时交互”以及“与哪个物体交互”。

#### 3. 消融实验结论
- **移除 VLM 微调**： 使用未微调的基座 VLM 导致成功率暴跌至 **17%**，证明了领域特定数据微调对获得交互推理能力至关重要。
- **移除可通行性导向操作策略**： 用传统的“先精确重定位物体再导航”的两阶段策略替代 TOM 策略后，成功率下降至 **53%**，路径长度增加，证明了 TOM 策略（以清除路径为核心目标）在交互导航中的高效性。

#### 4. 泛化与实物实验结论
- **跨机器人平台泛化**： 将 CoINS 应用于无操作能力的轮式机器人 TurtleBot3 时，其导航性能与先进的非交互导航器 Art-planner 相当，证明了框架的适应性。当应用于具备操作能力的四足机器人时，它能主动利用技能寻找更短路径。
- **实物验证成功**： 在真实的杂乱教室和走廊-房间场景中，CoINS 系统成功部署。机器人能够根据 InterNav-VLM 的指令，正确执行导航、推箱子和开门等技能，验证了从仿真到实物的有效转移以及整套系统的实用性。

### 总结
论文通过系统的仿真和实物实验，**定量和定性地证明了 CoINS 框架在交互导航任务上的优越性**。其核心优势在于：
1.  **智能的高层决策**： InterNav-VLM 通过技能感知和反事实推理，能做出更准确、更符合物理约束的交互决策。
2.  **高效的低层执行**： TOM 策略专注于路径清除而非精确摆放，提升了交互效率。
3.  **全面的性能提升**： 在成功率、路径效率和任务复杂度处理上均显著优于现有基线，尤其在需要多次交互的复杂场景中优势巨大。
4.  **良好的泛化性**： 能够适应不同能力的机器人平台，并能迁移到真实世界。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2601.03956v1)
- [HTML 版本](https://arxiv.org/html/2601.03956v1)
