# A Vision-and-Knowledge Enhanced Large Language Model for Generalizable Pedestrian Crossing Behavior Inference

**相关性评分**: 6.0/10

**排名**: #85


---


## 基本信息

- **arXiv ID**: [2601.00694v1](https://arxiv.org/abs/2601.00694v1)
- **发布时间**: 2026-01-02T14:13:28Z
- **相关性评分**: 6.0/10
- **是否相关**: 是

## 作者

Qingwen Pu, Kun Xie, Hong Yang, Guocong Zhai

## 关键词

Vision-Language-Action Model, VLA for Robotics, Inference Efficiency, Lightweight Architecture, Inference Acceleration, Edge Deployment

## 一句话总结

该论文提出PedX-LLM，一个结合视觉和领域知识增强的大型语言模型，用于可泛化的行人过街行为推理，但未直接涉及机器人应用或边缘部署优化。

## 摘要

Existing paradigms for inferring pedestrian crossing behavior, ranging from statistical models to supervised learning methods, demonstrate limited generalizability and perform inadequately on new sites. Recent advances in Large Language Models (LLMs) offer a shift from numerical pattern fitting to semantic, context-aware behavioral reasoning, yet existing LLM applications lack domain-specific adaptation and visual context. This study introduces Pedestrian Crossing LLM (PedX-LLM), a vision-and-knowledge enhanced framework designed to transform pedestrian crossing inference from site-specific pattern recognition to generalizable behavioral reasoning. By integrating LLaVA-extracted visual features with textual data and transportation domain knowledge, PedX-LLM fine-tunes a LLaMA-2-7B foundation model via Low-Rank Adaptation (LoRA) to infer crossing decisions. PedX-LLM achieves 82.0% balanced accuracy, outperforming the best statistical and supervised learning methods. Results demonstrate that the vision-augmented module contributes a 2.9% performance gain by capturing the built environment and integrating domain knowledge yields an additional 4.1% improvement. To evaluate generalizability across unseen environments, cross-site validation was conducted using site-based partitioning. The zero-shot PedX-LLM configuration achieves 66.9% balanced accuracy on five unseen test sites, outperforming the baseline data-driven methods by at least 18 percentage points. Incorporating just five validation examples via few-shot learning to PedX-LLM further elevates the balanced accuracy to 72.2%. PedX-LLM demonstrates strong generalizability to unseen scenarios, confirming that vision-and-knowledge-enhanced reasoning enables the model to mimic human-like decision logic and overcome the limitations of purely data-driven methods.

## 详细分析

## 论文摘要：一种用于可泛化行人过街行为推断的视觉与知识增强大语言模型

**1. 研究背景和动机**
现有推断行人过街行为的范式（从统计模型到监督学习方法）泛化能力有限，在新场景下表现不佳。尽管大语言模型（LLMs）为从数值模式拟合转向语义化、上下文感知的行为推理提供了可能，但现有LLM应用缺乏领域适应性及视觉上下文理解。因此，本研究旨在开发一个能实现**从场景特定模式识别到可泛化行为推理**转变的新框架。

**2. 核心方法和技术创新**
本研究提出了**PedX-LLM**框架，其核心技术创新在于：
- **多模态信息融合**：整合了由**LLaVA提取的视觉特征**（捕捉建成环境）与文本数据，为模型提供丰富的上下文。
- **领域知识增强**：显式地融入了交通领域的专业知识，以引导模型进行更合理的推理。
- **高效模型适配**：基于**LLaMA-2-7B**基础模型，采用**低秩自适应（LoRA）** 技术进行微调，实现了参数高效且领域特定的模型优化。

**3. 主要实验结果**
- **性能表现**：PedX-LLM达到了**82.0%** 的平衡准确率，超越了最佳的统计和传统监督学习方法。
- **模块贡献**：视觉增强模块带来了**2.9%** 的性能提升，而融入领域知识则进一步贡献了**4.1%** 的改进。
- **泛化能力**：在跨站点验证中，**零样本**配置在五个未见测试站点上取得了**66.9%** 的平衡准确率，显著优于基线数据驱动方法至少18个百分点。仅通过**少样本学习**（5个验证示例），准确率可进一步提升至**72.2%**。

**4. 研究意义和价值**
本研究证明了**视觉与知识增强的推理机制**能使模型模仿类人的决策逻辑，有效克服了纯数据驱动方法的局限性。PedX-LLM框架在**跨场景泛化能力**上表现出色，为行人行为建模、自动驾驶感知与决策、以及更广泛的智能交通系统应用，提供了一个更具鲁棒性和可解释性的新范式。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析

### 一、 论文想解决的核心问题
论文旨在解决**现有行人过街行为推断方法泛化能力不足**的问题。具体表现为：
- **传统方法（统计模型、监督学习）** 严重依赖特定地点的数据模式，在新场景（新地点）下性能显著下降。
- **现有大语言模型应用** 缺乏对交通领域的**领域知识适配**和**视觉上下文理解**，无法进行真正的情境感知推理。

### 二、 核心创新点
论文的核心创新在于提出了 **PedX-LLM** 框架，实现了三大创新融合：

1.  **范式创新**：将行人过街行为推断从 **“特定地点的数值模式拟合”** 转变为 **“可泛化的语义行为推理”**。这是研究范式的根本转变。
2.  **架构创新**：构建了 **“视觉-知识-语言”多模态增强框架**。
    - **视觉增强**：集成 **LLaVA** 提取的视觉特征，使模型能“看到”并理解**建成环境**（如道路结构、交通设施）。
    - **知识增强**：注入**交通领域知识**，使模型具备人类专家的决策逻辑和常识。
    - **模型适配**：基于 **LLaMA-2-7B** 基座模型，采用高效的 **LoRA** 技术进行微调，实现领域专业化。
3.  **性能与泛化能力创新**：
    - **性能**：在已知场景达到 **82.0%** 的平衡准确率，超越传统最佳方法。
    - **泛化**：通过**跨地点验证**证明其强大泛化能力。**零样本**设置下在5个未见地点达到 **66.9%** 的准确率，大幅领先基线方法（至少**18个百分点**）；**少量样本**学习后，准确率进一步提升至 **72.2%**。

### 三、 解决方案（How）
论文通过一个系统性的技术框架解决问题：

1.  **输入融合**：
    ```python
    # 概念化输入表示
    模型输入 = 文本化场景描述 + LLaVA提取的视觉特征 + 结构化领域知识
    ```
2.  **模型构建与训练**：
    - **基座模型**：选用强大的开源LLM——LLaMA-2-7B。
    - **高效微调**：采用 **LoRA**，仅训练少量参数，在保持通用能力的同时注入领域特性。
    - **训练目标**：使模型学会结合视觉场景和领域知识，像人类一样进行过街决策推理。
3.  **评估策略**：
    - **性能评估**：对比统计模型、监督学习基线。
    - **泛化评估**：采用**基于地点的数据划分**进行跨站点验证，严格模拟真实世界的新场景应用。
    - **消融实验**：量化评估**视觉模块**（贡献+2.9%）和**领域知识**（贡献+4.1%）各自的价值。

### 四、 实际价值与意义
- **技术价值**：为行为推理任务提供了一个可复用的**多模态LLM增强框架模板**，证明了“视觉+知识”双增强路径的有效性。
- **应用价值**：显著提升了自动驾驶系统、交通仿真、智慧城市管理中**行人行为预测的可靠性和泛化能力**，使其更贴近人类真实决策逻辑，减少对大量地点特定数据的依赖。
- **方法论价值**：展示了如何将通用大模型通过领域适配，转化为强大的**领域专家系统**，为其他垂直领域（如医疗、金融）的AI应用提供了借鉴。

**总结**：该论文的核心是创造性地利用**视觉与知识双引擎**来增强大语言模型，使其摆脱数据驱动的模式记忆，获得**类人的、可泛化的情境推理能力**，从而从根本上解决了行人过街行为预测在新场景中失效的难题。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: ## 论文总结

本文针对现有行人过街行为推断方法（如统计模型与监督学习）泛化能力不足、难以适应新场景的问题，提出了一种融合视觉与领域知识增强的大语言模型框架（PedX-LLM），旨在将行为推断从基于特定场景的模式识别提升为可泛化的语义推理。其核心方法是通过LLaVA提取视觉特征，结合文本数据与交通领域知识，并基于LoRA对LLaMA-2-7B进行微调，以实现对行人过街决策的推理。实验表明，该模型在平衡准确率上达到82.0%，显著优于传统方法；其视觉与知识模块分别带来2.9%与4.1%的性能提升，且在跨场景零样本测试中取得66.9%的准确率，通过少量样本学习可进一步提升至72.2%，证实了该方法通过模仿人类决策逻辑，有效提升了模型对未知场景的泛化能力。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文创新点分析

本文提出的 **PedX-LLM** 框架在行人过街行为推断领域引入了多项明确创新，旨在解决现有方法泛化性差、缺乏语义理解和环境感知能力等核心问题。以下逐条列出其创新点、改进之处及带来的优势：

- **创新点一：提出“视觉-知识增强”的多模态大语言模型框架**
  - **相比以往方法的改进/不同之处**：
    - **以往方法**：传统方法主要分为两类：1) 基于统计模型（如逻辑回归）或纯数据驱动的监督学习模型，这些方法本质上是“数值模式拟合”，严重依赖特定地点的数据分布，缺乏对场景语义和上下文的理解；2) 近期尝试使用通用大语言模型（LLMs）进行行为推理，但缺乏对交通领域的专门适配，且**完全缺失对视觉环境信息的整合**。
    - **本文方法**：首次构建了一个**融合视觉特征、文本数据和领域知识**的专用LLM框架。它利用**LLaVA**从图像中提取视觉特征（捕捉建筑环境、道路结构等），与文本化的事件描述结合，并注入交通领域知识，共同作为模型的输入。
  - **解决的具体问题/带来的优势**：
    - **解决了“缺乏视觉上下文”的问题**：纯文本LLM或传统数值模型无法“看到”行人决策时所处的具体物理环境（如斑马线位置、车流状况、道路宽度）。视觉模块的引入使模型能感知这些关键环境因素。
    - **实现了从“模式识别”到“行为推理”的范式转变**：模型不再仅仅拟合数据中的统计相关性，而是能够结合视觉场景和领域知识进行类似人类的、基于语义和上下文的推理。

- **创新点二：采用领域适配的、高效的模型微调策略**
  - **相比以往方法的改进/不同之处**：
    - **以往方法**：直接应用通用LLM（如GPT系列）进行零样本或少样本推理，缺乏针对行人过街这一垂直领域的参数优化，导致领域理解深度不足。
    - **本文方法**：以 **LLaMA-2-7B** 为基础模型，采用 **低秩适配（LoRA）** 技术进行微调。LoRA是一种参数高效的微调方法，只训练少量的低秩矩阵，而非整个庞大的模型参数。
  - **解决的具体问题/带来的优势**：
    - **解决了“领域特异性不足”的问题**：通过对基础LLM进行领域微调，使模型深入理解交通行为相关的概念、规则和因果关系，而不仅仅是表面语言模式。
    - **带来了“高效率与可及性”的优势**：使用LoRA大幅降低了计算成本和微调所需的数据量，使得在专业领域构建和部署增强型LLM变得更加可行。

- **创新点三：系统性验证了模型在跨场景下的强泛化能力**
  - **相比以往方法的改进/不同之处**：
    - **以往方法**：现有统计或监督学习方法通常在训练集所在站点表现良好，但在**未见过的全新站点（unseen sites）** 上性能急剧下降，因为它们学习到的是站点特有的、表面的数据模式。
    - **本文方法**：论文设计了严格的**跨站点验证（cross-site validation）**，将数据按站点划分，确保训练和测试站点完全独立。并评估了模型的**零样本（zero-shot）** 和**少样本（few-shot）** 泛化性能。
  - **解决的具体问题/带来的优势**：
    - **直接攻克了“泛化性差”这一核心痛点**：实验证明，PedX-LLM在五个未见测试站点上的零样本平衡准确率达到66.9%，远超基线数据驱动方法至少18个百分点。仅添加5个示例进行少样本学习后，准确率进一步提升至72.2%。
    - **优势**：这表明模型学会了可迁移的“行为推理逻辑”，而非记忆特定地点的数据特征，使其能够应用于新的、数据稀缺的交通场景，降低了部署中对大量标注数据的依赖。

- **创新点四：量化评估了各增强模块的贡献**
  - **相比以往方法的改进/不同之处**：
    - **以往方法**：大多数研究仅报告整体性能，很少清晰剥离并量化“视觉信息”和“领域知识”各自对最终性能的贡献度。
    - **本文方法**：通过消融实验明确量化：1) **视觉增强模块**带来了**2.9%** 的性能提升；2) **整合领域知识**带来了额外的**4.1%** 的性能提升。
  - **解决的具体问题/带来的优势**：
    - **解决了“模块贡献不明确”的问题**：提供了确凿证据，证明视觉上下文和领域知识对于实现高性能、可泛化的行为推理都是**必要且有效的**，而非简单的装饰。
    - **优势**：为后续研究指明了方向，强调了在行为建模中融合多模态信息和先验知识的重要性。

**总结**：本文的核心创新在于**构建并验证了一个通过视觉和知识增强来实现可泛化语义推理的新范式**。它不同于以往任何基于数值拟合或通用LLM的方法，通过**多模态输入（视觉+文本）、领域知识注入、参数高效微调**，最终解决了行人过街行为推断中长期存在的**场景泛化能力弱**的根本问题，为交通行为分析、自动驾驶系统感知预测等领域提供了更可靠、更拟人的决策推理工具。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 论文实验与评估效果分析

### 1. 主要实验效果
论文提出的 **PedX-LLM** 模型在行人过街行为推理任务中实现了显著的性能提升和泛化能力，具体效果如下：

- **整体性能**：在主要实验中，PedX-LLM 实现了 **82.0%** 的平衡准确率（Balanced Accuracy）。
- **泛化能力**：在未见过的测试场景中，零样本（Zero-shot）配置下达到 **66.9%** 的平衡准确率；通过少量样本（Few-shot，仅5个验证示例）学习后，性能进一步提升至 **72.2%**。

### 2. 数据集与评价指标
- **数据集**：  
  论文使用了 **多站点行人过街行为数据集**（具体名称未明确给出，但提及了“site-based partitioning”和“five unseen test sites”），数据包含视觉信息（如街景）和文本信息（如交通场景描述）。
- **评价指标**：  
  主要使用 **平衡准确率（Balanced Accuracy）**，适用于类别不平衡的数据评估。

### 3. 基线方法对比
论文将 PedX-LLM 与以下两类基线方法进行对比：
- **传统统计模型**：基于数值模式拟合的经典方法。
- **监督学习方法**：基于数据驱动的机器学习模型（如分类模型）。

### 4. 关键性能提升与结论
- **性能优势**：  
  PedX-LLM（82.0%）显著优于最佳统计方法和监督学习方法（具体数值未给出，但强调“outperforming”）。
- **模块贡献分析**：  
  - **视觉增强模块**：带来 **2.9%** 的性能提升，通过捕捉建筑环境信息增强上下文理解。  
  - **领域知识集成**：带来 **4.1%** 的额外提升，通过注入交通领域知识优化推理逻辑。
- **泛化能力结论**：  
  - 在五个未见测试站点上，PedX-LLM 的零样本性能（66.9%）比基线数据驱动方法 **至少高出18个百分点**。  
  - 结果表明，**视觉与知识增强的推理机制**使模型能够模拟人类决策逻辑，克服纯数据驱动方法的局限性，实现强泛化能力。

### 5. 技术实现要点
```python
# 模型框架核心组件示意
1. 视觉特征提取：LLaVA 模型处理街景图像
2. 文本与知识融合：交通领域知识库 + 场景文本描述
3. 基础模型微调：LLaMA-2-7B + LoRA（低秩适配）
4. 输出：行人过街决策（如“穿越”或“等待”）
```

**总结**：论文通过定量实验验证了 PedX-LLM 在准确率和泛化性上的显著优势，强调了 **视觉上下文** 与 **领域知识** 在提升 LLM 行为推理能力中的关键作用。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2601.00694v1)
- [HTML 版本](https://arxiv.org/html/2601.00694v1)
