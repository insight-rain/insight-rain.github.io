# Falcon-H1R: Pushing the Reasoning Frontiers with a Hybrid Model for Efficient Test-Time Scaling

**相关性评分**: 6.0/10

**排名**: #70


---


## 基本信息

- **arXiv ID**: [2601.02346v1](https://arxiv.org/abs/2601.02346v1)
- **发布时间**: 2026-01-05T18:44:27Z
- **相关性评分**: 6.0/10
- **是否相关**: 是

## 作者

Falcon LLM Team, Iheb Chaabane, Puneesh Khanna, Suhail Mohmad, Slim Frikha, Shi Hu, Abdalgader Abubaker, Reda Alami, Mikhail Lubinets, Mohamed El Amine Seddik, Hakim Hacid

## 关键词

Inference Efficiency, Lightweight Architecture, Inference Acceleration, Edge Deployment

## 一句话总结

Falcon-H1R是一个7B参数的推理优化模型，通过混合并行架构设计实现高效推理，适用于轻量级架构和边缘部署场景。

## 摘要

This work introduces Falcon-H1R, a 7B-parameter reasoning-optimized model that establishes the feasibility of achieving competitive reasoning performance with small language models (SLMs). Falcon-H1R stands out for its parameter efficiency, consistently matching or outperforming SOTA reasoning models that are $2\times$ to $7\times$ larger across a variety of reasoning-intensive benchmarks. These results underscore the importance of careful data curation and targeted training strategies (via both efficient SFT and RL scaling) in delivering significant performance gains without increasing model size. Furthermore, Falcon-H1R advances the 3D limits of reasoning efficiency by combining faster inference (through its hybrid-parallel architecture design), token efficiency, and higher accuracy. This unique blend makes Falcon-H1R-7B a practical backbone for scaling advanced reasoning systems, particularly in scenarios requiring extensive chain-of-thoughts generation and parallel test-time scaling. Leveraging the recently introduced DeepConf approach, Falcon-H1R achieves state-of-the-art test-time scaling efficiency, offering substantial improvements in both accuracy and computational cost. As a result, Falcon-H1R demonstrates that compact models, through targeted model training and architectural choices, can deliver robust and scalable reasoning performance.

## 详细分析

## 论文摘要：Falcon-H1R: 通过混合模型实现高效测试时扩展，推动推理前沿

### 1. 研究背景和动机
随着大型语言模型（LLMs）在复杂推理任务上取得显著进展，提升模型能力的传统路径（如扩大训练规模）正面临计算成本高昂和高质量数据有限的瓶颈。因此，**测试时扩展**（Test-Time Scaling, TTS）——即在推理阶段投入更多计算资源以激发模型潜在能力——成为一个新兴且关键的范式。然而，TTS（如并行生成多条推理链）通常伴随着高昂的推理开销。本研究旨在探索一个核心问题：**能否通过精心的模型设计、数据筛选和训练策略，构建一个参数高效的小型语言模型（SLM），使其在保持高推理精度的同时，大幅提升TTS的效率？** Falcon-H1R正是为此目标而生。

### 2. 核心方法和技术创新
Falcon-H1R是一个拥有**70亿参数**的推理优化模型，其核心创新体现在**架构**、**训练策略**和**效率优化**三个维度：
- **混合并行架构**：基于Falcon-H1系列，采用**Transformer与Mamba（状态空间模型）的混合设计**。这种架构在长序列、大批次场景下具有卓越的推理吞吐量和内存效率，为并行TTS技术提供了理想的骨干网络。
- **鲁棒的两阶段训练策略**：
    1.  **监督微调阶段**：采用“冷启动”SFT，使用经过严格筛选的数学、代码、科学等领域的长链思维数据。关键发现包括：使用**更大的学习率**、为难题**增加数据权重**、以及采用**数学主导的数据混合**策略能最有效地提升跨领域推理能力。
    2.  **强化学习阶段**：采用基于GRPO的RLVR方法进一步优化。通过**在线采样**、**移除KL惩罚项**以鼓励探索、以及**针对数学领域进行专项训练**等策略，在提升单次通过率（pass@1）的同时，保持了模型的探索多样性。
- **系统性效率优化**：
    - **训练端**：引入了**数据并行平衡令牌归一化**，解决了长、短序列混合训练时的梯度偏差问题，稳定了训练并提升了性能。
    - **推理端**：模型本身的高效架构，结合先进的TTS方法**DeepConf**（一种基于置信度动态剪枝弱推理链的技术），实现了在相同计算预算下运行更多并行链或提前终止，显著降低了token消耗。

### 3. 主要实验结果
Falcon-H1R-7B在多个推理密集型基准测试中展现了卓越的性能和效率：
- **标准推理性能**：在仅70亿参数下，其表现**匹配甚至超越了参数量2到7倍于它的先进模型**（如Phi-4-Reasoning-Plus-14B, GPT-OSS-20B, Qwen3-32B）。例如，在AIME24上达到88.1%，在AMO-Bench上达到36.3%，均位列前茅。
- **测试时扩展效率**：当集成DeepConf方法进行TTS时，Falcon-H1R在**精度和token效率上均实现领先**。例如，在AIME25上，它以**96.7%的准确率**，相比DeepSeek-R1-0528-Qwen3-8B**减少了38%的token使用量**，实现了更高的准确率和更低的计算成本。
- **安全评估**：模型在最终答案输出上表现出强大的安全对齐能力（安全评分加权平均98.19%）。其思维链（CoT）与最终答案之间的安全性差距，反映了模型在推理过程中对有害内容进行审慎评估的自然过程。

### 4. 研究意义和价值
本工作的价值在于：
- **证明了小型语言模型的巨大潜力**：Falcon-H1R成功表明，通过**针对性的架构设计、精细的数据工程和训练策略**，紧凑的模型同样可以实现顶尖的推理性能，挑战了“更大即更好”的固有观念。
- **重新定义了推理效率的边界**：该模型在**精度、token效率和推理速度**三个维度上同时推进了极限，为需要大规模并行推理链的实际应用（如复杂问题求解、代码生成）提供了一个**高效且实用的基础模型**。
- **为高效测试时扩展树立了标杆**：研究展示了如何将高效的基座模型与先进的TTS方法（如DeepConf）相结合，在提升性能的同时严格控制计算开销，为未来可扩展推理系统的开发提供了重要蓝本。

## 问答对

### 问题 1

**Q**: 这篇论文的核心创新点是什么，他想解决什么问题，怎么解决的？

**A**: ## 论文核心分析：Falcon-H1R

### **核心问题**
论文旨在解决一个关键矛盾：**如何在保持模型参数规模较小（7B）的同时，实现与大型模型（8B-32B）相竞争甚至更优的复杂推理性能，并显著降低推理成本**。这直接挑战了“模型能力必须随参数规模增长”的传统观念。

### **核心创新点**

#### 1. **架构创新：混合并行架构**
- **技术内容**： 采用 **Transformer-Mamba 混合架构**（Falcon-H1 系列）。该架构结合了Transformer的强注意力机制和Mamba状态空间模型的高效序列建模能力。
- **解决什么问题**： 传统Transformer在长序列、大批量推理（如测试时扩展）时计算和内存开销巨大。混合架构旨在实现：
    - **更高的推理吞吐量**： 在长序列（16K-32K tokens）和大批量（最高128）下，推理速度比纯Transformer基线（如Qwen3-8B）快 **20% 到 100%**。
    - **更低的内存占用**： 支持更长的上下文（训练达48K，推理达256K），更适合生成长链思维。
- **实际价值**： 为需要并行生成大量推理链的**测试时扩展**方法提供了高效的硬件基础，直接降低了部署成本。

#### 2. **训练策略创新：数据与流程优化**
- **技术内容**： 设计了一套精细的、两阶段训练流程（监督微调 + 强化学习），并围绕数据进行了深度优化。
    - **SFT阶段**：
        - **数据筛选**： 严格筛选数学、代码、科学领域的高质量、长链思维数据，强调难题。
        - **关键发现**： 采用**高学习率**、**高rollout数量**、**数学主导的数据混合**（数学技能向其他领域迁移效果最好）、**单教师模型**效果更佳。
        - **训练优化**： 引入**数据并行平衡令牌归一化**，解决了长/短序列混合训练时的梯度偏差问题，显著提升下游性能（+4-10%）。
    - **RL阶段**：
        - **算法改进**： 基于GRPO进行定制，移除KL惩罚项以鼓励探索，加入截断重要性采样和正样本交叉熵损失以稳定训练。
        - **数据与课程**： 使用与SFT**完全独立**的数据集，并按难度过滤。最终采用**纯数学领域**的RL训练，发现其对泛化能力提升最有效。
- **解决什么问题**： 传统训练方法在小型模型上难以激发出顶尖的推理能力。本文通过数据质量、混合策略和训练稳定性的极致优化，在7B模型上“压榨”出了超越其参数规模的性能。
- **实际价值**： 提供了一套可复现的高效训练“配方”，证明了通过精心设计的训练（而非单纯堆参数）可以极大提升小模型的推理上限。

#### 3. **效率与性能的协同创新：专为测试时扩展优化**
- **技术内容**： 将高效架构与强推理基座模型结合，并集成先进的测试时扩展方法 **DeepConf**。
    - **DeepConf集成**： 利用模型自身的置信度对并行生成的推理链进行动态剪枝（早停），淘汰低质量思路。
    - **三维优势**： Falcon-H1R 在 **准确率、令牌效率、推理速度** 三个维度上同时推进边界。
- **解决什么问题**： 测试时扩展（如自洽性采样）虽然能提升精度，但会成倍增加计算和token消耗，成本高昂。
- **实际价值**：
    - **更高精度，更低消耗**： 在AIME25上，Falcon-H1R-7B达到96.7%准确率，同时比DeepSeek-R1-8B**少用38%的tokens**。
    - **成为TTS的理想骨干**： 其高速、低内存的特性允许在相同计算预算内运行更多并行推理链，从而最大化TTS的收益。

### **解决方案总结**
论文通过一个 **“高效架构 + 精细训练 + TTS友好设计”** 的三位一体方案，成功打造了Falcon-H1R-7B：
1.  **用混合架构解决硬件效率瓶颈**，为大批量推理提速降耗。
2.  **用数据与训练策略解决小模型能力瓶颈**，通过高质量数据、数学主导的课程和稳定的RL训练，激发出卓越的基座推理能力。
3.  **用TTS集成解决精度与成本的最终权衡**，利用模型良好的校准性，在动态剪枝中实现“少花钱，多办事”，最终在多个数学、代码、科学推理基准上达到或超越更大模型的水平。

**最终结论**： Falcon-H1R 的核心贡献在于证明了**小型语言模型通过针对性的架构和训练优化，完全可以成为高效、强大且实用的推理系统核心**，为在资源受限场景下部署高级推理能力开辟了道路。


### 问题 2

**Q**: 请用一段话总结这篇论文，明确说明：论文试图解决的核心问题；提出的主要方法或框架；最终取得的主要效果或结论。要求语言简洁、信息密度高，不要复述摘要原文。

**A**: 这篇论文旨在解决**小型语言模型（SLMs）在复杂推理任务上性能不足，以及测试时扩展（TTS）方法计算成本高昂**的核心问题。为此，论文提出了**Falcon-H1R-7B模型**，其核心方法包括：1）采用**混合Transformer-Mamba架构**以实现高效并行推理；2）设计了一套**两阶段训练策略**，即通过精心筛选的、以数学为主的长链思维数据进行监督微调，再结合GRPO强化学习方法进行优化。最终，该模型在多项数学、代码和通用推理基准测试中，**以仅7B的参数量，达到或超越了参数量为其2至7倍的先进模型性能**，同时在与DeepConf等TTS方法结合时，展现出**更高的准确率、更低的令牌消耗和更快的推理速度**，证明了通过针对性训练和架构设计，小型模型也能实现强大且可扩展的推理能力。


### 问题 3

**Q**: 这篇论文相对于已有工作有哪些明确的创新点？请逐条列出，并对每一条说明：相比以往方法改进或不同之处在哪里，以及该创新解决了什么具体问题或带来了什么优势。

**A**: ## 论文创新点分析

这篇论文《Falcon-H1R: Pushing the Reasoning Frontiers with a Hybrid Model for Efficient Test-Time Scaling》在小型语言模型（SLM）的高效推理领域提出了多项明确的技术创新。其核心目标是证明，通过精心设计的架构、训练策略和推理优化，小模型（7B参数）可以在复杂推理任务上达到甚至超越更大模型（14B-47B）的性能，同时显著提升计算效率。

以下是其主要的创新点，以及它们相对于已有工作的改进和带来的具体优势：

---

### 1. **创新的混合架构：Transformer-Mamba 并行混合设计**
- **改进/不同之处**：
    - 大多数高性能推理模型（如GPT系列、Qwen等）主要基于纯Transformer架构。虽然已有一些混合架构（如Jamba、Mamba）探索了状态空间模型（SSM）以提升效率，但Falcon-H1R采用了**并行混合设计**（Parallel Hybrid Transformer-Mamba），将Transformer的注意力机制和Mamba的SSM机制在同一个块中并行处理，而非顺序串联。
    - 论文明确指出其架构源自Falcon-H1系列，并针对推理吞吐量和内存效率进行了优化，特别适合**长序列**和**大批次**场景。
- **解决的问题/带来的优势**：
    - **解决了**：传统Transformer在长序列、大批次推理时计算和内存开销巨大的问题，尤其是在需要并行生成多条思维链（Test-Time Scaling）的场景下。
    - **优势**：如附录B所示，该架构在中等至大批次（BS=16-128）和长输出（16K-32K tokens）场景下，推理吞吐量比纯Transformer模型（Qwen3-8B）**高出20%到100%**。这直接降低了部署成本，并使大规模并行思维链生成（TTS）变得经济可行。

### 2. **针对推理优化的两阶段训练策略：数据筛选与课程学习**
- **改进/不同之处**：
    - **监督微调（SFT）阶段**：
        - **数据筛选**：采用了**难度感知加权**策略。对困难问题（低通过率、长推理轨迹）进行上采样（1.25x-1.75x），对简单问题进行降采样甚至剔除。这与以往SFT通常平等对待所有数据或仅基于质量过滤的做法不同。
        - **数据构成**：发现并采用了**数学主导的混合数据**。实验表明，数学推理能力能更好地迁移到代码、科学等其他领域，反之则不然。因此最终SFT数据混合以数学为主，辅以适量代码和科学数据。
        - **训练优化**：引入了**数据并行平衡令牌归一化**技术，解决了在数据并行训练中，由于样本长度差异巨大（从短指令到超长思维链）导致的梯度噪声和不稳定问题。
    - **强化学习（RL）阶段**：
        - **采用GRPO而非PPO**：使用Group Relative Policy Optimization，这是一种专为具有可验证奖励（如数学答案正确性）的任务设计的RL算法。
        - **定制化改进**：对标准GRPO进行了多项改进，包括：移除KL惩罚项（`β=0`）以鼓励更多探索；采用**截断重要性采样（TIS）** 以减少训练与推理的偏差；为正确样本添加**交叉熵损失**以加速收敛；实施**在线采样与缓存**策略，高效处理零优势样本，减少30%的生成调用浪费。
- **解决的问题/带来的优势**：
    - **解决了**：
        1.  SFT阶段数据质量参差不齐和训练不稳定的问题。
        2.  RL阶段训练效率低、探索不足以及容易陷入局部最优的问题。
        3.  小模型在复杂、多步推理任务上能力不足的普遍瓶颈。
    - **优势**：
        1.  训练更稳定、收敛更快，模型能更有效地从高质量、高难度的数据中学习。
        2.  RL阶段能更高效地探索解决方案空间，显著提升模型在**单次通过（pass@1）** 上的性能。
        3.  最终使一个7B模型在多项数学（如AIME24: 88.1%）、代码（LiveCodeBench v6: 68.6%）和通用推理基准上，**达到或超越了参数量2-7倍于己的SOTA模型**（见表4-6），证明了“小模型也能强推理”。

### 3. **与高效测试时扩展（TTS）方法的深度集成与验证**
- **改进/不同之处**：
    - 论文不仅将Falcon-H1R作为一个独立的推理模型来评估，更将其定位为**高效TTS的“骨干网络”**。
    - 系统性地评估了模型在**DeepConf**这一先进的TTS方法下的表现。DeepConf能根据模型自身的置信度动态剪枝低质量的并行推理链，实现早期停止。
    - 在评估中，不仅关注最终准确率，还**精确测量了生成的总令牌数**，作为计算成本的核心指标。
- **解决的问题/带来的优势**：
    - **解决了**：TTS方法（如自洽性、多数投票）通常计算成本高昂的问题，因为需要生成和评估大量候选链。
    - **优势**：如表7所示，Falcon-H1R-7B在使用DeepConf@512设置时，在达到最高或接近最高准确率的同时，**生成的令牌数远少于其他竞品模型**。例如，在AIME25上达到96.7%准确率，比DeepSeek-R1-8B少用38%的令牌。这得益于：
        1.  **强大的基础模型**：单次推理准确率高，需要并行探索的链相对更少。
        2.  **良好的置信度校准**：模型对自身推理过程的置信度估计准确，使得DeepConf的早期停止机制能更激进地剪枝，而不损失精度。
        3.  **高效的架构**：如前所述，混合架构本身的高吞吐量进一步放大了TTS的效率优势。

### 4. **系统性揭示并利用了“数学推理能力具有最佳迁移性”的发现**
- **改进/不同之处**：
    - 这不是一个单一的技术模块，而是一个贯穿数据混合、训练课程设计的**核心洞察**。论文通过详尽的消融实验（第2.2、3.3节）明确验证了：在SFT和RL阶段，**以数学数据为主导的训练策略，其效果优于均衡混合或代码主导的策略**。
    - 这一发现为如何高效构建通用推理模型提供了新的、经验性的指导原则。
- **解决的问题/带来的优势**：
    - **解决了**：在多领域推理模型训练中，如何分配有限的数据和计算资源以达到最佳综合性能的难题。
    - **优势**：为社区提供了明确的训练策略指引——**优先提升数学推理能力**，可以更经济、更有效地带动模型整体推理水平的提升。这解释了为何Falcon-H1R作为一个7B模型，能在数学、代码、科学等多个需要严谨逻辑的领域都表现出色。

### 5. **对推理模型安全性的细致评估框架**
- **改进/不同之处**：
    - 论文在附录E中提出了一个**细粒度的安全评估框架**，将模型输出分解为**仅思维链（CoT Only）**、**仅最终答案（Answer Only）** 和**两者结合（CoT+Answer）** 三种模式进行评估。
    - 这超越了大多数工作仅评估最终答案安全性的做法。
- **解决的问题/带来的优势**：
    - **解决了**：对于具备复杂推理能力的模型，其安全性风险可能隐藏在思维过程中，而仅看最终答案无法全面评估的问题。
    - **优势**：
        1.  提供了更全面的安全画像。论文发现，模型在思维链阶段的安全得分（92.60%）确实低于最终答案阶段（98.19%），这被认为是**模型在进行深度安全推理时的自然现象**（例如，在思维中分析某个请求为何有害），而非安全漏洞。
        2.  这一发现对**实际部署具有重要指导意义**：提示开发者，向终端用户公开原始思维链可能需要谨慎，因为其中可能包含对有害内容的分析过程。更好的做法可能是仅展示最终的安全答案，而将思维链保留用于内部审计和调试。

---

## 总结

Falcon-H1R的核心创新在于一个**协同优化的系统**：它通过**创新的混合架构**提供了效率基础，通过**数据与算法驱动的训练策略**（特别是数学主导的课程学习和改进的GRPO）极大提升了小模型的内在推理能力，再通过与**前沿TTS技术（DeepConf）的深度适配**，将这种能力以极低的计算成本在推理时放大。最终，它在**准确性、令牌效率和推理速度这三个维度**上同时推进了边界，证明了小型语言模型在复杂推理任务上不仅可行，而且可以兼具高性能与高性价比，为实际部署提供了极具吸引力的解决方案。


### 问题 4

**Q**: 论文在实验或评估中最终实现了怎样的效果？请说明使用了哪些数据集和评价指标，与哪些基线方法进行了对比，以及在关键指标上的主要性能提升或结论。如果论文未给出明确的定量结果，也请说明原因。

**A**: ## 论文实验与评估效果总结

### 一、 核心评估效果
**Falcon-H1R-7B** 作为一个仅 **7B 参数** 的小型语言模型，在多项推理密集型基准测试中，其性能**匹配甚至超越了参数规模大2至7倍（14B-47B）的当前最先进模型**。这证明了通过精心设计的数据策略、训练方法和混合架构，小型模型也能实现顶尖的推理能力。

### 二、 使用的数据集与评价指标

#### 1. 标准推理任务评估
**评估基准（三大类）：**
*   **数学推理：**
    *   **AIME24/25**：美国数学邀请赛试题。
    *   **HMMT25**：哈佛-麻省理工数学锦标赛试题。
    *   **AMO-Bench**：高级数学奥林匹克级别难题。
    *   **MATH500**：MATH数据集中精选的中高难度竞赛题。
*   **代码生成：**
    *   **LiveCodeBench v6 (LCB v6)**：来自LeetCode等的编程场景。
    *   **SciCode**：科学代码生成与推理。
    *   **τ²-Telecom**：电信领域智能体任务执行。
    *   **Terminal Bench Hard (TB Hard)**：命令行环境多步规划。
*   **通用推理：**
    *   **GPQA-Diamond**：研究生级别的科学问答。
    *   **MMLU-Pro**：进阶版多任务语言理解。
    *   **Humanity’s Last Exam (HLE)**：跨STEM和人文的极难推理题。
    *   **IFBench**：精确的指令遵循与格式合规性测试。

**核心评价指标：**
*   **Pass@1**：在指定采样参数（温度、top-p）下，单次生成答案的正确率。这是评估基础模型推理能力的核心指标。

#### 2. 测试时扩展评估
*   **方法：** 采用 **DeepConf@512** 方法进行高效的并行推理链生成与动态剪枝。
*   **评估维度：**
    *   **准确率 (Acc. ↑)**：经过投票聚合后的最终答案正确率。
    *   **生成令牌数 (Tok. ↓)**：为达到该准确率所消耗的总令牌数，衡量**计算效率**。
*   **测试集：** AIME24, AIME25, GPQA-Diamond, AMO-Bench (解析可验证子集)。

#### 3. 安全性评估
*   **基准：** JailbreakBench, ALERT, WildGuard (AllenAI), WalledEval, SALAD Bench。
*   **指标：** 使用 **Llama-Guard-3-8B** 分类器评估在 **仅推理链(CoT Only)**、**仅答案(Answer Only)** 和 **两者结合(CoT+Answer)** 三种模式下的安全通过率。

### 三、 对比的基线方法
论文与多个SOTA模型进行了全面对比，覆盖了7B到47B参数范围：
*   **7B-8B 级别：** Qwen3-8B, DeepSeek-R1-0528-Qwen3-8B
*   **14B-20B 级别：** Phi-4-Reasoning-Plus-14B, Apriel-1.5-15b-Thinker, GPT-OSS-20B
*   **32B+ 级别：** Qwen3-32B, Nemotron-H-47B-Reasoning

### 四、 关键性能提升与结论

#### 1. 标准推理任务性能（核心结论）
Falcon-H1R-7B 在多个关键基准上达到了领先或顶尖水平：

| 模型 | AIME24 | AIME25 | HMMT25 | AMO-Bench | LCB v6 | GPQA-D | HLE | IFBench |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **Falcon-H1R-7B** | **88.1%** | 83.1% | **64.9%** | **36.3%** | 68.6% | 61.3% | 11.1 | 53.4 |
| GPT-OSS-20B | 83.3% | **84.4%** | 64.8% | 26.0% | **72.0%** | 61.2% | 9.8 | **69.4** |
| Qwen3-32B | 79.4% | 71.0% | 49.8% | 21.3% | 61.0% | 67.3% | 8.3 | 35.4 |

*   **数学推理：** 在 **AMO-Bench**（最高难度）上以 **36.3%** 的准确率大幅领先第二名GPT-OSS-20B（26.0%）超过10个百分点，展示了处理极难问题的卓越能力。
*   **代码生成：** 在 **LCB v6** 上以 **68.6%** 位列第二，仅次于GPT-OSS-20B，显著优于同尺寸模型。
*   **结论：** 证明了**小型模型通过针对性训练可以实现与大型模型相媲美的推理性能**。

#### 2. 测试时扩展效率（核心创新）
在 **DeepConf@512** 设置下，Falcon-H1R 展现了**卓越的“准确性-效率”权衡**：

| 模型 | AIME25 准确率 | AIME25 令牌消耗 (M) | 相对 DeepSeek-R1-8B 令牌节省 |
| :--- | :--- | :--- | :--- |
| **Falcon-H1R-7B** | **96.7%** | **95.1** | **~38%** |
| DeepSeek-R1-8B | 82.8% | 174.5 | - |
| Qwen3-32B | 86.7% | 174.8 | - |

*   **更高准确率，更低消耗：** 在AIME25上达到了 **96.7%** 的惊人准确率，同时消耗的令牌数（**95.1M**）远低于所有对比模型。
*   **三维效率优势：** 论文强调 Falcon-H1R 推动了推理效率的“3D极限”：**更高的准确率、更高的令牌效率（生成更少token）、更快的推理速度（得益于混合架构）**。这使其成为需要大规模并行思维链生成的**测试时扩展的理想骨干模型**。

#### 3. 安全性评估结果
*   **最终答案安全性高：** 在 **Answer Only** 模式下，加权平均安全通过率达到 **98.19%**，表明模型能可靠地输出安全的最终答复。
*   **推理过程更具探索性：** 在 **CoT Only** 模式下，安全通过率为 **92.60%**。这被解释为模型在思考过程中会深入分析（甚至触及）有害内容以做出正确判断，是**深思熟虑过程的自然体现，而非安全缺陷**。这为部署提供了重要见解：推理链适合内部审计，而最终答案适合直接呈现给用户。

### 总结
论文通过详实的实验证明，**Falcon-H1R-7B 不仅在静态推理基准上媲美大模型，更在动态、计算密集的测试时扩展场景中，实现了准确性与计算效率的双重突破**。其成功归因于**高质量的数学主导数据混合、两阶段（SFT+RL）针对性训练、以及Transformer-Mamba混合架构带来的高效推理能力**。这项工作为开发高效、实用且强大的小型推理模型提供了明确的路径和有力的实证。


## 相关链接

- [arXiv 页面](https://arxiv.org/abs/2601.02346v1)
- [HTML 版本](https://arxiv.org/html/2601.02346v1)
